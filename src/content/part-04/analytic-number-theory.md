# Analytic Number Theory

332

Cohen, H. 1993.ber Theory. New York: Springer. A Course in Computational Algebraic Num Ireland, K., and M. Rosen. 1982.Modern Number Theory, 2 nd edn. New York: Springer. A Classical Introduction to Serre, J.-P. 1973. A Course in Arithmetic. New York: Springer. Technical Articles and Books Baker, A. 1971. Imaginary quadratic fields with class num-ber 2. Annals of Mathematics (2) 94:139–52. Brauer, R. 1950. On the Zeta-function of algebraic number fields. I. American Journal of Mathematics 69:243–50. Brauer, R. 1950. On the Zeta-function of algebraic number fields. II.
American Journal of Mathematics 72:739–46. Goldfeld, D. 1985. Gauss’s class number problem for imagi-nary quadratic fields. Bulletin of the American Mathemat Granville, A., and G. Martin. 2006. Prime number races.ical Society American Mathematical Monthly13:23–37. 113:1–33. Gross, B., and D. Zagier. 1986. Heegner points and deriva-tives of L-series. Inventiones Mathematicae84:225–320. Heegner, K. 1952. Diophantische Analysis und Mod ulf unk-tionen. Mathematische Zeitschrift 56:227–53. Hua, L.-K. 1942.
On the least solution of Pell’s equation. Bulletin of the American Mathematical Society 48:731–35. Lang, S. 1970.Addison-Wesley. Algebraic Number Theory. Reading, MA: Narkiewicz, W. 1973.Scientific Publishers. Algebraic Numbers. Warsaw: Polish Siegel, C. L. 1935. Über die Classenzahl quadratischer Zahlörper. Acta Arithmetica 1:83–86. Stark, H. 1967. A complete determination of the complex quadratic fields of class-number one. Michigan Mathematical Journal 14:1–27. IV.2 Analytic Number Theory

Andrew Granville

1 Introduction

What is number theory? One might have thought that it was simply the study of numbers, but that is too broada definition, since numbers are almost ubiquitous in mathematics. To see what distinguishes number theory from the rest of mathematics, let us look at the equationx2 + y2 = 15 925, and consider whether it has any solutions. One answer is that it certainly does: indeed, the solution set forms a circle of radius$\sqrt{15} 925 \text{in the}$ plane.
However, a number theorist is interested in integer any such solutions exist.solutions, and now it is much less obvious whether is to notice that 15 925 is a multiple of 25: in fact, it is A useful first step in considering the above question

IV. Branches of Mathematics

25 posed further: it is 49. imes  637. Further more, the number 637 can be decom-. imes 13. That is, 15 925 = 52. imes 72. imes 13. This information helps us a lot, because if we can find integers a and b such that a2 + b2 = 13, then we can multiply them by 5 to the original equation. Now we notice that. imes 7 = 35 and we will have a solution a = 2 andb = 3 works, since 22+32 = 13.
Multiplying these num- bers by 35, we obtain the solution 702$+ 105^{2} = 15 925$ to the original equation. As this simple example shows, it is often useful to decompose positive integers multiplicative ly into com-pone nts that cannot be broken down any further. These components are called prime numbers, and the fundamental theorem of arithmetic every positive integer can be written as a product of[V.14](/part-05/the-fundamental-theorem-of-arithmetic) states that primes in exactly one way. That is, there is a one-to-one correspondence between positive integers and finite products of primes.
In many situations we know what we need to know about a positive integer once we have decomposed it into its prime factors and understood those, just as we can understand a lot about moleculesby studying the atoms of which they are composed. For example, it is known that the equation$x^{2} + y^{2} = n has$ an integer solution if and only if every prime of the form4 m+3 occurs an even number of times in the prime fac- tor ization ofno integer solutions to the equationn.
(This tells us, for instance, that there arex2 + y2 = 13 475,$since 13 475$= 52 . imes  72 . imes  11, and 11 appears an odd number of times in this product.)Once one begins the process of determining which integers are primes and which are not, it is soon appar-ent that there are many primes. However, as one goes further and further, the primes seem to consist of a smaller and smaller proportion of the positive integers. They also seem to come in a some what irregular pat-tern, which raises the question of whether there is any formula that describes all of them.
Failing that, can one perhaps describe a large class of them? We can also ask whether there are infinitely many primes. If there are, can we quickly determine how many there are up to a given point? Or at least give a good estimate for this number? Finally, when one has spent long enough looking for primes, one cannot help but ask whether there is a quick way of recognizing them. This last question isdiscussed in computational number theory [IV.3](/part-04/computational-number-theory);
the rest motivate the present article. Now that we have discussed what marks number theory out from the rest of mathematics, we are ready to make a further distinction: between analytic number theory. The main difference is that algebraic and

IV.2. Analytic Number Theory

in algebraic number theory (which is the main topic of algebraic numbers [IV.1](/part-04/number-theory)) one typically considers questions with answers that are given by exact formu-las, where as in analytic number theory, the topic of this article, one looks for sort of quantity that one estimates in analytic num-good approximations. For the ber theory, one does not expect an exact formula to exist, except perhaps one of a rather artificial and unilluminating kind. One of the best examples of such a quantity is one we shall discuss in detail: the number of primes less than or equal tox.
terminology that allows us to give some idea of the quality of an approximation. Suppose, for example, that Since we are discussing approximations, we will need we have a rather erratic functions how that, oncex is large enough, f (x)f (x)but are able tois never big- ger than 25 the functionx2 g(x). This is useful because we understand= x2 quite well. In general, if we can find a constant everyx, then we write cf (x)such that= O(g(x))|f (x). A typical usage| ⩽ cg(x) for occurs in the sentence “the average number of prime factors of an integer up tox is log log x + O(1)”;
in other words, there exists some constant that|the average - log log x| ⩽ c once xis sufficient lyc > 0 such large. We write$f (x) ∼ g(x) \text{if lim} f (x)/g(x) =$1; and also that is, when we want to say thatf (x). pprox  g(x) when we are being a little less precise, x →$\infty$ f (x) and g(x) come close whendo not want to be, more specific about what we meanxis sufficiently large, but we cannot be, or by “come close.” andthe symbol what terms the sum, or product, is to be It is convenient for us to use the notationfor product. Typically we will indicate beneath for sums taken over.
For example, integersm that are greater than or equal to 2, wherea(sm()⩾){2} will be a sum over all will be a product over all primes$p$.pprime

2 Bounds for the Number of Primes

Ancient Greek mathematicians knew that there were infinitely many primes. Their beautiful proof by contradiction goes as follows. Suppose that there are only finitely many primes, say denote byp , p , . . . , p . What are the prime factors ofk of them, which we will pmu st have at least one prime factor, and this must be1 p2 · · · (pk)1+1? Since this number is greater than 1 it2$kpp^{j}$, pfor some, . . . , p j). But then(since all primes are contained amongp divides both p p · · · pandis impossible.1(p2)1 p2 · · ·kpk+1, and hence their difference, 1, which(j1)2 k

333

ally exhibit infinitely many primes: it merely shows that there cannot be finitely many. It is more or less possi-Many people dislike this proof, since it does not actuble to correct this deficiency by defining the sequencex = 2, x = 3, and x = x x · · · x + 1 for eachk1⩾ 2. Then each2 xk must contain at least one prim(ek)+1 1 2 k factor, since ifqk <k say, and these prime factors must be distinct,, then q divides x which divides x - 1, while of primes.q divides x.
This gives us an infinite sequence$k^{k}$ ferent proof that there are infinitely many primes, one that turned out to be highly influential in what was In the eighteenth century euler [VI.19](/part-06/leonhard-euler-17071783) gave a difto come later. Suppose again that the list of primesisp , p , . . . , p . As we have mentioned, the funda- mental theorem of arithmetic implies that there is a1 2$k$ one-to-one correspondence between the set of all inte-gers and the set of products of the primes, which, if those are the only primes, is the set$a$, a , . . . , a ⩾ 0.
But, as Euler observed, this implies{(pa()1)1(pa()2)2 · · · (pa()k)k}: that a sum involving the elements of the first set should equal the analogous sum involving the elements of the1 2$k$ second set:

n1 sna positive intege(rn()⩾){1} = a \su(m1)\\\\\\\\\\\\\\\\\\\{}}$,\\(a2)\\\\{,\\\\}$...,(ak)⩾10 (p\su(m1()a)1 (p2()a)2 · · · p(1 a()k)k)s . um  1=a ⩾ 0 ((p1()a)1()s()a()⩾){0} ((pa()2)2)s · · ·a ⩾ 0 ((pa()k)k)s=j=k 1 1 1 - p(1 j()s)-1$.2 k$

The last equality holds because each sum in the second-last line is the sum of a geometric progression. Euler then noted that if we takes = 1, the right - hand side equals some rational number (since each$p > 1)j$

where as the left-hand side equals. nfty . This is a contra- diction, so there cannot be finitely many primes. (To seewhy the left-hand side is infinite whens = 1, note that(ing, and therefore1/n) ⩾n n+1(1/t) dt Nsince the function 1-1(1/n) ⩾N (1/t)/tdis decreas-t = . og N which tends to During the proof above, we gave a formula for$\infty\text{asNn}=→$. nfty$1$.)1 n-s under the false assumption that there are only finitely many primes. To correct it, all we have to do is rewrite it in the obvious way with out that assumption: na positive intege(rn()⩾){1} n1 s =p prime 1 - p(1 s)-1. (1)

334

Now, however, we need to be a little careful about whether the two sides of the formula converge. It is safe to write down such a formula when both sides are absolutely convergent, and this is true whens > 1. (An infinite sum or product is absolutely convergent if the value does not change when we take the terms in any order we want.) pens to (1) when are equal when Like Euler, we want to be able to interpret what hap-s >s =1, the natural thing to do is con-1.
Since both sides converge and sider their common limit as To do this we note, as above, that the left-hand side ofs tends to 1 from above. (1) is well approximated by . nfty dt = 1 , ts s - 1 so it diverges as s \to 11+. We deduce that$1$- p1 = 0. (2)pprime

Taking logarithms and discarding negligible terms, wethen find that

$= \infty$. (3)pp prime

So how numerous are the primes? One way to get anidea is to determine the behavior of the sum analogous to (3) for other sequences of integers. For instance,1/n2 converges, so the primes are, in this sense, more numerous than the squares. This argument works(n⩾)1 if we replace the power 2 by anywe have just observed, the sums > 1, since then, as1/ns is about$1$/(s -1/n(1) and in particular converges.
In fact, since. og n)2 converges, we see that the prime(sn()⩾){1} are in the same sense more numerous than the num-bers(n⩾)1{n(. og n)2}:$n ⩾ 1$, and hence there are infinitely many integers than or equal toxxfor which the number of primes lessis at least x/(. og x)2. Thus, there seem to be primes in abundance, but we would also like to verify our observations, made from calculations, that the primes constitute a smaller and smaller proportion of the integers as the integers become larger and larger.
The easiest way to see this is to try to count the primes using the “sieve of Eratosthenes.” In the sieve of Eratosthenes one starts with allthe positive integers up to some numberx. From these, one deletes the numbers 4, 6, 8 and so on—that is, all multiples of 2 apart from 2 itself. One then takes the first undeleted integer greater than 2, which is 3, and deletes all its multiples—again, not including the number 3 itself. Then one removes all multiples of 5 apart

IV. Branches of Mathematics

from 5, and so on. By the end of this process, one is left with the primes up tox. After deleting every second integer up to This suggests a way to guess at how many there are.x other than 2 (which we call “sieving by 2”) one is left with roughly half the integers up to$x$; after sieving by 3, one is left with roughly two thirds of those that had remained; continuing like this we expect to have about

xp^⩽y 1 - p1 (4)

integers left by the time we have sieved with all the primes up toy . Once y = . qrt{x} the undeleted integers are 1 and the primes up tox, since every composite has a prime factor no bigger than its square root. So, is(4) a good approximation for the number of primes up tox when y = . qrt{x}? about what the formula in (4) is estimating. It is sup-To answer this question, we need to be more precise posed to approximate the number of integers up tothat have no prime factors less than or equal toy , plusx the number of primes up toy.
The so-called inclusion exclusion principle imation given in (4) is accurate to within 2 can be used to show that the approx-k, where k is the number of primes less than or equal tois very small, this error term of 2 k is far larger than they. Unless k quantity we are trying to estimate, and the approxima-tion is use less. It is quite good ifk is less than a small constant times logx, but, as we have seen, this is far less than the number of primes we expect up to$y \approx \sqrt{x}$. Thus it is not clear whether (4) can be usedy if to obtain a good estimate for the number of primes uptox.
What we can do, however, is use this argument to give an upper bound for the number of primes up tox, since the number of primes up to x is never more than the number of integers up tox that are free of prime factors less than or equal toof primes up toy, which is no more than 2 y, plus the numberk plus the expression in (4). the product Now$, by (2)$, we know that asp⩽y (1 - 1/p) converges to zero. There-y gets larger and larger fore, for any small positive numbery such that (1 - 1/p) < ε/2.
Since every term inεwe can find a this product is at least 1 Hence, for anyp(x⩽)y⩾ (22)k our error term, 2/2, the product is at least 1 k, is no bigger/2 k. than the quantity in (4), and therefore the number of primes up tox is no larger than twice (4), which, by our choice ofy, is less than εx. Since we were free to makeεproportion of all the integers, as we predicted.as small as we liked, the primes are indeed a vanishing

IV.2. Analytic Number Theory

Even though the error term in the inclusion–exclusion principle is too large for us to use that method toestimate (4) wheny = . qrt{x}, we can still hope that (4) is a good approximation for the number of primes up to$x$: perhaps a different argument would give us a much smaller error term. And this turns out to be the case: in fact, the error never gets much bigger than (4). However, when actually about 8 y = /. qrt{9} times (4). So why does (4) not givex the number of primes up to x is a good approximation?
After sieving with prime supposed that roughly 1 in everyp of the remainingp we integers were deleted: a careful analysis yields that this can be justified whenp is small, but that this becomes an increasingly poor approximation of what really hap-pens for larger p; in fact (4) does not give a correct approximation once So what goes wrong? In the hope that the proportion yis bigger than a fixed power ofx.
is roughly 1 consequences of sieving by/p lies the unspoken assumption that thep are independent of what happened with the primes smaller than primes under consider at i on are no longer small, thenp. But if the this assumption is false. This is one of the main rea-sons that it is hard to estimate the number of primes up toof many related problems. x, and indeed similar difficulties lie at the heart One can refine the bounds given above but they do not seem to yield an asymptotic estimate for the primes(that is, an estimate which is correct to within a factor that tends to 1 as xgets large).
The first good guesses for such an estimate emerged at the begin-ning of the nineteenth century, none better than what emerges from an observation ofwhen studying tables of primes up to three million gauss [VI.26](/part - 06/carl - friedrich - gauss - 17771855), made at sixteen years of age, that “the density of primes at around x is about 1/ . og x.” Interpreting this, we guess that the number of primes up tox is aboutx 1 . pprox x dt .. og n2 . og tn=2

Let us compare this prediction (rounded to the nearest integer) with the latest data on numbers of primes, dis-covered by a mixture of ingenuity and computational power. Table 1 shows the actual numbers of primes up to various powers of 10 together with the difference between these numbers and what Gauss’s formula gives. The differences are far smaller than the numbers themselves, so his prediction is amazingly accu-rate. It does seem always to be an over count, but since the width of the last column is about half that of the

335

Table 1 the over count in Gauss’s prediction. Primes up to variousx, andx π(x) =#({primes ⩽ x}2)x Over count:. og dtt} - π(x) 101089 50 847 5345 761 455 1 700753 10101011 4 118 054 813455 052 511 11 5873 103 10101213 346 065 536 83937 607 912 018 108 97038 262 10101415 29 844 570 422 6693 204 941 750 802 1 052 618314 889 10101617 2 623 557 157 654 233279 238 341 033 925 3 214 6317 956 588 10101819 234 057 667 276 344 60724 739 954 287 740 860 21 949 55499 877 774 10102021 21 127 269 486 018 731 9282 220 819 602 560 918 840 222 744 643597 394 253 1022 201 467 286 689 315 906 290 1 932 355 207
central one it appears that the difference is something like$\sqrt{x}$. ity theorist, gave a probabilistic way of interpreting Gauss’s prediction. We can represent the primes as a In the 1930 s, Harald Cramér, the great probabil sequence of 0 s and 1 s. If we start with 3 and put a 1 each time we encounter a prime and 0 otherwise, then we obtain the sequence 1 idea is to suppose that this sequence, which repre-,0,1,0,1,0,0,0,1,0,1, . . ..
Cramér’s sents the primes, has the same properties as a “typical”sequence of 0 s and 1 s, and to use this principle to make precise conjectures about the primes. More precisely, le tables$X^{3}$, X[III.71 §4](/part-03/probability-distributions) taking the values 0 or 1, and let the4, . . .be an infinite sequence of random var i variable it equals 0 with probability 1 Xn equal 1 with probability 1 - 1/ . og n/). Assume also. og n (so that that the variables are independent, so for each led ge about the variables other than X tells us noth-m know- ing about Xmit self.
Cramér’s suggestion was that any mstatement about the distribution of 1 s in the sequence that represents the primes will be true if and only if it is true with probability 1 for his random sequences. Some care is needed in interpreting this statement: for example, with probability 1 a random sequence will contain infinitely many even numbers. However, it is possible to formulate a general principle that takes account of such examples. Here is an example of a use of the Gauss–Cramér model.
With the help of the central limit theorem 336 [III.71 §5](/part - 03/probability - distributions) one can prove that, with probability 1, there are x dt + O(. qrt{x}. og x) 2. og t 1 s among the first tells us that the same should be true of the sequencex terms in our sequence.
The model representing primes, and so we predict thatx dt . qrt #{primes up to x} = 2 . og t + O( x . og x), (5) just as the table suggests. The Gauss–Cramér model provides a beautiful way to think about distribution questions concerning the prime numbers, but it does not give proofs, and it does not seem likely that it can be made into such a tool; so for proofs we must look elsewhere. In analytic number theory one attempts to count objects that appear naturally in arithmetic, yet which resist being counted easily.
So far, our discussion of the primes has con-centrated on upper and lower bounds that follow from their basic definition and a few elementary properties—notably the fundamental theorem of arithmetic. Some of these bounds are good and some not so good. To improve on these bounds we shall do something that seems unnatural at first, and reformulate our questionas a question about complex functions. This will allow us to draw on deep tools from analysis.
3 The “Analysis” in Analytic Number Theory These analytic techniques were born in an 1859 memoir ofthat appears in the formula (1) of Euler, but with one riemann [VI.49], in which he looked at the function crucial difference: now he considered of$s$. To be precise, he defined what we now call the complex values Riemann zeta function as follows:

$ζ(s) = {}^{n⩾1} n1^{s}$.

It can be shown quite easily that this sum converges whenever the real part ofs is greater than 1, as we have already seen in the case of real the great advantages of allowing complex values ofs. However, one ofs is that the resulting function isand we can use a process of holomorphic analytic continuation[I.3 §5.6](/part-01/fundamental-definitions), to make sense oflar but more elementary example of this phenomenonζ(s) for every s apart from 1. (A simi- is the infinite series only if|z| < 1.
However, when it does converge, i(tn()⩾){0} zn, which converges if and equals 1 phic function that is defined every where except$/(1 - z)$, and this formula defines a holomor- z = 1.) Riemann proved the remarkable fact that confirming

IV. Branches of Mathematics

Gauss’s conjecture for the number of primes up tois equivalent to gaining a good understanding of thex zeros of the function for which$ζ(s) =$0. Riemann’s deep work gave birth toζ(s), that is, of the values of s our subject, so it seems worthwhile to at least sketch the key steps in the argument linking these seemingly unconnected topics. Riemann’s starting point was Euler’s formula (1). It is not hard to prove that this formula is valid whens is complex, as long as its real part is greater than 1, so wehaveζ(s) =p prime 1 - p(1 s)-1.
If we take the logarithm of both sides and then differ - entiate, we obtain the equation - ζζ(s)^ (s) =p prime p. og s - p1 = p primem⩾1 . og pmsp}. We need some way to distinguish between prime sp ⩽xprimesand prime sp for whichp > xx/p; that is, we want to count those⩾ 1, but not those with x/p < 1. This can be done using thethe value 0 fory < 1 and the value 1 for step function y >that takes1 (so that its graph looks like a step). At$y = 1$, the point of discontinuity, it is convenient to give the function the average value, 1 .
Perron’s formula, one of the big tools of analytic number theory.
describes this step function2 by an integral, as follows. For any$\{ c > 0$,⎪⎪⎪⎨0 if 0 < y < 1, 1$ys$

2π(is)\\\\\\\\\\{:\\\\\\\\\. \1 e(s)=c s ds = ⎪⎪⎪⎩(11)2 ifif yy >= 11,.}} The integral is a complex plane: the line consisting of all points path integral along a vertical line in thec + it with$t \in R$. We apply Perron’s formula with$y = x/p^{m}$, so that we count the term corresponding topm < x, but not when pm > x. To avoid the “pm when1,” assume thatobtainx is not a prime power. In that case we2. og ppprim(ep)(m⩽)$, mx⩾1 = 21πi \log ps}$: Re(s)=c p(xm)s dss= − 21πpiprimes: Re(s)$, m=⩾c 1ζζ(s) (s) \text{xss ds}$.
(6) We can justify swapping the order of the sum and the integral if thing then converges absolutely. Now the left-hand sidec is taken large enough, since every-

IV.2. Analytic Number Theory

of the above equation is not counting the number of primes up toxbut rather a “weighted” version: for each primep we add a weight of log p to the count. It turns out, though, that Gauss’s prediction for the number of primes up tox follows so long as we can show thatxis large. Notice that the sum in (6) is exactly the loga-is a good estimate for this weighted count when x rithm of the lowest common multiple of the integers less than or equal tothis weighted counting function for the primes is a nat-x, which perhaps explains why ural function to consider.
Another explanation is thatif the density of primes nearp is indeed about 1/ . og p, then multiplying by a weight of logp makes the density every where about 1.If you know some complex analysis, then you will know thatuate the integral in (6) in terms of the “residues” of Cauchy’s residue theorem allows one to eval the integrand$(ζ (s)/ζ(s))(x^{s} /s)$, that is, the poles of this function. More over, for any function lytic except perhaps at finitely many points, the polesf that is ana-$of$ f^ (s)/f (s)f^ (s)/f (s)has order 1, and the residue is simply theare the zeros and poles of f .
Each pole of order of the corresponding zero, or minus the order ofthe corresponding pole, off . Using these facts we can obtain the explicit formula pprim(ep()m()⩽){}$, (mx()⩾){1}\log p = x -ρ$: ζ(ρ)=0 xρρ - ζζ( {} (00)). (7) Here the zeros ofthat is, ifρ is a zero ofζ(s)ζ(s)are counted with multiplicity: of orderk, then there are k terms forbe such a formula, an exact expression for the numberρ in the sum. It is astonishing that there can of primes up tofunction: you can see why Riemann’s work stretch edx in terms of the zeros of a complicated people’s imagination and had such an impact.
allows us to easily determine the values ofleft-hand side of the complex plane (where the function Riemann made another surprising observation whichζ(s) on the is not naturally defined). The idea is to multiply some simple function so that the resulting productζ(s)ξ(s)by satisfies the functional equation

$ξ(s) = ξ(1 - s) \text{for all} s$. (8)

He determined that this can be done by taking1$s(s - 1)π^{-s}/ {}^{2}Γ ( {}^{1}s)ζ(s)$. Here Γ (s) is the famousξ(s) = gamma function function at positive integers (that is,2 2[III.31](/part-03/the-gamma-function), which equals the factorial$Γ (n) = (n - 1)$!), and is well-defined and continuous for all others. zeros of A careful analysis of (1) reveals that there are noζ(s) with Re(s) > 1. Then, with the help of

337

(8), we can deduce that the only zeros of Re(s) < 0 lie at the negative even integers -ζ(s)2,-4 with, . . . (the “trivial zeros”). So, to be able to use (7), we need todetermine the zeros inside the critical strip, the set of alls such that 0 ⩽ Re(s) ⩽ 1. Here Riemann made yet another extraordinary observation which, if true, would allow us tremendous insight into virtually every aspect of the distribution of primes. The Riemann hypothesis.0, then Re(s) =1.
If 0 ⩽ Re(s) ⩽ 1 and ζ(s) = line Re It is known that there are infinitely many zeros on the(s) =1 2, crowding closer and closer together as we go up the line. The Riemann hypothesis has been verified computationally for the ten billion zeros of lowest height (that is, with|Im(s)| smallest), it can be shown to hold for at least 40% of all zeros, and it fits nicely with many different heuristic assertions about the distribution of primes and other sequences. Yet, for all that, it remains an unproved hypothesis, perhaps the most famous and tantalizing in all of mathematics.
mann’s memoir gives no hint as to how he came upwith such an extraordinary conjecture, and for a long How did Riemann think of his “hypothesis”? Rie time afterwards it was held up as an example of the great heights to which humankind could ascend by pure thought alone. However, in the 1920 s Siegel and weil [VI.93](/part - 06/andr - weil - 19061998) got hold of Riemann’s unpublished notes and from these it is evident that Riemann had been able to determine the lowest few zeros to several decimal places through extensive hand calculations—somuch for “pure thought alone”!
Nevertheless, the Riemann hypothesis is a mammoth leap of imagination and to have come up with an algorithm to calculate zeros of put at i on al number theoryζ(s) is a remarkable achievement. (See[IV.3](/part - 04/computational - number - theory) for a discussion ofcom- how zeros of If the Riemann hypothesis is true, then it is not hardζ(s) can be calculated.) to prove the bound xρρ ⩽ |Imx1(ρ()/)2 |.

Inserting this into (7) one can deduce that. qrt . og p = x + O( x . og2 x). (9)(pp)prim(e⩽)x This, in turn, can be “translated” into (5). In fact these estimates hold if and only if the Riemann hypothesis is true. The Riemann hypothesis is not an easy thing to understand, nor to fully appreciate. The equivalent, (5),

338

is perhaps easier. Another version, which I prefer, isthat, for every$N ⩾ 100$,|. og (lcm[1,2, . . . , N]) - N| ⩽ . qrt{N}(. og N)2. To focus on the over count in Gauss’s guesstimate for the number of primes up to approximation, which can be deduced from (7) if, andx, we use the following only if, the Riemann hypothesis is true: 2$x(1/ \log t)\sqrt{dx}/t -\log$#${primesx ⩽ x} \approx 1 + 2 \sin (γγ\log x)$. (10)

all real numbers such that 1$+i^{γ}>^{γ}0$

is a zero ofζ(s)

The right-hand side here is the over count in Gauss’sprediction for the number of primes up tox, divided by something that grows like the table of primes it seemed that this quantity should. qrt{x}. When we looked at be roughly constant. However, that is not quite true aswe see upon examining the right-hand side. The first term on the right-hand side, the “1,” corresponds tothe contribution of the squares of the primes in (7). The subsequent terms correspond to the terms involving the zeros ofinatorγso the most significant terms in this sum areζ(s)$in (7)$;
these terms have denom those with the smallest values of these terms is a sine wave, which oscillates, half theγ. More over, each of time positive and half the time negative. Having the “log slowly (which is why we hardly notice them in the table$x$” in there means that these oscillations happen above), but they do happen, and indeed the quantity in(10) does eventually get negative.
No one has yet determined a value of value ofx for which there are more thanx for which this is negative (that is, ax(1/ . og t) dt primes up totime this happens is for x), though our best guess is that the first2 x . pprox 1.398 . imes 10316. How does one arrive at such a guess given that the table of primes extends only up to 1022? One begins by using the first thousand terms of the right-hand side of (10)to approximate the left-hand side;
wherever it looks as though it could be negative, one approximates with more terms, maybe a million, until one becomes pretty certain that the value is indeed negative. It is not uncommon to try to understand a given function better by representing it as a sum of sines and cosines like this; indeed this is how one studies the harmonics in music, and (10) becomes quite compelling from this perspective. Some experts suggest that (10) IV. Branches of Mathematics tells us that “the primes have music in them” and thus makes the Riemann hypothesis believable, even desirable.
To prove unconditionally that #{primes ⩽ x} ∼2 x . og dtt}, the so-called same approach as above but, since we are not asking for prime number theorem, we can take the such a strong approximation to the number of primes up tox, we need to show only that the zeros near to the line Re(s) = 1 do not contribute much to the for-$mula (7)$. By the end of the nineteenth century this task had been reduced to showing that there are no zeros actually on the line Re$(s) =$1:
this was eventually established by de la vallée poussin [VI.67](/part-06/charles-jean-de-la-valle-poussin-18661962) and hadamard [VI.65](/part-06/jacques-hadamard-18651963) in 1896.Subsequent research has provided wider and wider subregions of the critical strip with out zeros of(and thus improved approximations to the number ofζ(s) primes up to proving the Riemann hypothesis.
This remains as anx), with out coming any where near to outstanding open problem of mathematics. A simple question like “How many primes are there up to ment ary methods rather than all of these methods of$x$?” deserves a simple answer, one that uses ele complex analysis, which seem far from the question athand. However, (7) tells us that the prime number theorem is trueon the line Reif and only if(s) = 1, and so one might argue that it there are no zeros of ζ(s) is inevitable that complex analysis must be involved insuch a proof.
In 1949 Selberg and Erd ̋os surprised the mathematical world by giving an elementary proof of the prime number theorem. Here, the word “elemen-tary” does not mean “easy” but merely that the proof does not use advanced tools such as complex analysis—in fact, their argument is a complicated one. Of course their proof must some how show that there is no zeroon the line Re(s) = 1, and indeed their combinator- ics cunningly masks a subtle complex analysis proof beneath the surface (read Ingham’s discussion (1949) for a careful examination of the argument).
4 Primes in Arithmetic Progressions After giving good estimates for the number of primes up tox, which from now on we shall denote by π(x), we might ask for the number of such primes that are congruent toa mod q. (If you do not know what this means, seeπ(x; q, a) for this quantity. To start with, note that modular arithmetic [III.58](/part-03/modular-arithmetic).) Let us write

IV.2. Analytic Number Theory

there is only one prime congruent to 2 mod 4, and indeed there can be no more than one prime in any arithmetic progression a, a + q, a + 2 q, . . . if a and q have a common factor greater than 1. Letthe number of integers$a$, 1 ⩽ a ⩽ q, such thatφ(q)(a, q)denote = 1. (The notation factor ofa and q(a, q).) Then all but a small finite number stands for the highest common of the infinitely many primes belong to the met ic progressions$a$, a + q, a + 2 q, . . . with 1φ(q)⩽ a < qarith- and(a, q) = 1.
Calculation reveals that the primes seem to be pretty evenly split between these progressions, so we might guess that in the limit theφ(q) arithmetic proportion of primes in each of them is 1 is, whenever(a, q) = 1, we might conjecture that, as/φ(q). Thatx → $\infty$,π(x; q, a) ∼ π(x)φ(q). (11) congruent toorem of It is far from obvious even that the number of primes dirichleta mod[VI.36]. To begin to consider such qis infinite.
This is a famous the questions we need a systematic way to identify integersn that are congruent to a mod q, and this Dirichlet pro- vided by introducing a class of functions now known as (Dirichlet) characters. Formally, a character modq is a functionχ from Z to C with the following three properties (in ascending order of interest): (i)χ(n) = 0 whenever n and q have a common factor(ii) greater than 1;χevery integer is periodic modn); q (that is, χ(n + q) = χ(n) for (iii)χ is multiplicative (that is, χ(mn) = χ(m)χ(n) for any two integersm and n).
An easy but important example of a character modis the principal character$χ^{q}$, which takes the value 1 ifq(n, q)important example is the= 1 and 0 otherwise. If Legendre sym bolq is prime, then another(^· ): one sets (residue mo(dn)q ) to be 0 ifqn, andis a multiple of-1 if n is a quadratic nonresidueq, 1 if n is a quadraticq modifn is congruent modq. (An integer n is called aq to a perfect square.) Ifquadratic residueq is com-mod q posite, then a function known as the symbol$( {}^{·} )$, which generalizes the Legendre symbol, Legendre–Jacobi is also a character.
This too is an important example that helps us, in a slightly less direct way, to recognize$q$ squares mod These characters are all real-valued, which is theq. exception rather than the rule. Here is an example of a genuinely complex-valued character in the case q = 5. Set χ(n) to be 0 if n ≡ 0 (mod 5), i if n ≡ 339 2,-1 if n ≡ 4, -i if n ≡ 3, and 1 if n ≡ 1. To see that this is a character, note that the powers of 2 mod 5 are 2 i are i,-1, -i,1,,4 i,,3-,11,,-2, i,41,, . . .3, 1, . . ..
, while the powers of characters modthe properties above, together with the following for-It can be shown that there are precise lyq. Their usefulness to us comes fromφ(q) distinct mula, in which the sum is over all characters modan. ar{d}χ(a) denotes the complex conjugate of χ(a): qφ(q)1χ χ(a)χ(n) ̄= ⎧⎨⎩1 if0 otherwisen ≡ a (mod. q), What is this formula doing for us? Well, understand-ing the set of integers congruent toa mod q is equiva- lent to understanding the function that takes the value1 ifn ≡ a (mod q) and 0 otherwise. This function appears on the right-hand side of the formula.
How-ever, it is not a particularly nice function to deal with, so we write it as a linear combination of characters, which are much nicer functions because they are mul-tiplicative. The coefficient associated with the character χin this linear combination is the numbe. ar{r}χ(a)/φ(q). From the formula, it follows that

. og pp}prim(ep()m()⩽){}$, (mx()⩾){1}(pm()≡){a} (modq)= φ(q)1 χ(a) χ(pm)$. og p.χ (modq()p)prim(ep)m^⩽^, mx^⩾1

The sum on the left-hand side is a natural adaptation ofthe sum we considered earlier when we were counting all primes. And we can estimate it if we can get good estimates for each of the sums

$χ(p^{m}) \log p$.pprim(ep()m()⩽){}, (mx()⩾){1} We approach these sums much as we did before, obtain-ing an explicit formula, analogous to (7), (10), now in terms of the zeros of the Dirichlet L-function:

L(s$, χ) = {}^{n⩾1} χ(n)n^{s}$.

This function turns out to have properties closely analogous to the main properties ofζ(s). In particular, it is here that the multiplica ti vi ty ofχ is all-important, since it gives us a formula similar to (1):χ(n)ns = 1 - χ(p)(ps)-1. (12)(n⩾()1){p}prime 340 That is, the “generalized Riemann hypothesis” that all zeros L(s, χ) has an Euler product. We also believeρ of This would imply that the number of primes up to L(ρ, χ) = 0 in the critical strip satisfy Re(ρ) =1 2 x. that are congruent toa mod q can be estimated asπ(x; q, a) = π(x)φ(q) + O(. qrt{x}. og2(qx)).
(13) Therefore, the generalized Riemann hypothesis implies the estimate we were hoping for (formula (11)), provided thatx is a little bigger than q2. that is, with out the help of the generalized riemann hypothesis? Although we can more or less translate the In what range can we prove (11) unconditionally— proof of the prime number theorem over into this new setting, we find that it gives (11) only whenx is very large.
In fact, x has to be bigger than an exponential in a power of little larger than$q$, which is a lot bigger than the “$q2$” that we obtained from the general-x is a ized Riemann hypothesis. We see a new type of problem emerging here, in which we are asking for a good start-ing point for the range ofx for which we obtain good estimates, as a function of the modulus$q$; this does not have an analogy in our exploration of the prime num-ber theorem.
By the way, even though this bound “x is a little larger than$q2$” is far out of reach of current methods, it still does not seem to be the best answer;
 calcu-la tions reveal that (11) seems to hold whenx is just a little bigger thanq. So even the Riemann hypothesis and its generalizations are not powerful enough to tellus the precise behavior of the distribution of primes. Through out the twentieth century much thought was put in to bounding the number of zeros of dirichlet functions near to the 1-line. It turns out that one can L- make enormous improvements in the range ofx for which (11) holds (to “halfway between polynomial inq and exponential in q”) provided there are no Siegel zeros numbers with.
These putative zeros$β > 1 - c/\sqrt{qβ}$; they can be shown to beof L(s$, (q^{·} )) \text{would be real}$ extremely rare if they exist at all. Deuring–Heilbronn phenomenon That Siegel zeros are rare is a consequence of the: that zeros of L-func- tions charged particles.
(This phenomenon is akin to the[III.47](/part-03/l-functions) repel each other, rather like similarly fact that different algebraic numbers repel one another, part of the basis of the subject of Diophantine approx-imation.) whenof Siegel zeros, one can prove that there is always such How big is the smallest prime congruent to(a$, q) =$1? Despite the possibility of the existencea mod q

IV. Branches of Mathematics

a prime less thanq5.5 if qis sufficiently large. Obtaining a result of this type is not difficult when there are no Siegel zeros. If there are Siegel zeros, then we goback to the explicit formula, which is similar to (7) but now concerns zeros of L(s, χ). If β is a Siegel zero, then it turns out that in the explicit formula there are nowtwo obviously large terms:$x/φ(q) and -( a )x^{β}/βφ(q)$. When(a q ) = 1 it appears that they might almost can celq (sinceβ is close to 1), but with more care we obt a inx - aq xβ^β = (x - x^β) + x^β 1 - 1β ∼ x(1 - β) . og x.
This is a smaller main term than before, but it is nottoo hard to show that it is bigger than the contributions of all of the other zeros combined, because the Deuring–Heilbronn phenomenon implies that the Siegel zero repels those zeros, forcing them to be far to the left. When(a ) = −1, the same two terms tell us that if primes as we would expect up to(1 - β) . og qx is small, then there are twice as manyx that are congruent toa mod q. and algebraic numbers There is a close connection between Siegel zeros class numbers, which are defined and discussed in[IV.1 §7](/part-04/number-theory).
Dirichlet’s class number formula whereh states thatis the class number of the field$L(1$, (q · )) = πh-q/. qrt{q} Qfor(. qrt{q} >-q)$. A6$, class number is always a positive integer, so this result immediately implies that$- q L(1$, (· )) ⩾ π/. qrt{q}. Another consequence is thatis small. The reason this gives us information abouth - q is small if and only ifq L(1, (q · )) Siegel zeros is that one can show that the derivative L^ (σ , (· )) is positive (and not too small) for real num - bersσqclose to 1. This implies that L(1, (q · )) is small· if and only ifis, a Siegel zero L(s, (β.
Whenq )) has a real zero close to 1, thath = 1, the link is more direct: it can be shown that the Siegel zero imately 1$-6/(π \sqrt{q})$. (There are also more complicated^-^q β is approx- formulas for larger values of h-q.) These connections show that getting good lower bounds onon the possible range for Siegel zeros. Siegel show edh-q is equivalent to getting good bounds that for anyε > 0 there exists a constant c > 0ε

such that factory because by its very nature one cannot give an$L(1$, (q · )) ⩾ cε(q-)ε. His proof was unsatis- explicit value for$c$. Why not? Well, the proof comes

ε

in two parts. The first assumes the generalized Rie-mann hypothesis, in which case an explicit bound follows easily. The second obtains a lower bound in terms of the first counterexample hypothesis. So if the generalized Riemann hypothesis isto the generalized Riemann

IV.2. Analytic Number Theory

true but remains unproved, then Siegel’s proof can not be exploited to give explicit bounds. This dichotomy, between what can be proved with an explicit constant and what cannot be, is seen far and wide in analytic number theory—and when it appears it usually stems from an application of Siegel’s result, and especially its consequences for the range in which the estimate (11) is valid. take on prime values when we substitute in an inte-ger. To see this, note that if A polynomial with integer coefficients cannot alwaysp divides f (m) then p also div i desf (m + p)$, f (m + 2p)$, . . . .
However, there are some prime-rich polynomials, a famous example being the polynomialx2 + x + 41, which is prime forx = 0,1,2, . . . , 39. There are almost certainly quadratic polynomials that take on more consecutive prime val-ues, though their coefficients would have to be very large. If we ask the more restricted question of when the polynomial$x^{2} + x + p \text{is prime for} x = 0$, 1, 2, . . . , p - 2, then the answer, given by Rabinowitch, is rather sur-pr ising: it happens if and only if$h = 1$, where q = 4 bers and predicted that there are just nine values ofp - 1.
Gauss did extensive calculations of class num--q q with Using the Deuring–Heilbronn phenomenon researcher sh-q = 1, the largest of which is 163 = 4 . imes  41 - 1. showed, in the 1930 s, that there is at most one$h =$1 that is not already on Gauss’s list; but as usualq with with such methods, one could not give a bound on the$- q$ size of the putative extra counterexample.
It was not until the 1960 s that Baker and Stark proved that there was no tenth removed from those here (in fact Heegner gave whatq, both proofs involving techniques far we now understand to have been a correct proof in the 1950 s but he was so far ahead of his time that it was dif-ficult for mathematicians to appreciate his arguments and to believe that all of the details were correct).
In the1980 s Goldfeld, Gross, and Zagier gave the best result to date, showing thath-q ⩾77001 . og q this time using the Deuring–Heilbronn phenomenon with the zeros ofyet another type of L-function to repel the zeros of L(s, (This idea that primes are well-distributed in arith-q · )). metic progressions except for a few rare moduli was exploited by Bombieri and Vinogradov to prove that(11) holds “almost always” whenx is a little bigger thanq2(that is, in the same range that we get “always” from the generalized Riemann hypothesis).
More precisely, for given large$x$we have that (11) holds for “almost all”(a$, q)q \text{less than}=$1. “Almost all” means that, out of all. qrt{x}/(. og x)2 and for all a such thatq less 341 than not hold for every. qrt{x}/(. og x)2, the proportion for which (11) doesa with (a, q) = 1 tends to 0 as x → $\infty$. Thus, the possibility is not ruled out that there are infinitely many counterexamples. However, since this would contradict the generalized Riemann hypothesis, we do not believe that it is so. weaker result, but it is valid for the whole feasible range:
for any given large The Barban–Davenport–Halberstam the ore mx, the estimate (11) holds gives a for “almost all” pairs and(a, q) = 1. q and a such that q ⩽ x/(. og x)2 5 Primes in Short Intervals Gauss’s prediction referred to the primes “around”so it perhaps makes more sense to interpret his state-x, ment by considering the number of primes in short intervals at aroun dx. If we believe Gauss, then we might expect the number of primes betwee nx + y to be about y/ . og x. That is, in terms of thex and prime-counting functionπ, we might expect thatyπ(x + y) - π(x) ∼ . og x (14)

for about the range for|y| ⩽ x/2. However, we have to be a little care fuly. For example, if y =1 . og x, then we certainly cannot expect to have half a prime in each interval. Obviously we needy to be large enough that2 the prediction can be interpreted in a way that makes sense; indeed, the Gauss–Cramér model suggests that (14) should hold when|y| is a little bigger than (. og x)2.
we used in the proof of the prime number theorem, we find ourselves bounding differences between If we attempt to prove (14) using the same methodsρth powers as follows:(x + y)ρ - xρx+yρ =x x+y (tρ)-1 dt⩽x t Re(ρ)-1 dt⩽ y(x + y)Re(ρ)-1.

With bounds on the density of zeros ofthe right of 1, it has been shown that (14) holds forζ(s) well toy a little bigger than assuming the Riemann hypothesis, that such methods2 x7/12; but there is little hope, even will lead to a proof of (14) for intervals of length or less.$\sqrt{x}$ all”ing the Riemann hypothesis.
Once again, “almost all”In 1949 Selberg showed that (14) is true for “almostx when |y| is a little bigger than (. og x)2, assum- means with density tending to 1, rather than “all,” andit is feasible that there are infinitely many counterexamples, though at that time it seemed highly unlikely.

342

It therefore came as a surprise when Maier showed, in1984, that, for any fixed A > 0, the estimate (14) fails for infinitely many integers$x$, with y = (. og x)A. His ingenious proof rests on showing that the small primes do not always have as many multiples in an interval as one might expect. Let$p = 2 < p = 3 < · · · \text{be the sequence}$ of primes. We are now interested in the size of the gaps$p^{1} - p \text{between consecutive primes}$.
Since2 there are about difference is log(n+1)nx/x . og and we might ask how often thex primes up to x, the average difference between consecutive primes is about aver-age, whether the differences can get really small, and whether the differences can get really large. The Gauss–Cramér model suggests that the proportion ofn for which the gap between consecutive primes is more than. ambda times the average, that is p - p > λ. og p , is approximately eintervals[x$, x + {}^{-}λ^{λ}$;
and, similarly, the proportion of. og x] containing exactl(yn()+1)n k primesn is approximately e$- {}^{λ}λ^{k}/k$!, a suggestion which, as we shall see, is supported by other considerations. By looking at the tail of this distribution, Cramér conjectured that lim supn→. nfty((pn)+1 - pn)/(. og pn)2 = 1, and the evidence we have The Gauss–Cramér model does have a big drawback: seems to support this (see table 2). it does not “know any arithmetic.” In particular, as we noted earlier, it does not predict divisibility by small primes.
One manifestation of this failing is that it predicts that there should be just about as many gapsof length 1 between primes as there are of length 2. However, there is only one gap of length 1, since iftwo primes differ by 1, then one of them must be even, where as there are many examples of pairs of primes differing by 2, and there are believed to be infinitely many. For the model to make correct conjectures about prime pairs, we must consider divisibility by small primes in the formulation of the model, which makes it rather more complicated.
Since there are these glaring errors in the simpler model, Cramér’s conjec-ture for the largest gaps between consecutive primes must be treated with a degree of suspicion. And infact, if one corrects the model to account for divisibility by small primes, one is led to conjecture that lim sup(p - p )/(. og p )2 is greater than9. finding long sequences of composite numbers. How about trying to do this explicitly?
For example, we know Finding large gaps between primes is equivalent to n→$\infty$ n+1 n n 8 that$n$!+ j is composite for 2 ⩽ j ⩽ n, as it is divisi- ble byn between consecutive primes, the first of which isj. Therefore we have a gap of length at least

IV. Branches of Mathematics

Table 2 The largest known gaps between primes. pn pn^+1 - pn pn. og^+1 2-pnpn 1 693 182 318 746 371218 209 405 436 54319 581 334 192 4232 614 941 710 59925 056 082 08720 831 3232 010 733370 26131 3971 327113 1132112148210456652766906143472 0.62640.65760.67150.68120.70260.73950.79530.79750.81780.83110.9206 the largest prime less than or equal ton!$+ 1$. How- ever, this observation is not especially helpful, since the average gap between primes around$n$!
is log(n!), which is approximately equal toare looking for gaps that are large rn . og than the average.n, where as we However, it is possible to generalize this argument and show that there are indeed long sequences of consecutive integers, each with a small prime factor. In the1930 s, Erd ̋os reformulated the question as follows.
Fix a positive integerz, and for each prime p ⩽ z choose an integery as possible, every positive integer ap in such a way that, for as large an integern ⩽ ysatisfies at least one of the congruences X be the product of all the primes up ton ≡ ap (modz (which means, p).
Now let by the prime number theorem, that log X is about z), and letx ≡ −a x(be the integer between mod p) for every p ⩽ z. (This integer exists, X and 2 X such that by the between Chinese remainder the ore mp x + 1 and x + y, then m.) If- mx is an integer is a positive integer less thanprimep ⩽ z. Sincey, sox ≡ −m -ax ≡(modap (p)mod, it follows thatp) for some mto xis divisible by+ y are composite. Using this basic idea, it canp.
Thus, all the integers fromp x + 1 be shown that there are infinitely many primes whichp -p is about (. og p )(log log p ), which ispn for significantly larger than the average but no where close(n+1()n()n)n to Cramér’s conjecture. 6 Gaps between Primes That Are Smaller Than the Average We have just seen how to show that there are in-finitely many pairs of consecutive primes whose difference is much bigger than the average: that is, lim sup(p+ - p )/(. og p ) =. nfty. We would nown→. nftyn 1 n n

IV.2. Analytic Number Theory

like to show that there are infinitely many pairs of con-secutive primes whose difference is much smaller than the average: that is, lim inf0. Of course, it is believed that there are infinitely many$n^{→}$. nfty((pn)+1 - pn)/(. og pn) = pairs of primes that differ by 2, but this question seems intractable for now. the question of small gaps; the best result before 2000 Until recently researchers had very little success with was that there are infinitely many gaps of size less than one-quarter of the average.
However, a recent method of Goldston, Pintz, and Yıldırım, which counts primes in short intervals with simple weighting functions, proves that lim infand even that there are infinitely many pairs of con-$n^{→}$. nfty((pn)+1 - pn)/(. og pn) = 0, secutive primes with difference no larger than about mates for primes in arithmetic progressions; in par-ticular, that (11) holds for almost all$\log p^{n}$. Their proof, rather surprisingly, rests on esti-q up to . qrt{x} (as discussed earlier). More over, they obtain a conditional result of the following kind:
if in fact (11) holds for almost allq up to a little larger than . qrt{x}, then it follows that there exists an integer for infinitely many prime sp B .such that (pn)+1 - pn ⩽ Bn 7 Very Small Gaps between Primes There appear to be many pairs of primes that differ bytwo, like 3 and 5, 5 and 7,. . ., the so-called twin primes, though no one has yet proved that there are infinitely many. In fact, for every even integer 2 k there seem to be many pairs of primes that differ by 2 one has yet proved that there are infinitely many. Thisk, but again no is one of the outstanding problems in the subject.
1760 s: is it true that every even integer greater than 2 In a similar vein is Goldbach’s conjecture from the is the sum of two primes? This is still an open ques - tion, and indeed a publisher recently offered a million dollars for its solution. We know it is true for almost all integers, and it has been computer tested for every even integer up to 4 . imes 1014.
The most famous result on this question is due to Chen (1966), who showed that every even integer can be written as the sum of a prime and a second integer that has at most two prime factors (that is, it could be a prime or an “almost - prime”).In fact, goldbach [VI.17](/part - 06/christian - goldbach - 16901764) never asked this question.
He asked Euler, in a letter in the 1760 s, whether every integer greater than 1 can be written as the sum of at most three primes, which would imply what we now call the “Goldbach conjecture.” In the 1920 s vinogradov showed that every sufficiently large odd integer can be 343 written as the sum of three primes (and thus every suf-fic ient ly large even integer can be written as the sum of four primes). We actually believe that every odd inte-ger greater than 5 is the sum of three primes but the known proofs only work once the numbers involved are large enough.
In this case we can be explicit about “sufficiently large”—at the moment the proof needs themto be at least e5700, but it is rumored that this may soon be substantially reduced, perhaps even to 7.To guess at the precise number of prime pairs q, q + 2 with q ⩽ x we proceed as follows. If we do not consider divisibility by the small primes, then the Gauss–Cramér model suggests that a random integer up towe might exp ectx is prime with probability roughly 1 x/(. og x)2 prime pairs q,/ q. og + x2 up, so to primes, as thex.
However, we do have to account for the smallq, q + 1 example shows, so let us con - sider 2 - divisibility. The proportion of random pairs ofintegers that are both odd is 1, where as the proportion of random Thus we should adjust our guessq such that q and4 q + x/(2 are both odd is. og x)2 by a facto(r1)2.(of integers that are both not divisible by 3 (or indeed b(y1)2)/(1 4) = 2.
Similarly, the proportion of random pairs any given odd primetively), where as the proportion of randomp) is (2 3)2 (and (1 - 1/p)q2 such that, respec - q1 and(andq(+12 are both not divisible by 3 (or by prime - 2/p), respectively). Adjusting our formul ap) is for each prime3 p we end up with the prediction #q ⩽ x: q and q + 2 both prime∼ 2 ((11--12/p)/p)2 (. og xx)2.

This is known as the Despite its plausibility there do not seem to be a nyp asymptotic twin prime conjecture an odd prime . practical ideas around for turning the heuristic argu-ment above into something rigorous. The one good unconditional result known is that the number of twin primes less than or equal to times the quantity we have just predicted.
One canx is never more than four make a more precise prediction replacin gb yx(1/(. og t)2) dt, and then we expect that the dif-x/(. og x)2 ference between the two sides is no more than for some constant2 c > 0, a guesstimate that is wellc. qrt{x} supported by computational evidence. A similar method allows us to make predictions for the number of primes in any polynomial-type patterns. Letf (t), f (t), . . .
, f (t) \in Z[t] be distinct irreducible polynomials of degree greater than or equal to 1 with positive leading coefficient, and define1 2 k ω(p) to be the number of integersn (mod p) for which p divides344$\text{fwe have}^{1}(n)f^{2}(n)f (t)· · ·=f^{k}t(n)$, f.
(In the case of twin primes above(t) = t + 2 with ω(2) = 1 andω(p)always divides at least one of the polynomial values,= 2 for all odd prime(s1)2 p.) If ω(p) = p then p so they can be simultaneously prime just finitely often(an example of this is when$f (t) = t$, f (t) = t + 1, in which case ble set of polynomials for which we predict that the$ω(2) = 2)$. Otherwise we have a(n1)2 admissi- number of integersf (n), f (n), . . .
, f (n)n are prime is about less than x for which all of 1 2 k(1(1--ω(p)/p)1/p)kp prime. imes . og |f1(x)| . og |f2 x(x)| · · · . og |fk(x)| (15) once tic to make predictions in Goldbach’s conjecture, thatxis sufficiently large. One can use a similar heurisis, for the number of pairs of prime sp + q = 2 N. Again, these predictions are very wellp, q for which matched by the computational evidence. There are just a few cases of conjecture (15) that have been proved.
Modifications of the proof of the prime number theorem give such a result for admissible polynomials progressions) and for admissible qt + a (in other words, for primes in arithmeticat2 + btu + cu2 \in Z[t, u] (as well as some other polynomials in two vari- ables of degree two).
It is also known for a certain typeof polynomial inn variables of degree n (the admissible “norm-forms”).There was little improvement on this situation during the twentieth century until quite recently, when, by very different methods, Friedlander and Iwaniec broke through this stalemate showing such a result for the polynomial$t^{2} + u^{4}$, and then Heath-Brown did so for any admissible homogeneous polynomial in two variables of degree three.
Another truly extraordinary breakthrough occurred recently with a result of Green and Tao, proved in 2004, which states that for everykthere are infinitely many kof integers-term arithmetic progressions of primes: that is, pairs$a$, d such that a$, a + d$, a + 2 d, . . . , a+(k - 1)d are all prime. Green and Tao are currently hard at work attempting to show that the number ofk-term arith- metic progressions of primes is indeed well approx i-mated by (15). They are also extending their results to other families of polynomials.
8 Gaps between Primes Revisited In the 1970 s Gallagher deduced from the conjectured prediction (15) (with$f$(t) = t + a ) that the propor - jj IV. Branches of Mathematics tion of intervals primes is close to e[x, (x-)λλ+kλ/k . og! (as was also deduced, in sec - x] which contain exactly k tion 5 above, from the Gauss–Cramér heuristics).
This has recently been extended to support the prediction that, as we varyin the interval[x, xx from+ y]X to 2 is normally distributed with X, the number of primes meanwhereδx xis some constant strictly between 0 and 1 and+y (1/ . og t) dt and variance (1 - δ)y/ . og x, we take$y \text{to be} \sqrt{x}^{δ}$. information on the distribution of primes in intervals[x, x When+ y)y >via the explicit formula (7).
Indeed, when wex the Riemann zeta function supplies compute the “variance” X(1 X()2()X)x < (pp)prim(e⩽()x){+}\\\{}},\\\\\\\\\\\\\\\\\\\}y . og p - y2 dx using the explicit formula we obtain a sum of terms of the form 2 X (xi)(γ- γ ) dx. Here we are assuming the Riemann hypothesis and writing the zeros of1± iγ with 0 X < γj < γk < · · · . This sum is domi-ζ(s) as nated by the terms corresponding to those pairs for which2 n |γ - γ |1 is small (in which case there is lit-2 γj, γk tle cancellation in the integral).
Therefore, in order to understand the variance for the distribution of primes$j^{k}$ in short intervals we need to understand the dis tr ibu-tion of the zeros ofζ(s) in short intervals. In 1973 Montgomery investigated this and suggested that the proportion of pairs of zeros ofζ(s)whose difference is less thanα times the average gap between consecutive zeros is given by the integral

$α 1 - \sin πθ^{2} dθ$, (16)

0πθ

and he proved an equivalent form of this in a lim-ited range. If the zeros were placed “randomly,” then (16) would be replaced byfor smallα, which is far smaller thanα. In fact (16) is aboutα. This mean(s1)9α3 that there are far fewer pairs of zeros ofζ(s) that are close together than one might expect, which we express informally by saying that the zeros ofζ(s) repel one another.
Institute for Advanced Study in Princeton, montgomery mentioned his ideas to the physicist Freeman Dyson. In a now-famous conversation that took place at the Dyson immediately recognized (16) as a function that comes up in modeling energy levels in quantum chaos. Believing that this was unlikely to be a coincidence, hesuggested that the zeros of the Riemann zeta function are distributed, are in turn modeled on the distribution ofin all aspects, like energy levels, which eigenvalues

IV.2. Analytic Number Theory

[I.3 §4.3](/part-01/fundamental-definitions) of random There is now substantial computational and theoret-hermitian matrices [III.50 §3](/part-03/linear-operators-and-their-properties). ical evidence that Dyson’s suggestion is correct and canbe extended to Dirichlet L - functions, as well as other types of L - functions. L - functions, and even to other statistics about quences of this new “random matrix theory” have been One note of caution. Few of the conjectured conse unconditionally proved, or seem likely to be in the fore-see able future.
It simply provides a tool to make predictions where that was too difficult to do before. However, there is at least one key question about which we still cannot make a well-substantiated prediction: how big does. og |ζ(1 +ζ(s)it)| gets larger than get on th(e1)2 - line? One can show that. og T for values of t close toever, it is unclear, even if we do not insist on a rigorous2 T, and that it gets no larger than log T. How - proof, whether the true maximal order is nearer the upper or lower bound.
9 Sieve Methods Almost all of our discussion so far has been about de-velopments of Riemann’s approach to counting primes. This approach is very delicate and not as adaptableas one might wish to many natural questions (such as counting However, one can go back tok-tuples of primes nsieve methods + a1$, n + a2$, . . . , n, which are + ak). modifications of the sieve of Eratosthenes, and at least get upper bounds. For example, suppose we want to find an upper bound for the number of prime pairsn, n + 2 with N < n ⩽ 2 N.
One possibility would be to fix a numbern, n + 2 with N < ny and determine for how many pairs⩽ 2 N it is the case that neither ny norto ben(+2 N)2 has a prime factor less tha(n1()/){2}, then this method would exactly county. If we took the twin primes, but it seems to be far too difficult toimplement. But it turns out that if instead we take$y$ to be a small power of N, then the calculations become much easier and there are methods of obtaining good bounds.
(However, the bounds given by these methods become less accurate as the power gets closer to 12.) of inclusion–exclusion into a useful tool in this type ofquestion. This principle is best exhibited when count-In the 1920 s Brun showed how to make the principle ing the number of integersto given integerm. We begin with the number of inte-n in a set S that are coprime gers in S, which is obviously more than the quantity we seek. Next, we subtract, for each prime the number of integers in S that are divisible byp dividingpm.
If,$345$ nwe have counted 1\in  S is divisible by exactly+ r . imes  (-1 r) prime factors offor the contribution ofm, thenn so far, which is less than or equal to 0, and less than 0 forr ⩾2; where as we wanted to count 0 when$r ⩾ 2$ (since that is less than the quantity we seek. To compensaten is not coprime to m). Thus we obtain a number for that, we add back in the number of integers indivisible bypq for each pair of primes p < q which S divide for the contribution ofm. We have now counted 1 n, which is greater than or equal + r . imes (-1) +r 2 . imes 1 to 0, and greater than 0 for r ⩾ 3.
Similarly, we subtract the number of integers divisible by For eachn \in  S we end up counting pqr, etc.(1 - 1)r fornof, where(m, n). Expanding this sum with the binomial the-r is the number of distinct prime factors orem we may reexpress this identity as follows. Letχ (n) = 1 if (n, m) = 1 and 0 otherwise. Thenmχm(n) =d | (m, n) μ(d),

where divisible by the square of a prime and equalsμ(m), the Möbius function$, equals 0 if$(-1)mω(m)is otherwise, where factors ofm. ω(m) is the number of distinct prime may be obtained from The inclusion–exclusion inequalities just discussed which holds for any The reason for using these abbreviated sums ratherω(d()d()|){(}m, n()⩽()2){k}+1μ(d)k ⩽⩾ χ0, by summing over allm(n) ⩽ω(d()d()|){(}m, n()⩽()2){k} μ(d)$, n \in S$.
than the complete sum is that there are far fewer terms and thus, when one sums over values ofn, there will be far fewer rounding errors (remember that it was round-ing errors that sank our attempt to estimate the number of primes up tothe other hand, they have the disadvantage that theyx using the sieve of Eratosthenes). On cannot possibly give the exact answer, since they are missing many appropriate terms. However, with a judicious choice ofk the missing terms do not contribute much to the complete sum and we get a good answer. Minor variants work well for many questions.
In the “combinatorial sieve” one selects which the upper and lower bound sums, not by counting thed are part of total number of prime factors they contain but instead using other criteria, such as the numbers of prime factors of method, Brun showed that there cannot be too manyd in each of several intervals. Using such a twin primes prime sp for whichp, p +2; indeed, the sum of 1 p + 2 is also prime, converges, in/p, over all contrast with (3).

346

with some num be rsd In the “Selberg upper bound sieve” one comes up⩽ D (where D is chosen to be not too large), with. ambda d that are nonzero only when the property that. umχm(n) ⩽d | n . ambda d 2 for all n.

Summing over the appropriate optimal solution by minimizing the resulting quad-none then finds the ratic form. Lower bounds can also be obtained outof Selberg’s methods. It was by using such methods that Chen was able to prove there are infinitely manyprimesp for which p + 2 has at most two prime fac- tors, and that Goldston, Pintz, and Yıldırım were able toestablish that there are some times short gaps between primes. These methods are also an essential ingredient in the work of Green and Tao.
One can also get good upper bounds on the number of primes in arithmetic progressions and short intervals: • the number of primes in any interval of length y• is never greater than 2 the number of primes less thany/ . og y; x in an arith-metic progression mod2$x/φ(q)\log (x/q)$. q is never greater than Notice that in each case the log in the denominator is of the number of integers being considered ($y$ andx/qwill only make a significant difference if the number, respectively), not logx as expected, though this of integers being considered is small.
Otherwise these inequalities are bigger than the expected quantity by a factor of 2. Can this “2” be improved? It will be difficult because we showed earlier that if there are Siegel zeros then we get twice as many primes as expected in certain arithmetic progressions. Therefore, if we can improve the “2” in these two formulas, then we can deduce that there are no Siegel zeros! 10 Smooth Numbers An integer isless than or equal toy - smoot hy .
A proportion 1 if all of its prime factors are - log 2 of the integers up to fix edu > 1 there exists some numberx are . qrt{x} - smooth, and indeed, for anyρ(u) > 0 such that if$x = yu$, then a proportion ρ(u) of the integers up toto have any easy definition in general. For 1 x are y - smooth. This proportion does not seem⩽ u ⩽ 2 we haveρ(u) = 1 -. og u, but for larger uit is best defined as ρ(u) = u(10)1 ρ(u - t) dt, IV. Branches of Mathematics anwhen we give precise estimates for questions that arise integral delay equation.
Such an equation is typical in sieve theory. Questions about the distribution of smooth numbers arise frequently in the analysis of algorithms, and have consequently been the focus of a lot of recent research. (See example of the use of smooth numbers.)computational number theory [IV.3 §3](/part - 04/computational - number - theory) for an 11 The Circle Method Another method of analysis that plays a prominent rolein this subject is the so-called circle method, which goes back to method uses the fact that, for any integer hardy [VI.73](/part - 06/godfrey - harold - hardy - 18771947) and
littlewood [VI.79](/part - 06/john - edensor - littlewood - 18851977). Thisn,$1$⎧⎨$1 if$ n = 0,$e2i$πnt dt =$0$⎩0 otherwise. For example, if we wish to count the number, solutions to the equationp+q = n with p and qr (n)prime,, of we can express it as an integral as follows: $r (n) = p$, q^⩽n 0 1 e2 i^π(p^+q^-n)t dtboth prime1 2=0 e^-2 i^πn(tp)prime^, p^⩽n e2 i^πpt dt. The first equality holds because the integrand is 0 whenp + q = n and 1 otherwise, and the second is easy to check. At first sight it looks more difficult to estimate the integral than it is to estimateis not the case.
For instance, the prime number theo-r (n) directly, but this rem for arithmetic progressions allows us to estimate P (t) = e2 iπpt when t is a rational /m with m small. For in this case,$p^{⩽}n P m = {}^{(}a$, m)=1 e2 iπa/mp⩽n, 1 pπ(n)≡a (modm) π(n). pprox e2 iπa/m φ(m) = \mu(m)φ(m).

Ifsuch values oftis sufficiently close to(a, m)t are called the=1 /mmajor arcs, then P (t)and we believe. pprox  P (/m); that the integral over the major arcs gives, in total, a very good approximation tor (n); indeed, we get something very close to the quantity one predicts from something like (15). Thus to prove the Goldbach conjecture we need to show that the contribution to the integral from the other values oft (that is, from the minor arcs fully do this, but no one has yet succeeded in doing so) is small. In many problems one can success-

IV.2. Analytic Number Theory

for the Goldbach problem. Also useful is the “discrete analogue” of the above: using the identity m(1 m)j=-0 1 e2 i^πjn/m dt = ⎧⎨⎩1 if0 otherwisen ≡ 0 (mod m), (which holds for any given integer$m ⩾ 1)$, we have thatm-1 r (n) =p$, q^{⩽}n m1j = 0 e2i^{π}j((p + q)-n)/m$ both primem-1= (e-2 i)πjn/m P (j/m)2 j = 0

provided but working modm > n. A similar analysis can be used herem some times has advantages, as it allows us to use properties of the multiplicative group modm. simple sums like sums Sums like. They play a central role in many of the calcu-P (j/m()n)⩽in the paragraph above or more N e2 iπ(nk)/m are called exponential la tions one does in analytic number theory. There are several techniques for investigating them. (1) It is easy to calculate the sumit is a geometric progression. With higher-degree poly-(n⩽)N e2 iπn/m, since nomials one can often reduce to this case;
for example, by writing$n - n = h \text{we have}$ 1 2 e2 iπ(n2)/m(n⩽)N = {}n\\\{}},\\\\\\\\\\\\\\\\\\\} (n⩽)N e2 iπ((n2()1()-n()2()2))/m=1 2 e2 iπ(h2)/m e4 iπhn/m,(|h()|){⩽}N \ma(x0()\\\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\\}){ - h}<n⩽. in N, N-h^

and the inner sum is now a geometric progression. (2) The work of Weil and Deligne, which gives very accu-rate results on the number of solutions to equations mod ly tic number theory. For example, the “Kl oos term a np, is ideally suited to many applications in ana- sum”a run over the integers mo(da()1()a()2)···a k ≡ b (modp)e2 iπ(ap1 an(d+a()2)+···+(b, p()a()k))/p=, where the1, appears i

naturally in many questions; Deligne showed that ithas absolute value less than or equal tokp((k-1))/ {}2, an extraordinary amount of cancellation in this sum which has about(pk)-1 summands, each of absolute value 1. (See the weil conjectures [V.35](/part-05/the-weil-conjectures).) (3) We discussed earlier the fact that the values of satisfy a symmetry about the line Re(s) =1, given byζ(s) the “functional equation.” There are other functions(called “modular functions”) that also have symme - 2 347 tries in the complex plane;
typically the value of the function ats is related to the value of the function at(αsing αδ+ β)/(γs-βγ =+1. Some times an exponential sum can beδ), for some integers α, β, γ, δ satisfy- related to the value of a modular function, and subse-quently to the value of that modular function at another point, using the symmetry of the function. 12 More L-Functions There are many types of L-functions beyond Dirichlet L - functions, some of which are well understood, some not(see L - functions [III.47](/part - 03/l - functions)).
The type that has received the most attention recently is a class ofcan be associated with elliptic curves (see L-functions that arithmetic geometryan equation of the form[IV.5 §5.1](/part - 04/arithmetic - geometry)). Any2 elliptic curve= x3 + ax +Ebis given by, where the$discriminant 4$ a3 + 27 b2 is nonzero. The associated L- function Euler product: L(E, s) is most easily described in terms of its L(E, s) =p 1 - a(pp)s + p(p2()s)-1$. (17) Here4$ a3+a27 pbis an integer which, for primes2, is defined to bep minus the number of solu-p not dividing tions(mod(x, y) (p).
It can be shown that each mod p) to the equation y|a2 ≡| is less thanx3 +ax +b2 when Re$\sqrt{p}$, so the Euler product above converges absolutely(s) >3. Therefore, (17) is a good definition for$p$ these values ofthe complex plane, as we did for2 s. Can we now extend it to the whole ofζ(s)? This is a very deep problem—the answer is yes; in fact, it is the celebrated theorem of Andrew Wiles that implied last theorem [V.10](/part-05/fermats-last-theorem). fermat’s distribution of values of primes Another interesting question is to understand thep.
These all lie in the intervalap/2. qrt{p} [as we range over - 1,1]. One might expect them to be uniformly distributed in the inter - val, but in fact this is never the case. As discussed in algebraic numbers where$|α | =$. qrt{p}, and[IV.1](/part-04/number-theory) one can writeα is called the Weil number. Ifap = αp + α ̄p , we write angle$θ α^{p} \in = √[0$, π]pe±. We can then think o(fi()θ){p}, thenp ap = 2. qrt{p}. os (θθpas belong-) for some ing to the upper half of a circle.
The surprise is that for almost all elliptic curves thep θp are not uniform lyp distributed, which would mean the proportion in a cer-tain arc would be proportional to the length of that arc. Rather, they are distributed in such a way that the pro-portion of them in any given arc is proportional to the area under that arc. This is a recent result of Richard Taylor. 348 L(E, s)on the line Re The correct analogue of the Riemann hypothesis for turns out to be that all the nontrivial zeros lie(s) = 1. This is believed to be true.
More - over, it is believed that they, like the zeros ofare distributed according to the rules that govern theζ(s), eigenvalues of randomly chosen matrices. These L-functions often have zeros at s = 1 (which is linked toture [V.4](/part - 05/the-\text{birchswinnerton} - dyer - conjecture)) and these zeros repel zeros of dirichlet the birch–swinnerton-dyer conjec - L - functions (which is what was used by Goldfeld, Gross, and Zagier, as mentioned in section 4, to get their lower bound on L-functions arise in many areas of arithmetic geom - h-q).
etry, and their coefficients typically describe the num-ber of points satisfying certain equations modp. The Langlands program tions at a deep level.seeks to understand these con nec of the same analytic properties as those discussedin this article. Selberg has proposed that this phe-It seems that every “natural”L-function has many nomenon should be even more general.
Consider sums$A(s) = a /n^{s} that\cdot\cdot$are well-defined when Rehave an Euler product· · · )nin this (or an even smaller) region,⩾ 1 n p(s) >(1 + 1, bp/ps + (bp)2/(p2)s +•have coefficients an that are smaller than any• given power of satisfy |bn| < κnn, onceθ for some constants nis sufficiently large,$θ <1 2 andκ > 0$.

Selberg conjectures that we should be able to give agood definition to A(s) on the whole complex plane, and that value of A(s)A(s)with should have a symmetry connecting the A(1-s). Further more, he conjectures that the Riemann hypothesis should hold for The current wishful thinking is that Selberg’s family A(s)! ofby Langlands. L-functions is precisely the same as those considered 13 Conclusion In this article we have described current thinking on several key questions about the distribution of primes.
It is frustrating that after centuries of research so little has been proved, the primes guarding their mysteries so jealously. Each new breakthrough seems to require brilliant ideas and extraordinary technical prowess. As euler [VI.19](/part-06/leonhard-euler-17071783) wrote in 1770: Mathematicians have tried in vain to discover some order in the sequence of prime numbers but we have every reason to believe that there are some mysteries which the human mind will never penetrate.

IV. Branches of Mathematics

Further Reading

Hardy and Wright’s classic book (1980) stands aloneamong introductory number theory texts for the quality of its discussion of analytic topics. The best intro-duction to the heart of analytic number theory is the masterful book by Davenport (2000). Everything you have ever wanted to know about the Riemann zeta function is in Titchmarsh (1986). Finally, there aretwo recently released books by modern masters of the subject (Iwaniec and Kowalski 2004; Montgomery and Vaughan 2006) that introduce the reader to the key issues of the subject.
nif i cant for this article, whose content is not discussedin any of the listed books. The reference list below includes several papers, sig Davenport, H. 2000.New York: Springer. Multiplicative Number Theory, 3 rd edn. Deligne, P. 1977. Applications de la formule des traces aux sommes trigonométriques. In Cohomologie Étale (SGA 4 1/2). Lecture Notes in Mathematics, volume 569. New York: Springer. Green, B., and T. Tao. 2008. The primes contain arbitrarily long arithmetic progressions. Annals of Mathematics 167: Hardy, G. H., and E. M. Wright. 1980.481–547.Theory of Numbers, 5 th edn. Oxford:
Oxford University An Introduction to the Ingham, A. E. 1949. Review 10,595 c (MR0029411).Press.mat ical Reviews. Providence, RI: American Mathematical Mathe Iwaniec, H., and E. Kowalski. 2004.Society. AMS Colloquium Publications, volume 53. Providence, RI: Analytic Number Theory. Montgomery, H. L., and R. C. Vaughan. 2006.American Mathematical Society.tive Number Theory I: Classical Theory. Cambridge: Cam-Multiplica Soundararajan, K. 2007. Small gaps between prime num-bridge University Press.bers: the work of Goldston–Pintz–Yıldırım. Bulletin of the Titchmarsh, E. C.
1986.American Mathematical Society Function, 2 nd edn. Oxford: Oxford University Press. The Theory of the Riemann Zeta-44:1–18. IV.3 Computational Number Theory

Carl Pomerance

1 Introduction

Historically, computation has been a driving force inthe development of mathematics. To help measure the sizes of their fields, the Egyptians invented geometry. To help predict the positions of the planets, the Greeks invented trigonometry. Algebra was invented to deal

IV.3. Computational Number Theory

with equations that arose when mathematics was usedto model the world. The list goes on, and it is not just historical. If anything, computation is more important than ever. Much of modern technology rests on algorithms that compute quickly:
examples range from the wavelets [VII.3](/part-07/wavelets-and-applications) that allow CAT scans, to the numerical extrapolation of extremely complex systems in order to predict weather and global warming, and to the combinatorial algorithms that lie behind Internet search engines (see the mathematics of algorithm design [VII.5 §6](/part-07/the-mathematics-of-algorithm-design)). of our great theorems and conjectures are, at root, motivated by computational experience.
It is said that In pure mathematics we also compute, and many gauss needed only to work out a concrete example or two[VI.26](/part-06/carl-friedrich-gauss-17771855), who was an excellent computational ist, to discover, and then prove, the underlying theorem. While some branches of pure mathematics have perhaps lost contact with their computational origins, the advent of cheap computational power and convenient mathematical software has helped to reverse this trend.
One mathematical area where the new emphasis on computation can be clearly felt is number theory, and that is the main topic of this
article. A prescient call-toarms was issued by Gauss as long ago as 1801: The problem of distinguishing prime numbers from composite numbers, and of resolving the latter into their prime factors, is known to be one of the most important and useful in arithmetic. It has engaged the industry and wisdom of ancient and modern geometersto such an extent that it would be superfluous to discuss the problem at length.
Nevertheless we must con-fess that all methods that have been proposed thus far are either restricted to very special cases or are so labo-rious and difficult that even for numbers that do not exceed the limits of tables constructed by estimable men, they try the patience of even the practiced calculator. And these methods do not apply at all to larger numbers. . . . Further, the dignity of the science itself seems to require that every possible means beexplored for the solution of a problem so elegant and so celebrated.
number theory, but essentially all branches of num-ber theory have a computational component. And in Factorization into primes is a very basic issue in some areas there is such a robust computational liter-ature that we discuss the algorithms involved as mathematically interesting objects in their own right. In this article we will briefly present a few examples of the computational spirit: in analytic number theory (the distribution of primes and the Riemann hypothesis);

349

in Diophantine equations (Fermat’s last theorem andthe ABC conjecture); and in elementary number theory (primality and factorization). A secondary theme that we shall explore is the strong and constructive inter-play between computation, heuristic reasoning, and conjecture. 2 Distinguishing Prime Numbers from Composite Numbers The problem is simple to state. Given an integer decide ifn is prime or composite. And we all know ann > 1, algorithm. Divide Either we find a proper factor, in which case we known by each positive integer in turn.
that know thatn is composite, or we do not, in which case wen is prime. For example, take n = 269. It is odd, so it has no even divisors. It is not a multiple of 3, so it has no divisor which is a multiple of 3. Continuing, we rule out 5, 7, 11, and 13. The next possibility, 17, hasa square that is greater than 269, which means that if 269 were a multiple of 17, then it would also have to be a multiple of some number less than 17. Since we have ruled that out, we can stop our trial division at 13 and conclude that 269 is prime.
(If we were actually carrying out the algorithm, we might try dividing 269 by 17, in which case we would discover that 269$= 15 \times 17 + 14$. At that point we would notice that the quotient, 15, is less than 17, which is what would tell us that 172 was greater than 269. Then we could stop.) In general, since a composite number d ⩽ . qrt{n}, one can give up on the trial dividing once onen has a proper factor d with passes$\sqrt{n}$, at which point we know that n is prime.
tal computation with small numbers, and for machine This straightforward method is excellent for men computation for some what larger numbers. But it scales poorly, in that if you double the number of digits of$n$, then the time for the worst case is squared; it is therefore an “exponential-time” algorithm. One might tolerate such an algorithm for twenty-digit inputs, but think how long it would take to establish the primalityof a forty-digit number! And you can forget about numbers with hundreds or thousands of digits.
The issue of how the running time of an algorithm scales when one goes to larger inputs is absolutely paramount inmeasuring one algorithm against another. In contrast to the exponential time it takes to use trial division torecognize primes, consider the problem of multiplying two numbers. The school method of multiplication is to take each digit of one number in turn and multiplyit by the other number, forming a parallelogram array.

350

One then performs an addition to obtain the answer. If you now double the number of digits in each number, then the parallelogram becomes twice as large in each dimension, so the running time grows by a factorof about 4. Multiplication of two numbers is an example of a “polynomial time” algorithm; its running timescales by a constant factor when the input length is doubled. lows. Is there a polynomial-time algorithm that distin-guishes prime numbers from composite numbers?
Is One might then rephrase Gauss’s call to arms as fol there a polynomial-time algorithm that can produce anontrivial factor of a composite number? It might not be apparent at this point that these are two different questions, since trial division does both. We will see, though, that it is convenient to separate them, as did Gauss. Let us focus on recognizing primes. What we would like is a simply computed criterion that primes satisfy and composites do not, or vice versa. An old theorem of Wilson might just fit the bill. Note that 6!$= 720$, which is just one less than a multiple of 7.
Wilson’stheorem asserts that ifn is prime, then (n - 1)!≡ −1(is explained inmod n). (The meaning of this and similar statements modular arithmetic [III.58](/part-03/modular-arithmetic).) This can- not hold whenfactor ofn and is smaller thann is composite, for ifn, then it is a fac-p is a prime tor of$(n - 1)(n$!+-1. Thus, we have an ironclad criterion for1)!, so it cannot possibly be a factor of primality. However, the Wilson criterion does not meet the standard of being simply computed, since we know no especially rapid way of computing factorials mod-ulo another number.
For example, Wilson predicts that 268!$≡ −1 (mod 269)$, as we have already seen that 269 is prime. But if we did not know this already, howin the world could we quickly find the remainder when 268! is divided by 269? We can work out the product268! one factor at a time, but this would take many more steps than trying divisors up to 17. It is hard to prove that something cannot be done, and in fact there is no theorem that says we cannot compute in polynomial time. We do know some ways of speed-$a$!
mod$b$ ing up the computation over the totally naive method, but all methods known so far take exponential time. So, Wilson’s theorem initially seems promising, but in fact it is no help at all unless we can find a fast way to compute$a$! modb. that 2 take 3 How about75== 128, which is 2 more than a multiple of 7. Or243, which is 3 mod 5. Fermat’s little theorem fermat’s little theorem [III.58](/part-03/modular-arithmetic)? Note

IV. Branches of Mathematics

tells us that ifa^n ≡ a (mod n)n. If computing a large factorial modulo is prime and a is any integer, thennpower modulo is hard, perhaps it is also hard to compute a largen. ple to see if any ideas pop up. Take that we are trying to compute 2 It cannot hurt to try it out for some moderate exam-91$amod 91$. A powerful = 2 and n = 91, so idea in mathematics is that of reduction. Can we reduce this computational problem to a smaller one? Notice that if we had already computed 245 mod 91, obtaining a remainder$r^{1}$, say$, then 291 ≡ 2(r1)2 (mod 91)$.
That is, it is just a short additional calculation to get to our goal, yet the power 45 is only half as big. How to continue is clear: we further reduce to the exponent 22, which isless than half of 45. If 222 mod 91$= r$, then 245 ≡ 2 r2(so on. It is not so hard to “automate” this procedure: mod 91). And of course 222 is the square of (22)11$, and2$ the exponent sequence 1, 2, 5, 11, 22, 45, 91 can be read directly from the binary (base 2) re pre sen-tation of 91 as 1011011, since the above sequence in binary is 1, 10, 101, 1011, 10110, 101101, 1011011.
These are the initial strings from the left of 1011011.And it is plain that the transition from one term to the next is either the double or the double plus 1. digits of This procedure scales nicely. When the number ofn is doubled, so is the sequence of expo - nents, and the time it takes to get from one exponentto the next, being a modular multiplication, is multiplied by 4. (As with naive multiplication, naive divide - with-remainder also takes four times as long when the size of the problem is doubled.) Thus, the over all timeis multiplied by 8, yielding a polynomial time method.
We call this the “powermod” algorithm. taking So, let us try to illustrate Fermat’s little theorem, a = 2 and n = 91. Our sequence of powers is21≡ 2$, 2^{2} ≡ 4, 2^{5} ≡ 32, 2^{1}1 ≡ 46,$ 222≡ 23, 2^45 ≡ 57, 2^91 ≡ 37, where each congruence is modulo 91, and each term in the sequence is found by squaring the prior one mod 91 or squaring and multiplying by 2 mod 91. that we are supposed to get 2 for the final residue? Well, yes, but this is guaranteed only if Wait a second: does Fermat’s little theorem not sayn is prime. And as you have probably already noticed, 91 is composite.
In fact, the computation proves this.

IV.3. Computational Number Theory

tion that proves that reveal any nontrivial factorization!Quite remarkably, here is an example of a com put a-n is composite, yet it does not as above, but to change the base of the power from2 to 3. The answer you should come to is that 3 You are invited to try out the powermod algorithm91≡ 3(orem holds. Since you already know that 91 is com-mod 91): that is, the congruence for Fermat’s little the posi te, I am sure you would not jump to the false conclusion that it is prime!
So, as it stands, Fermat’s little theorem can some times be used to recognize composites, but it cannot be used to recognize primes. There are two interesting further points to be made regarding Fermat’s little theorem. First, on the nega-tive side, there are some composites, such as$n = 561$, where the Fermat congruence holds for These num be rsn are called Carmichael numbers every integer, anda. unfortunately (from the point of view of testing primality) there are infinitely many of them, a result dueto Alford, Granville, and me.
But, on the positive side, if one were to choose randomly among all pairs for which$a^{n} ≡ a (mod n)$, with a < n and n bounded a, n by a large numberx, almost certainly (as x grows) you would choose a pair with myself.nprime, a result of Erd ̋os and with another elementary property of (odd) prime num-bers. If It is possible to combine Fermat’s little the ore mn is an odd prime, there are exactly two solu- tions to the congruence$x^{2} ≡ 1 (mod n)$, namely ±1.
Actually, some composites have this property as well, but composites divisible by two different odd primes do not. Now let us suppose thatn is an odd number and that we wish to determine whether it is prime. Suppose thatwe pick some number a with 1 ⩽ a ⩽ n - 1 and discover thatx2 = an(a-n()1)-1≡≡1 1(mod(modn)n). If we set; so, by the simple proper tyx = a((n-1))/ {}2, then of primes just mentioned, ifbe±1. Therefore, if we calculaten is prime, thena((n-1))/2 and discoverx must that it is not congruent to$±1 (mod n)$, then n must be composite. Let us try this idea with$a = 2$, n = 561.
We know already that 22280 mod 561? This too turns out to be 1, so we have560≡ 1 (mod 561), so what is not shown that 561 is composite. However, we can go further, since now we know that 2140 is also a square root of 1 and computing this we find that 2140≡ 67(that is notmod 561). So now we have found a square root of 1±1, which proves that 561 is composite. (Of course, for this particular number, it is obviously 351 divisible by 3, so there was not really any mystery about whether it was prime or composite.
But the method can be used in much less obvious cases.) In practice, there is no need to backtrack from a higher exponent to a smaller one. Indeed, in order to calculate 2560 mod 561 by the efficient method outlined earlier, one calculates the numbers 2140 and 2280 along the way, so that this generalization of the earlier test is both quicker and stronger. Suppose that not divisible by Here is the general principle that we have illustrated.n is an odd prime and letn. Write n - 1 = 2 st, wherea be an integert is odd. Then either at ≡ 1 (mod n) or (a2()i)t ≡ −1 (mod n) for somei = 0,1, . . .
, s - 1. Call this the strong Fer- mat congruence proved independently by Monier and Rabin, there is no. The wonderful thing here is that, as analogue of a Carmichael number. They showed that ifn is an odd composite, then the strong Fermat congru- ence fails for at least three quarters of the choices fora with 1 ⩽ a ⩽ n - 1. If you want only to be able to distinguish between primes and composites in practice, and you do not insist on proof, then you have read enough.
Namely, given a large odd number a at random from [1, n - 1 n], and begin trying to verify, choose twenty values of the strong Fermat congruence with these bases should ever fail, you may stop: the numbern must bea. If it composite. And if the strong Fermat congruence holds, we might surmise th atn were composite, the Monier–Rabin theorem says thatn is actually prime. Indeed, if the chance that the strong Fermat congruence would hold for twenty random bases is at most 4-20, which is less than one chance in a trillion. Thus we have aremarkable probabilistic test for primality.
If it tells us that composite; if it tells us thatn is composite, then we know for sure thatn is prime, then the chancesn is that negligible.n is not prime are so small as to be more or less If three quarters of the numbers a in [1, n - 1] pro- vide the key to an easily checkable proof that the odd composite numbern is indeed composite, surely it should not be so hard to find just one! How about checking small numbers Excellent, but when do we stop? Let us think about this a, in order, until one is found? for a moment.
We have given up the power of random-ness and are forcing ourselves to choose sequentially among small numbers for the trial bases argue heuristically that they continue to behave as ifa. Can we 352 they were random choices? Well, there ne ct i ons among them. For example, if taking are a some con-= 2 does not result in a proof thatn is composite, then neither will taking any power of 2. It is theoretically possible for2 and 3 not to give proofs thatn is composite but for 6 to work just fine, but this turns out not to be very common.
So let us amend the heuristic and assume that we have independence for prime values ofa. Up to log prime number the ore mn log log n there are about log[V.26](/part - 05/the - prime - number - theorem - and - the - vi34 - jnos - bolyai - 18021860) discussed later in thisn primes (via the article); so, heuristically, the probability thatposite, but that none of these primes help us to prove it, n is com-is about 4-. og n < n-4^/3. Since the infinite sum(n-4()/){3} converges, perhaps a stopping point of logis sufficient, at least for largen.
n log log n that a stopping point of Miller was able to prove the slightly weaker res ultc(. og n)2 is adequate, but his proof assumes a generalization of the hypothesis [V.26](/part-05/the-prime-number-theorem-and-the-vi34-jnos-bolyai-18021860). (We discuss the Riemann hypoth-riemann esis below; the generalization that Miller assumes is beyond the scope of this article.) In further work, Bach was able to show that we may take$c = 2 \text{in this}$ last result.
Summarizing, if this generalized Riemann hypothesis holds, and if the strong Fermat congruence holds for every positive integer a ⩽ 2(. og n)2, then n is prime. So, provided that a famous unproved hypoth-esis in another field of mathematics is correct, one can decide in polynomial time, via a deterministic algorithm, whether tempting to use nth is conditional test, for if it should is prime or composite.
(It has been ever lie to you and tell you that a particular compos-ite number is prime, then this failure—if you were able to detect it—would be a disproof of one of the most famous conjectures in mathematics. Perhaps this is nottoo disastrous a failure!) tinually challenging us was whether it is possible totest for primality in polynomial time with out assuming After Miller’s test in the 1970 s, the question con unproved hypotheses. Recently, Agrawal et al. (2004)answered this question with a resounding yes.
Their idea begins with a combination of the binomial theo-rem and Fermat’s little theorem. Given an integer a, consider the polynomial(x + a)n and expand it in the usual way through the binomial theorem. Each inter me-diate term between the leading xn and the trailing an has the coefficient1 and$n - 1$. If nis prime, then this coefficient, which$n$!$/(j$!(n - j)!) for some j between is an integer, is divisible byn because n appears as a factor in the numerator that is not canceled by any factors in the denominator. That is, the coefficient is

IV. Branches of Mathematics

0(mod n). For example, (x + 1)7 is equal tox7 + 7 x6 + 21 x5 + 35 x4 + 35 x3 + 21 x2 + 7 x + 1, and we see each internal coefficient is a multiple of 7.Thus, we have(x + 1)7 ≡ x7 + 1 (mod 7). (Two poly- nomials are congruent mod cie nts are congruent modn.) In general, ifnif corresponding coeffi-n is prime and idea and Fermat’s little theorem we havea is any integer, then via this binomial-theorem(x + a)n ≡ xn + an ≡ xn + a (mod n). It is an easy exercise to show that this congruence in the simple casea = 1 is actually equivalent to primality.
But as with the Wilson criterion we know no way of quickly verifying that all these coefficients are indeed divisible by However, one can do more with polynomials thann. raise them to powers. We can also divide one polynomial by another to find a quotient and a remain-der, just as we do with integers. It makes sense, for example, to say thatg(x) ≡ h(x) (mod f (x)), mean- ing that when divided byg(x) andf (x)h(x). We will write leave the same remainderg(x) ≡ h(x)(mod n, f (x)) if the remainders upon division by f (x) are congruent mod ri thm for integer congruences, we can quickly com put en.
As with the powermod algo-g(x)n (mod n, f (x)), provided the degree of f (x) is not too big. This is exactly what Agrawal et al. propose. They have an auxiliary polynomialf (x) of not-too-high degree such that, if

(x + a)n ≡ xn + a (mod n, f (x)) for each$a = 1$, 2, . . . , B, for a not-too-high bound B, then certain composites that are easily recognized as com-n must be in a set that contains the primes and posit es. (Not all composites are hard to recognize assuch, e.g., any number with a small prime factor is easy to recognize.) These ideas put together form the pri-mality test of Agrawal et al. To give the argument in full detail one has to specify the auxiliary polynomialf (x) that is used and what the bound B is, and one has to prove rigorously that it is exactly the primes which pass the test.
nomial ple Agrawal et al. (2004) show that the auxiliary poly-xr -f (x)1, with an elementary upper bound forcan be taken to be the beautifully sim-r of about about((. og . og n)n()5)10. Doing this leads to a time bound o(f.)5 for the algorithm. Using a numeri- cally ineffective tool, they bring the time bound downto(. og n()7()^{}.}){5}. Recently, Lenstra and I presented a not-so- simple but numerically effective method of bringing the

IV.3. Computational Number Theory

exponent on loging the set of polynomials used beyond those of then down to 6. We did this by expand- formxr -1: in particular we used polynomials that are related to Gauss’s famous algorithm for construction of certain regularn-gons with straightedge and compass (seeisfying to us to bring in a famous tool of Gauss to say algebraic numbers [IV.1 §13](/part-04/number-theory)). It was indeed sat something about his problem of distinguishing prime numbers from composite numbers. Are the new polynomial-time primality tests good in practice?
So far, the answer is no, the competition isjust too tough. For example, using the arithmetic of elliptic curves proofs of primality for huge numbers. This algorithm[III.21](/part-03/elliptic-curves) we can come up with bona fide is conjectured to run in polynomial time but we have not even proved that it always terminates. If, at the end of the day, or in this case the end of the run, we have alegitimate proof, then perhaps we can tolerate the situation of not being sure that it would work out when we started!
The method, pioneered by Atkin and Morain, has recently proved the primality of a number that has over 20 000 decimal digits, and is not of some special form such as 2 n - 1 that makes testing for primality easier. The record for the new breed of polynomial-time tests is a measly 300 digits. faster primality tests. Mersenne primes comprise the most famous of these forms; these are primes that are For numbers of certain special forms there are much 1 less than a power of 2. It is suspected that there are infinitely many examples, but we seem to be very far from a proof of this.
Just forty-three Mersenne primes are known, the record example being 230 402 457- 1, a prime with more than 9 For much more on primality testing, and for ref-.15 million decimal digits. erences to various other sources, see Crandall and Pomerance (2005). 3 Factoring Composite Numbers Compared with what we know about testing primality, our ability to factor large numbers is still in the dark ages. In fact this imbalance between the two problems forms the bulwark for the security of electronic commerce on the Internet.
(See mathematics and cryptography important application of mathematics, but also an odd[VII.7](/part-07/mathematics-and-cryptography) for an account of why.) This is a very one, and not something to brag about, since it depends on the in ability of mathematicians to efficiently solve a basic problem!Nevertheless, we do have our tricks. Part of the landscape is euclid’s algorithm [III.22] for computing the

353

greatest common divisor (GCD) of two numbers. One might naively think that, to find the GCD of two positive integers so rs and pick the largest one common to the two. Butm and n, one should find all of their divi Euclid’s algorithm is much more efficient: the number of arithmetic steps is bounded by the logarithm of the smaller number, so not only does it run in polynomialtime, it is in fact quite speedy.
So, if we can build up a special num berm that may be likely to have a nontrivial factor in common withwe can use Euclid’s algorithm to discover this factor.n, For example, Pollard and Strassen (independently) used this idea, together with fast subroutines for multiplication and polynomial evaluation, to enhance the trial division method discussed in the last section.
Some-what miraculously, one can take the integers up to(n1()/){2}, break them inton1/4 subintervals of length n1/4, and for each subinterval calculate the GCD ofn with the product of all the integers in the subinterval, spending only about(n1()/){4} elementary steps in total. If n is com- posite, then at least one GCD will be larger than 1, and then a search over the first such subinterval will locate a nontrivial factor of fastest rigorous and deterministic method of factoringn. To date, this algorithm is the that we know.
unproved but reasonable-seeming hypotheses about Most practical factoring algorithms are based on the natural numbers. Although we may not know howto prove rigorously that these methods will always produce a factorization, or do so quickly, in practice theydo. This situation resembles the experimental sciences, where hypotheses are tested against experiments. Our experience with certain factoring algorithms is now so overwhelming that a scientist might claim that a physical law is involved.
As mathematicians, we still search for proof, but fortunately the numbers we factor do not feel the need to wait for us. school years: factor 8051. The trick is to notice that8051 I often mention a contest problem from my high$= 902 - 72 = (90 - 7)(90 + 7)$, from which the factorization 83·97 can be read off. In fact every odd composite can be factored as the difference oftwo squares, an idea that goes back to fermat [VI.12](/part-06/pierre-fermat-1601665).
Indeed, ifu = 1(a + nb)has the nontrivial factorization and v = 1 (a - b)$, \text{so that nab}=$, then letu2 - v2, andifn ahas a divisor very close to2 = u + v, b = u - v2. This method works very welln1/2$, as n = 8051 does$, but in the worst case, the Fermat method is slower than trial division. 354 Kraitchik, Brillhart–Morris on, and Schroeppel) tries to efficiently extend Fermat’s idea to all odd composites. My quadratic sieve method (which follows work of For example, take wi thj = 41, and consider the num be rsn = 1649. We start just abovej2 - 1649.
Asn1/2 j runs, we will eventually hit a value where j2 - 1649 isa square, and so be able to use Fermat’s method. Let’stry it: 412- 1649 = 32,$422$- 1649 = 115,$432$- 1649 = 200,.. . Well, no squares yet, which is not surprising, since the Fermat method is often very poor. But wait, do the first and third lines not multiply together to give a square? Yes they do, 32$· 200 = 80^{2}$. So, multiplying the first and third lines, and treating them as congruences mod 1649, we have

$(41 · 43)2 ≡ 802 (mod 1649)$.

That is, we have a pair This is not quite the same as havingu, v with u2 u≡2 - v(v2)2(mod 1649 = 1649, but). we do have 1649 a divisor of$u2 - v2 = (u - v)(u + v)$. Now maybe 1649 divides one of these factors, but if it does not, then it is split between them, and so a computation of the GCD of u - v (or u + v) with1649 will reveal a proper factor. Now$u = 41· 43 ≡ 114 (mod 1649)$, and so we see instant lyv = 80 and that GCD of 114 u ≡ ±v (-80 mod 1649 = 34 with 1649 is 17. Dividing, we see), so we are in business. The$that 1649$= 17 · 97, and we are done. Can we generalize this?
In trying to factor$n = 1649$ we considered consecutive values of the quadratic poly-nomialf (j) = j2 - n for j starting just above . qrt{n}, and viewed these as congruences we found a set M of numbersj2 j ≡withf (j) (modf (j)n). Then equal to a square, say$u^{2} ≡ v^{2} (mod n)v$. Since2. We then letu ≡ ±v (u =modj^∈Mj^∈Mn), we couldj, so that splitn via the GCD of u - v and n. small example with form our square, but we ignored 115. If we had thought There is another lesson that we can learn from ourn = 1649.
We used 32 and 200 to about it, we might have noticed from the start that 32 and 200 were more likely to be useful than 115. The reason is that 32 and 200 areing that they have only small prime factors), while 115 smooth numbers (meanis not smooth, having the relatively large prime factor23. Say you havek + 1 positive integers that involve IV. Branches of Mathematics in their prime factorizations only the first It is an easy theorem that some nonempty subset ofk primes. these numbers has product a square.
The proof has us associate with each of these numbers, which can be written in the form(pa)1 (pa)2 · · · (pa)k, an exponent vec- tor even exponents, we really only care whether the expo-(a1, a2, . . . , ak). Since squares are detected by al(l1()2)k nentsa are odd or even. Thus, we think of these vec-i

tors as having coordinates 0 and 1, and when we add them (which corresponds to multiplying the underlying numbers), we do so mod 2. Since we have$k + 1 vectors$, each with only leads quickly to a nonempty subset that adds up to thek coordinates, an easy matrix calculation 0-vector. The product of the corresponding integers isthen a square.
third numbers, which are 3223 In our toy example with3052, have exponent vectors$n ==(5$1649, the first and2,503$,005)0andand 200(3, 0, 2=)$, which reduce tothe sum of them is(1$,0(,00,)0, and0)$, which indicates that we(1, 0, 0), so we see that have a square.
We were lucky that we could make dowith just two vectors, instead of the four that the above argument shows would be sufficient. numbers in the sequence nent vectors mod 2, and then uses a matrix to find a In general with the quadratic sieve, one finds smooth j2 - n, forms the expo- nonempty subset which adds up to the 0-vector, which then corresponds to a set M for which f (j) is aj\in M

square. In addition, the “sieve” in the quadratic sieve comes in with the search for smooth values of f (j) = j2 - n. These numbers are the consecutive values of a (quad-ratic) polynomial, so those divisible by a given prime can be found in regular places in the sequence. For example, in our illustration,$j^{2} - 1649 \text{is divisible by} 5$ precisely when$j ≡ 2 or 3 (mod 5)$. A sieve very much like the sieve of Eratosthenes can then be used to effi-ciently find the special numbers$j where j^{2} - n is$ smooth.
A key issue, though, is how smooth a valuef (j) has to be for us to decide to accept it. If we choose a smaller bound for the primes involved, we do not have to find all that many of them to use the matrix method. But such very smooth values might be very rare. If we use a larger bound for the primes involved, then smooth values off (j) may be more common, but we will need many of them. Some where between smaller and larger is just right! In order to make the choice, it would help to know how frequently values of an irreducible quadratic polynomial are smooth.
Unfor-tunately, we do not have a theorem that tells us, but we

IV.3. Computational Number Theory

can still make a good choice by assuming that this fre-quency is about that for a random number of the same size, an assumption that is probably correct even if itis hard to prove. Finally, note that if the final GCD yields only a trivial factor with more linear dependencies, each with a fresh chance at$n$, one can continue just a bit longer and find splittingn. These thoughts lead us to a time bound of about

. xp . og n log log n

for the quadratic sieve to factor exponential in the number of digits ofn. Instead of beingn, as with trial division, this is exponential in about the square rootof the number of digits ofn. This is certainly a huge improvement, but it is still a far cry from polynomialtime. toring method with the same time complexity as that Lenstra and I actually have a rigorous random fac above for the quadratic sieve. (It is random in the sense that a coin is flipped at various junctures, and decisions on what to do next depend on the out comes of these flips.
Through this process, we expect to get a bona fide factorization within the advertised time bound.) However, the method is not so computer practical, and ifyou had to choose in practice between the two, then you should go with the nonrigorous quadratic sieve. Atriumph for the quadratic sieve was the 1994 factorization of the 129-digit RSA cryptographic challenge first published in Martin Gardner’s column in Scientific American The number field sieve in 1977.
, which is another sieve-based factoring algorithm, was discovered in the late 1980 sby Pollard for integers close to powers, and later developed by Buhler, Lenstra, and me for general integers. The method is similar in spirit to the quadratic sieve, but assembles its squares from the product of certain sets of algebraic integers. The number field sieve has a conjectured time complexity of the type . xp (c(. og n()1()/){3}(log log n()2()/){3}), for a value ofc slightly below 2.
For composite numbers beyond 100 digits or so that have no small prime factor, it is the method of choice, with the current record being 200 decimal digits. property that if you use them, then all composite num-bers of about the same size are equally hard to factor. The sieve-based factorization methods share the For instance, factoringis a product of five primes each roughly near the fifthnwill be about as difficult ifn 355 root of roughly near the square root ofn as it will be if n is a product of two primesn.
This is quite unlike trial division, which is happiest when there is a small prime factor. We will now describe a famous factorization method due to Lenstra that detects small prime factors before large ones, and beyond baby cases is much superior to trial dividing. This is his method. elliptic curve Just as the quadratic sieve searches for a number mcurve method.
But where the quadratic sieve pains tak-with a nontrivial GCD with n, so does the elliptic ingly builds up to a successful ces ses, the elliptic curve method hopes to hit uponm from many small suc - m with essentially one lucky choice.
 with imagine that if Choosing random num be rsn can also have instant success, but you can welln has no small prime factors, then them and testing their GCD expected time for success would be enormous. Instead, the elliptic curve method involves considerably more cleverness. Consider first the “p - 1 method” of Pollard. Suppose you have a number large numberk. Unbeknownst to you, n you wish to factor and a cer ta inn has a prime factor factorqp withwithqp--1 not a divisor of1 a divisor of k, and another primek. You can use this imbalance to split orem there are many numbers n.
First of all, by Fermat’s little the-$u with u^{k} ≡ 1 (mod p) and$m beu(uk)k≡-11 reduced mod(mod q). Say you have one of these, and letn. Then the GCD of m and n is a nontrivial factor ofq. Pollard suggests tak i ngn; it is divisible byk as the least common mul-p but not by tiple of the integers to some moderate bound so that ithas many divisors and perhaps a decent chance that it is divisible byis whenn has a prime factorp -1. The best case of Pollard’s method p with p - 1 smooth (has all small prime factors—see the quadratic sieve discus-sion above).
But ifn has no prime factors p with p - 1 smooth, Pollard’s method fares poorly. prime the What is going on here is that corresponding to thep - p1 nonzero residues modwe have the multiplica tiv ep. Further more, when group[I.3 §2.1](/part - 01/fundamental - definitions) of doing arithmetic modton, we are, whether we realize it or not, doing arith - n with numbers relatively prime metic in this group. We are exploiting the fact that$uk$is the group identity mod Lenstra had the brilliant idea of using the Pol la rdp, but not mod q. method in the context of elliptic curve groups.
There are many elliptic curve groups associated with the prime where the number of elements is smooth. Of greatp, and therefore many chances to hit upon one 356 importance here are theorems of Hasse and Deuring. An elliptic curve [III.21](/part - 03/elliptic - curves) modp (for p > 3) can be taken as the set of solutions to the congruence x3 + ax + b (mod p), for given integers a, bywith^2 ≡ the property thatx3 + ax + b does not have repeated roots modity” thrown in (see below). A fairly simple addition law$p$.
There is one additional “point at infin(but not as simple as adding coordinatewise!) makes the elliptic curve into a group, with the point at infinityas the identity (see rational points on curves and the mordell conjecture later generalized by weil [VI.93](/part-06/andr-weil-19061998) with his famous proof[V.29](/part-05/rational-points-on-curves-and-vi40-ernst-eduard-kummer-18101893)).
Hasse, in a result of the “Riemann hypothesis for curves,” showed us that the number of elements in the elliptic curve group always lies between$p + 1 - 2 \sqrt{p} and p + 1 + 2 \sqrt{p} (see$ the weil conjectures that every number in this range is indeed associated[V.35](/part-05/the-weil-conjectures))). And Deuring proved with some elliptic curve modp. choose(mod Say we randomly choose integersn)b. This gives us the curve with coefficients so that(y1)2 is congruent tox1, y(x1()3)1$, a+$, and thenax1 a+, bb and a point mimic the Pollard strategy, with a number$P = (x1$, y1) on the curve.
One can thenk as before with many divisors, and with the point role ofu. Let k P denote the k-fold sum of P playing the P added to itself using elliptic curve addition. Ifinfinity on the curve considered modk Pp (which it will beis the point at if the number of points on the curve is a divisor ofk), but not on the curve considered modus a num berm whose GCD with n is divisible byq, then this givesp and not by To see whereq. We will have fact ore dm comes from it is convenient to con-n. sider the curve projectively:
we take solutionsof the congruence$y^{2}z ≡ x^{3} + axz^{2} + bz^{3} ((x$, y, z)mod p). The triple(cx, cy, cz) when c = 0 is considered to be the same asis now demystified; it is just(x, y, z). The mysterious point at infinity(0,1,0). And our point P is(x1, y1, 1). (This is the mod p version of classical pro- jective geometry compute the pointk P[I.3 §6.7](/part-01/fundamental-definitions).) Say we work mod$= (x$, y , z ). Then the candi-n and date for the number point at infinity mod$mp$, thenis justkz zk≡k.
Indeed, if0 k (mod p)k P, and if itis the is not the point at infinity mod When Pollard’sp - 1 method fails, our only recoursekq, then zk ≡ 0 (mod q). is to raise things do not work for our randomly chosen curve, wek or give up. With the elliptic curve method, if can pick another. Corresponding to the hidden prime$p$ inmodn, we are actually picking new elliptic curve group sp, and so gaining a fresh chance for the number of elements in the group to be smooth. The elliptic curve

IV. Branches of Mathematics

method has been quite successful in factoring numbers which have a prime factor up to about fifty decimal digits, and occasionally even some what larger primes have been discovered. curve method to find the least prime factorabout We conjecture that the expected time for the ellipticp of n is. xp  2 log p log log p

arithmetic operations mod from proving this conjecture is not lack of know led gen. What is holding us back about elliptic curves, but rather lack of knowledge ofthe distribution of smooth numbers. ods, the reader is referred to Crandall and Pomerance(2005).For more on these and other factorization meth4 The Riemann Hypothesis andthe Distribution of the Primes As a teenager looking at a modest table of primes, Gauss conjectured that their frequency decays loga-rithmically and that li(x) =x (1/ . og t) dt should be a good approximation for between 1 and$x$.
Sixty years later,π(x)2, the number of primes riemann [VI.49] showed how Gauss’s conjecture can be proved if one assumes that the Riemann zeta functionζ(s) = n-s has no zeros in the complex half-plane where the real part of$s \text{is greater than}^{1}$. The series for ζ(s) conver gesn only for Re Res > 0, with a simple pole ats > 1, but it may be analytically continued to2 s = 1.
(For a brief descrip- tion of the process of analytic continuation, see fundamental mathematical definitions [I.3 §5.6](/part-01/fundamental-definitions).)some This continuation may be seen quite concretely via the= - - . nfty ({ }-s)-1 { } identity the fractional part ofζ(s) s/(s x1)(so thats1 x{xx} = xd-x, with[x]): note$x$ that this integral converges quite nicely in the half-plane Re$s >$0. In fact, via Riemann’s functional equation mentioned below, morphic function in the whole complex plane, with theζ(s) can be continued to a mero- single pole at The assertion thats = 1.
ζ(s) = 0 for Re s >1 is known as thethe most famous unsolved problem in mathematics.riemann hypothesis [IV.2 §3](/part-04/number-theory); arguably it is2 Though[VI.67](/part-06/charles-jean-de-la-valle-poussin-18661962) were able in 1896 to prove (independently) a hadamard [VI.65](/part-06/jacques-hadamard-18651963) and de la vallée poussin weak form of Gauss’s conjecture known as the prime number theorem strength of the approximation li[V.26](/part-05/the-prime-number-theorem-and-the-vi34-jnos-bolyai-18021860), the apparent breathtaking(x) to π(x) is uncanny. For example, take$x$ = 1022.
We haveπ(1022) = 201 467 286 689 315 906 290

IV.3. Computational Number Theory

exactly, and, to the nearest integer, we have

li$(10^{2}2) \approx 201 467 286 691 248 261 497$. As you can plainly see, Gauss’s guess is right on the money! numerical methods for integration, and it is directly The numerical computation of li(x) is simple via obtainable in various mathematics computing pack-ages. However, the computation of$π(10^{2}2) (\text{due to}$ Gourdon) is far from trivial. It would be far too labo-rious to count these approximately 2$\times 10^{2}0 primes$ one by one, so how are they counted? In fact, we have various combinatorial tricks to count with out listing everything.
For example, one does not need to count one by one to see that there are exactly 2$[10^{2}2/6] + 1$ integers in the interval from 1 to 1022 that are relatively prime to 6. Rather, one thinks of these numbers grouped in blocks of six, with two in each block coprime to 6. (The “$+$1” comes from the partial block at the end.) Building on early ideas of Meissel and Lehmer, Lagarias, Miller, and Odlyzko presented an elegant combinato-rial method for computingπ(x) that takes about (x2()/){3} elementary steps.
The method was refined by Delégliseand Rivat, and then Gourdon found a way to distribute the computation to many computers. From work of von Koch, and later Schoenfeld, we know that the Riemann hypothesis isassertion that equivalent to the

$|π(x) - li(x)| < \sqrt{x} \log x (1)$

for all cise 1.37). Thus, the mammoth calculation ofx ⩾ 3 (see Crandall and Pomerance 2005, exer-π(1022) might be viewed as computational evidence for the Riemann hypothesis—in fact, if the count had turned outto violate (1), we would have had a disproof. tion of the zeros of It may not be obvious what (1) has to do with the loca-ζ(s). To understand the connection, let us first dismiss the so-called “trivial” zeros, which occur at each negative even integer. The nontrivial zeros tioned above, are conjectured to satisfy Reρare known to be infinite in number, and, as men-$ρ ⩽^{1}$.
There are certain symmetries among these zeros: indeed, ifis a zero, then so ar$\bar{e}ρ$, 1 - ρ, and 1 - ρ ̄. Therefore, the2ρ Riemann hypothesis is the assertion that every nontriv-ial zero has real part equal to 1 . (The symmetry with $ρequationand 1 -ζ(ρ$, which follows from Riemann’s functional1- s) = 2(2π)-s . os2 ( {}1πs)Γ (s)ζ(s), per- haps provides some heuristic support for the Riemann2 hypothesis.)

357

fundamental theorem of arithmetic yields the identity The connection to prime numbers begins with[V.14](/part-05/the-fundamental-theorem-of-arithmetic), which the ζ(s) =n . nfty=1 n-s =p primej . nfty = 0 p-js= (1 - p-s )-1, pprime

a product that converges when Rethe logarithmic derivative (that is, taking the logarithms > 1. Thus, taking of both sides and then differentiating), we have. nftyζζ(s)(s) = − p. og s - p1 = − . og pjsp}.pprim(ep)primej = 1 That is, if we defineΛ(n) to be log p if n = pj for a primep and an integer j ⩾ 1, and Λ(n) = 0 if n is not of this form, then we have the identity$\infty Λ(n) = −ζ (s)$.n^s ζ(s)

Through various relatively routine calculations, one can then relate the function n=1ψ(x) =n ⩽ x Λ(n)to the residues at the poles ofζ^ /ζ, which correspond to the zeros (and single pole) of showed, we have the following beautiful formula:ζ. In fact, as Riemannψ(x) = x -ρ xρρ - . og (2π) -1 2 . og (1 - x - 2) ifsum over the nontrivial zerosx itself is not a prime or prime power, and where theρ of ζ is to be understood in the symmetric sense where we sum over those|Im ρ| < T and let T →. nfty.
Through elementary manip-ρ with ula tions, an understanding of the functionily gives an equivalent understanding ofπ(x)ψ(x), and itread- should be clear now thatto the nontrivial zerosρ ofψ(x)ζ. is intimately connected pretation. It is the logarithm of the least common mul-tiple of the integers in the interval The functionψ(x)defined above has a simple inter-[1, x]. As with (1) we have an elementary translation of the riemann hypothesis: it is equivalent to the assertion that

$|ψ(x) - x| < \sqrt{x} \log^{2} x$

for allx ⩾ 3. This inequality involves only the ele- ment ary concepts of least common multiple, natural logarithm, absolute value, and square root, yet it is equivalent to the Riemann hypothesis. been calculated and it has been verified that they lie on A number of nontrivial zerosρ of ζ(s) have actually

358

the line re computationally verify that a complex numbers =^1^2 . One might wonder how some one canρ has re calculations to (an unrealistically large) 10ρ =^1^2. For example, suppose that we are carrying^10 significant digits, and suppose we come across a zero with real part 1+ 10^-^10^100 . It would be far beyond the precision of the calculation to be able to distinguish this num-ber from2 1 itself. Nevertheless, we do have a method for seeing if particular zeros are two ideas involved, one of which comes from ele-2$ρ \text{satisfy Re} ρ = {}^{12}$. There ment ary calculus.
If we have a continuous real-valued functionf (x)defined on the real numbers, we can some times use the intermediate value theorem to count zeros. For example, say0. Then we know for sure thatf (1) > f0, has at least one zerof (1.7) < 0, f (2.3) >$between 1 and 1and 2$.3. If we know for other reasons that.7, and at least one zero between 1 f has exactly.7 two zeros, then we have accounted for both of them.
To locate zeros of the complex function valued functiong(t) is constructed with the propertyζ(s), a real- that sign changes forζ(1 2 + it) = 0 if and only ifg(t) for 0 < t < Tg(t), we can get a = 0. By looking at lower bound for the number of zeros$ρ of ζ \text{with Re} ρ = {}^{12}$ and 0 argument principle< Im ρ < T. In addition, we can use the so-called from complex analysis to count the exact number lucky and this exact count is equal to our lower bound, of zeros with 0< Im ρ < T.
If we are then we have accounted for all ofing that they all have real part 1 (and, in addition, thatζ’s zeros here, show they are all simple zeros). If the counts did not match, it would not be a disproof of the Riemann hypothesis,2 but certainly it would indicate a region where we should be checking the data more closely. So far, whenever we have tried this approach, the counts have matched, though some times we have been forced to evaluateg(t) at very closely spaced points. The first few nontrivial zeros were computed by Riemann himself.
The famous cryptographer and early computer scientist some zeta zeros. The current record for this kind ofalan turing [VI.94](/part-06/alan-turing-19121954) also computed calculation is held by Gourdon, who has shown that the first 1013 zeta zeros with positive imaginary part all have real part equal to 12, as predicted by Riemann. Gourdon’s method is a modification of that pioneeredby Odlyzko and Schönhage (1988), who ushered in the modern age of zeta-zero calculations. Explicit zeta-function calculations can lead to highly useful explicit prime number estimates.
Ifnth prime, then the prime number theorem implies pn is the that$pn ∼ n \log n as n →$. nfty. Actually, there is a sec-

IV. Branches of Mathematics

ondary term of or de rc ient ly largen, we have np log log> nn. og, and so for all suffi-n. By using explicit zeta estimates, Rosser was able to put a numerical bound on the “sufficiently large” in this statement, and$n$ then, by checking small cases, was able to prove thatin factp > n . og n for every n. The paper of Rosser and Schoenfeld (1962) is filled with highly useful and numerically explicit inequalities of this kind.$n$ hypothesis had been proved. Mathematics is never Let us imagine for a moment that the Riemann “used up,” as there is always that next problem around the bend.
Even if we know that all of zeta’s nontrivial zeros lie on the line Imthey are distributed on this line. We have a fairly con-$s = {}^{12}$, we can still ask how cise understanding of how many zeros there should be up to a given height T . In fact, as already found by Riemann, this count is about$(1/2π)T \log T$. Thus, on average, the zeros would tend to get closer and closer with about(1/2π). og T of them in a unit interval near height T .
tween one zeta zero and the next, but there is much more that one can ask about how these spacings are This tells us the average distance, or spacing, be distributed. In order to discuss this question, it is very convenient to “normalize” the spacings, so that the average (normalized) gap between consecutive zeros is 1. By Riemann’s result, together with our assumption of the Riemann hypothesis, this can be done ifwe multiply a gap near$T by (1/2π) \log T$, or, equiv- alently, if for each zero par tt = Im ρ by (1/2π)tρ. og we replace its imaginaryt.
In this way we arrive at a sequence consecutive zeros, which on average are about 1.δ1, δ2, . . . of normalized gaps between with others close to 0; it is just the average that is 1.Checking numerically, we see that someδn are large, Mathematics is well equipped to study random phe-nomena, and we have names for various probability distributions Is this what is happening here? These zeta zeros are[III.71](/part-03/probability-distributions), such as Poisson, Gaussian, etc. not random at all, but perhaps thinking in terms of randomness has promise.
Pólya suggested that the zeros of the zeta function In the early twentieth century, hilbert [VI.63](/part-06/david-hilbert-18621943) and might correspond to the operator [III.50](/part-03/linear-operators-and-their-properties). Now this is provocative! But what eigenvalues [I.3 §4.3](/part-01/fundamental-definitions) of some operator? Some fifty years later in a now famous conversation between Dyson and Montgomery at the Institute for Advanced Study, it was conjectured that the nontrivial zeros behave like the eigenvalues of

IV.3. Computational Number Theory

1.0

0.8

0.6

Density

0.4

0.2

0 0.5 1.0 Normalized spacing1.5 2.0 2.5 3.0

Figure 1 and the Gaudin distribution. Nearest-neighbor spacing a random matrix from the so-calledtary ensemble. This conjecture, now known as the Gaussian uni GUE conjecture, can be numerically tested in vari-ous ways. Odlyzko has done this, and found persuasive evidence for the conjecture: the higher the batches of zeros one looks at, the more closely their distribution corresponds to what the GUE conjecture predicts. nparts of these zeros are around 1 For example, take the 1 041 417 089 numbers starting at 1023 + 17 368 588 794.
(The imaginary.3 . imes  1022.) For eachδn with interval(j/100, (j + 1)/100] we can compute the pro- portion of these normalized gaps that lie in this inter-val, and plot it. If we were dealing with eigenvalues from a random matrix from the GUE, we would expect these statistics to converge to a certain distribution known as theno closed formula, but which is easily computable).Gaudin distribution (for which there is Odlyzko has kindly supplied me with the graph in fig-ure 1, which plots the Gaudin distribution against the data just described (but leaves out every second data point to avoid
clutter). Like pearls on a necklace! The fit is absolutely remarkable. The vital interplay of thought experiments and numerical computation has taken us to what we feel is a deeper understanding of the zeta function. But where do we go next? The GUE conjecture suggests a con-nection to random matrix theory, and pursuing further connections seems promising to many. It may be that random matrix theory will allow us only to formulate

359

great conjectures about the zeta function, and will not lead to great theorems. But then again, who can deny the power of a glimpse at the truth? We await the next chapter in this development. 5 Diophantine Equations and the ABC Conjecture Let us move now from the Riemann hypothesis tomat’s last theorem [V.10](/part-05/fermats-last-theorem). Until the last decade it fer too was one of the most famous unsolved problemsin mathematics, once even having a mention on an episode oftionxn + y Star Trekn = zn has no solutions in positive inte-.
The assertion is that the equa- gersx, y, z, n, where n ⩾ 3.
 This conjecture had remained unproved for three and a half centuries until Andrew Wiles published a proof in 1995. In addition, perhaps more important than the solution of this particular Diophantine equation (that is, an equation where the unknowns are restricted to the integers), the centuries-long quest for a proof helped establish the field ofthe proof itself established a long-sought and wonder-algebraic number theory [IV.1](/part-04/number-theory). And ful connection between elliptic curves.
modular forms [III.59](/part-03/modular-forms) and That is, just in case you are not an expert on all of the But do you know why Fermat’s last theorem is true? intricacies of the proof, are you surprised that there are in fact no solutions? In fact, there is a fairly simple heuristic argument that supports the assertion. First note that the casen = 3, namely x3 + y3 = z3, can be handled by elementary methods, and this in fact had already been done by euler [VI.19](/part-06/leonhard-euler-17071783). So, let us focus on the cases when powers of integers.
How likely is it that the sum of twon ⩾ 4.1 Let Sn be the set of positive nth members ofall likely, since Wiles has proved that this never occurs!Sn is itself a member of Sn? Well, not at But recall that we are trying to think naively. Sn Let us try to mimic our situation by replacing the set with a random set. In fact, we will throw all of the powers together into one set. Following an idea of Erd ̋and Ulam (1971) we create a set Rby a random process: os each integer chance it gets thrown intom is considered independently, and the R is proportional to (m - 3()/){4}.
This process would typically give us aboutx1/4 num- bers in R in the interval [1, x], or at least this would be the order of magnitude. Now the total number of fourth and higher powers between 1 andx is also about x1/4, but we ignore this.1. Actually, Fermat himself had a simple proof in the case n = 4,

360

so we can take our random set R as modeling the sit- uation for these powers, namely the union of all sets S for n ⩾ 4. We ask how likely it is to have a + b = c wheren a, b, and c all come from R. astional to The probability that a number a + b with 0 < a < b < m(a-3()/){4}(m -anda)m-3 may be represented a, (b/)4, since for each∈ R is propor-a less than R is a-3/4 m(m0<a<m/the probability that - a)-2 3/4. Actually, there is a minor caveat a and m -a both lie in whento cover this, we add the single termm is even, since then a = m - a(1 whenm)-3(a/)4=to th(e1)2 m: above sum.
Replacing eachwe get a larger sum that is easy to estimate and turnsm - a in the sum wit(h2()1)2 m, out to be proportional to(m-1()/){2}. That is, the chance that a random number R is at most a certain quantity that is proportional tom is a sum of two members ofm-1/2. Now the events that would have to occur formthanto be given as such a sum involve numbers small erm, so the event that m itself is in R is indepen- dent of these.
Therefore, the probability that only the sum of two members of R, but also itself am is not member of(m-1()/){2}(m-3()/){4}R=, is at most a quantity proportional to(m-5()/){4}. So now we can count how many times we should expect a sum of two members of itself be a member of R. This is at most a constant times R tom-5/4. But this sum is convergent, so we expect only finitely many examples. Further, since the tail ofa convergent series is tiny, we do not expect any large m examples. Thus, this argument suggests that there are at most finitely many positive integer solutions to

$x^{u} + y^{v} = z^{w}$, (2)

where the exponents mat’s last theorem is the special case whenu, v, w are at least 4. Since Fer-u = v = w, we would have at most finitely many counterexamples to that as well. There are actually This seems tidy enough, but now we get a surprise!infinitely many solutions to (2) in positive integers with note that 174+344 u=, 17 v,5 w. This is the case all at least 4. For example, a = 1, b = 2, ugers, and=4 of a more general identity: ifc = au + bu, we have (ac)a, bu are positive inte-+ (bc)u = (cu)+1.
Another way to get infinitely many examples is to build on the possible existence of just one example. Ifx, y, zthe same exponents, we may replace, u, v , w are positive integers satisfying (2), then withx, y , z with a^vw x, a^uw y , a^uvz for any integer a, and so get infinitely many solutions.

IV. Branches of Mathematics

side ring—that a given integer is a power—are not quite independent. For instance, if The point is that events of the kind that we are con-A and B are both uth pow- ers, then so isinfinite families just mentioned. AB, and this idea is exploited in the the rescue of our heuristic argument? One simple way So how do we neatly bar these trivialities and come to to do this is to insist that the numbers relatively prime.
This gives no restriction whatsoever inx, y, z in (2) be the Fermat case of equal exponents, since a solution toxn +yn = zn with d the greatest common divisor of x, y(z/d), z leads to the coprime solutio nn$. (x/d)n + (y/d)n =$ Concerning Fermat’s last theorem, one might ask how far it had actually been verified before the final proof by Wiles. The paper by Buhler et al. (1993) reports a verification for all exponents type of calculation, which is far from trivial, has itsn up to 4 000 000. This roots in nineteenth-century work of kummer [VI.40] and early-twentieth-century work of Vandiver.
In fact, Buhler et al. (1993) also verify in the same range a related conjecture of Vandiver dealing with cyclo-tomic fields, but this conjecture may in fact be false in general. The probabilistic thinking above, combined with computation of small cases, can carry us deeply into some very provocative conjectures. The above probabilistic argument can easily be extended to suggest that (2) has at most finitely many relatively prime solutio nsw with 1 x, y/u, z+over all possible exponent triples1/v + 1/w < 1.
This conjecture hasu, v , come to be known as the Fermat–Catalan conjecture, since it contains within it essentially Fermat’s last theorem and also the Catalan conjecture (recently proved by Mih ̆a ilescu) that 8 and 9 are the only consecutive powers. there are topic of computing comes in. For example, since 1 It is good that we do allow for the possibility that some solutions, and this is where our main$+8 =$ 9, we have a solution toy = 2, and z = 3.
(The exponent 7 is chosen to insurex7 + y3 = z2$, where x = 1$, that the reciprocal sum of the exponents is less than 1.Of course, we could replace 7 by any larger integer, but since in each case the power involved is the number 1, they should all together be considered as just one example.) Here are the known solutions to (2): 1$n + 23 = 32$,$25$+ 72 = 34,$132$+ 73 = 29, IV.3. Computational Number Theory 27$+ 173 = 712$,$35$+ 114 = 1222,$338$+ 1 549 0342 = 15 6133, 14143$+ 2 213 4592 = 657$,

92623$+ 15 312 283^{2} = 113^{7}$,$177$+ 76 2713 = 21 063 9282,$438$+ 96 2223 = 30 042 9072.

The larger members were found in an exhaustive computer search by Beukers and Zagier. Perhaps this is the complete list of all solutions, or perhaps not—we have no proof. be said. Using results from a famous paper of Faltings, However, for particular choices ofu, v, w, more can Darmon and Granville (1995) have shown that for any fixed choice ofu, v, w with reciprocal sum at most 1, there are at most finitely many coprime triples$z solving (2)$. For a particular choice of exponents, onex, y, might try to actually find all of the solutions.
If it can be handled at all, this task can involve a delicate inter-play between arithmetic geometry [IV.5](/part-04/arithmetic-geometry), effective methods in transcendental number theory, and good hard computing. In particular, the exponent triple sets$\\{2}$,3,7\\\\\\\\\\\\\\\\\\\\\}, 2, 3, 8$, \\{2}$, 3, 9\\, and 2, 4, 5} are known to have all their solutions in the above table. See Poonen et al. (2007) for the treatment of the case$\\{2}$, 3, 7\\\\\\\\\\\\\\\\\\\} and links to other work. is deceptively simple.
It involves positive integer solu-tions to the equation the abc conjecture$a +$[V.1](/part-05/the-abc-conjecture) of Oesterlé and Masser$b = c$, hence the name. To put some meaning into$a + b = c$, we define the radical of a nonzero integern as the product of the primes that divide ple, rad(10)n=, denoting this as rad10, rad(72) = 6, and rad(n). So, for exam-(65 536) = 2. In particular, high powers have small radicals in comparison to the number itself, and so do many other numbers. Basically, the ABC conjecture asserts that if a + b = c, then the radical of abc cannot be too small.
More specifically we have the following. The ABC conjecture. For eachε > 0 there are at most finitely many relatively prime positive integer trip lesb, c with a + b = c and rad(abc) < (c1()-){ε}. a, Note that the ABC conjecture immediately solves the Fermat–Catalan problem. Indeed, ifintegers with 1/u + 1/v + 1/w < u1, then it is easily, v, w are positive found that we must have 1$/u + 1/v + 1/w ⩽ 41/42$. Suppose we have a coprime solution to (2). Thenx ⩽$361$ zw/u and y ⩽ zw/v, so that rad(xuyv zw ) ⩽ xyz ⩽ (zw )41^/42.

Thus, the ABC conjecture with$ε = 1/42 \text{implies that}$ there are at most finitely many solutions. sequences; for a delightful survey, see Granville and Tucker (2002). In fact, the ABC conjecture and its gen-The ABC conjecture has many other marvelous con eral iz at i ons can be used to prove so many things that I have joked that it is beginning to resemble a false state-ment, since a false statement implies everything. But probably the ABC conjecture is true. Indeed, though abit harder to see, the Erd ̋os–Ulam probabilistic argument can be modified to provide heuristic evidence forit too.
 on the distribution of integersis below some bound. These ideas, which lead to a Basic to this argument is a perfectly rigorous res ultn for which rad(n) more explicit version of the ABC conjecture, are worked through in the thesis of van Frankenhuijsen and by Stewart and Tenenbaum. Here is a slightly weaker statement: ifa +b = c are relatively prime positive integers andcis sufficiently large, then we have. qrt$rad$(abc) > (c1()-1)/ . og c. (3) dence stacks up against (3). This inequality asserts that if rad One might like to know how the numerical evi-(abc) = r , then log(c/r )/ . og c < 1.
So,$let$ T (a, b, c) denote the test statistic log(c/r )/ . og c. There is a Web site maintained by Nitaj that contains a wealth of information about the ABC conjecture (www. math.unicaen.fr/ ̃nitaj/abc.html). Checking the data, there are quite a few examples with$T$ (a$, b, c) ⩾ 1, the$ champion so far being a = 72 · 412 · 3113 = 2 477 678 547 239 b = 1116 · 132 · 79 = 613 474 843 408 551 921 511 c = 2 · 33 · 523 · 953 = 613 474 845 886 230 468 750 r = 2 · 3 · 5 · 7 · 11 · 13 · 41 · 79 · 311 · 953 = 28 828 335 646 110, so that T (a$, b, c) = \log \log (c/r )c = 2.43886 . . . .$ Is it always
true that$T$ (a$, b, c) < 2.$5? that one is not actually proving a theorem, but mak-ing a guess. Heuristics are often based on the idea of One can get carried away with heuristics, for getting randomness, and all bets are off if there is some under-lying structure. But how do we know that there is no

362

underlying structure? Consider the case of an “conjecture.” Here we consider integers a, b, c, and abc dd witha + b + c + d = 0. The condition that the terms be relatively prime now takes on two possible meanings: pairwise relatively prime or no nontrivial common divisor of all four numbers. The first condition seems morein the spirit of the three-term conjecture, but may be a tad too strong in that it disallows using any even num-bers. So say we take the four terms with no pair having a common factor greater than 2.
Under this condition, our heuristics seem to suggest that for eachε > 0, we have rad(abcd()1()+){ε} < . ax \\{|a|}, |b|,|c|,|d|\\\\\\\\\\\\\\\\\\\\\} (4) for at most finitely many cases. But consider the poly-nomial identity (x + 1)5 = (x - 1)5 + 10(x2 + 1)2 - 8 (suggested to me by Granville). If we take tip le of 10, the four terms involved in the identity arex as a mul- pairwise relatively prime except for the last two, which have a common factor of 2. Let x = 11 k - 1, which isa multiple of 10.
The largest of the four terms is 115 k, and the radical of the product of the four terms is at most 110$(11 k - 2)((11 k - 1)2 + 1) < 110 · 1(13)k$. The heuristics are saying that this cannot be, yet hereit is right before our eyes! supplying an underlying structure. For the four-term What is happening is that the polynomial identity is abcdε > 0, all counterexamples to (4) come from at most conjecture, Granville conjectures that for each finitely many polynomial families.
And the number of polynomial families grows to infinity asε shrinks to 0.We have looked here at only a small portion of the field of Diophantine equations, and then we have looked mainly at the dynamic relationship between heuristics and computational searches for small solu - tions. For much more on the subject of computational Diophantine methods, see Smart (1998). of study behave as if they were random, and we have visited several cases where it is useful to think this Heuristic arguments often assume that the objects way.
Other examples include the twin prime conjec-ture (there are infinitely many prime sp such that p + 2 is prime), Goldbach’s conjecture (every even number larger than 2 is the sum of two primes), and count less other conjectures in number theory. Often the computational evidence for the probabilistic view is striking, IV. Branches of Mathematics even overwhelming, and we become convinced of the truth of our model. But on the other hand, if it is this pseudo-proof that is all we have to go on, we may still be very far from the truth.
Nevertheless, the interplay of computations and heuristic thinking forms an indispensable part of our arsenal, and mathematics is the richer for it. Remarks and Acknowledgments.mend to the reader the book by Cohen (1993) for a discus - I would like to re com sion of computational algebraic number theory, a subject that is neglected in this article. I am grateful to the following people, who generously shared their expertise: X. Gour - don, A. Granville, A. Odlyzko, E. Schaefer, K. Soundararajan, C. Stewart, R. Tijdeman, and M. van Frankenhuijsen. I amalso thankful to A. Granville and D.
Pomerance for helpful suggestions with the exposition. I was supported in part by NSF grant DMS - 0401422. Further Reading Agrawal, M., N. Kayal, and N. Saxena. 2004. PRIMES is in P.Annals of Mathematics 160:781–93. Buhler, J., R. Crandall, R. Ernvall, and T. Metsänkylä. 1993.Irregular primes and cyclotomic invariants to four million. Mathematics of Computation 61:151–53. Cohen, H. 1993.ber Theory. Graduate Texts in Mathematics, volume 138.A Course in Computational Algebraic Num Crandall, R., and C. Pomerance. 2005.New York: Springer. Computational Perspective, 2 nd edn. New York:
Springer. Prime Numbers: A Darmon, H., and A. Granville. 1995. On the equations F(x, y) and Axp + Byq = Czr. Bulletin of the Londonzm = Mathematical Society 27:513–43. Erd ̋on Fermat’s last theorem.os, P., and S. Ulam. 1971. Some probabilistic remarks Rocky Mountain Journal of Mathematics 1:613–16. Granville, A., and T. J. Tucker. 2002. It’s as easy as Notices of the American Mathematical Society 49:1224–abc. Odlyzko, A. M., and A. Schönhage. 1988. Fast algorithms31.for multiple evaluations of the Riemann zeta function. Transactions of the American Mathematical Society797–809. 309:
Poonen, B., E. Schaefer, and M. Stoll. 2007. Twists ofand primitive solutions to$x2 + y3 = z7$. Duke Mathemat - X(7) ics Journal 137:103–58. Rosser, J. B., and L. Schoenfeld. 1962. Approximate formu-las for some functions of prime numbers. Illinois Journal of Mathematics 6:64–94. Smart, N. 1998.Equations. London Mathematical Society Student Texts, The Algorithmic Resolution of Diophantine volume 41. Cambridge: Cambridge University Press. IV.4.
Algebraic Geometry IV.4 Algebraic Geometry János Kollár 1 Introduction Succinctly put, algebraic geometry is the study of geom-etry using polynomials and the investigation of polynomials using geometry. Many of us were taught the beginnings of algebraic geometry in high school, under the name “analytic geometry.” When we say thaty = mx + b is the equa- tion of a line L, or that x2 + y2 = r2 describes a circle C of radiu sr , we establish a basic connection between geometry and algebra. If we want to find the points where the line L and the circley in the circle equation to get C intersect, we
just substitutex2 + (mxmx + b)+2 b = forr2 and solve the resulting quadratic equation to obtain the x This simple example encapsulates the method of coordinates of the two intersection points. algebraic geometry: a geometric problem is translated into algebra, where it is readily solvable; conversely, we get insight into algebra problems by using geometry. It is hard to guess the solutions of systems of polynomial equations, but once a corresponding geometric picture is drawn, we start to have a qualitative understanding of them. The precise quantitative answer is then provided by algebra.
2 Polynomials and Their Geometry Polynomials are the expressions one can put together from variables and numbers by addition and multiplication. The most familiar are one-variable polynomials such asx3 - x + 4, but we can use two or three vari- ables to get, for instance, 2 x5 - 3 xy2 + y3 (which has degree 5 in two variables) or x5 - y7 + x2 z8 - xyz + 1(which has degree 10 in three variables). In general, onecan usen variables, in which case they are frequently denoted by$x^{1}$, x2, . . . , xn, and we write f (x1, . . .
, xn), f (Polynomials are the only functions that computersx) or simply fto denote an unspecified polynomial. can work with. (Although your pocket calculator is likely to have a button for logarithms, it is secretly computing a polynomial whose value at a number with logb up to many decimal places.) b agrees for the linex2 We can slightly rewrite the equations we gave earlier + y2 - r2 L=and the circle0. We can then describe C: as$y - mx L and - b C = as0 andzero$363 Figure 1 A hyperboloid intersecting a plane. sets all points:
L is the zero set of(x, y) such thaty y--mxmx--bb(that is, the set of = 0) and C is the zero set ofx2 + y2 - r2. Similarly, the zero set of 2 x2 + 3 y2 - z2 - 7 in 3 - space is a hyperboloid, the zero set ofz - x - y in 3 - space is a plane, and the common zero set of these two equationsin 3-space is the intersection of the hyperboloid and the plane, which is an ellipse (see figure 1). The set of common zeros of a system of polynomial equations in any number of variables is called analgebraic set. These are the basic objects of algebraic geometry.
few have a feeling for 4-space, also called and 5-space is by and large inconceivable to almost Most people feel that geometry ends in 3-space. Very space-time, every one. So what is the meaning of geometry in many variables? Algebra comes to our rescue here. While I have great difficulty visualizing what a four-dimensional sphere ofradiusr in 5-space should be, I can easily write down its equation,(x2)1 + (x2)2 + (x3)2 + (x2)4 + (x5)2 - r2 = 0, and work with it. This equation is also something a computer can handle, which is immensely useful in applications. for the rest of this article.
This is where all geometry I will, nonetheless, stick to two or three variables starts and there are plenty of interesting questions and results. The importance of algebraic geometry derives from the fact that significant interactions between algebra 364 and geometry happen very frequently. Let us look attwo examples, just for illustration. 3 Most Shapes Are Algebraic Shapes that occur frequently enough to have their own name, for instance, lines, planes, circles, ellipses, hyperbolas, parabolas, hyperboloids, paraboloids, ellipsoids, are almost all algebraic.
Even the more esoteric conchoid (or shell curve) of Dürer, the trident of[VI.14](/part - 06/isaac - newton - 16421727), and the folium of Kepler are algebraic.newton Some shapes cannot be described by polynomial equations, but they can be described by polynomial inequalities. For instance, the inequalities 0⩽ x ⩽ a and 0⩽ y ⩽ b together describe a rectangle with side lengths it i es are called a, b. Shapes described by polynomial in equal-semialgebraic, and every polyhedron is semialgebraic. example, at the graph of the sine function This crosses the Not everything is an algebraic set, though.
Look, for$x$-axis infinitely many times (at multi-$y = \sin x$. ples ofas many roots as its degree, soπ). If f (x) is any polynomial, then it has at mosty = f (x) will never look like y = . in x. We can, however, get very close to sinx with a poly- nomial if we concentrate on values of large. For instance, the degree - 7 Taylor polynomialx that are not toox - 1 6 x3 + 1201 x5 - 50401 x7 differs from sinx by an error of at most 0.1 for -π <x < πrem of Nash that says that every “reasonable” geomet-.
This is a very special case of a basic theoric shape is algebraic if we ignore what happens very far from the origin. So, what is reasonable? certainly not everything. Fractals seem profoundly nonalgebraic. The nicest shapes are these can be described by polynomials.manifolds [I.3 §6.9](/part - 01/fundamental - definitions), and all of Nash’s theorem. Let M be any manifold in Rn. Fix any large number zero set is as close to R. Then there is a polynomial M as we want, at least inside af whose ball of radius R around the origin.
4 Codes and Finite Geometries Consider the equationx2 + y2 = z2, which describes a double cone in 3 - space (see figure 4). If we confine ourselves to natural numbers, then the solutions of x2 + y2 = z2 are the Pythagorean triples, correspond- ing to right-angled triangles where all sides have inte-ger lengths, of which the two best-known examples are

(3$,4,5) and (5,12, 13)$.

IV. Branches of Mathematics

we care only about the whether they are even or odd). For instance, 3 Let us now look at the same equation, but declare that parities of the two sides (that is,2+152 and4 The parities of2 are both even, so we say that 3 x2 + y2 and of (z2)2 depend only on those + 152 ≡ 42 (mod 2). of either 0 (the even case) or 1 (the odd case). Our equationx, y , and z, so we can pretend that x, y , and z are all modulo 2 therefore has four solutions: 000, 011, 101, 110.
These look like code words in a computer message. It was quite a surprise when it was discovered that using polynomials and their solutions modulo 2 is a great—probably the best—way of constructing correcting codes [[VII.6 §§3–5]](/part - 07/reliable - transmission - of - information). error ing here. Let us think for a moment about what 3-space is for us.
For many it is an amorphous everything, but There is something very substantial and new happen for algebraic geometers (with ancestor) it is simply a collection of points described descartes [VI.11](/part-06/ren-descartes-15961650) as our by three numbers, thex, y , and z coordinates. Let us make a jump here, and declare that “3-space modulo 2”is the collection of all “points” given by three coordinates modulo 2. Four of these are listed above, and there are four more.
The beauty of algebra is that suddenly we can talk about lines, planes, spheres, cones in this“3-space having only eight points.” ulo any integer. For example, working modulo 7, wehave 0, 1, 2, 3, 4, 5, 6 as possible coordinates, and so We do not need to stop here, and one can work mod“3-space modulo 7” has 73$= 343 points$. intriguing, but also technically difficult. Its great reward is that one can view this process as a “discretization”Talking about geometry in these spaces is very of ordinary space.
Working modulo cia lly whenn is a prime number) gets very close to then for large n (espe- usual geometry. retic questions. It was, for instance, instrumental in This approach is especially fruitful in number-theo Wiles’s proof of Fermat’s last theorem. For more on these topics, see arithmetic geometry [IV.5](/part-04/arithmetic-geometry). 5 Snapshots of Polynomials Consider the equation real solutions form a circle of radius x2 + y2 = R$. If \sqrt{R} >R$; if0, then the R = 0, we get only the origin; and if R < 0, we get the empty set.
Thus, if determines what R > 0, then the geometry of the solution set R is, but otherwise it does not. We

IV.4. Algebraic Geometry

can of course look at complex solutions, and the com-plex solutions always determine R. (For instance, the intersection points with the$x - \text{axis are} (±\sqrt{R}$, 0).) solutions ofcan also look for solutions in the “plane modulo If R is a rational number, we can ask about rationalx2 + y2 = R, and if R is an integer, wem” for any One can even look for solutions where m. x = x(t), y = y(t) are themselves polynomials in a variable t.
(Most generally, we can ask for solutions where are elements of any ring containing the number Rx.), y each time we look at solution sets we are taking a “snap-To my mind, the polynomial is the central object, and shot” of the polynomial. Some snapshots are good (like the above real snapshot for R > 0) and some are bad (like the above real snapshot for How good can snapshots be? Can we determine a$R < 0)$. polynomial from its snapshots? bola, but “an” equation would be more correct.
Indeed, the hyperbola One frequently talks about “the” equation of a hyper-x2 - y2 - R = 0 can also be given by an equationcx2 - cy2 - c R = 0, for any c ≠ 0. We can also use the equation(x2 - y2 - R)2 = 0, which we may well not recognize in its expanded form. Higher powers can also be used. What about the equation$f$ (x$, y) =(x^{2} - y^{2} - R)(x^{2} + y^{2} + R^{2}) =$0? If we look only at real solutions, this is still just the hyperbola sincex2 + y2 + R2 is always positive for x, y real.
However, as with one-variable polynomials, one should look at all complex roots to understand everything. Then we see thatis not on the hyperbola$f (\sqrt{-1R}$, 0) = 0, but the complex pointx2 - y2 - R = 0. In general,(. qrt{-1 R},0) as long ashas exactly the same complex roots as R . eq 0, we get that if f is a polynomial thatx2 - y2 - R, thenf (x, y) = c(x2 - y2 - R)m for some m andc . eq Why is the0. R = 0 case different?
The reason is that for R . eq 0 the polynomial x2 - y2 - R is irreducible (that is, it cannot be written as the product of other polyno - mials), while$x^{2} - y^{2} = (x + y)(x - y) \text{is reducible}$ with irreducible factorsx + y and x - y. In the lat- ter case one gets that ifhas exactly the same complex roots asg(x$, y) \text{is a polynomial thatx}^{2} - y^{2}$, thenf = c · (x + y)m(x - y)n for some m, n and c ≠ 0. is answered by the fundamental theorem of algebraic geometry.
It is some times called Hilbert’s theorem on The analogous question for systems of equations the zeros, but its German name is used most of the time. For simplicity, we state only the case of one equation.

365

Hilbert’s Nullstellensatz.andg have the same complex solutions if and only if Two complex polynomials f they have the same irreducible factors. coefficients. For instance, y2 We can do even better for polynomials with integer- 1) = 0 have the same solutions over the real orx2 - y2 - 1 = 0 and 2(x2 - complex numbers, and the same solutions modulo for any odd primep, but they have different solutions$p$ modulo 2. The general result in this case is easy and simple.
Arithmetic Nullstellensatz.teger coefficientsf and g have the same solutions Two polynomials with in- mod ulom for every m if and only if f = ±g. 6 Bézout’s Theorem and Intersection Theory If complex roots, at least when they are counted withh(x) is a polynomial of degree n, then it has n multiplicity. What happens with a syst emg(x$, y) =$0? Geometrically we see two curves in the$f$ (x$, y) =$ plane, so we expect that there will typically be finitely many intersection points. These usually intersect in a single point, but they canbe parallel and they can coincide.
The first case leads Iff , g are both linear, we have two lines in the plane. to the classical declaration that “parallel lines meet atinfinity” and the definition of projective planes and projective spaces tive spaces and the corresponding projective varieties[III.72](/part-03/projective-space). (The introduction of pro je cis a key step in algebraic geometry. It is some what tech-nical so we shall skip it here, but it is indispensable even at the most basic level.)Next, consider two polynomials of degree 2, that is, two plane conics.
Two smooth conics usually intersectin at most four points (just try this by drawing two ellipses). There are also some rather degenerate cases. Two conics may coincide, or, if they are both reducible, they can have a common line. In any case, we are ready to formulate a basic result, dating back to 1779. Bézout’s theorem.mials inn variables, and for each Let f1(x), . . . , fi letn(xd) be the degree be n polyno-i$of$ f . Then either i

(i) most the equation(s)$d d · · · df^{1}(solutions; or$ x) = · · · = fn(x) = 0 have at (ii) thef vanish identically on an algebraic curv(e1()2)n C, i

and so there is a continuous family of solutions. the system of equationsz =As an example, the second alternative happens for0, which has (t, t2, t3)xzas a solution for any- y2 = y3 - z2 =t. Thisx3 -

366

case is actually quite rare. If we pick the coefficients ofthe polynomials fr and om ly, then the first alternative

$i$

happens with probability 1.Ideally, we would like to make the stronger claim that if the first alternative happens, then there ared d · · · dsolutions, but counted “with multiplicity.”exactly This actually works, and gives us our first example of1 2$n$ an extremely useful feature of algebraic geometry. Evenin very degenerate situations it is possible to define and count the multiplicities easily. This is frequently of great help since the typical (or “generic”) cases are usually very hard to compute.
To get around this problem, we can some times find a special, degenerate case where we know that the answer will be the same, butthe computations are much easier. algebraic and one geometric. The algebraic definition is computationally very efficient, but some what techni-There are two ways to think about multiplicity: one cal. The geometric interpretation is easier to explain, sothat is the one we shall give here, but it would be hard to compute with in practice. Ifx = p is an isolated solution of the equationsf1(x) = · · · = fn(x) = 0 with multiplicity m, then the perturbed system

$f^{1}(x) + {}^{1} = · · · = f^{n}(x) + n = 0$

has exact lym solutions near x = p for almost all small values of thei. etry that deals with generalizations of Bézout’s the-orem. Above, we looked at intersections of Intersection theory is the branch of algebraic geom-hypersurfaces—that is, of zero sets of single polynomials—but we may wish to look at intersections of more general algebraic sets. Also, even when the second alternative holds, we may want to count the number of isolated intersection points; this can be very tricky but also very useful.
7 Varieties, Schemes, Orbifolds, and Stacks Consider the system of two pieces, thezxz==0 plane and theyz = 0 in 3-space. It consist sx = y = 0 line. It is easy to see that neither the plane nor the line can be written as the union of algebraic sets (except by nitpickers who point out that the line is the union of the line itself and of any point on the line). In general, any algebraic set can be written in exactly one way as the union of smaller algebraic sets that in turn cannot be decomposed further. These basic building blocks are called irreducible algebraic sets or algebraic varieties.

IV. Branches of Mathematics

y

x

Figure 2 A smooth cubic: y2 = x3 - x.

Some times this is not exactly what one would naively expect. For instance, the curve in figure 2 has two con-nected components. The two parts are, however, not algebraic sets. An explanation is provided by looking at the complex solutions of this equation. We shall see later that these form a connected set, namely a torus (with a miss-ing point at infinity). We see two components when we look at the real solutions because we are taking across-section of this torus.
In general, the zero setf = 0 is irreducible as an alge- braic set if and only iff is irreducible as a polynomial (or if it is the power of an irreducible polynomial). the implication in one direction is easy to see: if$f = gh$, then the zero set ofand of the zero set off his the union of the zero set of. g For many questions, keeping track only of the zero set is not enough. For instance, look at the polynomialf = x2(x - 1)(x - 2)3. It has degree 6 and three roots atand one usually says that$x = 0$,1,$2$.
These roots behave differently, however, f has a double root at x = 0 and a triple root atx = 2. If we perturb f by adding a small numberf (x) + = 0 has two (complex) solutions near 0, oneto it, then the perturbed equation solution near 1 and three (complex) solutions near 2.Thus, these multiplicities carry important geometric meaning about the perturbation of the equation. Similarly, it is natural to say that while$x2y = 0 andxy3 =$0 define the same algebraic set (consisting of the two axes), the first “assigns multiplicity 2” to theand the other “assigns multiplicity 3” to thex-axis.y-axis
equations. Consider the systemsx3 More complicated things can happen for systems of= y =0 in 3-space. Both define thex =zy-axis and it is2 = 0 and reasonable to say that the first does so with multiplic-ity 2, the second with multiplicity 3. There is, however,

IV.4. Algebraic Geometry

a further difference. In the first case the multiplicity seems to “go in they-direction” and in the second case it seems to go in the other systems, likex -x-direction. We can also look atcy = y3 = 0, if we want to see more complicated behavior. Roughly speaking, a scheme is an algebraic set where we also keep track of the multiplicities and of the directions they occur in. Consider thexy-plane and consider the map that reflects across the origin. Thus a point to(-x, -y). Let us try to glue each point(x, y)(x, y)is mapped to its image(-x,-y). What do we get?
The right half-plane x ⩾ 0 is mapped to the left half-plane x ⩽ 0, so it is enough to work out what happens with the right half-plane. The positivey-axis is glued to the negative y- axis, and the resulting surface is a dunce cap (but less pointy). Algebraically, it is one half of the cone$z^{2} = x^{2} + y^{2}$. This cone looks nice and smooth except at the ver-tex. There it is more complicated, but the above construction shows that it can be obtained from a plane by a reflection across a point. More generally, suppose we take then-dimensional space Rnand finitely many symmetries of it.
If we glue together points that move into each other, we again get an algebraic variety, most of whose points are smooth, but some of which are more complicated. A variety made up of pieces like these is called anprecisely, we also keep track of which symmetries have orbifold. (When this is defined more been used.) In practice, such varieties occur frequently; that is why they deserve a separate name. come is amended to people who would have been flagellants in Finally, if we marry a scheme to an orbifold, the out-stack. The study of stacks is strongly re com earlier times.
8 Curves, Surfaces, Threefolds As with any geometric object, one of the simplest ques-tions one can ask about a variety is: what is its dimension? As expected, a curve in the plane has dimen-sion 1, and a surface in 3-space has dimension 2. This seems quite simple until one writes down examples like$S = (x4 + y4 + z4 = 0)$, which is only the origin in R3. This example is, nonetheless, still two dimensional: the explanation is that we were looking at the wrong snapshot.
Using complex numbers we can solve the equa-tion as$z = {}^{4} - x^{4} - y^{4}$, so the complex solutions ofx4 + y4 + z4 = 0 can be described by two indepen- dent variablesit is quite reasonable to say thatx, y and a dependent variable S is two dimensional.z. Thus,

367

some complex space This idea works more generally. If Cn, then choose a random set of X is any variety inndinate system, for independent directions to serve as a basis, or coor-C^n, and hence for X. With proba- bility 1 (i.e., except in degenerate cases) one finds that there is so med such that the firstd coordinates of a point depend on them. This numberx in X can vary independently, while the restd depends on X only and is called the dimension) ofdimension X .
(or, to be precise, the algebraic section If X is a variety and X ∩(f = 0) has dimension one less than dimf is a polynomial, then the inter-X (unless value zero onf vanishes identically on X). X or never takes the$If$ X is a subset of R^ndefined by real equations, and if it is smooth (see the next section for a discussion of smoothness), then its topological dimension [III.17](/part - 03/dimension) is the same as its algebraic dimension. twice the algebraic dimension. Thus, for an algebraic geometer, For complex varieties, the topological dimension is Cn has dimension n.
In particular, for us C is the “complex line,” where as everybody else calls this the “complex plane.” Our “complex plane” is, of course, C2. is a variety of dimension 2, and aof dimension 3.A variety of dimension 1 is called a threefold curve is a variety. A surface oped and beautiful subject. We shall see later how onecan start to get an over view of all algebraic curves. Sur-The theory of algebraic curves is a very well develfaces have been intensively studied for the last century, and now we have reached a reasonably complete understanding of them.
This is a much more complicated theory than for curves. Still very little is known for varieties of dimension 3 and up. At least conjecturally, all these dimensions behave in roughly the same way. Despite some progress, especially in dimension 3, many questions are wide open. 9 Singularities and Their Resolutions If we look at the simplest examples of algebraic curves in figure 3, we see that most points of a curve are smooth, but that there may be a finite set of more complicated singular points. Let us compare these with the curve in figure 2. equation has no constant term.
The equation of figure 2 All three curves pass through the origin, since their has a linear term and the curve looks nice and smooth at the origin, where as the equations of figure 3 contain 368 (a) y x (b) y x Figure 3 Singular cubics: (a)y2 = x3 + x2 and (b) y2 = x3. no linear term and the curves are more complicated atthe origin. This is not an accident. For small values ofx, the higher powers x2, x3, . . . are much smaller than x in absolute value, so near the origin the linear terms dominate.
If we have only linear terms ax + by = 0, we get a line through the origin, and an algebraic curve ax + by + cx2 + gxy + ey2+· · · = 0 is close to the lineax + by = 0, at least for very small values of x and y. atesthe coordinate change The study of a curve near another point with coordin-(p, q) can be reduced to the case(x, y) \to (x - p, y(p, q)-=q)(.0,0) via ear term the hyperplane In general, if L(f ), the hypersurface L(f )f (0)==0. This is the so-called0 and ffhas a (nonzero) lin-= 0 is very close toimplicit function theorem. Such points are called smooth.
Points that are not smooth are called show that the singular points ofsingular X form an algebraic. One can easily set, defined by the vanishing of all partial derivatives. artial f /. artial x . A random hypersurface will, with probability 1, i

be smooth, but there are many singular hypersurfaces as well. ety of dimension comparing The smooth and singular points of an arbitrary vari-X with dd-dimensional linear subspaces.can be defined analogously by such as topology and differential geometry, but by and large these fields shy away from their study (with the Singularities also occur in other geometric fields,

IV. Branches of Mathematics

not able exception of catastrophe theory). By contrast, algebraic geometry provides very powerful tools for their investigation. Let us start with singularities of hypersurfaces, or equivalently with thinking about these it is natural to work not just with critical points of functions. When polynomials but with more general power series, thatis, functionsf (x , . . . , x )that can be written as “polynomials of infinite degree.” For simplicity of notationwe shall assume that1$f (n0) = 0$.
Two functions f , g are considered to be change$x \to φ (x)$, where each equivalent if there is a coordinateφ is given by a power series, such that$i^{i} f (φ^{1}(x)$, $. . . , φn(ix)) = g(x)$. In the one-variable case, anyf can be written asf = xm(am + (am)+1 x + · · · ), where am . eq 0. The (inverse of the) substitution. qrtx \to xm am + (am)+1 x + · · · then shows thatf is equivalent to xm. The functions xmare in equivalent for different values ofm, so in this particular case the lowest-degree monomial occurring inf determines f up to equivalence.
(Note that even iffan infinite power series:
 it is because we cannot invert is a polynomial, the above change of variable involves polynomials, even locally, that it is more convenient toconsider general power series.) do not determine the singularity, but taking more terms is usually enough to do so, because of the following In general, the lowest-degree terms of a power series result. Algebraization of analytic singularities.
Given a power seriesf by deleting all monomials of degree greater thanf, let (f⩽)N denote the polynomial obtained from N.$If$(f0=is an isolated singular point of the hypersurface0), then f is equivalent to ffor sufficiently

⩽N

large N.

take To see an example of a nonisolated singularity at$x^{2} 0$, g(x, y, z) = y + 1 - x - z3= (y + x + x2 + x3 + · · · )2 - z3.

It has singular points not just at along the curvey + (x/(1 - x)) = z0=, but everywhere0. On the other hand, one can easily check that all truncations have an isolated singular point at 0.(g⩽)N do functions of the form A very fruitful question of singularity theory asks: If we have two power series, f + g as perturbations off and g, we can viewf .

IV.4. Algebraic Geometry

what can we say about the perturbations of a given polynomial or power seriesf? xtom For instance, in the one-variable case, the polynomial xcan be perturbed asr if r < m. Every perturbation contain sxm + xr, which is equivalent xm, so ifalent tor > mx, then no perturbation ofr (because near the originx(xm)mwill be equiv-will be much larger than possible perturbations of$x^{r})$. Hence, up to equivalence, the set of allxm is {xr}: r ⩽ m.
On the other hand, it is not hard to see that for any given for which the polynomials, there are only twenty-four different values of$xy(x^{2} - y^{2})+y^{2}(x^{2} - y^{2}η)$ and$xy(x^{2} - y^{2})+ηy^{2}(x^{2} - y^{2}) \text{are equivalent}$. (Indeed, both polynomials describe four lines through the ori-gin. The first one gives the lines$y = 0$, x = y , x = −y,$andx = −y$, and the second gives the same lines except thatη replaces . The linear part of any sup- posed equivalence gives a linear transformation map-ping the first set of four lines to the second.
There are twenty-four ways to assign which line goes to which line.) Thusxy(x2 - y2) has a continuous family of in equivalent perturbations. Simple singularities.power series$f (x^{1}$, . . . , x Suppose that the polynomial orn)has only finitely many in equivalent perturbations. Thenof the following normal forms: f is equivalent to one Am (x1)m+1 + (x2)2 + · · · + (xn)2 (m ⩾ 1)$, Dm (x1)2x2 + (xm()2)-1 + (x3)2 + · · · + (x2)n (m ⩾ 4)$, E6 (x1)3 + (x4)2 + (x3)2 + · · · + (x2)n$, E7 (x1)3 + x1(x3)2 + (x3)2 + · · · + (x2)n$, E8 (x1)3 + (x5)2 + (x3)2 + · · · + (x2)n.
The names should bring to mind the classification of lie groups but not easy to explain. When[III.48](/part-03/lie-theory). The connections are numerous$n = 3$, these are also called Consider again the cone Du Val singularities or$z^{2}\text{rational double points} = x^{2} + y^{2}$. Earlier, we. described a two-to-one parametrization of it. Here is another, and for many purposes better, parametrization over the real numbers. In the(u, v, w)-space consider the smooth cylinderu2 + v2 = 1. The map (u, v, w) \to  (uw, vw, w) maps the cylinder onto the cone (see figure 4).
The map is one-to-one away from the vertex, the preimage of which is the circle$u^{2} + v^{2} = 1 \text{in the} (w = 0)-plane$. (Sharp-eyed readers will have noticed that this map is not so nice if we use complex numbers. In general, we want par a me tr iz at i ons that work both for real and

369

Figure 4 A resolution of the cone.

complex numbers, but that would be quite a bit more complicated to describe.)The advantage of the cylinder over the cone is that it does not have a singularity. Par a me tr iz at i ons of vari-eties in terms of smooth varieties are very useful, and there is a major result that tells us that they always exist, at least when the varieties are real or complex. (The corresponding result is still unknown for the finite geometries considered earlier.) Resolution of singularities (Hironaka).X there is another smooth variety Y and a poly nom i-For any variety ally defined surjective mapπ:
Y \to X such that π is invertible at all smooth points of X. cylinder, but the cylinder minus finitely many points inthe collapsed circle would also work. In order to avoid(In the cone example above, one can take the whole such silly cases, we require strong sense:
if a sequence of smooth pointsπ to be surjective in a veryx \in Xi converges to a limit inpreimagesπ-1(x ) converges to a limit in X , then a subsequence of their Y .)i 10 Classification of Curves In order to get an idea of how the classification of alge-braic varieties should proceed, let us look at hypersurfaces of degree a degree - d polynomiald inf (xn - space. These are given by, . . . , x ) = 0. The set of all polynomials of degree at most1 n d forms a vector spacecrete invariants, the dimension and the degree, and one Vn, d.
Thus hypersurfaces have two obvious dis - 370 can move between hypersurfaces of the same dimen-sion and degree by varying the coefficients off continu - ously. More over, the entire set Vn, d is itself an algebraic variety. Our aim is to develop a similar understanding for all varieties, which can be done in two steps. attached to varieties, which stay the same if we change a variety continuously. Such integers are called The first step is to define some integers, naturally discrete invariants The second is to show that the set of all varieties. The simplest example is the dimension.
with the same discrete invariant is parametrized by another algebraic variety, called the moduli space [IV.8](/part - 04/moduli - spaces). More over, we would like the variety used for this parametrization to be chosen as economically as pos - sible. We will look at this in more detail in the next section. Let us see how it is accomplished for curves. Here there is only one more discrete invariant be sides the dimension, known as thehas many different definitions: one of the simplest is genus of the curve. This through topology. Let look at its complex points.
Locally, this set looks like E be a smooth curve and let us C, so it is a topological surface. After patching up some holes at infinity, we get a compact surface. Multiplica-tion by. qrt{-1} gives an orientation, so basic topology tells us that we get a sphere with a certain number of han-dles attached (see differential topology [IV.7](/part - 04/dierential - topology)). The genus of the curve is defined to be the number of these handles (that is, the genus of the corresponding sur - face).
To see what this means in practice, let us look at some examples. A line in 2-space is like the complex numbers, which can be viewed as a sphere minus a point. This sphere, C plus the point at infinity, is also called the Riemann sphere Next, we look at conics. Here it is better to use some. So the genus is zero. projective geometry. Take any tangent of the conic and move this so that it becomes the line at infinity. Then we get a parabola, which, in suitable coordinates, is given by an equation$y = x2$.
The polynomial map t \to  (t$, t2)$, with its inverse(x, y) \to  x, shows that this parabola is isomorphic to a line, so again has genus 0. ing is that smooth (and has genus 0) but it is singular at infinity. Cubics are quite a bit more complicated. A first warn-y = x3 is the wrong cubic to look at. It is (The earlier expediency of keeping silent about projec-tive geometry starts to bite us!) In any case, the correct thing to do is to choose the tangent line of the cubic at an inflection point and move that to infinity. After some computation we obtain a much-simplified

IV. Branches of Mathematics

equationy2 = f (x), where f has degree 3. What is the genus?Consider the special case$y^{2} = x(x - 1)(x - 2)$. We try to understand the two-to-one projection to the(complex)x-axis, but it is better to do this when thexthat it is the Riemann sphere. If we remove the interval-axis has already had the point at infinity added, so 0⩽ x ⩽ 1 and the half line 2 ⩽ x ⩽ +. nfty from the Rie- mann sphere, then the functiony = x(x - 1)(x - 2) has two branches.
(This means that ent values for eachx, the positive and negative squareytakes two differ roots ofx(x -1)(x - 2), but if one moves x about, one can lettwo slits is topologically like a cylinder, hence the com-y vary in a continuous way.) The sphere minus plex cubic is glued together from two cylinders. So weget the torus and the genus is 1.
has genus directly topologically. It turns out that a smooth plane curve of degree12(d - 1)(d - 2), but I find this hard to see$d$ ters to give a similarly simple description of the discrete invariants for higher-dimensional varieties. It is a (probably hope less) dream of algebraic geome Unfortunately, the topological invariants of the complex points are not good enough, and they probably mislead more than help. As a further illustration of the approach to the classification of curves, here is a list of all curves of low genus. Genus 0. There is only one curve of genus 0.
As we saw, it can be realized as a line or as a conic in the plane. Genus 1.it can be given by an equation of the form Every curve of genus 1 is a plane cubic, andy2 =f (x)ally called, where elliptic curvesf has degree 3. Genus-1 curves are usu-[III.21](/part-03/elliptic-curves), since they first appeared (in the guise of elliptic integrals) in connec-tion with the arc length of ellipses. We look at these in more detail later. Genus 2.equation of the form Every curve of genus 2 can be given by an y2 = f (x), where f has degree 5.
(These curves are singular at infinity.) more generally, iff has degree 2 g + 1 or 2 g + 2, then the curvey2 = f (x) has genus g. For g ⩾ 3, such curves, Genus 3.called plane curve of degree 4 (or it is hyperelliptic).hyperelliptic Every curve of genus 3 can be realized as a, are rather special. Genus 4. Every curve of genus 4 can be presented as a space curve given by two equations of degrees 2 and 3 (or it is hyperelliptic).

IV.4. Algebraic Geometry

not form a separate family. One can move continuously from any hyperelliptic curve to a general curve of the It should be emphasized that hyperelliptic curves do kind described above. This can be seen through more-complicated representations. One can continue in this manner a bit longer, up to about genus 10, but no such explicit construction ispossible when the genus is large. 11 Moduli Spaces Let us go back to plane cubics, which we parametrized by the vector space V of degree - 3 polynomials in two variables. This is not very economical.
For instance, x3 + 2 y3 + 1 and 3 x3 +2 \\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\}36 y3 +}}3 are different polynomials, but define the same curve. Further more, there is not much reason to distinguish$x^{3} + 2y^{3} + 1 from$ 2 x3 + y3 + 1, since they are obtained from each other by switching the two coordinate axes. More generally, as we have seen in the previous section, any cubic curve can be transformed into one given by an equation$y^{2} = f (x)$, where f = ax^3 + bx^2 + cx + d. two more steps to take.
First, one can set the leading coefficient of This is better but not yet optimal, and there aref to be 1. Indeed, substitute y = . qrt{ay} and then divide the whole equation byx3 + · · ·. Second, we can make a substitution a to get y(x1)2 ==1 ux(y2)1=+f (uxv to get another elliptic curve with equation+ v) = f (x ), where f is easy to write down explicitly. One can see that these are the only coordinate changes that we can make with out messing1 1 1 1 up the form y2 = (cubic polynomial). answer, look at the three roots ofr It is still not very clear what happens.
To get a better)(x - r )(x - r ). (Again, complex numbers inevitablyf, so f (x) = (x - appear.) If we make the substitution1 2 3 x \to (r2 - r1)x + rare 0 and 1. Thus our elliptic curve is transformed into1, we get a new polynomial f1(x), two of whose rootsy2 = x(x - 1)(x - λ). So instead of the four unknown coefficients off , we are down to only one unknown, λ. formation we sent any two roots. For instance, we can substitute This form is still not completely unique. In our trans-$r^{1}$, r2 to 0, 1, but we could have usedx \to  1-x, sendingλ \to  1 - λ, or x \to  .
ambda x, sending λ \to  λ-1.
All together, the six values

λ, 1λ , 1 - λ, 1 -1 λ , 1--λλ , 1--λ. ambda give “the same” elliptic curve. Most of the time these six values are different, but there may be coincidences. For instance, we get only three different values if

371

. ambda tic curve= −1. This corresponds to the fact that the ellip-y^2 = x(x - 1)(x + 1) has four symme- tries:(x, y) \to (-x, ±. qrt{-1 y}) and (x, y) \to (x, ±y). (An unusual feature of elliptic curves is that they all have the second pair of symmetries. At$λ = 1 \text{we pick}$ up 4 the number of different values above.)/2 new symmetries, which corresponds to halving action of the symmetric group tat i ons of a three-element set) on the set The best way to think about it is to view this as an S3 (the group of permu - C \ \\\\\\\\\\\\{0,1\\\\\\\\\\\\}.
but we have in fact reached the final result. It is not at all obvious that we have run out of tricks, Moduli of elliptic curves.is in a natural one-to-one correspondence with the The set of all elliptic curves points of the quotient orbifold if old points correspond to the elliptic curves with extra$(C \ \\{0}$,1\\\\\\\\\\\\\\\\\\\\\})/S3. The orb- automorphisms.
nomenon. This is the simplest illustration of a general phe Moduli principle.all algebraic varieties with fixed discrete invariants is In most cases of interest, the set of in a natural one-to-one correspondence with the points of an orbifold. The orbifold points correspond to the varieties with extra automorphisms. smooth curves of genus among the most intensely studied orbifolds in algebraic The moduli orbifold (also called the moduli space) ofg is denoted by Mg.
These are geometry, especially since the recent discovery of their fundamental position in string theory [IV.17 §2](/part-04/vertex-operator-algebras) and mirror symmetry [IV.16](/part-04/mirror-symmetry). 12 Effective Nullstellensatz In order to show that there are still interesting ele-ment ary questions in algebraic geometry, let us try to decide when common complex zero. The classical answer is given m given polynomials f1, . . . , fm have no by the following result, which tells us that an obviously necessary condition is in fact sufficient. Weak Nullstellensatz. The polynomials$f1$, . . .
, fm have no common complex zero if and only if there are poly-nomials$g^{1}$, . . . , gm such thatg1 f1 + · · · + gmfm = 1.

Let us now make a guess that we can findg withj

degree at most 100. We can then write

gj = i 1+···+i n⩽100 aj, i1\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\}}}..., in (x1)i 1 · · · (xi)n n, 372 where theg f + · · · +aj, ig1\\{,\\..., ifn are indeterminates. If we write as a polynomial in the variable sx the constant term which must equal 1. Thus we ge(t1)1, . . . , (x1)n, then all the coefficients must vanish, savemm a system ofa. The solvability of systems of linear equations linear equations in the indeterminates is well - known (with good computer implementations)}.Thus we can decide if there is a solution with degj,(i1)\\\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\\}..., in g ⩽j 100.
Of course it is possible that 100 was too smalla guess, and we may have to repeat the process with larger and larger degree bounds. Will this ever end? The answer is given by the following result, which was proved only recently. Effective Nullstellensatz.mials of degree less than or equal to Let$f1$, . . . , fd inm nbe polyno - variables, wheretheng df ⩾+ · · · +3, n ⩾g 2. If they have no common zero, f = 1 has a solution such that degg1⩽1 dn - d.m mj

deg For most systems, one can find solutions such that g ⩽ (n - 1)(d - 1), but in general the upper bound jdn - d cannot be improved. method for deciding whether or not a system of polyno-mial equations has a common solution. Unfortunately, As explained above, this provides a computational this is rather use less in practice as we end up with exceedingly large linear systems. We still do not have a computationally effective and foolproof method. 13 So, What Is Algebraic Geometry? To me algebraic geometry is a belief in the unity ofgeometry and algebra.
The most exciting and profound developments arise from the discovery of new connec - tions. We have seen hints of some of these; many more were left unmentioned. Born with Cartesian coordin - ates, algebraic geometry is now intertwined with coding theory, number theory, computer-aided geometric design, and theoretical physics. Several of these con-nections have emerged in the last decade, and I hope to see many more in the future. Further Reading Most of the algebraic geometry literature is very tech - nical. A not able exception is Plane Algebraic Curves (Birkhäuser, Boston, MA, 1986), by E.
Brieskorn and H. Knörrer, which starts with a long over view of algebraic curves through arts and sciences since antiquity, IV. Branches of Mathematics with many nice pictures and reproductions.book of Complex Curve Theory (American Mathemat - A Scr ap ical Society, Providence, RI, 2003), by C. H. Clemens, and Press, Cambridge, 1992), by F. Kirwan, also start at an Complex Algebraic Curves (Cambridge University easily accessible level, but then delve more quickly into advanced subjects. geometry is bridge University Press, Cambridge, 1988), by M.
Reid. The best introduction to the techniques of algebraic Undergraduate Algebraic Geometry (Cam For those wish ing for a general over view, An Invitation to Algebraic Geometry K. E. Smith, L. Kahanpää, P. Kekäläinen, and W. Traves, is(Springer, New York, 2000), by a good choice, while York, 1995), by J. Harris, and Algebraic Geometry Basic Algebraic Geometry(Springer, New, volumes I and II (Springer, New York, 1994), by I. R.Shafarevich, are suitable for more systematic readings. IV.5 Arithmetic Geometry Jordan S.
Ellenberg 1 Diophantine Problems, Alone and in Teams Our goal is to sketch some of the essential ideas of arithmetic geometry; we begin with a problem which, on the face of it, involves no geometry and only a bit of arithmetic. Problem. Show that the equation

$x2 + y2 = 7z2 (1)$

has no solution in nonzero rational number sx, y , z. from the Pythagorean equationwe know has(Note that it is only in the coefficient 7 that (1) differs infinitely many solutions. It is a feature ofx2 + y2 = z2, which arithmetic geometry that modest changes of this kind can have drastic effects!) Solution$.fying (1)$; we will derive from this a contradiction. Sup pos ex, y , z are rational numbers satis- can write Ifn is the least common denominator of x, y , z, wex = a/n, y = b/n, z = c/n

such thata, b, c, and n are integers. Our original equation (1) now becomes na2 + nb2 = 7 nc2,

and multiplying through by$n2 \text{one hasa}2 + b2 = 7c2$. (2)

IV.5. Arithmetic Geometry

If replace them bya, b, and c have a common factora/m, b/m, and c/m, and (2) still holdsm, then we can for these new numbers. We may therefore suppose thata, b, and c are integers with no common factor. modular arithmetic reductions of We now reduce the above equation modulo 7 (seea and b modulo 7. The right-hand side of[III.58](/part-03/modular-arithmetic)). Denote b$\bar{y}a$ an$\bar{d}$ b the (2) is a multiple of 7, so it reduces to 0. We are left with

$a$ ̄2$+ b$ ̄2$= 0$. (3)

Now there are only seven possibilities fo$\bar{r}a$, and seven possibilities fo$\bar{r}$(3) amounts to checking the forty-nine choices o. ar{f}b. So the analysis of the solutions ofa,  ̄$b$ and seeing which ones satisfy the equation. A few min-utes of calculation are enough to convince us that (3) is satisfied only i. ar{f}But saying tha. ar{t}a a==$\bar{b}b=$ ̄=0.0 is the same as saying thataa2 andandbb2 are both multiples of 7. This being the case, are both multiples of 49. It follows that their$sum$, 7$c2$, is a multiple of 49 as well.
Therefore, c2 is a multiple of 7, and this implies that tip le of 7. In particular, a, b, and c share a com monc itself is a mul- factor of 7. We have now arrived at the desired contra-diction, since we chosea, b, and c to have no common factor. Thus, the hypothesized solution leads us to a contradiction, so we are forced to conclude that there is not, in fact, any solution to (1) consisting of nonzero rational numbers.1 a polynomial equation like (2) is called a problem In general, the determination of rational solutions to.
We were able to dispose of (2) in a paragraph, Diophantine but that turns out to be the exception: in general, Dio-phantine problems can be extraordinarily difficult. For instance, we might modify the exponents in (2) and consider the equation

$x5 + y5 = 7z5$. (4)

I do not know whether (4) has any solutions in nonzero rational numbers or not; one can be sure, though, that determining the answer would be a substantial piece of work, and it is quite possible that the most powerful techniques available to us are in sufficient to answer this simple question. More generally, one can take an arbitrary commutative mial equation has solutions inring [III.81](/part-03/rings-ideals-and-modules)R, and ask whether a certain polyno-R. For instance, does(2) have a solution with ring C[t]? (The answer is yes.
We leave it as an exercisex, y, z in the polynomial the solution1. Exercise: why does our argument not obtain a contradiction from$x = y = z =$0?

373

to find some solutions.) We call the problem of solving a polynomial equation over R a Diophantine problem over cise boundary, but to a first approximation one may say R. The subject of arithmetic geometry has no pre- that it concerns the solution of Diophantine problems over subrings of number fields [III.63](/part-03/number-fields). (To be honest, a problem is usually called Diophantine only when R is a subring of a number field.
However, the more general definition suits our current purposes.) With any particular equation like (2), one can associate each commutative ring infinitely many Diophantine problems, one for$R$. A central insight—in some sense the basic insight—of modern algebraic geometryis that this whole gigantic ensemble of problems can be treated as a single entity. This widening of scope reveals structure that is invisible if we consider each problem on its own. The aggregate we make of all these Diophantine problems is called a scheme.
We will return to schemes later, and will try, with out giving precise definitions, to convey some sense of what is meant by this not very suggestive term. of the immense progress that has taken place in arith-A word of apology: I will give only the barest sketch metic geometry in recent decades—there is simply too much to cover in an article of the present scope. I have chosen instead to discuss at some length the idea of a scheme, assuming, I hope, minimal technical know-ledge on the part of the reader.
In the final section, I shall discuss some outstanding problems in arith-metic geometry with the help of the ideas developed in the body of the article. It must be conceded that the theory of schemes, developed by Grothendieck and his collaborators in the 1960 s, belongs to algebraic geometry as a whole, and not to arithmetic geometry alone. I think, though, that in the arithmetic setting, the useof schemes, and the concomitant extension of geometric ideas to contexts that seem “nongeometric” at first glance, is particularly central.
2 Geometry with out Geometry Before we dive into the abstract theory of schemes, let us splash around a little longer among the polynomial equations of degree 2. Though it is not obvious from our discussion so far, the solution of Diophantine prob-lems is properly classified as part of geometry. Our goal here will be to explain why this is so. Suppose we consider the equation

$x2 + y2 = 1$. (5)

374

One can ask: which values ofx, y \in Qsatisfy (5)? This problem has a flavor very different from that of the pre-vious section. There we looked at an equation with no rational solutions. We shall see in a moment that (5), by contrast, has infinitely many rational solutions. The solutions resentative examples.
(The four solutions$x = 0$, y = 1 and x = 3 5$, y = −(±4 51\text{are rep}-$,0) and(0,±1) are the ones that would be said, in the usual mathematical parlance, to be “staring you in the face.”)Equation (5) is, of course, immediately recognizable as “the equation of a circle.” What, precisely, do wemean by that assertion? We mean that the set of pairs of real numbers plotted in the Cartesian plane.(x, y) satisfying (5) forms a circle when trance in the figure of the circle. Now suppose that wewant to find more solutions to (5).
One way to proceed So geometry, as usually construed, makes its enis as follows. Let P be the point line through P of slopem. Then we have the following(1,0), and let L be a geometric fact. (G) The intersection of a line with a circle consists of either zero, one, or two points; the case of a single point occurs only when the line is tangent to the circle. From (G) we conclude that, unless L is the tangent line to the circle at P, there is exactly one point other than P where the line intersects the circle. In order to find solutions for this point.
So suppose L is the line through(x$, y) to (5)$, we must determine coordinates(1,0) with slope equation ismy, which is to say it is the line L= m(x - 1). Then in order to find them who sex and the circle, we need to solve the simultaneous equa--coordinates of the points of intersection between Lm tions$y = m(x - 1) and x^{2} + y^{2} =$1; that is, we need to solvex2 + m2(x - 1)2 = 1 or, equivalently,(1 + m2)x2 - 2 m2 x + (m2 - 1) = 0. (6) Of course, (6) has the solution x = 1. How many other solutions are there?
The geometric argument above leads us to believe that there is at most one solution to (6). Alternatively, we can use the following algebraic fact, which is analogous2 to the geometric fact (G). (A) The equation$(1 + m^{2})x^{2} - 2m^{2}x + (m^{2} - 1) = 0$ has either zero, one, or two solutions inx. because the notion of tangency is more subtle in the algebraic setting, as we will see in section 4 below.2. Note that (A), unlike (G), contains no mention of tangency; that is

IV. Branches of Mathematics

Of course, the conclusion of statement (A) holds for anyis a consequence of the factor theorem.nontrivial quadratic equation inx, not just (6); it theorem; one can find by direct computation that the solutions of (6) are In this case, it is not really necessary to appeal to any x = 1 and x = (m2 - 1)/(m2 +1 circle and L). We conclude that the intersection between the unit consists of (1, 0) and the point P withmm coordinates m(m2)2 -+ 11 , m - 22 m + 1 .
(7) which associates with each slope What is more, since every point on the circle, other than Equation (7) establishes a correspond en cem a solution Pmm \to to (5).Pm,(1, 0) itself, is joined to (1, 0)by a unique line, we find that we have established a one-to-one correspondence between slopesm and solutions, other than (1, 0), to$equation (5)$. A very nice feature of this construction is that it allows us to construct solutions to (5) not only over R but over smaller fields, like Q: it is evident that, when myielded by (7).
For example, taking is rational, so are the coordinates of the solutio nm = 2 yields the solution(5) admits infinitely many solutions over(3 5$,- {}^{45})$. In fact, not only does (7) show us that Q, it also gives us an explicit way toof a variablem. We leave it as an exercise to prove that parametrize the solutions in terms the solutions of (5) over Q, apart from(1,0), are in one- to-one correspondence with rational values ofrare is the Diophantine problem whose solutions canm. Alas, be parametrized in this way!
Still, polynomial equations like (5) with solutions that can be parametrized by one or more variables play a special role in arithmetic geometry; they are called any measure the best-understood class of examples inrational varieties and constitute by the subject. ture of this discussion. We relied on geometric intu-ition (e.g., our knowledge of facts like (G)) to give us I want to draw your attention to one essential fea ideas about how to construct solutions to (5).
On the other hand, now that we have erected an algebraic justification for our construction, we can kick away our geometric intuition as need less scaffolding. It was a geometric fact about lines and circles thatto us that (6) should have only one solution other than suggested x = 1. However, once one has had that thought, one can prove of the purely algebraic statement (A), which involves nothat there is at most one such solution by means geometry whatsoever.

IV.5. Arithmetic Geometry

erence to geometry means that it can be applied in sit-The fact that our argument can stand with out any refuations that might not, at first glance, seem geometric. For instance, suppose we wished to study solutions to (5) over the finite field not seem rightfully to be called “a circle” at all—it is F7. Now this solution set would just a finite set of points! Nonetheless, our geometri-cally inspired argument still works perfectly.
The possible values of corresponding solutions Pm in F7 are 0, 1, 2, 3, 4, 5, 6, and theare (-1, 0), (0, -1), (2,2),(with5,5)(,1(,50,)2, form the whole solution set of (5) over), (2, 5), (0,1). These seven points, to get herm F . We have now started to reap the benefits of consid - 7 ering a whole bundle of Diophantine problems at once; in order to find the solutions to (5) over F , we used a method that was inspired by the problem of find-ing solutions to (5) over R. Similarly, in general, meth - 7 ods suggested by geometry can help us solve Diophantine problems.
And these methods, once translated into purely algebraic form, still apply in situations that do not appear to be geometric. the purely algebraic appearance of certain equations is We must now open our minds to the possibility that deceptive. Perhaps there could be a sense of “geometry”that was general enough to include entities like the solution set of (5) over example had every right to be called a “circle.” And why F7, and in which this particular not? It has properties a circle has: most importantly forus, it has either zero, one, or two intersection points with any line.
Of course, there are features of “circleness” which this set of points lacks: infinitude, continu - ity, roundness, etc. But these latter qualities turn out to be inessential when we are doing arithmetic geometry. From our viewpoint the set of solutions of (5) over F has every right to be called the unit circle. view as an upending of the traditional story of Carte-To sum up, you might think of the modern point of sian space.
There, we have geometric objects (curves, lines, points, surfaces) and we ask questions such as, “What is the equation of this curve?” or “What are the coordinates of that point?” The underlying object is the geometric one, and the algebra is there to tell us about its properties. For us, the situation is exactly reversed: the underlying object is the equation, and the various geometric properties of solution sets of the equation are merely tools that tell us about the equation’s algebraic properties. For an arithmetic geometer, “the unit circle” is the equationx2 + y2 = 1.
And the round thing on the page? That is just a picture of the solutions to 375 the equation over R. It is a distinction that makes a remarkable difference. 3 From Varieties to Rings to Schemes In this section, we will attempt to give a clearer answer to the question, “What is a scheme?” Instead of trying to lay out a precise definition—which requires more alge-braic apparatus than would fit comfortably here—we will approach the question by means of an analogy. 3.1 Adjectives and Qualities So let us think about adjectives.
Any adjective, such as“yellow” for instance, picks out a set of nouns to which the adjective applies. For each adjective call this set of nounsΓ (A). For instance, Γ (A“yellow”, we might) is an infinite set that might look like banana, sun, . . . .3 And anyone would agree that\. lemon, school bus,Γ (A)\\} is an important thing to know about Now suppose that, moved by a desire for lexical par - A. simony, a theoretic i an among us suggested that adjec-tives could in fact be dispensed with entirely.
If, instead of grammatical theory involving only nouns. A, we spoke only of Γ (A), we could get by with a obvious ways that things could go wrong. For instance, what if lots of different adjectives were sent to the same Is this a good idea? Well, there are certainly some set of nouns? Then our new viewpoint would be less precise than the old one. But it certainly seems that iftwo adjectives apply to exactly the same set of nouns, then it is fair to say that the adjectives are the same, orat least synonymous.
instance, we can ask of two adjectives whether oneis What about relationships between adjectives? For stronger than another, in the way that “gigantic” is stronger than “large.” Is this relationship between adjectives still visible on the level of sets of nouns? The answer is yes: it seems fair to say that than”B precisely when Γ (A) is a subset of AΓ (B)is “stronger. In other words, what it means to say that “gigantic” is stronger than “large” is that all gigantic things are large, though some large things may not be gigantic. So far, so good. We have paid a price in technical difficulty:
it is much more cumbersome to speak of infinite sets of nouns than it was to use simple, familiar adjectives. But we have gained something, too: “yellow” is not so clear-cut, but since our goal is to make this look like mathematics, let us pretend that every object in the world is either3. Of course, in real life, there are nouns whose relationship with definitively yellow or definitively not yellow.

376

the opportunity for generalization. Our theoretic i an—whom we may now call a “set-theoretic grammarian”— observes that there is, perhaps, nothing special about the sets of nouns that happen to be of the formΓ (A) for some already known adjective A. Why not take a con- ceptual leap and“a set of nouns”? To avoid confusion with the usual redefine the word “adjective” to mean meaning of “adjective,” the theoretic i an might even use a new term, like “quality,” to refer to his new objects of study. with.
For example, there is a quality“sun”Now we have a whole new world of qualities to play which is stronger than “yellow,” and a quality“school bus”, “sun” (not the same thing as the noun“sun”!) which is stronger than the qualities “yellow,” “gigantic,” “large,”and“school bus”,“sun”. reconception of the notion of “adjective” is a good idea. In fact, it probably is not, which is why set-theo-I may not have convinced you that, on balance, this retic grammar is not a going concern. The correspond-ing story in algebraic geometry, however, is quite a different matter.

3.2 Coordinate Rings

A warning: the next couple of sections will be difficult going for those not familiar with rings and ideals—such readers can either skip to section 4, or try to follow the discussion after reading[III.81](/part-03/rings-ideals-and-modules) (see also algebraic numbers rings, ideals, and modules[IV.1](/part-04/number-theory)). on, just “variety”) is the set of solutions over Let us recall that a complex affine variety (from now C to some finite set of polynomial equations. For instance, one variety Vwe could define is the set of points(x, y) in C2 satisfying our favorite equation x2 + y2 = 1.
(8)

Then unit circle,” though in fact the shape of the set of Vis what we called in the previous section “the complex solutions of (8) is a sphere with two points removed. (This is not supposed to be obvious.) It is a question of general interest, given some variety X, to understand the ring of polynomial functions that take points on X to complex numbers. This ring is called the coordinate ring of X , and is denoted Γ (X). regard it as a function defined on our particular vari-ety Certainly, given any polynomial in V.
So is the coordinate ring of V xjust the polyno-and y, we can mial ring function$f$ C[x$, y]= 2x^{2}$? Not quite. Consider, for instance, the+2 y2+5. If we evaluate this function

IV. Branches of Mathematics

at various points on$V$, f (0, 1) = 7, f (1, 0). qrt = 7, . qrt . qrtf (1/ 2,1/ 2) = 7, f (i, 2) = 7, . . . ,

we notice thatsincex2 + y2 = f 1 for all keeps taking the same value; indeed,(x, y) \in V, we see that f =$2So 2$(x2 x+2 + y22)y+2 + 5 takes the value 7 at5 and 7 are just different names for the every point on V. same function on SoΓ (V ) is smaller than V . C[x, y]; it is the ring obtained from C[x, y] by declaring two polynomials f and g to be the same function whenever they take the same value at every point of$V$.
(More formally, we are defining an complex polynomials in two variables.) It turns out that equivalence relation [I.2 §2.3](/part-01/language-and-grammar) on the set of fence is a multiple ofand ghave this property precisely when their differ-x2 +y2 -1. Thus, the ring of poly- nomial functions on ideal generated byx2 V+is the quotient ofy2 - 1. This ring is denoted by C[x, y] by the$C$[x, y]/(x2 + y2 - 1). any variety.
It is not hard to show that, if We have shown how to attach a ring of functions to X and Y are two varieties, and if their coordinate ringsΓ (Y ) are isomorphic[I.3 §4.1](/part-01/fundamental-definitions), then X andΓ (X)Y are inand a sense the “same” variety. It is a short step from this observation to the idea of abandoning the study of vari-eties entirely in favor of the study of rings.
Of course, we are here in the position of the set-theoretic gram-marian in the parable above, with “variety” playing the part of “adjective” and “coordinate ring” the part of “setof nouns.” Happily, we can recover the geometric properties of a variety from the algebraic properties of its coordinate ring; if this were not the case, the coordinate ring would not be such a useful object! The relationship between geometry and algebra is a long story—and much of it belongs to algebraic geometry in general, not arithmetic geometry in particular—but to give the flavor, let us discuss some examples.
irreducibility A straightforward geometric property of a variety is. We say a variety X is reducible if X can be expressed as the union of two varieties neither of which is the whole of$X$. For example$, the X1 and X2$, variety

x2 = y2 (9)

in C2 is the union of the lines$x = y and x = −y$. A vari- ety is called irreducible if it is not reducible. All varieties are thus built up from irreducible varieties: the relation-ship between irreducible varieties and general varieties

IV.5. Arithmetic Geometry

is rather like the relationship between prime numbers and general positive integers. ring Moving from geometry to algebra, we recall that a R is called an integral domain if, whenever f , g are nonzero elements of nonzero; the ring C[x, y] Ris a good example., their product f g is also Fact.integral domain. A variety X is irreducible if and only if Γ (X) is an Experts will note that we are glossing over issues of “reducedness” here. ple is illustrative:
consider the two functions and We will not prove this fact, but the following exam-g = x + y on the variety Xdefined by (9)$. Nei-$ f = x - y ther of these functions is the zero function; note, for instance, that$f (1$, -1) is nonzero, as is g(1,1). Their product, however, is$x^{2} - y^{2}$, which is equal to zero onthe functions$X$; soΓ (X)f is not an integral domain. Notice that and g that we chose are closely related to the decomposition of X as the union of two smaller varieties. Another crucial geometric notion is that of functions from one variety to another.
(It is common practice tocall such functions “maps” or “morphisms”; we will use the three words interchangeably.) For instance, sup-pose that W is the variety in C3 determined by the equation xyz = 1. Then the map F$: C3$\to C2 defined by F(x$, y, z) = 12 (x + yz)$, 2 i1 (x - yz) maps points of W to points of V . eties makes it very easy to see the maps between the varieties.
We merely observe that if It turns out that knowing the coordinate rings of vari-$G$:$V \to V \text{is a}$ map between varieties$V^{1} and V^{2}$, and if f1 is a polyno-2 mial function ontion on V that sends every point V2, then we have a polynomial func-v to f (G(v)). This function onis the function1 V^1 is denoted byx + y on V , and G^*(f )F . For example, ifis the map above, f Fthat^*(f )G^*=is a^1^2 (x C-algebra homomorphism (that is, a homo-+ yz) +^2 i^1 (x - yz). It is easy to check morphism of rings that sends each element of C to itself) from$Γ (V^{2}) to Γ (V^{1})$.
What is more, one has the following theorem. Fact.dence sending For any pair of varieties G to G* is a bijection between the poly-V , W , the correspon- nomial functions sending W to V and the C-algebra homomorphisms fromΓ (V ) to Γ (W ).

377

“there is an injective map from You would not be far off in thinking of the statement V to W” as analogous to “quality The move to transform geometry into algebra is A is stronger than quality B.” not something one under takes out of sheer love of abstraction, or hatred of geometry. Instead, it is part of the universal mathematical instinct to unify seem-ingly disparate theories. I cannot put it any better than Dieudonné (1985) does in his Geometry: History of Algebraic . .
.kind–Weber dates the awareness of the profound anal-from [the 1882 memoirs of] Kronecker and Dedeogies between algebraic geometry and the theory ofalgebraic numbers, which originated at the same time. More over, this conception of algebraic geometry is the most simple and most clear for us, trained as we are in the wielding of “abstract” algebraic notions: rings, ideals, modules, etc. But it is precisely this “abstract” character that repulsed most contemporaries, discon-certed as they were by not being able to recover the corresponding geometric notions easily.
Thus the influ-ence of the algebraic school remained very weak up until 1920.the first to dream of one vast algebraico-geometric con-. . . It certainly seems that Kronecker was struc tion comprising these two theories at once; this dream has begun to be realized only recently, in our era, with the theory of schemes. Let us therefore move on to schemes.

3.3 Schemes

We have seen that each varietyΓ (X), and further more that the algebraic study of these X gives rise to a ring rings can stand in for the geometric study of varieties. But just as not every set of nouns corresponds to an adjective, not every ring arises as the coordinate ringof a variety. For example, the ring Z of integers is not the coordinate ring of a variety, as we can see by the following argument: for every complex number a and every variety V , and therefore V , the constant function C ⊂ Γ (V ) for every variety a is a function on V .
Since Z does not contain C as a subring, it is not the coordinate ring of any variety. marian’s coup de grâce. We know that some, but not all, Now we are ready to imitate the set-theoretic gram rings arise from geometric objects (varieties); and weknow that the geometry of these varieties is described by algebraic properties of these special rings. Why not, then, just consider every ring$R$to be a “geometric object” whose geometry is determined by algebraic properties of$R$? The grammarian needed to invent a

378

new word, “quality,” to describe his generalized adjec-tives; we are in the same position with our rings-that are-not-coordinate-rings; we will call them schemes. rather prosaic—schemes are rings! (In fact, we are hid-ing some technicalities; it is correct to say that So, after all this work, the definition of scheme is affine schemes schemes will not interfere with the phenomena that are rings.
Restricting our attention to affine we are aiming to explain.) More interesting is to askhow we can carry out the task whose difficulty “disconcerted” the early algebraic geometers—how can weidentify “geometric” features of arbitrary rings? For instance, if R is supposed to be an arbitrary geo- metric object, it ought to have “points.” But what arethe “points” of a ring? Clearly we cannot mean by this the elements of the ring; for in the case$R = Γ (X)$, the elements ofwe need, given a point R are functionsp onon X, is some entity attached X, not points on X.
What to the ring The key observation is that we can think of R that corresponds to p. p as a map fromΓ (X) to C: given a functionf from Γ (X) we map it to the complex numberf (p). This map is a homomorphism, called theatp. Since points on X give us homomorphisms on evaluation homomorphismΓ (X)ring R, a natural way to define the word “point” for the$= Γ (X)$, with out using geometry, is to say that a “point” is a homomorphism from R to C. It turns out that the kernel of such a homomorphism is a maximal ideal, i.e., a proper ideal in larger ideal except R itself.
More over, every maximal R which is contained in no ideal ofway to describe the points of R arises from a point p Xof might be to say that X. So a very concise they are the maximal ideals of R. A modern algebraic geometer would say that all points, not only the maximal ones. The “points” cor-prime ideals correspond to responding to the nonmaximal ideals are not points in the usual sense of the term;
for instance, the point corresponding to the zero ideal (when it is prime) is the “generic point,” which is in one sense every where on X at once, and in another sense no where in par- ticular at all.
This description sounds rather woolly, but on the algebraic side the zero ideal is something quite concrete—and in fact, having a precise notion of “generic point” turns out quite often to be useful in making a certain species of vague geometric argument into a rigorous proof. The definition we have arrived at makes sense for all rings R, and not just those of the form R = Γ (X). So we might define the “points” of a ring ideals. The set of prime ideals of R is given the name R to be its prime

IV. Branches of Mathematics

Specated with R, and it is Spec R. (More precisely, Spec R that we call the Ris defined to be a scheme associ“locally ringed topological space” whose points are the prime ideals ofof this definition for our discussion here.)R, but we will not need the full power made in the first section, that a scheme incorporates into one package Diophantine problems over many dif-We are now in a position to elucidate our claim, ferent rings. Suppose, for instance, that Z[x$, y]/(x^{2} + y^{2} - 1)$. We are going to catalog the homo-R is the ring morphisms tell you the values of$f$:$R \to Zf (x)$.
To specify and f (y)f , I merely have toin Z. But I cannot choose these values arbitrarily: since in R, it must be the case that f (x)2+f (y)(x2)2+-y12=-0 in1 =Z0. In other words, the pair tion over Z to the Diophantine equation(f (x)$, f (y)) \text{constitutes a solu} - x^{2} + y^{2} = 1$. What is more, the same argument shows that, for ring S, a homomorphism f:$R \to S \text{yields a solutionany}$ over S to x2 + y2 = 1, and vice versa. In summary, for each twe en the set of ring homomorphisms from S, there is a one-to-one correspondence be-R to S, and solutions over$S to x^{2} + y^{2} = 1$.
This behavior is what we have in mind when we say that the ring$R$“packages” information about Diophantine equations over different rings. esting geometric property of varieties can be computedby means of the coordinate ring, which means it can It turns out, just as one might hope, that every inter be defined not only for varieties but also for general schemes. We have already seen, for instance, that a variety domain.
Thus, we say in general that a scheme Spec X is irreducible if and only if Γ (X) is an integral R is irreducible if and only ifmore precisely, if the quotient of R is an integral domain (or, R by its nilradical is an integral domain). One can speak of the connectedness of a scheme, its dimension, whether it is smooth, andso forth. All these geometric properties turn out, like irreducibility, to have purely algebraic descriptions. Infact, to the arithmetic geometer’s way of thinking, all these are, at bottom, algebraic properties.

3.4 Example: Spec Z, the Number Line

The first ring we encounter in our mathematical education—and the ring that is the ultimate subject of num-ber theory—is Z, the ring of integers. How does it fit into our picture? The scheme Specof prime ideals of Z, which come in two flavors: there Z has as its points the set are the principal ideals there is the zero ideal.(p), with pa prime number; and

IV.5. Arithmetic Geometry

tions” on Spec I merely need to tell you how to evaluate an integer We are supposed to think of Z. How can an integer be a function? Well, Z as the ring of “func-n at a point of Spec Z. If the point is a nonzero prime ideal (p)cisely the homomorphism whose kernel is, then the evaluation homomorphism at(p)(p); so theis pre value of At the point$n at((p)0)$, the evaluation homomorphism is theis just the reduction of n modulo p. identity map Z$\to Z$; so the value ofn at (0) is just n. 4 How Many Points Does a Circle Have?
We now return to the method of section 2, paying particular attention to the case where the equation $x^{2}\text{Let us write} + y^{2} =$1 is considered over a finite field V for the scheme of solutions of Fp. x2 +yof solutions of2 = 1. For any ringx2 + y R2, we will denote by= 1. V (R) the set In particular, it is ahow large this set is: in other words, how many points If Ris a finite field finite Fp , the setset. So it is natural to wonder V (Fp) is a subset of (F2)p. does a circle have?
observed that, for every In section 2, guided by our geometric intuition, we$m \in Q$, the point$P$ m = m(m2)2 -+ 11 $, m - 22 + m1$ lies on The algebraic computation showing that P$V$.msatisfies the equationx2 + y2 =1 is no different over a finite field. So we might be inclined to think thatsists of$p +$1 points: namely, the points PV (Ffor eachp ) con - mm But this is not right: for instance, when$\in F^{p}$, together with (1,0).
p = 5 it is easy to check that the four points(-1, 0) make up all of V (F )$. Computing P(0,1)$, (0,-1 for vari-), (1,0)$, ousor 3$, the formula for Pm, we quickly discover the problem; whenm does not make sense, becaus(e5)m m is 2 the denominator did not see over Q$m$, where2 +1 is zero! This is a wrinkle we$m^{2} + 1 \text{was always positive}$. section of the line Lwith What is the geometric story here? Consider the inter-V . If (x, y) belongs to this intersection, then2, that is, the line y = 2(x - 1)$, x2+(2(x - 1))2 = 1$, so 5 x2 - 8 x + 3 = 0.
Since 5 = 0 and8 in other words,= 3 in F5, this equation can be written as 3 x = 1, which in turn implies that- 3 yx ==0;0. In other words, the line Lone point! 2 intersects the circle V at only We are left with two possibilities, both disturbing to our geometric intuition. We might declare that Lgent to$V$; but this means that V would have multiple2 is tan-379 tangents at(1,0), since the vertical line x = 1 should surely still be considered a tangent. The alternative isto declare that L is not tangent to V;
but then we are in the equally unsavory situation of having a line which, while not tangent to the circle2 V , intersects it at only one point. You are now beginning to see why Idid not include an algebraic definition of “tangent” in statement (A) above!This quandary illustrates the nature of arithmetic geometry nicely.
When we move into novel contexts, like geometry over F , some features stay fixed (such as “a line intersects a circle in at most two points”), while others have to be discarded (such as “there exists$p$ exactly one line, which we may call the tangent line tothe circle at(1,0), that intersects the circle at (1$, 0) and$ no other point”4). to compute the number of points inall, when Notwithstanding these subtleties, we are now readyp = 2 one can check directly that V (Fp )(. First of0,1) and(this case, we assume for the rest of this section that1, 0) are the only two points in V (F2).
Having treated pe qu at i on is odd. It follows from basic number theory that them2 + 1 = 0 has a solution in F if and only ifsuchp ≡m1. So, if(mod 4 p )≡, in which case there are exactly two3 (mod 4), then every line Lp inter- sects the circle at a point other thanp + 1 points in all$. If p ≡ 1 (mod 4(1,)$, there are two0), and we havem choices of eliminating these two choices ofm for which Lm inter sec tsm yields a total of V only at (1, 0); p -We conclude that1 points in V (Fp|)V (. F )| is equal to 2 when p = 2,$to$(mod 4 p - 1 when).
The interested reader will find the following$p ≡ 1 (mod 4^{p} )$, and to p + 1 when p ≡ 3 exercises useful: how many solutions are there to3$y^{2} = 1 over F$? What about$x^{2} + y^{2} =$0?$x^{2} +$ any More generally, let system of equationsp X be the scheme of solutions of F1(x1, $. . . , xn) = 0, F2(x1$, . . . , xn) = 0, . . . , (10) where the Fare polynomials with integral coeffii cients. Then one can associate with N (X), N (X), N (X), . . . , where N (X)F a list of integersis the number of solutions to (10) with integers turns out to contain a surprising amount of2 3 5 x1, . . .
, (xp)n \in  Fp. This list of geometric information about the scheme the simplest schemes, the analysis of these lists is a X; even for deep problem of intense current interest, as we will seein the next section. Vat a single point., but that there are certain nontangent lines that intersect the circle4.
In this case, the right attitude to adopt is that L2 is not tangent to 380 Contemporary Arithmetic Geometry5 Some Problems in Classical and In this section I will try to give an impression of a few of arithmetic geometry’s great successes, and to gesture at some problems of current interest for researchers inthe area. be trying to give brief and nontechnical descriptions of some mathematics of extreme depth and complex - A word of warning is in order. In what follows, I will ity.
Consequently, I will feel very free to oversimplify. I will try to avoid making assertions that are actually false, but I will often use definitions (like that of the L-function attached to an elliptic curve) that do not exactly agree with those in the literature. 5.1 From Fermat to Birch–Swinnerton-Dyer The world is not lacking in expositions of the proof of fermat’s last theorem [V.10](/part - 05/fermats - last - theorem) and I will not attempt to give another one here, although it is with out ques-tion the most not able contemporary achievement in arithmetic geometry.
(Here I am using the mathemat i - cian’s sense of “contemporary,” which, as the old joke goes, means “theorems proved since I entered graduate school.” The shorthand for “theorems proved before Ientered graduate school” is “classical.”) I will content myself with making some comments about the struc-ture of the proof, emphasizing connections with the parts of arithmetic geometry we have discussed above. Fermat’s last theorem (rightly called “Fermat’s conjecture,” since it is almost impossible to imagine that fermat [VI.12](/part - 06/pierre - fermat - 1601665) proved it) asserts that the
equation A + B = C, (11) where integers Ais an odd prime, has no solutions in positive, B, C. dently by Frey and Hellegouarch, of associating with any solution The proof uses the crucial idea, introduced indepen-(A, B, C) of (11) a certain variety X , A, B

namely the curve described by the equation

$y^{2} = x(x - A )(x + B )$.

What can we say about ple heuristic. There are$Np^{p}\text{choices for}(X^{A}$, B)? We begin with a sim-x in F . For each choice offory, depending on whe the rx, there are either zero, one, or two choice sx(x - A )(xp + B ) is a quadratic nonresidue, zero, or a quadratic residue in F . Since there are equally many quadratic residues and nonresidues in cases arise equally often. If so, there would on average$p F^{p}$, we might guess that those two be one choice ofy for each of the p choices of x, which

IV. Branches of Mathematics

inclines us to make the estimateato be the error in this estimate:$N^{p}a(X = A$, Bp)-∼Np. Define(X ). It is worth remembering that when attached top x2 + y2 = 1, the behavior of Xp was the sch emep - p NA, B(X) was very regular; in particular, this quantity took the value 1 at primes congruent to 1 mod 4 and-p1 at primes congruent to 3 mod 4. (We note, in particular, that the heuristic estimate N (X) ∼ p is quite good in this case.) Might one hope that kind of regularity? p ap displays the same famous theorem of Mazur shows;
not only do the fail to vary periodically, even their reductions modulo In fact, the behavior of theap is very irregular, as aap various primes are irregular! Fact (Mazur).and letb be a positive integer. It is not the case that Suppose that is a prime greater than 3, acongruent to 1 p takes the same value(modb).5 (mod ) for all primes p paper into a slogan—Wiles proved that, whenis a solution to (11), the reductions mod On the other hand—if I may compress a 200-pageof the A, B, a C necessarily theorem when behaved periodically, contradicting Mazur’s> 3.
The case = 3 is an old the ore mp of conjecture, and, I hope, bolsters our assertion that the euler [VI.19](/part - 06/leonhard - euler - 17071783). This completes the proof of Fermat’s careful study of the values to study a variety X!Np(X) is an interesting way ifno repeated roots, the curvef (x)But the story does not end with Fermat. In general, is a cubic polynomial with coefficients in Edefined by the equation Z and

y2 = f (x) (12)

is called anelliptic curve is not an ellipse). The study of rational elliptic curve [III.21](/part-03/elliptic-curves) (note well that an points on elliptic curves (that is, pairs of rational num-bers satisfying (12)) has been occupying arithmetic geometers since before our subject existed as such; a decent treatment of the story would fill a book, as indeed it does fill the book of Silverman and Tate(1992). We can define a (E) to be p - N (E) as above. First of all, if our heuristic mate, we might expect thatp N(ap)p(E)(E) ∼is small compare dp is a good esti-p with shows that$p$;
and, in fact, a theorem of Hasse from the 1930 sa (E) ⩽ 2. qrt{p}for all but finitely manyp.p

and much more general way: he proves that certain do not possess any rational points. This implies that a version of the5. The theorem proved by Mazur is stated by him in a very different modular curves fact above is true, not only for$y^{2} = f (x)$, where f is a cubic polynomial with out repeated roots. We X^A, B, but for any equation of the form will leave it to the other able treatments of Fermat to develop that point of view.

IV.5. Arithmetic Geometry

many rational points, and some only finitely many. One might expect that an elliptic curve with many points It turns out that some elliptic curves have infinitely over Q would tend to have more points over finite fields as well, since the coordinates of a rational point can be reduced modpto yield a point over the finite field F . Conversely, one might imagine that, by knowing the listof numbers$a^{p}$, one could draw conclusions about thep points of E over Q. way to package the information of the infinite list ofintegers In order to draw such conclusions, one needs a nicea .
Such a package is given by the L-function [III.47](/part-03/l-functions) of the elliptic curve, defined to be the following function of a variablep s: L(E, s) = p (1 - app-s + (p1()-2)s)-1. (13) The notation over all primes apart from a finite set, which is easy means that this product is evaluated to determine from the polynomial case, we are over simplifying; what I have written heref . (As is often the differs in some irrelevant-to-us respects from what is usually called L(E, s) in the literature.) It is not hard to check that (13) is a convergent product when number greater than 3.
Not much deeper is the facts is a real that the right-hand side of (13) is well-defined whenis a complex number whose real part exceeds2 3 . What$s$ istogether with later theorems of Breuil, Conrad, Dia-much deeper—following from the theorem of Wiles,2 mond, and Taylor—is that we can extend a holomorphic function [I.3 §5.6](/part-01/fundamental-definitions) defined for L(E, s)every to complex numbers. relationship between the values of value of A heuristic argument might suggest the following$L(E, 1)$.
If the a^p are typically negative (corre-N^p (E) and the sponding to thethe terms in the infinite product tend to be smaller Np (E) typically being greater than p) than 1; when the product tend to be larger than 1. In particular, oneap are positive, the terms in the might expect the value of L(E, 1) to be closer to 0 when heuristic should be taken with a healthy pinch of salt, E has many rational points. Of course, this given thatnite product on the right-hand side of (13)!
None the-L(E, 1)is not in fact defined by the inf i less, which makes precise the heuristic prediction above, the birch–swinnerton-dyer conjecture [V.4](/part-05/the-birchswinnerton-dyer-conjecture), is widely believed, and supported by many partial results and numerical experiments. We do not have the space here to state the conjecture in full generality. However, the following conjecture would follow from Birch–Swinnerton - Dyer. 381 Conjecture.points over QThe elliptic curve if and only if L(E, E1)has infinitely many = 0. in 1988:
that L(E, Kolyvagin proved one direction of this conjecture1). eq 0. (To be precise, he proved a theorem that Ehas finitely many rational points if yields the assertion here once combined with the later theorems of Wiles and others.) It follows from a theorem of Gross and Zagier that rational points if L(E, s) has a simple Ehas infinitely many zero ats = 1. That more or less sums up our present knowledge about the relationship between L-functions and rational points on elliptic curves.
This lack of knowledge has not, how - ever, prevented us from constructing a complex of ever more rarefied conjectures in the same vein, of which the Birch–Swinnerton-Dyer conjecture is only a tiny and relatively down - to-earth sliver. Before we leave the subject of counting points behind, we will pause and point out one more beautiful result: the theorem of andré weil [VI.93](/part - 06/andr - weil - 19061998) bounding the number of points on a curve over a finite field.
(Because we have not introduced projective geometry, we will satisfy ourselves with a some what less beautiful formulation than the usual one.) let polynomial in two variables, and let F(x, y)X be an irreducible be the scheme of solutions of define a certain subset of F(x, y) = 0. Then the complex points of C2, which we call an algebraic X curve condition on the points of. Since X is obtained by imposing one polynomial C2, we expect that X has complex dimension 1, which is to say it has real dimen - sion 2. Topologically speaking, X(C) is, therefore, a surface.
It turns out that, for almost all choices ofthe surface X(C)will have the topology of a “g - holed F , doughnut” with tive integersg andd points removed, for some nonneg a - d. In this case we say that X is a curve of genus In section 2 we saw that the behavior of schemes overg. finite fields seemed to “remember” facts arising from our geometric intuition over R and C: our example there was the fact that circles and lines intersect in at most two points. The theorem of Weil reveals a similar, though much deeper, phenomenon. Fact.is a curve of genus Suppose the scheme$g$.
Then, for all but finitely many X of solutions of F(x, y) prime sp + 1 + p2, the number of points ofg. qrt{p} and at least p + 1 - X2 gover. qrt{p} - Fpd.is at most between geometry and arithmetic. The more compli-cated the topology of Weil’s theorem illustrates the startlingly close bonds X(C), the further the number of$382 F$ p-points can vary from the “expected” answer ofp. What is more, it turns out that knowing the size ofthe set X(F )for every finite field F allows us to determine the genus ofsets of poin tsq X(F )some how “remember” the topol-$X$.
In other words, theqfinite ogy of the space of complex points language, we say that there is a theory applying to gen - q X(C)! In modern eral schemes, called étale cohomology, which mimics the theory of cohomology applying to the topology ofvarieties over C. taking the polynomial case, it turns out that Let us return for a moment to our favorite curve, by F(x, y)X(C) has = xg2 =+ y0 and2 - 1. In thisd = 2: our previous result thatp - 1 points therefore conforms exactly with the Weil X(Fp ) contains either p + 1 or bounds. We also remark that elliptic curves always have genus 1;
so the theorem of Hasse alluded to above is a special case of Weil’s theorem as well. Recall from section 2 that the solutions to x2 + y2 = 1, over R, over Q, or over various finite fields, could be parametrized by the variable parametrization that enabled us to determine a sim-m. It was this ple formula for the size of$X(F^{p}) \text{in this case}$. We remarked earlier that most schemes could not be so parametrized; now we can make that statement a bit more precise, at least for algebraic curves.
Fact.be parametrized by a single variable. If X is a genus-0 curve, then the points of X can (though stating it properly requires us to say more thanwe can here about “singular curves”). In other words, a The converse of this fact is more or less true as well thoroughly algebraic question—whether the solutions of a Diophantine equation can be parametrized—ishereby given a geometric answer.

5.2 Rational Points on Curves

As we said above, some elliptic curves (which are curves of genus 1) have finitely many rational points, and others have infinitely many. What is the situation for algebraic curves of other flavors?We have already encountered a curve of genus 0 with infinitely many points: namely, the curve On the other hand, the curve x2 + y2 = x27 also has + y2 = 1.$genus 0$, and a simple modification of the argument ofthe first section shows that this curve has no rational points. It turns out these are the only two possibilities. Fact. If X is a curve of genus 0, then X(Q) is either empty or infinite.

IV. Branches of Mathematics

dichotomy, thanks to the theorem of Mazur we alluded Genus-1 curves are known to fall into a similar to earlier. Fact.sixteen rational points or it has infinitely many rational If X is a genus-1 curve, then either X has at most points. 1920 s, Mordell made the following conjecture. What about curves of higher genus? In the early Conjecture.then Xhas finitely many rational points. If X is a curve of genus greater than 2, in fact, he proved a more general theorem of which this conjecture is a special case. It is worth remark-This conjecture was proved by Faltings in 1983;
ing that the work of Faltings involves a great deal of importation of geometric intuition to the study of the scheme Spec Z. wonder whether you can bound its size. For example, if When you prove that a set is finite, it is natural to f (x)the curve is a degree 6 polynomial with no repeated roots, y2 = f (x)turns out to have genus 2; so by Faltings’s theorem there are only finitely many pairs ofrational numbers(x$, y) satisfying y^{2} = f (x)$.
Question.degree 6 polynomials with coefficients in Is there a constant B such that, for all Q and no repeated roots, the equation$y^{2} = f (x) \text{has at most} B$solutions? is a strong consensus about whether the answer will be This question remains open, and I do not think there yes or no. The current world record is held by the curve y2 = 378 371 081 x2(x2 - 9)2 - 229 833 600(x2 - 1)2, which was constructed by Keller and Kulesz and has588 rational points. tion to a conjecture of Lang, which involves points Interest in the above question comes from its relaon higher-dimensional varieties.
Caporaso, Harris, and Mazur showed that Lang’s conjecture implies a positive answer to the question above. This suggests a natural attack on the conjecture: if one can find a way toconstruct an infinite sequence of degree 6 polynomials f (x) so that the equations y = f (x) have ever more numerous rational solutions, then one has a disproofof Lang’s conjecture! No one has yet been successful at this task. If one could prove that the answer to the question above was affirmative, it would probably bol-ster our faith in the correctness of Lang’s conjecture,

IV.6. Algebraic Topology

though of course it would bring us no nearer to turning the conjecture into a theorem. In this article we have seen only a glimpse of the modern theory of arithmetic geometry, and perhaps Ihave over emphasized mathematicians’ successes at the expense of the much larger territory of questions, like Lang’s conjecture above, about which we remain wholly ignorant. At this stage in the history of mathematics, we can confidently say that the schemes attached to Diophantine problemsis to say as much as we can about have geometry what this geom-.
What remains etry is like described here, our understanding is still quite unsat-, and in this respect, despite the progress is factory when compared with our knowledge of more classical geometric situations.

Further Reading

Dieudonné, J. 1985.terey, CA: Wadsworth. History of Algebraic Geometry. Mon Silverman, J., and J. Tate. 1992.Curves. New York: Springer. Rational Points on Elliptic IV.6 Algebraic Topology

Burt Totaro

Introduction

Topology is concerned with the properties of a geomet-ric shape that are unchanged when we continuously deform it. In more technical terms, topology tries toclassify topological spaces [III.90](/part-03/topological-spaces), where two spaces are considered the same if they are homeomorphic. Algebraic topology assigns numbers to a topological space, which can be thought of as the “number of holes”in that space. These holes can be used to show that two spaces are not homeomorphic: if they have differ-ent numbers of holes of some kind, then one cannot be a continuous deformation of the other.
In the happi-est cases, we can hope to show the converse statement: that two spaces with the same number of holes (in some precise sense) are homeomorphic. with its origins in the nineteenth century. Before that, mathematics usually sought to solve problems exactly: Topology is a relatively new branch of mathematics, to solve an equation, to find the path of a falling body, to compute the probability that a game of dice will lead to bankruptcy. As the complexity of mathematical problems grew, it became clear that most problems would never be solved by an exact formula:
a classic example is the problem, known as the three-body

383

problem of Earth, the Sun, and the Moon under the influence of[V.33](/part-05/the-three-body-problem), of computing the future movements gravity. Topology allows the possibility of making qual-it ative predictions when quantitative ones are impossible. For example, a simple topological fact is that a trip from New York to Montevideo must cross the equator at some point, although we cannot say exactly where. 1 Connectedness and Intersection Numbers Perhaps the simplest topological property is one called connectedness.
This can be defined in various ways, as we shall see in a moment, but once we have a notion of what it means for a space to be connected we can then divide a topological space up into connected pieces, called components. The number of these pieces is a simple but useful different numbers of connected components, then they invariant [I.4 §2.2](/part-01/general-goals): if two spaces have are not homeomorphic. of connectedness are equivalent. However, they can be generalized to give ways of measuring the number of For nice topological spaces, the different definitions holes in a space;
these generalizations are interestingly different and all of them are important. notion of a mapping The first interpretation of connectedness uses thef from the unit interval path, which is defined to be a continuous[0,1] to a given space X. (We think of f as a path from f (0) to f (1).) Let us declare two points ofpath from one to the other. The set of X to be equivalent if there is a equivalence classes of X and is written[I.2 §2.3](/part-01/language-and-grammar) is called the set ofπ (X).
This is a very natural way ofpath components defining the “number of connected pieces” into which X breaks up. One can generalize this notion by con-0 side ring mappings into X from other standard spaces such as spheres: this leads to the notion of homotopy groups, which will be the topic of section 2. based on functions from functions from a line segment into A different way of thinking about connectedness is X to the real line rather than X. Let us assume that we are in a situation where it makes sense to differentiate functions onopen subset of some Euclidean space, or more gener-X.
For example, X could be an ally a valued functions on smooth manifold X whose derivative is every where[I.3 §6.9](/part-01/fundamental-definitions). Consider all the real equal to zero: these functions form a real[I.3 §2.3](/part-01/fundamental-definitions), which we call H0(X, R)(the “zeroth cohom-vector space ology group of Xwith real coefficients”). Calculus tells us that if a function defined on an interval has deriva-tive zero, then it must be constant, but that is not true 384 when the domain has several connected pieces:
all wecan say then is that the function is constant on each connected piece of X. The number of degrees of free- dom of such a function is therefore equal to the num-ber of connected pieces, so the dimension of the vector space H0(X, R) is another way to describe the number of connected components of example of a cohomology group. Cohomology will be X. This is the simplest discussed in section 4.We can use the idea of connectedness to prove a serious theorem of algebra: every real polynomial of odd degree has a real root. For example, there must be some real numberx such that x3 + 3 x - 4 = 0.
The basic observation is that whenor a highly negative number, the termx is a large positive numberx3 is much bigger (in absolute value) than the other terms of the polyno - mial. Since this top term is an odd power ofx, we havef (x) > 0 for some positive number x and f (x) < 0 for some negative number then it would be a continuous mapping from the realx. If f were never equal to zero, line into the real line minus the origin. But the real lineis connected, while the real line minus the origin has two connected components, the positive and negative numbers.
It is easy to show that a continuous map froma connected space X to another space Y must map X into just one connected component ofthis contradicts the fact thatf takes both positive and Y: in our case, negative values. Thereforef must be equal to zero at some point, and the proof is complete. This argument can be phrased in terms of the “intermediate value theorem” of calculus, which is indeed one of the most basic topological theorems.
An equivalent reformulation of this theorem states that a continuous curve that goes from the lower half-plane tothe upper half-plane must cross the horizontal axis at some point. This idea leads toone of the most useful concepts in topology. let intersection numbers M, be a smooth oriented manifold. (Roughly speaking, a manifold is oriented if you cannot continuously slidea shape about inside it and end up with a reflection of that shape. The simplest nonoriented manifold is a Möbius strip:
to reflect a shape, slide it around the strip an odd number of times.) Let A and B be two closed oriented submanifolds ofup to the dimension of M. Finally, suppose that M with dimensions adding A and Bthe “correct” dimension, namely 0, and is therefore aintersect transversely, so that their intersection has collection of separated points. assigning a weight of Now letp be one of these points. There is a way of + 1 or - 1 to p, which depends IV. Branches of Mathematics B A A C (a) (b) Figure 1(a)A · Bi nt er section numbers:$=$1; (b)$A · C = −1$.
B B + 1 A + 1 + 1 A –1 Figure 2 Moving a submanifold. in a natural way on the relationship between the orientations ofif M is a sphere, A, B, and A is the equator of M(see figure 1). For example, M , B is a closed curve, and appropriate directions are given to B, then the weight of p will tell you whether B crosses A and Aonly finitely many points, then we can define the inter-upwards or downwards atp. If A and B intersect in section number of A and B, written A · B, to be the sum of the weights (+1 or - 1) at all the intersection points.
In particular, this will happen if(that is, we can think of it as a closed bounded subset M is compact [III.9](/part - 03/compactness - and-\text{compactication}) of RN for some N). is that it is anmove The important point about the intersection number A and Bin variant about in a continuous way, ending up, in the following sense: if you with another pair of transverse submanifolds A^ and B^ , then the intersection number A^ · B^ is the same as A · B, even though the number of intersection points can change.
To see why this might be true, consider again the case where A and B are curves and M is two dimensional: if1, we can wiggle one of them to turn that point into A and B meet at a point with weight three points with weights 1,-1, and 1, but the total contribution to the intersection number is unchanged. This is illustrated in figure 2. As a result, the intersection number A · Bis defined for any two submanifolds of complementary dimension:
if they do not intersect transversely, one can move them until they do and use the definition we have just given. In particular, if two submanifolds have nonzero intersection number, then they can never be moved to IV.6. Algebraic Topology Figure 3 A surface bounded by a knot. be disjoint from each other. This is another way todescribe the earlier arguments about connectedness. It is easy to write down one curve from New York to Montevideo whose intersection number with the equator is equal to 1. Therefore, no matter how we move that curve (provided that we keep the endpoints fixed:
more generally, if either boundary should be kept fixed), its intersection num - A or B has a boundary, then that ber with the equator will always be 1, and in particular it must meet the equator in at least one point. One of many applications of intersection numbers in topology is the idea offrom knot theory [III.44](/part - 03/knot - polynomials). Alinking numbers knot is a path in space that, which comes begins and ends at the same point, or, more formally, a closed connected one-dimensional submanifold of R3. Given any knot$S in R3 with K$as its boundary (see figure 3).
Now let$K$, it is always possible to find a surface$L$ be a knot that is disjoint fromof K with Lis defined to be the intersection number K. The linking number of numbers imply that if the linking number of L with the surface S. The properties of intersection K with L is nonzero, then the knots sense that it is impossible to pull them apart. K and Lare “linked,” in the 2 Homotopy Groups If we remove the origin from the plane R2, then we obtain a new space that is different from the plane in a fundamental way: it has a hole in it.
However, we cannot detect this difference by counting components, since both the plane and the plane with out the origin are connected. We begin this section by defining an invariant called the fundamental group, which does detect this kind of hole. As a first approximation, one could say that the elements of the fundamental group of a space X are loops, which can be formally defined as continuous functionsf from [0,1] to X such that f (0) = f (1). However, this is not quite accurate, for two reasons.
The first reason, which is extremely important, is that two loops 385 XXBBAAXX Figure 4 group and in higher homotopy groups. Multiplication in the fundamental are regarded as equivalent if one can be continuously deformed to the other while all the time staying inside Xbe more formal about this, let us suppose that. If this is the case, we say that they are homotopicf . Toandfis a collection of loops1 are two loops. Then afshomotopyin X, one for each between sf0 between and0 f1 0 and 1, such that the function F(s$, t) = f (t) \text{is a con} - s$ tinuous function from[0,1]2 to X.
Thus, as s increases from 0 to 1, the loop f1. If two loops are homotopic, then we count them asfs moves continuously from f0 to the same. So the elements of the homotopy group arenot actually loops but equivalence classes, or homotopy classes Even this is not quite correct, because for technical, of loops. reasons we need to impose an extra condition on our loops: that they all start from (and therefore end at)a given point, called the base point. If X is connected, it turns out not to matter what this base point is, butwe need it to be the same for all loops.
The reason for this is that it gives us a way to multiply two loops: ifis the base point and A and B are two loops that startx and end at around A and then going aroun dx, then we can define a new loop by going B. This is illustrated in figure 4. We regard this new loop as the product ofthe loops A and B. It is not hard to check that the homo- topy class of this product depends only on the homo-topy classes of A and B, and that the resulting binary operation turns the set of homotopy classes of loops into a group [I.3 §2.1](/part - 01/fundamental - definitions).
It is this group that we call the fundamental group of$X$. It is denoted π1(X). the spaces we are likely to encounter. This makes it animportant way to distinguish one space from another. The fundamental group can be computed for most of First of all, for anyn the fundamental group of Rn is the trivial group with just one element, because any loop in Rn can be continuously shrunk to its base point. On the other hand, the fundamental group of R2\{0, the plane with the origin removed, is isomorphic to the group Z of the integers.
This tells us that we can associate with any loop in R2\ {0} an integer that does not change 386 if we modify the loop in a continuous way. This inte-ger is known as the winding number. Intuitively, the winding number measures the total number of times that the mapping goes around the origin, with coun-ter clockwise circuits counting positively and clockwise ones negatively. Since the fundamental group ofis not the trivial group$, R2$\ {0} cannot be homeomor - R2 \ {0}phic to the plane.
(It is an interesting exercise to try to find an elementary proof of this result—that is, a proof that does not use, or implicitly reconstruct, any of the machinery of algebraic topology. Such proofs do exist, but it is tricky to find them.) A classic application of the fundamental group is to prove[V.13](/part - 05/the - fundamental - theorem - of - algebra), which states that every nonconstant polyno-the fundamental theorem of algebra mial with complex coefficients has a complex root.
(The proof is sketched in the article just cited, though the fundamental group is not explicitly mentioned there.) of “one-dimensional holes” that a space has. A basic example is given by the circle, which has fundamental The fundamental group tells us about the number group Z, just as R2\ {0} does, and for essentially the same reason: given a path in the circle that begins and ends at the same point, we can see how many times itgoes around the circle.
In the next section we shall see some more examples. Before we think about higher-dimensional holes, we first need to discuss one of the most important topolog-ical spaces: then-dimensional sphere. For any natural number$n$, this is defined to be the set of points in R$n^{+1}$ at distance 1 from the origin. It is denoted0-sphere S0 consists of two points, the 1-sphere Sn. Thus$, the S1 is$ the circle, and the 2-sphere S2 is the usual sphere, like the surface of Earth.
Higher-dimensional spheres take a little bit of getting used to, but we can work with them in the same way that we can with lower-dimensional spheres. For example, we can construct the 2-sphere from a closed two-dimensional disk by identifying all the points on the boundary circle with each other. Inthe same way, the 3-sphere can be obtained from a solid three-dimensional ball by identifying all the points onthe boundary 2-sphere.
A related picture is to think of the 3-sphere as being obtained from our familiar three-dimensional space R3 by adding one point “at infinity.”Now let us think about the familiar sphere$S2$. This has trivial fundamental group, since any loop drawn on the sphere can be shrunk to a point. However, this does not mean that the topology of$S^{2} \text{is trivial}$. It just means that in order to detect its interesting properties

IV. Branches of Mathematics

we need a different invariant. And it is possible to base such an invariant on the observation that even if loops can always be shrunk, there are other maps that cannot. Indeed, the sphere itself cannot be shrunk to a point. To say this more formally, the identity map from the sphere to itself is not homotopic to a map from the sphere to just one point. This idea leads to the notion of higher-dimensional homotopy groups of a topological space idea is to measure the number of “$n$-dimensional holes”X.
The rough in continuous mappings from the X, for any natural number nn, by considering all the-sphere to X. We want to see whether any of these spheres wrap around a holein X. Once again, we consider two mappings from Sn toelements of the X to be equivalent if they are homotopic. And thenth homotopy group π (X) are again defined to be the homotopy classes of these mappings.nf ([0 Let,01)]=finto the circ lef (be a continuous map from1) = x. If we like we can turn the interval S1 by “identifying” the points 0[0,1] to X with and 1: then specified point inf becomes a map from S1 mapping to x.
In order to be able to S1 to X, with one define a group operation for mappings from a higher-dimensional$S^{n}$, we similarly fix a point$s in S^{n} \text{and a}$ base point tox. x in X and look just at maps that send s Let A and B be two continuous mappings from Sn to Xsn with this property. The “product” mapping to Xis defined as follows. First “pinch” the equator A·B from of Sn down to a point.
When n = 1, the equator con- sists of just two points and the result is a figure eight. Similarly, for generaln, we end up with two copies of Sn that touch each other, one made out of the northern hemisphere and one out of the southern hemisphere ofthe original unpinched copy of$S^{n}$. We now use the map Athe top half intoto map the bottom half into X , with the equator mapping to the X and the map B to map base pointx.
(For both halves, the pinched equator is playing the part of the point As in the one-dimensional case, this operation makess.) the set homotopy group of the spaceπn(X) into a group, and this group is the X. One can think of itnth as measuring how many “$n$-dimensional holes” a space has. These groups are the beginning of “algebraic” topology: starting from any topological space, we constructan algebraic object, in this case a group.
If two spaces are homeomorphic, then their fundamental groups (and higher homotopy groups) must be isomorphic. This is richer than the original idea of just measuring

IV.6. Algebraic Topology

the information than just a number.number of holes, since a group contains more Any continuous function from Sn into Rm can be con- tinuous ly shrunk to a point in a straightforward way. This shows that all the higher homotopy groups of Rm are also trivial, which is a precise formulation of the vague idea that Rm has no holes. different topological spaces Under certain circumstances one can show that two X and Y must have the same number of holes of all types.
This is clearly true if X and Y are homeomorphic, but it is also true if X and Yequ iv a len ce are equivalent in a weaker sense, known as. Let X and Y be topological spaces and lethomotopyf0 and f1 be continuous maps from X to Y . A homo- topy from spheres: it is a continuous family of continuous mapsf0 to f1 is defined more or less as it was for from X to Y that starts with f0 and ends with f1. As then, if such a homotopy exists, we say that are homotopic.
Next, a homotopy equivalence from a$f0 and f1$ space such that there is another continuous map X to a space Y is a continuous map fg::$XY \to \to XY$ with the property that the composition homotopic to the identity map on X, andg ◦ff◦: g X:$\to Y \to X is Y$ is homotopic to the identity map onreplaced the word “homotopic” with “equal,” we would Y . (Notice that if we obtain the definition of a homeomorphism.) When there is a homotopy equivalence from and Y are homotopy equivalent, and also that X to Y, we say that X and XY have the same homotopy type. is the plane with the origin removed.
We have already observed that these have the same fundamental group, A good example is when X is the unit circle and Y and commented that it was “for essentially the same reason.” Now we can be more precise. Let$f$:$X \to Y$ be the map that takes(x, y) belongs to the circle and the second to the plane).(x, y) to (x, y)(where the first Let$g$: Y \to  X be the map that takes (u$, v) to\sqrt{u}2u + v2$, . qrt{u}2 v + v2.

(Note thatu2+v2 is never zero because the origin is not contained in Y .) Then g ◦ f is easily seen to equal the identity on the unit circle, so it is certainly homotopic tothe identity. As forf ◦g, it is given by the same formula aseach radial line to the point where that line inter sec tsg itself. More geometrically, it takes the points on the unit circle. It is not hard to show that this map ishomotopic to the identity on Y . (The basic idea is to “shrink the radial lines down” to the points where they intersect the circle.)

387

homotopy equivalent to the circle. Figure 5 Some spaces that are equivalent if they have the same number of holes ofall types. This is a more flexible notion of “having the Very roughly speaking, two spaces are homotopy same shape” than the notion of homeomorphism. For example, Euclidean spaces of different dimensions are not homeomorphic to each other, but they are all homo-topy equivalent. Indeed, they are all homotopy equivalent to a point: such spaces are called and one thinks of them as the spaces that have no contractible, hole of any sort.
The circle is not contractible, but it is homotopy equivalent to many other natural spaces: the plane R2 minus the origin (as we have seen), the cylinder S1 . imes  R, the compact cylinder S1 . imes  [0, 1], and even the Möbius strip (see figure 5). Most invariants in algebraic topology (such as homotopy groups and cohomology groups) are the same for any two spaces that are homotopy equivalent. Thus, knowing that the fundamental group of the circle is isomorphic to the integers tells us that the same is true for the various homotopy equivalent spaces just mentioned.
roughly speaking, this says that all these spaces have “one basic one-dimensional hole.” 3 Calculations of the Fundamental Group and Higher Homotopy Groups To give some more feeling for the fundamental group, let us review what we already know and look at a few more examples. The fundamental group of the2-sphere, or indeed of any higher-dimensional sphere, is trivial. The two-dimensional torus mental group Z2= Z. imes Z.
Thus, a loop in the torus deter-S1 . imes S1 has funda- mines two integers, which measure how many times it winds around in the meridian direction and how many in the longitudinal direction. The fundamental group can also be non-Abelian; that is, we can haveab ≠ ba for some elements a and b of the fundamental group. The simplest example is a spacegle point (see figure 6).
The fundamental group of X built out of two circles that meet at a sin - X is the free group [IV.10 §2](/part - 04/geometric - and - combinatorial - group - theory) on two generatorsa and 388 a b Figure 6 One-point union of two circles. AABBBBAA Figure 7 Proof thatπ2 of any space is Abelian.bpr od uct you can write down using the generators and. Roughly speaking, an element of this group is any their inverses, such asa - 1 or b and b - 1 appear next to each other, you cancel abaab - 1 a, except that if a and them first.
(So instead ofply write$abab - 1$, for example.) The generators corre - abb-1 bab-1 one would sim- spond to loops around each of the two circles. The free group is in a sense the most highly non-Abelian group. In particular, ical terms tells us that going around loopab is not equal to ba, which in topolog-a and then loop goes around loopb in the spaceb Xand then loopis not homotopic to the loop thata. homotopy equivalent to the plane with two points removed, which appears in many contexts.
More gener-This space may seem some what artificial, but it is ally, the fundamental group of the plane with removed is the free group ond generators: this is a pre - d points cise sense in which the fundamental group measures the number of holes. In contrast with the fundamental group, the higher homotopy groups2. Figure 7 gives a “proof with out words” in the caseπn(X) are Abelian when n is at leastn = 2, the proof being the same for any larger n. In the figure, we view the 2-sphere as the square with its boundary identified to a point.
So any elements A and Bsquare toof π2(X)Xare represented by continuous maps of the that map the boundary of the square to the base pointa homotopy from$x$. The figure exhibits (several steps of)AB to BA, with the shaded regions and the boundary of the square all mapping to the base pointx. The picture is reminiscent of the sim- plest nontrivial braid, in which one string is twisted around another; this is the beginning of a deep con-nection between algebraic topology and braid groups [III.4](/part - 03/braid - groups). IV. Branches of Mathematics dimensions.
For example, every compact connected The fundamental group is especially powerful in low surface (or two-dimensional manifold) is homeomor-phic to one of those on a standard list (see differential topology manifolds on this list have different (nonisomorphic)[IV.7 §2.3](/part - 04/dierential - topology)), and we compute that all the fundamental groups. So, when you capture a closed sur-face in the wild, computing its fundamental group tells you exactly where it fits in the classification. More over, the geometric properties of the surface are closely tied to its fundamental group.
The surfaces with anian metric [I.3 §6.10](/part - 01/fundamental - definitions) of positive curvature rie man-[III.13](/part - 03/curvature) (the 2-sphere and exactly the surfaces with finite fundamental group; the real projective plane [I.3 §6.7](/part - 01/fundamental - definitions)) are surfaces with a metric of curvature zero (the torus and Klein bottle) are exactly the surfaces with a fundamental group that is infinite but “almost Abelian” (there isan Abelian subgroup of finite index);
and the remaining surfaces, those that have a metric of negative curvature, have “highly non - Abelian” fundamental group, like the free group (see figure 8). sional manifolds, we now know, thanks to the advances After more than a century of studying three-dimenof Thurston and Perelman, that the picture is almost the same for these as it is for 2 - manifolds: the fundamental group controls the geometric properties ofthe 3-manifold almost completely (see differential topology4-manifolds and in higher dimensions: there are many[IV.7 §2.4](/part - 04/dierential - topology)).
But this is completely untrue for different folds with trivial fundamental group, and we need more simply connected manifolds, meaning man i invariants to be able to distinguish between them. (To begin with, the 4-sphere S4 and the product S2 . imes S2 are both simply connected. More generally, we can take the connected sum of any number of copies of$S^{2} \times S^{2}$, obtained by removing 4-balls from these manifolds and identifying the boundary 3-spheres.
These 4-manifolds are all simply connected, and yet no two of them are homeomorphic or even homotopy equivalent.) An obvious way in which we might try to distinguish different spaces is to use indeed this works in simple cases. For example, higher homotopy groups, andπ of the connected sum ofphic to Z2 r .
Also, we can show that the spherer copies of S2 . imes  S2 is isomor-(Sn)2 of any dimension is not contractible (although it is simply connected forn ⩾ 2) by computing that π (Sn) is iso- morphic to the integers (rather than the trivial group).Thus, each continuous map from the n - sphere to its elfn determines an integer, called the degree of the map,

IV.6. Algebraic Topology

Sphere One-holed torus

Figure 8 A sphere, a torus, and a surface of genus 2. which generalizes the notion of winding number for maps from the circle to itself. practical way of distinguishing one space from another, because they are amazingly hard to compute. A first In general, however, the homotopy groups are not a hint of this was Hopf’s 1931 discovery that$π^{3}(S^{2}) is$ isomorphic to the integers: it is clear that the 2-sphere has a two-dimensional hole, as measured by$π (S^{2})$ Z, but in what sense does it have a three-dimensional2 hole?
This does not correspond to our naive view of what such a hole should be. The problem of com-puting the homotopy groups of spheres turns out to be one of the hardest in all of mathematics: some ofwhat we know is shown in table 1, but despite massive efforts the homotopy groups$π (S^{2})$, for example, arei

known only fori ⩽ 64. There are tantalizing patterns in these calculations, with a number-theoretic flavor, butit seems impossible to formulate a precise guess for the homotopy groups of spheres in general. And com-puting the homotopy groups for spaces more complex than spheres is even more complicated. the so-called to represent a nonzero element of To get an idea of the difficulties involved, let us define Hopf map from S3 to S2π, which turns out(S2). There are in fact several equivalent definitions.
One of them is to regard a point(x , x , x , x ) in S3 as a pair of complex3 numbers do by setting(z1, zz2)=1 such thatx2 + 3 ix4 and|z1|2 z + |=zx2|2+=ix1. This we. We then map the pair This may not look like a map to$((z1)1$, (z2)1) to the complex numbe(r2)2 S2, but it is becaus(e3)4 z1/z2.zbut the2 may be zero, so in fact the image of the map is not Riemann sphere C ∪ . nfty, which can be identified C with S2 in a natural way.
points article on quaternions in this volume [III.76](/part - 03/quaternions - octonions - and - normed - iv25 - probabilistic - models - of - critical - phenomena), it is shown Another way of defining the Hopf map is to regard$(x^{1}$, x2$, x3$, x4) in S3 as unit quaternions. In the that each unit quaternion can be associated with a rota-tion of the sphere. If we fix some points in the sphere and map each unit quaternion to the image ofthe associated rotation, then we get a map from s under S3 to S2 that is homotopic to the map defined in the previous paragraph.

389

. . .

Two-holed torus

reappear more than once later in this article. The Hopf map is an important construction, and will 4 Homology Groups and the Cohomology Ring Homotopy groups, then, can be rather mysterious and very hard to calculate. Fortunately, there is a different way to measure the number of holes in a topological space: homology and cohomology groups. The definitions are more subtle than the definition of homotopy groups, but the groups turn out to be easier to compute and are for this reason much more commonly used.
Recall that elements of thenth homotopy groupπcontinuous maps from then(X) of a topological spacen-sphere to X are represented by X . Let X be a manifold, for simplicity. There are two key differences between homotopy groups and homology groups. The first is that the basic objects of homology are more general thann-dimensional spheres: every closed orientedan element of then-dimensional submanifold nth homology group of A of X determines X, Hn(X).
This might make homology groups seem much big-ger than homotopy groups, but that is not the case, because of the second major difference between homo-topy and homology. As with homotopy, the elements of the homology groups are not the submanifolds themselves but equivalence classes of submanifolds, butthe definition of the equivalence relation for homology makes it much easier for two of these submanifolds to be equivalent than it is for two spheres to behomotopic.
here are some examples that convey some of its flavor. We shall not give a formal definition of homology, but Leta circle that goes around the origin. If we continuously X be the plane with the origin removed and let A be deform this circle, we will obtain a new curve that is homotopic to the original circle, but with homology wecan do more. For instance, we can start with a continuous deformation that causes two of its points to touch and turns it into a figure eight.
One half of this figure eight will have to contain the origin, but we can leave 390 Table 1 The first few homotopy groups of spheres. S1 S2 S3 S4π Z 0 0 0π 0 Z 0 0π 0 Z Z 0π 0 Z/2 Z/2 Zπ 0 Z/2 Z/2 Z/2π 0 Z/4 . imes Z/3 Z/4 . imes Z/3 Z/2π 0 Z/2 Z/2 Z . imes Z/4 . imes Z/3π 0 Z/2 Z/2 Z/2 . imes Z/2π 0 Z/3 Z/3 Z/2 . imes Z/2π10 0 Z/3 . imes Z/5 Z/3 . imes Z/5 Z/8 . imes Z/3 . imes Z/ A Figure 9 in the homology of the surface. The circle A represents zero that still and slide the other part away. The result is then two closed curves, with the origin inside one and out side the other.
This pair of curves, which together form a 1-manifold with two components, is equivalent to the original circle. It can be seen as a continuous deformation of a more general kind. A second example shows how natural it is to include other manifolds in the definition of homology. This time let X be R3 with a circle removed, and let A be a sphere that contains the circle in its interior. Suppose that the circle is in the XY-plane and that both it and the sphere A are centered at the origin. Then we can pinch the top and bottom ofthey just touch.
If we do so, then we obtain a shape A toward the origin until that looks like a torus, except that the hole in the mid-dle has been shrunk to zero. But we can open up this hole with the help of a further continuous deformation and obtain a genuine torus, which is a “tube” around the original circle. From the point of view of homology, this torus is equivalent to the sphere A.
a compact orientedof A more general rule is that if X with a boundary, then this boundary(n + 1)-dimensional submanifold X is a manifold and. artial B will be B is equivalent to zero (which is the same as saying that[. artial B] = 0 in H (X)): see figure 9. The group operation is easy to define: ifn A and B are two disjoint submanifolds ofogy classes[A] and [B], then X[A], giving rise to homol-+ [B] is the homol-

IV. Branches of Mathematics S5 S6 S7 S8 S9$00 00 00 00 00 00 00 00 00 00 ZZZ$//22 ZZ0/2 00 Z 000 000$Z$/8 Z . imes /2 Z/3 Z/8 Z . imes /2 Z/3 ZZ//22 ZZ/2 0 Z$3 Z$/2 0 Z/8 . imes Z/3 Z/2 Z/2 ogy class of[A ∪ B]. (More generally, the definition of homology allows us to add up any collection of sub-manifolds, whether or not they overlap.) Here are some simple examples of homology groups, which, unlike the fundamental group, are always Abelian. The homology groups of a sphere,$H (S^{n})$, are isomorphic to thei

integers Z fori = 0 and for i = n, and 0 otherwise. This contrasts with the complicated homotopy groups of the sphere, and better reflects the naive idea that then-sphere has one n-dimensional hole and no other holes. Note that the fundamental group of the circle, the group of integers, is the same as its first homology group. More generally, for any path-connected space, the first homology group is always the “Abelianization”of the fundamental group (which is formally defined to be its largest Abelian quotient).
For example, the funda-mental group of the plane with two points removed is the free group on two generators, while the first homol-ogy group is the free Abelian group on two generators, or Z2. H The homology groups of the two-dimensional torus(S1. imes S1) are isomorphic to Z for i = 0, to Z2 for i = 1, i

and to Z fori = 2. All of this has geometric meaning. The zeroth homology group of any space is isomorphic to Zr for a space X with r connected components. So the fact that the zeroth homology group of the torus is isomorphic to Z means that the torus is connected. Any closed loop in the torus determines an element of the first homology group Z2, which measures how many times the loop winds around the meridian and longitu-dinal directions of the torus. And finally, the homology of the torus in dimension 2 is isomorphic to Z because the torus is a closed orientable manifold.
That tells usthat the whole torus defines an element of the second homology group of the torus, which is in fact a gen-erator of that group. By contrast, the homotopy group

IV.6. Algebraic Topology

πing maps from the 2-sphere to the 2-torus, but homol-2(S1 . imes  S1)is the trivial group: there are no interest ogy shows that there are interesting maps from other closed 2-manifolds to the 2-torus. As we have mentioned, calculating homology groups is much easier than calculating homotopy groups. Themain reason for this is the existence of results that tell you the homology groups of a space that is built up from smaller pieces in terms of the homology groups of those pieces and their intersections.
Another important property of homology groups is that they are “functo-rial” in the sense that a continuous mapf from a space X to a space Y leads in a natural way to a homomor- phism defined to bef* from[f (A)]Hi(X). In other words$, to H^{i}(Y ) \text{for eachf}^{*}i([A]):$ f*([A])is theis equivalence class of the image of We can define the closely related idea of “cohom-A under f . ology” simply by a different numbering. Let X be a closed oriented define theith cohomology groupn-dimensional manifold. Then we Hi(X) to be the homology groupa cohomology class (an element of(Hn)-i(X).
Thus, one way to write down H^i(X)) is by choos- ing a closed oriented submanifold in X. (This means that the dimension of S of codimension S is n - i.) Wei write For more general spaces than manifolds, cohomology[S] for the corresponding cohomology class. is not just a simple renumbering of homology. Informally, if element of X is a topological space, then we think of an Hi(X) as being represented by a codimen- sion-X. For example, suppose thati subspace of X that can move around freely inf is a continuous map from X to an i-dimensional manifold.
If X is a manifold and image of a “typical” point in the manifold will be an$f$is sufficiently “well-behaved,” then the inverse i- co dimensional submanifold of point about, this submanifold will vary continuously, X, and as we move the and will do so in a way that is similar to the way that a circle became two circles and a sphere became a torus earlier. Iff still determines a cohomology class in X is a more general topological space, the map Hi(X), which we think of as being represented by the inverse image in X of any point in the manifold.
manifold, cohomology has distinct advantages over homology. This may seem odd, since the cohomology However, even when X is an oriented n-dimensional groups are the homology groups with different names. However, this renumbering allows us to give very useful extra algebraic structure to the cohomology groups of Xtiply them as well. Further more, we can do so in such a: not only can we add cohomology classes, we can mul-

391

A⬘

AABBB⬘ Figure 10 Aand^2 =BA^2·=AB^  =· B0,^  =A 0.· B = [point], way that, taken together, the cohomology groups ofform a ring [III.81 §1](/part-03/rings-ideals-and-modules). (Of course, we could do this for$X$ the homology groups, but the cohomology groups forma so-called graded ring. In particular, if$[A] \in H^{i}(X)$ and$[B] \in H^{j}(X)$, then [A] · [B] \in  H^i^+^j(X).) geometric meaning, especially on manifolds: it is given The multiplication of cohomology classes has a rich by thealizes our discussion of intersection numbers in sec-intersection of two submanifolds. This gener tion 1:
there we considered zero-dimensional intersections of submanifolds, where as we are now considering(cohomology classes of) higher-dimensional intersections. To be precise, let manifolds of X , of codimension S and T be closed oriented sub-i and j, respectively. By moving in Hi(X)) we can assume that S slightly (which does not change its class S and T intersect trans- versely, which implies that the intersection of T is a smooth submanifold of codimension i + j Sinand X . Then the product of the cohomology classes[T ] is simply the cohomology class of the intersection[S] and S ∩ T in (Hi)+j(X).
(In addition, the submanifold S ∩ T in her its an orientation fromto define the associated cohomology class.)S, T, and X: this is needed manifold, it is enough to specify a basis for the cohom-ology groups (which, as we have already discussed, are As a result, to compute the cohomology ring of a relatively easy to determine) using some submanifolds and to see how these submanifolds intersect. For example, we can compute the cohomology ring of the 2 torus as shown in figure 10.
For another example, itis not hard to show that the cohomology of the com[III.72](/part-03/projective-space) CP2 has a basis given plex projective plane by three basic submanifolds: a point, which belongs tosion 4; a complex projective line H^4(CP^2) because it is a submanifold of codimen-CP^1 = S^2, which belongs tois in H0(CP(H2)2)(and represents the identity element 1 of CP2); and the whole manifold CP2, which the cohomology ring.
The product in the cohomology ring is described by saying that[CP1][CP1] = [point], because any two distinct lines CP1 in the plane meet transversely in a single point.

392

plex projective plane, although very simple, has several This calculation of the cohomology ring of the com strong consequences. First of all, it implies Bézout’stheorem on intersections of complex algebraic curves (seeof degree algebraic geometry d in CP2 represents[IV.4 §6](/part - 04/algebra)). An algebraic curved times the class of a line CP1 in$H2(CP2)$. Therefore, if two algebraic curves D and cohomology class E of degrees d[Dand∩ E]e equals meet transversely, then the[D] · [E] = (d[CP1])(e[CP1]) = de[point].
For complex submanifolds of a complex manifold, intersection numbers are always+1, not - 1, and so this means that We can also use the computation of the cohomology D and E meet in exactly de points. ring of groups of spheres. It turns out that CP2 to prove something about the homotopy CP2 can be constructed as the union of the 2-sphere and the closed four-dimensional ball, with each point of the boundary S^3 of the ball identified with a point in S^2 by the Hopf map, which was defined in the previous section.
A constant map from one space to another, or a map homotopic to a constant map, gives
rise to the zero homomorphism between the homology groups$H^{i}$, at least when$i > 0$. The Hopf map f:$S^{3} \to S^{2} also$ induces the zero homomorphism because the nonzero homology groups of S3 and S2 are in different dimensions. Nonetheless, we will show that topic to the constant map. If it were, then the spacef is not homo- CP2 obtained by attaching a 4-ball to the 2-sphere using the map obtained by attaching a 4-ball to the 2-sphere using af would be homotopy equivalent to the space constant map. The latter space S4 identified at one point.
But in fact Y is the union of Y is not homotopy S2 and equivalent to the complex projective plane, because their cohomology rings are not isomorphic. In particular, the product of any element ofzero, unlike what happens in CP2 where H2(Y )[CPwith itself is1][CP1] =[ful version of this argument shows that point]. Therefore f is nonzero in π3(S2). A more care-π (S2) is iso- morphic to the integers, and the Hopf mapis a generator of this group$. 3 f:$ S3 \to S2 between all the basic concepts of algebraic topology:
This argument shows some of the rich relations homotopy groups, cohomology rings, manifolds, andso on. To conclude, here is a way to visualize the nontriviality of the Hopf mapset of S3 that maps to any given point of the 2-sphere.f:$S^{3} \to S^{2}$. Look at the sub- These inverse images are all circles in the 3-sphere. Todraw them, we can use the fact that S3 minus a point

IV. Branches of Mathematics

Figure 11 Fibers of the Hopf map.

is homeomorphic to R3; so these inverse images form a family of disjoint circles that fills up three-dimensional space, with one circle being drawn as a line (the circle through the point we removed from S3). The striking feature of this picture is that any two of this huge family of circles have linking number 1 with each other: there is no way to pull any two of them apart (see figure 11). 5 Vector Bundles and Characteristic Classes We now introduce another major topological idea: fiber bundles. If E and B are topological spaces, x is a point in B, and p:
E \to  B is a continuous map, then the fiber ofsay thatp overp xis ais the subspace of fiber bundle, with fiber E that maps to F, if every fiberx. We ofthepbase space is homeomorphic to the same space and E the total space. For example, any F. We call B product space B . imes  Fis a fiber bundle over B, called the trivial case is the map that takes F-bundle over B. (The continuous map in this(x, y) to x.) But there are many nontrivial fiber bundles. For example, the Möbiusstrip is a fiber bundle over the circle with fiber a closed interval.
This example helps to explain the old name“twisted product” for fiber bundles. Another example: the Hopf map makes the 3-sphere the total space of a circle bundle over the 2-sphere. plicated spaces from simple pieces. We will focus on the most important special case: vector bundles. AFiber bundles are a fundamental way to build up com-vector bundle over a space Bis a fiber bund lep: E \to B whose fibers are all real vector spaces of some dimensionn.

IV.6. Algebraic Topology

Figure 12 bundle for the circle and the torus. Trivializations of the tangent This dimension is called thedle. A line bundle means a vector bundle of rank 1; for rank of the vector bun example, we can view the Möbius strip (not including its boundary) as a line bundle over the circle S1. It is a nontrivial trivial line bundle line bundle; that is, it is not isomorphic to the S1 . imes  R. (There are many ways of con- struc ting it: one is to take the strip\\{(x}$, y): 0$⩽ x ⩽ 1 and identify each point(0, y) with the point (1, -y).
The base space of this line bundle is the set of all points$(x, 0)$, which is a circle since (0, 0) and (1, 0) have been identified.) bundle easily define this bundle by considering If M is a smooth manifold of dimension T M \to  M is a vector bundle of rankn M, itsnas a sub-. We can tangent manifold of some Euclidean space RN . (Every smooth manifold can be embedded into Euclidean space.) Then T M is the subspace of M . imes RN of pairs (x, v) such that the vector T M \to  M sends a pairv is tangent to(x, v)M to the point at the point xx. The fiber;
the map over with vx belonging to an affine subspace ofthen has the form of the set of all pairs RN of dimen-(x, v) sion equal to that of$M$. For any fiber bundle, a section means a continuous map from the base space total space E that maps each point x in B to some point B to the in the fiber overa manifold is called ax. A section of the tangent bundle of vector field. We can draw a vector field on a given manifold by putting an arrow (possiblyof zero length) at every point of the manifold.
In order to classify smooth manifolds, it is important to study their tangent bundles, and in particular to see whether they are trivial or not. Some manifolds, like the circle S1 and the torus S1 . imes S1, do have trivial tangent bundle. The tangent bundle of ann-manifold Mare linearly independent at every point ofis trivial if and only if we can findnvector fields that M . So we can prove that the tangent bundle is trivial just by writing down such vector fields; see figure 12 for the circle orthe torus. But how can we show that the tangent bundle of a given manifold is nontrivial?

393

Figure 13 The hairy ball theorem.

One way is to use intersection numbers. Let M be a closed oriented image of the “zero-section” inside the tangent bund len-manifold. We can identify M with the T Mzero vector at that point. Since the dimension of, the section that assigns to every point of MT Mtheis precisely double that oftion numbers in section 1 gives a well-defined integer M, the discussion of inter sec-M2 = M · M, the self-intersection number of M inside T M; this is called the Euler characteristicχ(M).
By the definition of intersection numbers, for any vector field v Euler characteristic ofon M that meets the zero-section transversely, the M is equal to the number of zeros$of$ v, counted with signs. As a result, if the Euler characteristic of M is not zero, then every vector field on section; in other words, every vector field on M must meet the zero-M must equal zero some where. The simplest example occurs when$M \text{is the} 2 - sphere S^{2}$.
We can easily write down a vector field (for example, the one pointing toward the east along circles of latitude, which vanishes at the north and south poles) whose intersection number with the zero-section is 2. Therefore the 2-sphere has Euler characteristic 2, and so every vector field on the 2-sphere must vanish some where. This is a famous the-orem of topology known as the “hairy ball theorem”: it is impossible to comb the hair on a coconut (see figure 13). classes This is the beginning of the theory of, which measure how nontrivial a given vector characteristic bundle is.
There is no need to restrict ourselves to the tangent bundle of a manifold. For any oriented vector bundle define a cohomology class E of rank n on a topological spaceχ(E) in Hn(X), the X, we can Euler class the Euler class of, which vanishes if the bundle is trivial. Intuitively, E is the cohomology class represented by the zero set of a general section of E, which (for example, ifn submanifold of X is a manifold) should be a codimension-X, since X has codimension n in E.
If class of the tangent bundle in X is a closed oriented n-manifold, then the Euler Hn(X) = Z is the Euler characteristic of X.

394

tic classes was the Gauss–Bonnet theorem, generalized One of the inspirations for the theory of character is to all dimensions in the 1940 s. The theorem expresses the Euler characteristic of a closed manifold with a Riemannian metric as the integral over the manifold of a certain curvature function. More broadly, a central goal of differential geometry is to understand how the geo-metric properties of a Riemannian manifold such as its curvature are related to the topology of the manifold. (that is, bundles where the fibers are complex vector spaces) turn out to be particularly convenient:
indeed, The characteristic classes for complex vector bundles real vector bundles are often studied by constructing the associated complex vector bundle. If E is a com- plex vector bundle of rankn over a topological space X, theof cohomology classes on Chern classes of E are a sequence X, with ci(E)c1(E), . . . , cbe long ing ton(E)(H2)i(X), which all vanish if the bundle is trivial. The top Chern class,$c^{n}(E)$, is simply the Euler class of E: thus, it is the first obstruction to finding a section of E that is every where nonzero.
The more general Chern classes have a similar interpretation. For any 1⩽ j ⩽ n, ch oosej general sections of E. The subset of X over which these sections become linearly dependent will have codimension 2$(n + 1 - j) (assuming$, for example, that X is a manifold). The Chern class (cn()+1)-j(E) is pre- cisely the cohomology class of this subset. Thus the Chern classes measure in a natural way the failure of a given complex vector bundle to be trivial.
Thegin classes of a real vector bundle are defined to be the Pon try a Chern classes of the associated complex vector bundle. A triumph of differential topology is Sullivan’s 1977 theorem that there are only finitely many smooth closed simply connected manifolds of dimension at least 5 with any given homotopy type and given Pontryagin classes of the tangent bundle. This statement fails badly in dimension 4, as Donaldson discovered in the 1980 s (see differential topology [IV.7 §2.5](/part - 04/dierential - topology)).
6 Kco homology Theories-Theory and Generalized The effectiveness of vector bundles in geometry led toa new way of measuring the “holes” in a topological space$X$: looking at how many different vector bundles overa cohomology-like ring associated to any space, known Xthere are. This idea gives a simple way to define as$K$-theory (after the German word “Klasse,” since the theory involves equivalence classes of vector bundles).It turns out that K-theory gives a very useful new angle IV. Branches of Mathematics by which to look at topological spaces.
Some problems that could be solved only with enormous effort using ordinary cohomology became easy with idea was created in algebraic geometry by Grothendieck K - theory. The in the 1950 s and then brought into topology by Atiyah and Hirzebruch in the 1960 s. For a topological space K0 The definition of(X), the K-theory Kof-theory can be given in a few lines. XX, whose elements can be writ-, we define an Abelian group ten as formal differences[E] - [F], where E and F are any two complex vector bundles over tions we impose in this group are that[EX.
The only rela-⊕F] = [E]+[F] for any two vector bundles E and F over X . Here E ⊕ F denotes the denote the fibers at a given point direct sum of the two bundles; ifx in X, the fiber of Ex and Fx E ⊕This simple definition leads to a rich theory. First of F at x is simply Ex . imes Fx. all, the Abelian group K0(X)is in fact a ring: we multiply two vector bundles on product [III.89](/part - 03/tensor - products). In this respect, X by forming the K-theory behaves like tensor ordinary cohomology.
The analogy suggests that the group K0(X) should form part of a whole sequence of Abelian groups groups can be defined. In particular,$K^{i}(X)$, for integers i, and indeed these K^-^i(X) can be defined as the subgroup of those elements of whose restriction to K0(point . imes  X) is zero. K0(Si. imes X) be Then a miracle occurs: the groups periodic of order 2: Ki(X) = (Ki)+2(X)Ki(X)for all integers turn out toiodicity. This is a famous phenomenon known as. So there are really only two different Bott peri-K-groups attached to any topological space:$K^{0}(X) and K^{1}(X)$.
This may suggest that K-theory contains less infor- mation than ordinary cohomology, but that is not so. Neither K-theory nor ordinary cohomology determines the other, although there are strong relations between them. Each brings different aspects of the shape of a space to the fore. Ordinary cohomology, with its num-bering, shows fairly directly the way a space is built up from pieces of different dimensions.ing only two different groups, looks cruder at first (and K-theory, hav- is often easier to compute as a result).
But geometric problems involving vector bundles often involve information that is subtle and hard to extract from ordinary cohomology, where as this information is brought to the surface by K-theory. cohomology is that the group The basic relation between KK0-theory and ordinary(X) constructed from the vector bundles onthe even-dimensional cohomology groups of X“knows” something about all X. To be precise, the rank of the Abelian group K0(X) is the sum

IV.6. Algebraic Topology

of the ranks of all the even-dimensional cohomology groups(H2)i(X). This connection comes from associat- ing with a given vector bundle on The odd K-group K1(X) is related in the same way to X its Chern classes. the odd-dimensional ordinary cohomology. As we have already hinted, the precise group$K^{0}(X)$, as opposed to just its rank, is better adapted to some geometric problems than ordinary cohomology. This phenomenon shows the power of looking at geomet-ric problems in terms of vector bundles, and thus ultimately in terms of linear algebra.
Among the classic applications of K-theory is the proof, by Bott, Ker- vaire, and Milnor, that the 0-sphere, the 1-sphere, the 3-sphere, and the 7-sphere are the only spheres whose tangent bundles are trivial. This has a deep algebraic consequence, in the spirit of the fundamental theorem of algebra: the only dimensions in which there can be a real division algebra (not assumed to be commutative or even associative) are 1, 2, 4, and 8. There are indeed division algebras of all four types:
the real numbers, complex numbers, quaternions, and octonions(see quaternions, octonions, and normed division algebras [III.76](/part-03/quaternions-octonions-and-normed-iv25-probabilistic-models-of-critical-phenomena)). bra of dimension trivial tangent bundle. In fact, let us merely assume that Let us see why the existence of a real division alge-n implies that the (n - 1)-sphere has we have a finite-dimensional real vector space bilinear map V . imes V \to V, which we call the “product,”V with a such that ifx and y are vectors in V with xy = 0, then eitherx = 0 or y = 0.
For convenience, let us also assume that there is an identity element 1 inso 1$· x = x · 1 = x \text{for all} x \in V$; one can, how - V , ever, do with out this assumption. Ifn, then we can identify V with Rn. Then, for each point V has dimensionx in the sphere (Sn)-1, left multiplication by x gives a linear isomorphism from Rn to itself. By scaling the output to have length 1, left multiplication bya diffeomorphism from Sn-1 to itself which maps thex gives point 1 (scaled to have length 1) totive of this diffeomorphism at the point 1 gives a lin - x.
Taking the deriva- ear isomorphism from the tangent space of the sphere at the point 1 to the tangent space atx. Since the pointx on the sphere is arbitrary, a choice of basis for the tangent space of the sphere at the point 1 deter-mines a trivialization of the whole tangent bundle of the$(n - 1)-sphere$. best “explanation” for the low-dimensional homotopy Among other applications, K-theory provides the groups of spheres, and in particular for the number-theoretic patterns that are seen there.
Notably, denom - 395 inators of Bernoulli numbers appear among those groups (such asπ (Sn) Z/24 for n at least 5), and this pattern was explained using Kervaire, and Adams.$n^{+3} K - \text{theory by Milnor}$, a deep analysis of linear differential equations on closed manifolds using the atiyah–singer index theorem K-theory.
The theorem has[V.2](/part-05/the-atiyahsinger-index-theorem) provides made theories in physics. K-theory important for gauge theories and string K-theory can also be defined for noncommutative rings, and is in fact the central con-cept in “noncommutative geometry” (see operator algebras The success of[IV.15 §5](/part-04/operator-algebras)).K-theory led to a search for other “generalized cohomology theories.” There is one other theory that stands out for its power: complex cobordism cobordism groups of a manifold. The definition is very geometric:
the complex M are generated by mappings of manifolds (with a complex structure onthe tangent bundle) into M . The relations say that any manifold counts as zero if it is the boundary of some other manifold. For example, the union of two circles would count as zero if you could find a cylinder whose ends were those circles. than either far into the structure of a topological space, but at It turns out that complex cobordism is much richer K-theory or ordinary cohomology. It sees the cost of being difficult to compute.
Over the past thirty years, a whole series of cohomology theories, such as elliptic cohomology and Morava have been constructed as “simplifications” of complex K-theories, cobordism: there is a constant tension in topology between invariants that carry a lot of information and invariants that are easy to compute. In one direction, complex cobordism and its variants provide the most powerful tool for the computation and understand-ing of the homotopy groups of spheres.
Beyond the range where Bernoulli numbers appear, we see deeper number theory such as modular forms [III.59](/part-03/modular-forms). In another direction, the geometric definition of complex cobordism makes it useful in algebraic geometry. 7 Conclusion The line of thought introduced by pioneering topolo-gists like riemann [VI.49] is simple but powerful. Try to translate any problem, even a purely algebraic one, into geometric terms. Then ignore the details of the geometry and study the underlying shape or topologyof the problem.
Finally, go back to the original problem and see how much has been gained. The funda-mental topological ideas such as cohomology are used

396

through out mathematics, from number theory to string theory.

Further Reading

From the definition of topological spaces to the fun-da mental group and a little beyond, I like M. A. Armstrong’s The current standard graduate textbook is A. Hatcher’s Basic Topology (Springer, New York, 1983). Algebraic Topology (Cambridge University Press, Cambridge, 2002). Two of the great topologists, Bott and Milnor, are also brilliant writers. Every young topologist should read R. Bott and L. Tu’sin Algebraic Topology (Springer, New York, 1982), J. Mil-Differential Forms nor’ston, NJ, 1963), and J. Milnor and J.
Stasheff’s Morse Theory (Princeton University Press, Prince-Characteristic Classes1974). (Princeton University Press, Princeton, NJ, IV.7 Differential Topology C. H. Taubes 1 Smooth Manifolds This article is about classifying certain objects called smooth manifolds, so I need to start by telling you what they are. A good example to keep in mind is the surface of a smooth ball. If you look at a small portion ofit from very close up, then it looks like a portion of a flat plane, but of course it differs in a radical way froma flat plane on larger distance scales. This is a general phenomenon:
a smooth manifold can be very convoluted, but must be quite regular in close-up. This “local regularity” is the condition that each point in a manifold belongs to a neighborhood that looks like a portion of standard Euclidean space in some dimension. If the dimension in question isfold, then the manifold itself is said to have dimensiond for every point of the mani-d. A schematic of this is shown in figure 1.What does it mean to say that a neighborhood “looks like a portion of standard Euclidean space”?
It means that there is a “nice” one-to-one mapφ from the neigh- borhood into Rd (with its usual notion of distance). One can think ofborhood with points inφas “identifying” points in the neigh-R$d$: that is, xis identified with coordinate chartφ(x). If we do this, then the functionof the neighborhood, and any chosenφ is called a basis for the linear functions on the Euclidean space is called a coordinate system. The reason for this is that φ allows us to use the coordinates in Rd to label points in the neighborhood: ifx belongs to the neighborhood,

IV. Branches of Mathematics

Figure 1 resemble regions in a Euclidean space. Small portions of a manifold Figure 2 grid to a distorted rectangular grid. A transition function from a rectangular then one can label it with the coordinates ofφ(x). For example, Europe is part of the surface of a sphere. Atypical map of Europe identifies each point in Europe with a point in flat, two-dimensional Euclidean space, that is, a square grid labeled with latitude and longitude. These two numbers give us a coordinate sys-tem for the map, which can also be transferred to a coordinate system for Europe itself.
Now, here is a straightforward but central observation. Suppose that intersect, and suppose that functions M and N are two neighborhoods thatφ:$M \to R^{d} andψ$: N \to  Rd are used to give them each a coordinate chart. Then the intersection M ∩N is given two coordi- nate charts, and this gives us an identification between the open regions$φ(M ∩ N) and ψ(M ∩ N) of R^{d}$: given a point in the second isxin the first region, the corresponding point$ψ(φ^{-1}(x))$.
This composition of maps is called a coordinates from one of the charts on the intersecting transition function, and it tells you how the region relate to those of the other. The transition func-tion is a homeomorphism [III.90](/part-03/topological-spaces) between the regions

φ(M ∩ N) and ψ(M ∩ N).

IV.7. Differential Topology

Euclidean region and use the transition functionto map it to the second one. It is possible that the image Suppose that you take a rectangular grid in the firstψφ-1 will again be a rectangular grid, but in general it will besomewhat distorted. An illustration is given in figure 2. rounded by regions that can be identified with parts of Euclidean space is a The proper term for a space whose points are sur-topological manifold.
The word “topological” is used in order to indicate that there are no constraints on the coordinate-chart transition functions apart from the basic one that they should be continuous. However, some continuous functions are quite unpleasant, so one typically introduces extra constraints in order to limit the distorting effect that the transition functions can have on a rectangular coordinate grid. Of prime interest here is the case where the transition functions are required to be differentiable to all orders.
If a manifold has a collection of charts for which all the transition functions are infinitely differentiable, then it is said to have aa smooth manifold. Smooth manifolds are especially smooth structure, and it is called interesting because they are the natural arena for calculus. Roughly speaking, they are the most general con-text in which the notion of differentiation to any order makes intrinsic sense. A function f, defined on a manifold, is said to be differentiable Rd , the functionif, given any of its coordinate chartsg(y) = f (φ-1(y))(which is definedφ:
N . oon a region ofis impossible on a manifold if it does not admit charts Rd) is differentiable[I.3 §5.3](/part - 01/fundamental - definitions). Calculus with differentiable transition functions, because a func-tion that might appear differentiable in one chart will not, in general, be differentiable when viewed from a neighboring chart. point. Consider the following two coordinate charts ofa neighborhood of the origin in the real line. The first is Here is a one-dimensional example to illustrate this the obvious chart that simply represents a real numberx by itself.
(Formally speaking, one is taking the func- tion The second representsφto be defined by the simple formul ax by the point (x1()/){3}φ(x). (Here the = x.) cube root of a negative number the cube root of-x.) What is the transition function xis defined to be minus between these two charts? Well, if region of R used for the first chart, thent is a point in theφ-1(t) = t, soψ(φ-1(t)) = ψ(t) = (t1()/){3}. This is a continuous function oftbut it is not differentiable at the origin.
on the region used for the second chart, the function Now consider the simplest possible function defined 397 h(s) = s, and let us work out the corresponding func- tionbe the value off on the manifold itself. The value ofh at the point s corresponding tof at x shouldx. This point isψ(x) = x1/3, so f (x) = h(x1/3) = x1/3. Finally, since the point to the pointt = φ(x) =xxin the manifold correspondsin the first region, the corresponding function on the first region is$g(t) = (t1()/){3}$.
(This is the same function asf only because φ happens to be the very special map that takes each number to itself.) Thus, the eminently differentiable functionh on one coordinate chart translates into the continuous butnot differentiable functiong on the other. Suppose one is given a topological manifold M with two sets of charts, both of which have infinitely differ-entiable transition functions. Then each set of charts gives us a smooth structure on the manifold. Of great importance is the fact that these two smooth structures can be fundamentally different.
Ktiable To see what this means, let us call the sets of chartsandif it is differentiable from the viewpoint of L. Given a function f , let us call it K-differ en-K, and point of L-differentiable L. It may easily happen that a function isif it is differentiable from the view Kversa. However, we can say that-differentiable with out being$L$-differentiable or vice K and L give the same smooth structure from M to itself with the following three properties.on M when there is a map, F , First, F is invertible and both F and F-1 are contin- uous.
Second, the composition oftion that is$K$-differentiable is$L$-differentiable. Third, F with any func- the composition of the inverse of$F^{-}1 \text{with any func}-$ tion that isspeaking, Fl turns the-differentiable is$K$-differentiable functions into$K$-differentiable. Loosely $L$-differentiable ones and F-1 turns them back again. If no such function tures given by K and FL exists, then the smooth struc-are considered to be genuinely different. dimensional example again.
As noted previously, the functions that you deem to be differentiable if you use To see how this plays out, let us look at the one the be differentiable if you use theφ-chart are not the same as those you deem toψ-chart. For example, the functionx \to x1/3 is not φ-differentiable but it is ψdifferentiable sets of functions define the-differentiable. Even so, theφ-differentiable and same smoothψ- structure for the line, since any tion becomesφ-differentiable once you compose itψ-differentiable func with the self-map$F$:$t \to t3$.
have more than one smooth structure, but this turns It is very far from obvious that any manifold can

398

out to be the case. There are also manifolds that are entirely lacking in smooth structures. These two facts lead directly to the central concern of this essay, the long-sought quest for the two holy grails of differential topology. • A list of all smooth structures on any given topo-• logical manifold. An algorithm to identify any given smooth struc- ture on any given topological manifold with the corresponding structure from the list. 2 What Is Known about Manifolds? Much has been accomplished as of the writing of this article with respect to the two points listed above.
This said, the task for this part of the article is to summarize the state of affairs at the beginning of the twenty-firstcentury. Various examples of manifolds are described along the way. sion to set the stage. If you have two manifolds andyou set them side by side with out their touching, then The story here requires a brief, preliminary dig res technically speaking they can be regarded as a single manifold that happens to have two components. Insuch a case, one can study the components individually. Therefore, in this article I shall talk exclusively about connected manifolds:
that is, manifolds with just one component. In a connected manifold, one can get from any point to any other point with out ever leaving the manifold. guish between manifolds such as the sphere, which are bounded in extent, and manifolds such as the plane, A second technical point is that it is useful to distinwhich go off to infinity. More precisely, I am talking about the distinction between compact manifolds: a compact manifold can be thought compact [III.9](/part-03/compactness-and-compactication) and nonof as one that can be expressed as a closed bounded subset of Rn for some n.
The discussion that fol- lows will be almost entirely about compact manifolds. As some of the examples below will demonstrate, the story for compact manifolds is less convoluted than the analogous story for noncompact ones. For sim-plicity I shall often use the word “manifold” to mean “compact manifold”; it will be clear from the context if noncompact manifolds are also being discussed.

2.1 Dimension 0

There is only one dimension-0 manifold. It is a single point. The period at the end of this sentence looks,

IV. Branches of Mathematics

yy Uxx U

Figure 3 Two charts that cover the circle.

from afar, like a connected, dimension-0 manifold. Note that the distinction between topological and smooth is irrelevant here.

2.2 Dimension 1

There is only one compact, connected, one-dimensional topological manifold, namely the circle. More over, the circle has just one smooth structure. Here is one way torepresent this structure. Take as a representative circle the unit circle in theall points(x, y) with x2 xy+ y-plane, that is, the set of2 = 1. This can be cov- ered by two overlapping intervals, each of which cov-ers slightly more than half of the circle. The intervals Ututes a coordinate chart. The one on the left,1 and U2 are drawn in figure 3.
Each interval consti-U , can be parametrized in a continuous fashion by taking the1 angle of a given point as measured counterclockwis efrom the posit i vex-axis. For example, the point (1, 0) has angle 0, and the point(-1,0) has angle π. In order to parametrize angleπ at the negative U2 by angle, you will have to start withx-axis. If you move around U , varying this angle continuously, then when you reach the point(1,0) you will have parametrized it as a point2 in As you can see, the arcs U2 using the angle 2π. U1 and U2 intersect in two separated, smaller arcs; these are labeled figure 4.
The transition function on V is the identity V1 and V2 in map, since the same as its U angle. By contrast, the U1 angle of any given point in U1 angle of a point V1 is the inthe transition function on V2 is obtained from the2 V(U2)1 is not the identity map but angle by adding 22 π. Thus, the map that adds 2 This one-dimensional example brings up a number ofπ to the coordinate function. important issues, all related to a particularly troubling question. To state it, consider first that there are lots of closed loops in the plane that can be taken as model cir-cles.
Indeed, the word “lots” considerably under states the situation. More over, why should we restrict our

IV.7. Differential Topology

y

V1 V2 x

Figure 4 The intersection of the arcs$U1 and U2$. Figure 5 A knotted loop in 3-space. attention to circles in the plane? There are closed loops galore in 3-space too: see figure 5, for example. For that matter, any manifold of dimension greater than 1 has smooth loops. Earlier, it was asserted that there is just one smooth, compact, connected, one-dimensional manifold, so all of these loops must be considered the“same.” Why is this? it might appear were it sitting in some larger space. Here is the answer.
We often think of a manifold as For example, we might imagine a circle sitting in the plane, or sitting knotted in three-dimensional Euclidean space. However, the notion of “smooth manifold”introduced above is an intrinsic one, in the sense that it does not depend on how the manifold is placed inside a higher-dimensional space. Indeed, it is not even necessary for there to be a higher-dimensional space at all. In the case of the circle, this can be said in the following way. The circle can be placed as a loop in the plane, or as a knot in 3-space, or whatever.
Each view of the circle in a higher-dimensional Euclidean space defines a collec-tion of functions that are considered differentiable: one just takes the differentiable functions of the coordinates of the big Euclidean space and restricts them to the circle. As it turns out, any one such collection defines the same smooth structure on the circle as any other. Thus, the smooth structures that are provided by these different views of a circle are all the same, even though

399

Figure 6 A Möbius strip has just one side.

there are many interesting ways of placing a circle in agiven higher-dimensional space. (In fact, the classification of knots in 3-space is a fascinating, vibrant topic in its own right: see knot polynomials [III.44](/part-03/knot-polynomials).) ture for the circle? For that matter, how is it proved that there is but a single compact topological manifold How is it proved that there is only one smooth struc in dimension 1? Since this article is not meant to pro-vide proofs, these questions are left as serious exercises with the following advice.
Think hard about the definitions and, for the smooth-manifold question, use some calculus.

2.3 Dimension 2

The story for two-dimensional, connected, compact manifolds is much richer than that for dimension 1. In the first place, there is a basic dichotomy between two kinds of manifold: orientable and nonorientable. Roughly speaking, this is the distinction between manifolds that have two sides and those that have just one. To give a more formal definition, a two-dimen-sional manifold is called orientable if every loop in the manifold that does not cross itself or have any kinks has two distinct sides.
This is to say that there is no path from one side of the loop to the other that avoids the loop yet remains very close to it. The Möbius strip (see figure 6) is not orientable because there are paths from one side of the central loop to the other that do not cross the central loop yet remain very close to it. The orientable, compact, connected, topological, two-dimensional manifolds are in one-to-one corre-spondence with a collection of fundamental foods: the apple, the doughnut, the two-holed pretzel, the three-holed pretzel, the four-holed pretzel, and so on (see figure 7).
Technically, they are classified by an integer, called the genus. This is 0 for the sphere, 1 for the torus, 2 for the two-holed torus, etc. The genus counts the number of holes that appear in a given example from

400

Sphere One-holed torus

Figure 7 The orientable manifolds of dimension 2. Figure 8 Cutting and gluing. figure 7. To say that this classifies them is to say that two such manifolds are the same if and only if they have the same genus. This is a theorem due to poincaré [VI.61](/part-06/jules-henri-poincar-18541912).As it turns out, every topological two-dimensional manifold has exactly one smooth structure, so the listin figure 7 is the same as the list of the smooth orientable two-dimensional manifolds.
Here one should keep in mind that the notion of a smooth manifold is intrinsic, and therefore independent of how the man-ifold is represented as a surface in 3-space, or in any other space. For example, the surfaces of an orange, a banana, and a watermelon each represent embed-ded images of the two-dimensional sphere, the left most example in figure 7. plays a key role when it comes to classifying manifoldsof higher dimensions.
Notice that the two-holed torus The shapes illustrated in figure 7 suggest an idea that can be viewed as the result of taking two one-holed tori, cutting disks out of both, gluing the results together across their boundary circles, and then smoothing the corners. This operation is depicted in figure 8. This sort of cutting and gluing operation is an example of whatis called a surgery. The analogous surgery can also be done with a one-holed torus and a two-holed torus to obtain a three-holed torus. And so on.
Thus, all of the oriented two-dimensional manifolds can be built using standard surgeries on copies of just two fundamental building blocks: the one-holed torus and the sphere. Here is a nice exercise to test your understanding ofthis process. Suppose that you perform a surgery, as in figure 8, on a sphere and another manifold that the resulting manifold is the same, with regard to M. Prove its topological and smooth structure, as M. sional manifolds can be built using a version of surgery As it turns out, all of the nonorientable two-dimen-

IV. Branches of Mathematics

. . .

Two-holed torus

Projective plane Klein bottle

Figure 9 tive plane, one identifies the boundary of the Möbius strip Two nonorientable surfaces. To form the pro jec with the boundary of the hemisphere. that first cuts a disk out of an orientable two-dimen-sional manifold and then glues on a Möbius strip. To be more precise, note that the Möbius strip has a circle as its boundary. Cut a disk out of any given orientable, two-dimensional manifold and the result also has a circular boundary. Glue the latter circular boundary to the Möbius strip boundary, smooth the corners, and the result is a smooth manifold that is nonorientable.
Every nonorientable, topological (and thus every nonorientable, smooth), two-dimensional manifold is obtained in this way. More over, the manifold you get depends only on the number of holes (the genus) of the orientable manifold that is used. The manifold obtained from the surgery of a Möbius strip with a sphere is called theone that uses the Möbius strip and the torus is called projective plane. The the Klein bottle. These shapes are illustrated in figure 9. No nonorientable example can be put into three - dimen-sional Euclidean space in a clean way;
any such placement is forced to have portions that pass through other portions, as can be seen in the illustration of the Klein bottle. hausts all two-dimensional manifolds? One method How does one prove that the list given above exuses versions of the geometric techniques that are discussed below in the three-dimensional context. IV.7. Differential Topology 2.4 Dimension 3 There is now a complete classification of all smooth, three-dimensional manifolds; however, this is a very recent achievement.
There has been for some time a conjectured list of all three-dimensional manifolds, anda conjectured procedure for telling one from the other. The proof of these conjectures was recently completedby Grigori Perelman; this is a much-celebrated event in the mathematics community. The proof uses geometry about which more is said in the final part of this article. Here I shall concentrate on the classification scheme. essary to introduce the notion of aon a manifold.
Roughly speaking, this means a rule for Before getting to the classification scheme, it is nec-geometric structure defining the lengths of paths on the manifold. This rule must satisfy the following conditions. The con-stant path that simply stays at one point has length 0, but any path that moves at all has positive length. Sec - ond, if one path starts where another ends, the length of their concatenation (that is, the result of putting thetwo paths together) is the sum of their lengths.
urally to a notion of distance points Note that a rule of this sort for path lengths leads nat - x and yon the manifold: one takes the length ofd(x, y) between any two the shortest path between them. It turns out to be par-ticular ly interesting whend(x, y)2 varies as a smooth function of As it happens, there is nothing special about havingx and y . a geometric structure. Manifolds have them in spades. The following are three very useful geometric structures for the interior of the ball of radius 2 about the origin inn-dimensional Euclidean space.
In these for- mulas, the given path is viewed as if drawn in real timeby some hyper-dimensional artist, withx(t) denoting the position of the pencil tip on the path at timetranges over some interval of the real line: t. Here, length= |x(t) ̇| dt;⎫⎪⎪⎪⎪⎪⎪⎪⎪ length$= |x(t)$ ̇$|1 + {}^{14}|1x(t)|^{2} dt$;⎪⎬⎪⎪⎪⎪ (1) length$= |x(t)$ ̇$|1 - {}^{1}|1x(t)|^{2} dt$.⎪⎪⎪⎪⎪⎭ In these formulas,  ̇path$t \to x(t)$.
x denotes the time-derivative of the^4 standard Euclidean distance between pairs of points. For this reason it is called the The first of these geometric structures leads to the Euclidean geometry for the ball. The second defines what is called geometry because the distance between any two points spherical

401

is the angle between certain corresponding points inthe sphere of radius 1 in(n + 1)-dimensional Euclid- ean space. The correspondence comes from an$(n + 1)-$ dimensional version of the stereographic projection that is used for maps of the Earth’s polar regions. The third distance function defines what is called the hyperbolic geometryof radius 2 innon the ball. This arises when the ball-dimensional Euclidean space is iden- tified in a certain way with a particular hyperbola in(n + 1)-dimensional Euclidean space.
out to be symmetrical with respect to rotations and certain other transformations of the unit ball. (You The geometric structures that are depicted in (1) turn can read more about Euclidean, spherical, and hyperbolic geometry in definitions [[I.3 §§6.2, 6.5, 6.6]](/part-01/some-fundamental-mathematical-de-ni tions).)some fundamental mathematical metric structures on any given manifold and so one might hope to find one that has some particularly desir-As was remarked above, there are very many geoable properties.
With this goal in mind, suppose that Ihave specified some “standard” geometric structure$S$ for the ball in Rn to serve as a model of an exception- ally desirable structure. This could be one of the ones I have just defined or some other favorite. This leads to a corresponding notion of the structure S for a com- pact manifold.
Roughly speaking, one says that a geo-metric structure on a manifold is of the type S if every point in the manifold feels as though it belongs to the unit ball with the structure structure S on the ball to provide coordinate charts that S, that is, if one can use the respect the geometric structure on the manifold. To bemore precise, suppose that I am defining a coordinate system in a small neighborhood functionφ:$N \to R^{d}$.
If I can always do this in such a N of x by means of a way that the image that the distance between any two pointsφ(N) lies inside the ball, and suchx and y in Nφ(y)equals the distance between their images, defined in terms of the structure S on the ball,φ(x) and then I will say that the manifold has structure of type In particular, a geometric structure is said to be Euclid-S. eanb all is Euclidean, spherical, or hyperbolic, respectively., spherical, or hyperbolic when the structure on the For example, the sphere in any dimension has a spherical geometric structure (as it should!).
As it turns out, every two-dimensional manifold has a geometric structure that is either spherical, Euclidean, or hyper-bolic. More over, if it has a structure of one of these types, then it cannot have one of a different type. In particular, the sphere has a spherical structure, but not a Euclidean or hyperbolic structure. Meanwhile, the torus

402

in dimension 2 has a Euclidean geometric structure but only a Euclidean one, and all of the other manifolds listed in figure 7 have hyperbolic geometric structures and only hyperbolic ones. William Thurston had the great insight to realize that three-dimensional manifolds might be classifiable using geometric structures. In particular, he made what was known as the says, roughly speaking, that every three-dimensional geometrization conjecture, which manifold is made up of “nice” pieces:
Every smooth three-dimensional manifold can be cut ina canonical fashion along a predetermined set of two dimensional spheres and one-holed tori so that each ofthe resulting parts has precisely one of a list of eight possible geometric structures. Euclidean, and hyperbolic ones. These plus the other five are, in a sense that can be made precise, those The eight possible structures include the spherical, that are maximally symmetric.
The other five are associ-ated with various lie groups [III.48 §1](/part-03/lie-theory), as are the listed three. Since its proof by Perelman, the geometrization conjecture has come to be known as the geometrization theorem. As I shall explain in a moment, this provides a satisfactory resolution of the three-dimensional part of the quest set out at the end of section 1. This is because a manifold with one of the eight geometric structures can be described in a canonical fashion using group theory.
As a result, the geometrization theorem turns the classification issue for manifolds into a ques-tion that group theory can answer. What follows is an indication of how this comes about. Each of the eight geometric structures has an associated ture. For example, in the case of the spherical structure, model space which has the given geometric struc the model space is the three-dimensional sphere. For the Euclidean structure, the model space is the three-dimensional Euclidean space.
For the hyperbolic structure, it is the hyperbola in the four-dimensional Euclid-ean space, where the coordinates(x, y, z, t) obey t2 =$1$+x2 + y2 + z2. In all of the eight cases, the model space has a canonical group of self-maps that preserve the distance between any two pairs of points. In the Euclidean case, this group is the group of translations and rotations of the three-dimensional Euclidean space.
In the spherical case, it is the group of rotations of the four-dimensional Euclidean space, and in the hyperbolic case, it is the group of Lorentz transformations of four-dimensional Minkowski space. The associated IV. Branches of Mathematics group of self-maps is called the given geometric structure. isometry group for the The connection between manifolds and group theory arises because a certain set of discrete subgroups of the isometry group of any one of the eight model spaces determines a compact manifold with the correspond-ing geometric structure.
(A subgroup is called discrete if every point in the subgroup is isolated, meaning that it belongs to a neighborhood that contains no other points from the subgroup.) This compact manifold is obtained as follows. Two points space are declared to be equivalentx andif there is an isom - y in the model etry T , belonging to the subgroup, such that T x = y . In other words, isometries from the subgroup. It is easy to check thatx is equivalent to all its images under this notion of equivalence is a genuine relation [I.2 §2.3](/part - 01/language - and - grammar).
The equivalence classes are then equivalence in one-to-one correspondence with the points of the associated compact manifold. Think of the real line as a model space whose isometry group is the group of translations. The set of transla-Here is a one-dimensional example of how this works. tions by integer multiples of 2π forms a discrete sub- group of this group.
Given a point possible images under translations from the sub grou pt in the real line, the are all the numbers of the form$t + 2nπ$, where n is an integer, so one regards two real numbers as equivalent if they differ by a multiple of 2π, and the equivalence class oft is t + 2 nπ: n \in Z. One can associate with this equivalence class the point(x, y) = (. os  t, . in  t) in the circle, since adding a multiple of 2 not affect either its sine or its cosine.
(Intuitively speak-π to t does ing, if you regard eacht as equivalent to t + 2π, then you are wrapping the real line around and around a circle.) isometry group and compact manifolds with the given geometric structure goes in the other direction as well. This association between certain subgroups of the That is, the subgroup can be recovered from the man-ifold in a relatively straightforward fashion using the fact that each point in the manifold lies in a coordinate chart where its distance function is the same as that of the associated model space.
amount of evidence for the validity of the geometriza-tion conjecture, much of it supplied by Thurston. In Even before Perelman’s work there was a tremendous order to discuss this evidence, a small digression isrequired to give some of the background. First, I need to bring in the notion of a sphere. A link is the name given to a finite disjoint link in the three-dimensional

IV.7. Differential Topology

Figure 10 A link formed out of two knots.

union of knots. Figure 10 depicts an example of one that is made out of two knots. thicken the link so as to view it as a union of knotted, solid tubes. (Think of the knot as the copper in an insu-I also need the notion of surgery on a link. To this end, lated wire and view the solid tube as the copper plus the surrounding insulation.) Notice that the boundary of any given component tube is really a copy of ourone-holed torus from figure 7.
Therefore, removing any one of the tubes leaves a tubular-shaped missing region from the three-dimensional sphere whose boundary is a torus. Now, to define a surgery, imagine removing a knotted tube and then gluing it back in a different way. That is, imagine gluing the boundary of the tube to the boundary of the resulting missing region using an identifica-tion that is not the same as the original. For example, take the “unknot,” a standard round circle in a given plane, here viewed as living inside a coordinate chart of the three-dimensional sphere.
Take out the solid tube around it, and then replace the tube by gluing the boundary in the “wrong” way, as follows. Consider the left most torus in figure 11 as the boundary of the complement of the tube in R3. Consider the middle torus as the inside of the tube. The “wrong” gluing identifies the circles marked “R” and “L” on the left most torus with their counterparts on the middle torus. The result-ing space is a three-dimensional manifold which turns out to be the product of the circle with the two-dimensional sphere.
That is to say, it is the set of ordered pairs(x, y), where x is a point in the circle and y is a point in the two-dimensional sphere. There are many other possible ways to glue the boundary torus, and almost all of the corresponding surgeries give rise todistinct three-dimensional manifolds. One of these is illustrated in the right most part of figure 11.In general, given any link one can construct a countably infinite set of distinct, smooth three - dimensional 403 manifolds by using surgeries on it.
Further more, Ray-mond Lickorish proved that every three-dimensional manifold can be obtained by using surgery on some link in the three-dimensional sphere. Unfortunately, this character ization of three-dimensional manifolds via surgeries on links does not provide a satisfactory resolution to the central quest of classifying smooth structures because the process is far from unique: for any given manifold there is a bewildering assortment of links and surgeries that can be used to produce it.
More over, as of this writing, there is no known way to clas-sify knots and links in the three-dimensional sphere. for his geometrization conjecture. Given any link, allbut finitely many of the three-dimensional manifolds In any event, here is a taste of Thurston’s evidence you can produce from it by surgery satisfy the conclu-sions of the geometrization conjecture.
Thurston also proved that, given any knot apart from the unknot, allbut finitely many surgeries on it produce a manifold with a hyperbolic geometric structure. By the way, Perelman’s proof of the geometrization theorem gives as a special case a proof of the Poincaré conjecture we need the notion of a, proposed by Poincaré in 1904. To state this simply connected manifold. This is a manifold with the property that any closed loop init can be shrunk down to a point.
To be more precise, designate a point in the manifold as the “base point.”Then any path in the manifold that starts and ends at the chosen base point can be continuously deformedin such a way that at each stage of the deformation the path still starts and ends at the base point, and so that the end result is the trivial path that starts at the base point and just stays there.
For example, the two dimensional sphere is simply connected, but the torus is not, since a loop that goes “once around” the torus (for example, any of the loops R or L in the various tori of figure 11) cannot be shrunk to a point. In fact, a sphere is the only two-dimensional manifold that is simply connected, and spheres are simply connected inall dimensions greater than 1. The Poincaré conjecture.nected, three-dimensional manifold is the three - dimen-Every compact, simply consional sphere. 2.5 Dimension 4 This is the weird dimension.
Nobody has managed toformulate a useful and viable conjecture for the classification of smooth, compact, four-dimensional man - ifolds. On the other hand, the classification story for 404 L R R L Figure 11 Different ways of gluing a tube into a tube-shaped hole. many categories of topological four-dimensional manifolds is well - understood. For the most part, this workis by Michael Freedman. not admit smooth structures.
The so - called “Some of the topological manifolds in dimension 4 do118 conjecture” proposes necessary and sufficient conditions for a four - dimensional, topological manifold to have at least one smooth structure. The fraction refers to the absolute value of the ratio of the rank118 here to the signature of a certain symmetric, bilinear form that appears in the four-dimensional story. The case 0 excepted, the conjecture asserts that a smooth struc-ture exists if and only if this ratio is at least 11 .
The0 bilinear form in question is obtained by counting with8 signed weights the intersection points between vari-ous two-dimensional surfaces inside the given fourdimensional manifold. In this regard, note that a typi-cal pair of two-dimensional surfaces in four dimensions will intersect at finitely many points. This is a higher-dimensional analogue of a fact that is rather easier to visualize: that a typical pair of loops in the two - dimen-sional plane will intersect at finitely many points. Not surprisingly, the bilinear form here is called the intersection form classification theorems.;
it plays a prominent role in Freedman’s Meanwhile, the problem of listing all smooth structures is wide open in four dimensions: there are no cases of a topological manifold with at least one smooth structure where the list of distinct struc-tures is known to be complete. Some topological fourdimensional manifolds are known to have (countably) infinitely many distinct smooth structures. For oth-ers there is only one known structure. For example, the four-dimensional sphere has one obvious smooth structure and this is the only one known.
However, the underlying topological manifold may, for all any-one knows, have many distinct smooth structures. By the way, the story for noncompact manifolds in dimen - sion 4 is truly bizarre. For example, it is known that there are uncountably many smooth manifolds that are homeomorphic to the standard, four-dimensional Euclidean space. But even here, our understanding is IV. Branches of Mathematics R L less than optimal since there is no known explicit construction of a single one of these “exotic” smooth structures.
ants that have the power to distinguish smooth struc-tures on a given topological 4 - manifold. Donaldson’s Simon Donaldson provided a set of geometric in var i invariants were recently superseded by a suite of more computable invariants; these were proposed by Edward Witten and are called the Seiberg–Witten invariants. More recently still, Peter Oszvath and Zoltan Szabo designed a possibly equivalent set of invariants that are even easier to use. Do the Seiberg–Witten invariants(broadly defined) distinguish all smooth structures? No one knows.
A bit more is said about these invariants inthe final part of this article. cal version of the four-dimensional Poincaré conjecture that follows. Note that Freedman’s results include the topologi The four-dimensional sphere is the only compact, topological based map from either a one-dimensional circle or a4-manifold with the following property: every two-dimensional sphere can be continuously deformed so that the result maps onto the base point. The smooth version of this conjecture has not been resolved.
zation conjecture/theorem?Is there a four-dimensional version of the geometri2.6 Dimensions 5 and Greater Surprisingly enough, the issues raised at the end ofthe first section have more or less been resolved in all dimensions that are greater than 4. This was done some time ago by Stephen Smale with input from John Stallings. In these higher dimensions it is also possible to say what conditions need to hold in order for a topological manifold to admit a smooth structure.
For example, John Milnor and others determined that the respective number of smooth structures on the spheres of dimensions 5–18 are as follows: 1, 1, 28, 2, 8, 6, 992,1, 3, 2, 16 256, 2, 16, 16. IV.7. Differential Topology greater than 4 are easier to deal with than dimen - sions 3 and 4. However, there is a good reason for this. At first sight, it is surprising that the dimensions It turns out that there is more room to maneuver in these higher-dimensional spaces and this extra room makes all the difference.
To get a sense for this, letbe a positive integer, and let Sn denote the n - dimen - n sional sphere. To make this more concrete, view Sn as the set of points R$n \text{such that} x^{2} + · · · +(x^{1}$, . . . , x(xn)2 +1)=in the Euclidean space1. Now consider the product manifold, points(x, y), where1 Snx. imes is in one copy of (Sn)n. This is the set of pairs of+1 Sn and y is in another. This product manifold has dimension 2 A standard picture of Sn . imes  Sn has two distinguish edn.
copies of Sn inside it, one consisting of all points of the formsisting of all points(x, y) with(x, y)y = (1 with, 0, . . . )x =and the other con-(1,0, . . . ). Let us call the first copy SR and the second one SL. Of partic- ular interest here is the fact that precisely one point, the point((1 S$, 0 R, . . . )$, (and SL1, intersect in0, . . . )). By the way, in then = 1 case, the space S1 . imes  S1 is the doughnut in figure 7.
The one-dimensional spheres S and S inside it are the circles that are drawn in the left most diagram in figure 11.RIf you are with me so far, suppose now that an L advanced alien en route from Arcturus to the galactic center kidnaps you and drops you into some unknown, 2 n-dimensional manifold. You suspect that it is Sn. imes Sn, but are not sure. One reason that you suspect this tobe the case is that you have found a pair ofn-dimen- sional spheres in it, one you call call M . Unfortunately, they intersect in 2 MR and the other you N + 1 points, L where N > 0.
You would be less nervous about things if you could find a pair of different spheres that intersect precisely once. So you wonder whether perhaps you can push intersection points. ML around a bit so as to remove the 2 N unwanted The surprise here is that the issue of removing intersection points in any dimension concerns only certain zero-, one-, and two-dimensional manifolds that live inside your 2 tion due to Hassler Whitney. In particular, Whitney dis-n-dimensional one.
This is an old observa- covered that in the 2 n-dimensional manifold you must be able to find a disk of dimension two whose bound-ary loop lies half in$M^{L} \text{and half in} M^{R}$. This boundary loop must hit two of the intersection points (one whenit passes from M to M and one when it passes back again). The disk must also stick out orthogonally toand MR where it touches them. If its interior is dis join(t L)R ML from both$M^{L} and M^{R}$, and if there are no points where

405

the disk comes back to intersect itself, then you can push the part of M that is very near the disk along the L disk while stretching the remaining part to keep things from tearing. If you extend the disk a bit past$MR$, then you will have removed two of the intersection points when you have pushed past the end of the disk. Figure 12 is a schematic of this. This pushing operation(the Whitney trick) can be performed in any manifold of any dimension if you can find the required disk. The problem is to find the disk.
Figure 13 is a drawing of across-sectional slice showing a “good” disk on the left and some badly chosen disks in the middle and on the right. If you have a badly chosen disk that nevertheless satisfies the required boundary conditions, then you might hope to find a tiny wiggle of its interior that makes it better. You would like the new disk to have noself-intersection points and you would like its interior to be disjoint from both direction that is parallel to the disk itself will help, for ML and MR.
No wiggle along a any such wiggle only changes the position of the intersection point in the disk. Likewise, a wiggle in a direc-tion parallel to the offending ML or MR is use less since it only changes the position of the intersection point in the latter space. Thus, 2+ n of the 2 n dimensions are use less when it comes to wiggling a disk. However, there are 2 n - (n + 2) = n - 2 remaining dimensions to work with, which is a positive number when 2 fact, when this is true a generic wiggle in any of these$n > 4$.
In extra dimensions does the trick. Now, when 2 n = 4 (so n = 2) there are no extra dimensions, and, consequently, no small wiggle can make a new disk with out intersection points. So if a given candidate disk intersects$MR$, then the Whitney trick just trades the old pair of intersection points fora new collection. If the disk intersects either itself or Mpoints: that is, points where one part has come around L, then the new version of$M^{L} \text{has self} - intersection$ to intersect another. This failure of the Whitney trick is the bane of four-dimensional topology.
Thus, a major lemma for Michael Freedman’s classification theorem about topological four-dimensional manifolds describes ubiquitous circumstances where a topologically (but not smoothly!) embedded disk can be found for use in the Whitney trick. 3 How Geometry Enters the Fray Much of our current understanding about smooth man-ifolds in dimensions 4 or less has come via what

406

M

L

MR MR

Original

Figure 12 The Whitney trick.

ML Whitney disk ML Disk ML Disk

MR MR MR

Figure 13 Some possible Whitney disks.

might be called geometric techniques. The search for acanonical geometric structure on a given three-dimensional manifold is an example. Perelman’s proof of the geometrization theorem proceeds in this manner. The idea is to choose any convenient geometric structure on a given three-dimensional manifold and then con-tinuous ly deform it by some well-defined rule. If one views the deformation as a time-dependent process, then the goal is to design the deformation rule to make the geometric structure ever more symmetric as time goes on.
A rule introduced and much studied by Richard Hamilton and then used by Perelman specifies the time-derivative of the geometric structure at any given time in terms of certain of its properties at that time. It is a nonlinear version of the classical[I.3 §5.4](/part-01/fundamental-definitions). For those unfamiliar with the latter, the sim-heat equation plest version modifies functions on the real line and will now be described. Letter, and letf (x) denote a given function on the line,τ denote the time parame- representing the initial distribution of heat.
The resulting time-dependent family of functions associates with any given positive value forτ a function, Fτ(x), which represents the distribution of heat at timeτ. The partial derivative ofond partial derivative with respect to Fτ(x) with respect to τ is equal to its sec-x, and the initial

IV. Branches of Mathematics

ML New ML

M

R

Whitney disk

Final

condition is thatis zero out side some interval, then one can write down$F^{0}(x) = f (x)$. If the initial function f a formula for$F^{τ}$: Fτ(x) = (2πτ)(11()/){2}−. nfty. nfty  (e-)(x-y()2()/){2}τ f (y)dy. (2) One can see from (2) that inx as τtends to infinity. In particular, this limit is Fτ (x) tends uniformly to zero completely ignorant of the starting function being identically zero, it is also the most symmetric$f$; and, function possible. The representation for$F^{τ} in (2) indi-$ cates how this comes about.
The value of point is a weighted average of the values of the original$F^{τ} \text{at any given}$ function. More over, asmore like the standard average over ever-larger regionsτ increases, this average looks of the line. Physically this is very plausible as well: the heat spreads itself out more and more thinly as time goes on.
that Hamilton introduced and Perelman used is defined The time-dependent family of geometric structures by an equation that relates the time-derivative of the geometric structure at any given time to its Ricci curvature geometric structures for the second derivatives that, a certain natural substitute in the context of enter the heat equation for the functions$F^{τ} above$. The idea much studied by Hamilton and then by Perelman is to let the evolving geometric structure decompose the manifold into the canonical pieces that are predicted to exist by the geometrization conjecture.
Perelman proved that the pieces required by the geometrization conjecture emerge as regions whose points stay relatively close together (as measured by a certain rescaling of the distance function) while the points in distinct regions move farther and farther apart. the time-evolution of a geometric structure is rather The equation used by Perelman and Hamilton for

IV.7. Differential Topology

complicated. Its standard incarnation involves the no-tion of a riemannian metric [I.3 §6.10](/part-01/fundamental-definitions). This appears in any given coordinate chart on anifold as a symmetric, positive-definiten - dimensional man - n . imes n matrix whose entries are functions of the coordinates. The var-ious components of this matrix are traditionally written asstructure and can in turn be derived from it.{gij}1 ⩽ i, j^⩽n.
The matrix determines the geometric ily of Riemannian metrics, for the time dependence is obtained using an equa-Hamilton and Perelman study a time-dependent fam-τ \to gτ, where the rule tion for the form. artial (g )τ-derivative of= −2 R [g ]g, whereτ that has the schematic{R } are the components of the aforementioned Ricci curva-ture, a certain symmetric matrix that is determined atττijijτij1⩽i, j^⩽n any given ric has a Ricci curvature; its components are standardτ by the metric gτ.
Every Riemannian met- (nonlinear) functions of the components of the matrix and their first- and second-order partial derivatives inthe coordinate directions. The Ricci curvatures for the metrics that define the respective Euclidean, spherical, and hyperbolic geometries have the particularly simple form Rij = cgij , where c is 0, 1, or - 1, respec - tively. For more about these ideas, see[III.78](/part - 03/ricci - flow).
ricci flow article, geometry has also played a central role in the developments in the classification program for smooth, As was mentioned at the beginning of this part of the four-dimensional manifolds. In this case, geometrically defined data are used to distinguish smooth structures on topologically equivalent manifolds. What follows isa very brief sketch of how this is done. To begin with, the idea is to introduce a geometric structure on the manifold and then to use the latter to define a canonical system of partial differential equations.
In any given coordinate chart, these equations arefor a particular set of functions. The equations state that certain linear combinations of the collection of first derivatives of the functions from the set are equal to terms that are linear and quadratic in the values of the functions themselves. In the case of the Donald-son invariants, and also of the newer Seiberg–Witten invariants, the relevant equations are nonlinear generalizations of the electricity and magnetism.maxwell equations [IV.13 §1.1](/part - 04/general - relativity - and - the - einstein - equations) for braic weights.
The purpose of the algebraic weightingof the count is to obtain an In any event, one then counts the solutions with alge - invariant [I.4 §2.2](/part - 01/general - goals), that is, a count that does not change if the given geomet-ric structure is changed. The point here is that the

407

naive count will typically depend on the structure, but a suitably weighted count will not. Imagine, for example, that one has a continuously varying family of geomet-ric structures, and that new solutions appear and old ones disappear only in pairs, where one solution has been assigned weight+1 and the other - 1. and disappearance phenomenon. The equation in ques-The following toy model illustrates this appearance tion is for a single function on the circle. That is, it will concern a function, f , of one variable, x, that is peri-odic with period 2∂f /∂x + τf - f3 π=.
For example, take the equation0, where τ is a constant that is specified in advance. Varying a model for the variation of the geometric structure.τ can now be viewed as When$τ >$0 there are exactly three solutions: f ≡ 0, ftion is≡ τ, andf ≡f0. Thus, the number of solutions changes≡ −τ. However, when τ ⩽ 0, the only solu- as independent ofτ crosses zero. Even so, a suitable weighted count isτ. Let us return now to the four-dimensional story. If the weighted sum is independent of the chosen metric structure, then it depends only on the under ly-geoing smooth structure.
Therefore, if two geometric structures on a given topological manifold provide distinct sums, then the underlying smooth structures must be distinct. defined invariants for four-dimensional manifolds that As I remarked earlier, Oszvath and Szabo have are easier to use than the Seiberg–Witten invariants, but probably equivalent to them. These are also defined as the number of solutions to a particular system of differential equations, counted in a creative way.
In this case, the equations are analogues of the cauchy–riemann equationsbe defined after cutting the 4-manifold into simpler[I.3 §5.6](/part-01/fundamental-definitions), and the arena is a space that can pieces. There are myriad ways to slice a 4-manifold inthe prescribed manner, but a suitably creative, algebraic count of solutions provides the same number for each. ential equations to distinguish smooth structures on a With hindsight, one can see that the use of differ given topological manifold makes good sense, since a smooth structure is needed to take a derivative in the first place.
Even so, this author is constantly amazed bythe fact that the Donaldson/Seiberg–Witten/Oszvath Szabo strategy of algebraically counting differential equation solutions yields counts that are both tractable and useful. (Getting the same count in all cases is no help at all.)

408

Further Reading

Those who wish to learn more about manifolds in general can consult J. Milnor’s book Differentiable Viewpoint (Princeton University Press, Topology from the Princeton, NJ, 1997) or the book ogy (Prentice Hall, Englewood Cliffs, NJ, 1974), by Differential Topol V. Guillemin and A. Pollack. A good introduction tothe classification problem in dimensions 2 and 3 is the book(Princeton University Press, Princeton, NJ, 1997), by Three-Dimensional Geometry and Topology W. Thurston. This book also has a nice discussion of geometric structures.
A full account of Perelman’s proof of the Poincaré conjecture can be found in Flow and the Poincaré Conjecture, by J. Morgan and Ricci G. Tian (American Mathematical Society, Providence, RI,2007). The story for topological 4-manifolds is told in the book by M. Freedman and F. Quinn titled Topology of NJ, 1990).
There are no books available that serve as4-Manifolds (Princeton University Press, Princeton, general introductions to the smooth 4-manifold story. A book that does introduce the Seiberg–Witten invariants isto the Topology of Smooth Four-Manifolds The Seiberg–Witten Equations and Applications(Princeton University Press, Princeton, NJ, 1995), by J. Morgan. Meanwhile, the Donaldson invariants are discussed in detail in the book by Donaldson and P. Kronheimer titled Press, Oxford, 1990).
Finally, parts of the story for Geometry of Four-Manifolds (Oxford University dimensions greater than 4 are told intheh-Cobordism Theorem (Princeton University Press, Lectures on Princeton, NJ, 1965), by J. Milnor, and Essays on Topological Manifolds, Smoothings and Tri-Foundational angulations1977), by R. Kirby and L. Siebenman.(Princeton University Press, Princeton, NJ, IV.8 Moduli Spaces David D. Ben-Zvi Many of the most important problems in mathemat-ics concern classification [I.4 §2](/part-01/general-goals).
One has a class of mathematical objects and a notion of when two objects should count as equivalent. It may well be that two equivalent objects look superficially very different, soone wishes to describe them in such a way that equivalent objects have the same description and in equivalent objects have different descriptions. Moduli spaces can be thought of as geometric solutions tocle we shall illustrate some of the key features of mod-geometric classification problems. In this arti-

IV. Branches of Mathematics

uli spaces, with an emphasis on the moduli spaces of riemann surfaces [III.79](/part-03/riemann-surfaces). In broad terms, a moduli problem consists of three ingredients. Objects: which geometric objects would we like to Equivalences: describe, oras being isomorphic, or “the same”?parametrize when do we identify two of our objects? Families: modulate?how do we allow our objects to vary, or In this article we will discuss what these ingredients sig-nify, as well as what it means to solve a moduli problem, and we will give some indications as to why this might be a good thing to do.
etrypology Moduli spaces arise through out[IV.4](/part-04/algebra), differential geometry, and[IV.6](/part-04/algebraic-topology). (Moduli spaces in topology are often algebraic geom-algebraic toreferred to asgive a geometric structure to the classifying spaces.) The basic idea is tototality of the objects we are trying to classify. If we can understand this geo-metric structure, then we obtain powerful insights into the geometry of the objects themselves. Further more, moduli spaces are rich geometric objects in their own right.
They are “meaningful” spaces, in that any state-ment about their geometry has a “modular” interpretation, in terms of the original classification problem. As a result, when one investigates them one can often reach much further than one can with other spaces.
moduli spaces such as the moduli of elliptic curves [III.21](/part-03/elliptic-curves) (which we discuss below) play a central role in a vari-ety of areas that have no immediate link to the geometry being classified, in particular in algebraic number theory the study of moduli spaces has benefited tremendously[IV.1](/part-04/number-theory) and algebraic topology. More over, in recent years from interactions with physics (in par-ticular with string theory [IV.17 §2](/part-04/vertex-operator-algebras)). These interactions have led to a variety of new questions and new techniques. 1 Warmup:
The Moduli Space of Lines in the Plane Let us begin with a problem that looks rather simple, but that nevertheless illustrates many of the important ideas of moduli spaces. Problem.plane R2 that pass through the origin. Describe the collection of all lines in the real To save writing, we are using the word “line” to mean“line that passes through the origin.” This classification

IV.8. Moduli Spaces

problem is easily solved by assigning to each line essential parameter, or modulus, a quantity that we can L an calculate for each line and that will help us tell different lines apart. All we have to do is take standard Cartesian coordinatesθ(L) between the linex, y on the plane and measure the angle L and the x-axis, taken in coun- ter clockwise fashion. We find that the possible valuesofθ are those for which 0 ⩽ θ < π, and that for every suchofθ with theθ there is exactly one linex-axis. So as a set L, we have a complete that makes an angle solution to our classification problem:
the set of lines L, known as the real projective line RP1, is in one-to-one correspondence with the half-open interval[0, π). classification problem. What does this entail? We haveHowever, we are seeking a geometric solution to the a natural notion of when two lines are near each other,which our solution should capture—in other words, the collection of lines has a natural topology [III.90](/part-03/topological-spaces). So far, our solution does not reflect the fact that lines L for which the angle θ(L) is close to π are almost horizontal:
they are therefore close to thewhichθ = 0) and to the lines L with θ(L) close to zero.x-axis (for We need to find some way of “wrapping around” the interval[0, π) so that π becomes close to 0. One way to do this is to take not the half-open interval“identify” the points 0 and[0, π) but the closed intervalπ. (This idea can easily be[0, π], and then to made formal by defining an appropriate relation [I.2 §2.3](/part-01/language-and-grammar).) Ifπ and 0 are regarded as the equivalence same, then numbers close to close to 0.
This is a way of saying that if you attach theπ are close to numbers two ends of a line segment together, then, topologically speaking, you obtain a circle. gested by the following geometric construction of Consider the unit circle A more natural way of achieving the same end is sug- S1 ⊂ R2. To each point s \in RP(S1)1., there is an obvious way of assigning a line L(s): take the line that passes through have a family of lines parametrized bys and the origin. Thus, we S1, that is, a map (or function)in our set RP1 s.
What is important about this is that we\to  L(s) that takes points in S1 to lines already know what it means for two points in S1 to be close to each other, and the map$s \to L(s) \text{is continu}-$ ous. However, this map is a two-to-one function rather than a bijection, sinces and -s always give the same line. To remedy this, we can identify each cle S1 with its antipodal point -s. We then have a one-s in the cir- to-one correspondence between RP1 and the resulting quotient space [I.3 §3.3](/part-01/fundamental-definitions) (which again is topologically

409

a circle), and this correspondence is continuous in both directions. The key feature of the space RP1, considered as the moduli space the ways in which lines canof lines in the plane, is that it captures modulate, or vary continuously in families. But when do families of lines arise?A good example is provided by the following construction. Whenever we have a continuous curve C ⊂ R2 \ 0 in the plane, we can assign to each point L(c) that passes through 0 and c. This gives us a fam i lyc in C the line of lines parametrized bytakesc to L(c) is a continuous function from C.
More over, the function that C to RP1, so the parametrization is a continuous one. Suppose, for example, that C is a copy of R realized as the set of points C to RP1 gives an isomorphism between(x, 1) at height 1. Then the map from R and the set{L}:$θ(L) \neq 0$, which is the subset of RP1 consisting of all lines apart from thewe have an intuitive notion of what it means for a col - x - axis. Put more abstractly, lection of lines through the origin to depend continu-ously on some parameters, and this notion is captured precisely by the geometry of RP1:
for instance, if you tell me you have a continuous 37-parameter family of lines in R2, this is the same as saying that you have a continuous map fromv \in R37 to a line L(v)R37\in to RPRP1. (More concretely, we1, which sends a point could say that the real function$v \to θ(L(v)) on R37$ is continuous away from the locus whereθ is close toπthat measures the angle from the. Near this locus we could use instead the functiony -axis.) φ

1.1 Other Families

The idea of families of lines leads to various other geo-metric structures on the space RP1, and not just its topological structure. For example, we have the notionof a differentiable family of lines in the plane, which is a family of lines for which the angles vary differ en-tiably. (The same ideas apply if we replace “differentiable” by “measurable,” “$C \infty$,” “real analytic,” etc.) To parametrize such a family appropriately, we would like RP1 to be a [I.3 §6.9](/part-01/fundamental-definitions), so that we can calculate derivatives of functions on it.
Such astructure on differentiable manifold RP1 can be specified by using the angle functions functionθθgives us a coordinate for lines that are notand φdefined in the previous section. The too close to thex - axis, and φ gives us a coordinate for lines that are not too close to the cu late derivatives of functions on RPy - axis. We can cal - 1 by writing them in terms of these coordinates. One can justify this dif-ferentiable structure on RP1 by checking that for any 410 differentiable curve C ⊂ R2 \ 0 the map c \to L(c) comes out as differentiable.
This means that ifto thex - axis, then the function x \to θ(L(x))L(c) is not close is differentiable at The functionsx = xc\to , and similarly forθ(L(x)) and \to φ(L(x))φ and theare call edy - axis. pullbacks“pulling back,”, because they are the result of converting, orθ and φfrom functions defined on RP1 to functions defined on We now can state the fundamental property of C. RP1 as a differentiable space.
A differentiable family of lines in R2 parametrized by a differentiable manifold tion from X to RP1, taking a point X is the same thing as a func-x to a line L(x), such that the pullbacksx \to  θ(L(x)) and x \to  φ(L(x)) of the functionsθ, φare differentiable functions. We say that RP1 (with its differentiable structure) is the lines in moduli space R2. This means thatof (differentiably varying families of)RP1 carries the universal differentiable family of lines we have assigned to each point of.
From the very definition, RP1 a line in R2, and these lines vary differentiably as we vary the point.
The above assertion says that lines, parametrized by a space any differentiable family of X, is described by giv- ing a map f: X \to  RP1 and assigning to x \in  X the line L(f (x)).

1.2 Reformulation: Line Bundles

It is interesting to reformulate the notion of a (continu-ous or differentiable) family of lines as follows. Let X be a space and let points in X. For each pointx \to  L(x) be an assignment of lines tox \in  X, we place a copy of R^2$at$ X . imes x; in other words, we consider the Cartesian product R2. We may now visualize the line L(x) as living in the copy of R2 that lies overx. This gives us a contin- uously varying collection of lines byx \in  X, otherwise known as a line bundle L(x) parametrized over X.
More over, this line bundle is embedded in the “trivial”vector bundle [IV.6 §5](/part-04/algebraic-topology)$X \times R^{2}$, which is the constant assignment that takes each case when$X$ is RP1 itself, we have a “tautological” line$x \text{to the plane} R^{2}$. In the bundle: to each point$s \in RP^{1}$, which we can think of as a line$L^{s} in R^{2}$, it assigns that very same line Ls. Proposition. For any topological space X there is a natural bijection between the following two sets: (i) the set of continuous functions$f$:$X \to RP^{1}$;
and (ii)the trivial vector bundle the set of line bundles on X X. imes  that are contained in R2.

IV. Branches of Mathematics

ing pullback of the tautological line bundle on This bijection sends a functionf to the correspond - RP1. That is, the functionx \to  L . (This is a pullback because it conver tsf is mapped to the line bundle L from a function defined on$f$ (x) RP1 to a function defined on Thus, the space X.) RP1 carries the universal line bun- dle that sits in the trivial a line bundle sitting in the trivial R2 bundle—any time we have R2 bundle, we can obtain it by pulling back the universal (tautological)example on RP1.

1.3 Invariants of Families

Associated with any continuous function circle S1 to itself is an integer known as itsf from the degree. Roughly speaking, the degree oftimesf (x) goes around the circle whenf is the number ofx goes around once. (If it goes backwards degree is-n.) Another way to think of the degree is asn times, then we say that the the number of times a typical point in S1 is passed byf (x)as +1 if it is passed in the counter clockwise directionas x goes around the circle, where we count this$and$-1 if it is passed in the clockwise direction.
Earlier, we showed that the circle$S^{1}$, which we obtained by identifying the endpoints of the closed interval[0, π], could be used to parametrize the mod- uli space RP1 of lines. Combining this with the notion of degree, we can draw some interesting conclusions. In particular, we can define the notion of winding numbersγ from the circle. Suppose that we are given a continuous function S1 into the plane R2 and suppose that it avoids 0. The image of this map will be a closed loop$C$(which may cross itself). This defines for us a map from then work out S1 to itself:
first do L(c), which belongs toγ to obtain a point RP1, and final lyc in C, use the parametrization of RP1 to associate with L(c) a point in S1 again. The degree of the resulting compos- ite map will be hence C, winds around 0, so half this number is defined twice the number of times thatγ, and to be the winding number of More generally, given a family of lines inγ.
R2 parame- trized by some space“manner in which Xwinds around the circle.” To be pre-X, we would like to measure the cise, given a function$φ from X \text{to RP}^{1}$, which defines the parametrized family of lines, we would like to beable to say, for any map$f$: S1 \to X, what the wind- ing number is of the composition pointx in S1 to its image f (x) inφf X and from there, which takes a to the corresponding lineφ(f (x)) in the family. Thus,

IV.8. Moduli Spaces

the map ti onf:φS1 gives us a way of assigning to each func-\to  X an integer, the winding number ofφfφis continuously deformed: that is, it is a topological. The way this assignment works does not change if invariant ofφbelongs to in the firstφ. What it does depend on is the class that cohomology group[IV.6 §4](/part-04/algebraic-topology) of space X, HX^1(X, which is contained in the trivial Z). Equivalently, to any line bundle on a R2 - bundle, we have associated a cohomology class, known as the Euler class of the bundle.
This is the first example of a characteristic class [IV.6 §5](/part - 04/algebraic - topology) for vector bundles. It demonstrates that if we understand the topology of moduli spaces of classes of geometric objects, then we can define topological invariants for families of those objects. 2 The Moduli of Curves and Teichmüller Spaces We now turn our attention to perhaps the most famous examples of moduli spaces, the moduli spaces of curves, and their first cousins, the Teichmüller spaces.
These moduli spaces are the geometric solution to the problem of classification of compact Riemann surfaces, and can be thought of as the “higher theory” of Rie-mann surfaces. The moduli spaces are “meaningful spaces,” in that each of their points stands for a Rie-mann surface. As a result, any statement about their geometry tells us something about the geometry of Riemann surfaces. surfaceented) to which a We turn first to the objects.
Recall that ais a topological surface complex structure X (connected and ori-has been given. Riemann Complex structures can be described in many ways, and they enable us to do complex analysis, geometry, and algebra on the surface us to define holomorphic$X$[I.3 §5.6](/part - 01/fundamental - definitions) (complex - analytic). In particular, they enable andof Xmer om or ph ic functions.
To be precise, X is a two-dimensional manifold,[V.31](/part - 05/the - riemannroch - theorem) on open subsets but the charts are thought of as open subsets of rather than of R, and the maps that glue them together C are required to be holomorphic. An equivalent notionis that of a conformal structure on X, which is the structure needed to make it possible to define angles between curves in X. Yet another important equivalent notion is that ofinto a complex-algebraic curve algebraic structure(leading to the persis - on X , making X tent confusion in terminology:
a Riemann surface is two dimensional, and therefore a surface, from the point of view of topology or the real numbers, but one dimen - sional, and therefore a curve, from the point of view of 411 complex analysis and algebra). An algebraic structure iswhat allows us to speak of polynomial, rational, or algebraic functions on$X$, and is usually specified by realizingin complex X as the set of solutions to polynomial equations[III.72](/part-03/projective-space) CP2 (or CPn).
a moduli space, for Riemann surfaces we must next specify when we regard two Riemann surfaces as equiv-In order to speak of a classification problem, let alone projective space alent. (We postpone the discussion of the final ingre-dient, the notion of families of Riemann surfaces, to section 2.2.) To do this, we must give a notion ofmorphism between Riemann surfaces: when should twoiso Riemann surfaces X and Ybe “identified,” or thought of as giving two equivalent realizations of the same underlying object of our classification?
This issue was hidden in our toy example of classifying lines in the plane: there we simply identified two lines if and only if they were equal as lines in the plane. This naive option is not available to us with the more abstractly defined Riemann surfaces. If we considered Riemann surfaces realized concretely as subsets of some larger space—for example, as solution sets to algebraic equations in complex projective space—we could similarly choose to identify surfaces only if they were equal as subsets. However, this is too fine a classification for most applications:
what we care about is the geometry of Riemann surfaces, and not incidental fea-intrinsic tures that result from the particular way we choose to realize them. At the other extreme, we might choose to ignore the extra geometric structure that makes a surface into a Riemann surface. That is, we could identify two Riemann surfaces X and Y if they are topologically equiva- lent, or homeomorphic (the “coffee mug is a doughnut”perspective).
The classification of compact Riemann surfaces up to topological equivalence is captured by a single positive integer, the genus$g$(“number of holes”) of the surface. Any surface of genus zero is homeomor-phic to the Riemann sphere CP1$≃ S^{2}$, any surface of genus 1 is homeomorphic to a torus$S1 \times S1$, and so on. Thus, in this case there is no issue of “modulation”—the classification is solved by giving a list of possible values of a single discrete invariant. as Riemann surfaces manifolds, then this classification is too crude:
it com-However, if we are interested in Riemann surfaces rather than simply as topological pletely ignores the complex structure. We would now like to refine our classification to remedy this defect. To this end, we say that two Riemann surfaces(conformally, or holomorphically) equivalent X andif there is Y are

412

a topological equivalence between them that preserves the geometry, i.e., a homeomorphism that preserves the angles between curves, or takes holomorphic functionsto holomorphic functions, or takes rational functions to rational functions. (These conditions are all equiv-alent.) Note that we still have at our disposal our discrete invariant—the genus of a surface. However, as we shall see, this invariant is not fine enough to distinguish between all in equivalent Riemann surfaces.
In fact, it ispossible to have families of in equivalent Riemann surfaces that are parametrized by(but we cannot make proper sense of this idea until we continuous parameters have said precisely what is meant by a family of Rie-mann surfaces). Thus, the next step is to fix our discrete invariant and to try to classify all the different isomor-phism classes of Riemann surfaces with the same genus by assembling them in a natural geometric fashion.
uniformization theorem simply connected Riemann surface is holomorphically An important step toward this classification is the[V.34](/part-05/the-uniformization-theorem). This states that any isomorphic to one of the following three: the Rie-mann sphere CP1, the complex plane C, or the upper half-plane H (equivalently, the unit disk D). Since the universal covering space surface is a simply connected Riemann surface, the[III.93](/part-03/universal-covers) of any Riemann uniformization theorem provides an approach to clas-sify ing arbitrary Riemann surfaces.
For instance, any compact ply connected, and in fact homeomorphic to the Rie-[III.9](/part-03/compactness-and-compactication) Riemann surface of genus zero is sim mann sphere, so the uniformization theorem already solves our classification problem in genus zero: up to equivalence, CP1 is the only Riemann surface of genus zero, and so in this case the topological and conformal classifications agree.

2.1 Moduli of Elliptic Curves

Next, we consider Riemann surfaces whose universal cover is C, which is the same as saying that they are quotients ofof C by Z, which means that we regard two complex C. For example, we can look at a quotient numbers This has the effect of “wrap pi ngz and w as equivalent if Ca round” into a cylin-z - w is an integer. der. Cylinders are not compact, but to get a compact surface we could take a quotient by Z2 instead: that is, we could regard ference is of the formz anda +wbi, where as equivalent if their dif-a and b are both integers.
Now C is wrapped around in two directions and the result is a torus with a complex (or, equiva-lently, conformal or algebraic) structure. This is a compact Riemann surface of genus 1. More generally, we

IV. Branches of Mathematics

can replace Z2 by any lattice L, regarding z and w as equivalent ifadditive subgroup ofz - w belongs to C with two properties. First, it is L. (A lattice L in C is an not contained in any line. Second, it is means that there is a constantd > 0 such that the dis-discrete, which tance between any two points inare also discussed in the general goals of mathe-L is at least d. Lattices mat ical research [I.4 §4](/part-01/general-goals). A basis for a lattice L is a pair of complex numbers that everyz in L can be written in the formu and v belonging toau L+suchbv with for example, ifa and bintegers.
Such a basis will not be unique: L = Z⊕Z, then the obvious basis is u = 1 and well.) If we take a quotient ofv = i, but u = 1 and v = C1 by a lattice, then we+ i would do just as again obtain a torus with complex structure. It turns out that any compact Riemann surface of genus 1 can be produced in this way. From a topological point of view, any two tori are the same, but once we consider the complex structure we start to find that different choices of lattice may leadto different Riemann surfaces. Certain changes to L do not tice have an effect:
for example, if we multiply a lat - L by some nonzero complex number λ, then the quotient surface is naturally isomorphic to C/Lwill not be affected. That is, C/. ambda L. Therefore, we need C/L only worry about the difference between lattices when one is not a multiple of the other. Geometrically, this says that one cannot be obtained from the other by a combination of rotation and dilation. Notice that by taking the quotient C/L we obtain not just a “naked” Riemann surface, but one equipped withan “origin,” that is, a distinguished point e \in E, which is the image of the origin 0\in  C.
In other words, we obtain an elliptic curve: Definition.face E of genus 1, equipped with a marked point An elliptic curve (over C) is a Riemann sur-e \in  E. Elliptic curves, up to isomorphism, are in bijection with lattices L ⊂ C up to rotation. Remark.lian group In fact, since C, the elliptic curve L ⊂ C is a E subgroup= C/L is naturally anof the Abe- Abelian group, withan important motivation for keepinge as its identity element. This ise as part of the data that defines an elliptic curve.
A more subtle rea-son for remembering the location ofe when we speak ofis useful, because any surface Eis that it helps us to define EE of genus 1 has lots more uniquely. This of symmetries, or automorphisms [I.3 §4.1](/part-01/fundamental-definitions): there is always a holomorphic automorphism ofpointx to any other given point y . (If we think of E taking any E

IV.8. Moduli Spaces

as a group, these are achieved by translations.) Thus, if some one hands us another genus-1 surface E^ , there may be no way to identify E with E^ , or there may be infinitely many ways: we can always compose a given isomorphism between them with a self-symmetry of E. As we will discuss later, automorphisms haunt almost every moduli problem, and are crucial when we consider the behavior of families. It is usually convenient to “rigidify” the situation some what, so that the pos-sible isomorphisms between different objects are less “floppy” and more uniquely determined.
In the case of elliptic curves, distinguishing the point by reducing the symmetry of E. Once we do that, theree achieves this is usually at most one way to identify two elliptic curves (one way, that is, that takes origin to origin). choice of a marked point) can be described by concrete“linear algebra data”: a lattice We see that Riemann surfaces of genus 1 (with the L ⊂ C, or rather the equiv- alence class consisting of all nonzero scalar multiples. ambda L of L. This is the ideal setting to study a classification, or moduli, problem.
The next step is to find an explicit parametrization of the collection of all lattices, up to multiplication, and to decide in what sense we have obtained a geometric solution to the classification problem. follow a procedure used for all moduli problems: first parametrize lattices together with the choice of some In order to parametrize the collection of lattices, we additional structure, and then see what happens when we forget this choice. For every lattice basisω, ω \in L: that is, we represent L we choose a L as the set of all integer combinations1 2 aω1 + bω2.
We do this in an parallelogram oriented fashion: we require that the spanned byω and ω is positively ori-fundamental ented. (That is, the numbers 0,1ω1, ω1 2+ω2, and ω2 list the vertices of the parallelogram in a counterclockwis eorder. From the geometric point of view of the elliptic curve E, L is the fundamental group[IV.6 §2](/part - 04/algebraic - topology) of E, and the orientation condition says that we generateby two loops, or “meridians,”$A = ω$, B = ω , which L are oriented, in that their oriented intersection num - ber A ∩ B is equal to + 1 rather than1 - 1.) Since we are2
interested in lattices only up to multiplication, we can multiply L by a complex number so as to turn ω into 1 and hence dition now says thatω2 intoωωis in the upper half - plane= ω2/ω1. The orientation con - H1: i.e., its imaginary part is positive, Im complex numberω \in H in the upper half-plane deter-ω > 0. Conversely, any mines a unique oriented lattice$L = Z1 ⊕ Zω (\text{that is}$,

413

the set of all integer combinations a + bω of 1 and ω) and no two of these lattices are related by a rotation. What does this tell us about elliptic curves? We saw earlier that an elliptic curve is defined by a lattice an identitye. Now we have seen that if we give L Lso me and extra structure, namely an oriented basis, then we can parametrize it by a complex numberω \in H. This makes precise for us the “additional structure” that we wantto place on elliptic curves.
We say that a marked elliptic curve is an elliptic curve of an oriented basisω1, ωE, e2 for the associated lattice together with the choice (fundamental group)L of E. The point is that any lattice has infinitely many different bases, which lead to many automorphisms of E. By “marking” one of these bases, we stop them being automorphisms. 2.2 Families and Teichmüller Spaces With our new definition, we can summarize the earlier discussion by saying that marked elliptic curves are inbijection with pointsω \in H of the upper half - plane.
The upper half-plane is, however, much more than justa set of points: it carries a host of geometric structures, in particular a topology and a complex structure. Inwhat sense do these structures reflect geometric properties of marked elliptic curves? In other words, in what sense is the complex manifold H, known in this context as the faces with one marked point, a geometric solution to Teichmüller space T1\\\{,\\\}1 of genus - 1 Riemann sur- the problem of classifying marked elliptic curves? of a continuous family of Riemann surfaces, and also the notion of a complex-analytic family.
AIn order to answer this question, we need the notion continuous family of Riemann surface sical space S, such as the circle parametrized by a topolog - S1, for example, is a “continuously varying” assignment of a Riemann surface uli of lines in the plane, a continuous family of lines was Xs to every point s of S. In our example of the mod- characterized by the property that the angles between the lines and the functions of the parameters.
Geometrically defined col - x-axis or y-axis defined continuous lections of lines, such as those produced by a curve CMore abstractly, a continuous family of lines defined ain the plane, then gave rise to continuous families. line bundle over the parameter space. A good criterion for a family of Riemann surfaces is likewise that any“reasonably defined” geometric quantity that we can calculate for every Riemann surface should vary continuously in the family.
For example, a classical con-struc tion of Riemann surfaces of genusg comes from 414 taking 4 resulting Riemann surface is fully determined by theg-gons and gluing opposite sides together. The edge-lengths and angles of the polygon. Therefore, acontinuous family of Riemann surfaces described in this fashion should be precisely a family such that the edge-lengths and angles give continuous functions of the parameter set. lection In more abstract topological terms, if we have a col-\.
\1 , s \in S\. of Riemann surfaces dependings on points in a spacea continuous family, then we should give the union S and we wish to make it into" which should simultaneously extend the topology ons\in S Xs itself the structure of a topological space X, each individual surface bundle. Associated with Xs. The result is called a X is the map that Riemann takes each pointx to the particular s for which x belongs to continuous, and perhaps more (it could be a fibration, Xs. We should demand that this map is or fiber bundle). This definition has the advantage of great flexibility.
For example, if S is a complex man- ifold, then in just the same way we can speak of a complex-analytic family of Riemann surfaces$\\{X}$, s . ns S\\\\\\\\\\\\\\\\\\\\\} parametrized by S: now we ask for the union of the X to carry not just a topology but a complex struc-s

ture (i.e., it should form a complex manifold), extend-ing the complex structure on the fibers and mapping holomorphically to the parameter set. The same holds with “complex-analytic” replaced by “algebraic.” These abstract definitions have the property that if our Rie-mann surfaces are described in a concrete way—cut out by equations, glued from coordinate patches, etc.—then the coefficients of our equations or gluing data will vary as complex-analytic functions in our family pre-cisely when the family is complex analytic (and likewise for continuous or algebraic families).
As a reality check, note that a (continuous, analytic, or other) family of Riemann surfaces parametrized bya single points = S is indeed just a single Riemann surfaces i der Riemann surfaces only up to equivalence, so there Xs. Just as in this simple case we wish to con- is a notion of equivalence or isomorphism of two ana-lytic families{X } and {X^ } parametrized by the same space the surfaces S. We simply regard the families as equivalent if X ands X^ are isomorphic for everys s, and if the isomorphism depends analytically onss s.
Armed with the notion of family, we can now formulate the characteristic property that the upper half-plane possesses when we think of it as the moduli space of marked elliptic curves. We define a continuous or IV. Branches of Mathematics analytic family of marked elliptic curves to be a fam-ily where the underlying genus - 1 surfaces vary continuously or analytically, while the choice of basepointe \in E and the basis of the lattice L vary continuously.s The upper half - planes H plays a role for marked ellip - s tic curves that is similar to the role played by RP1 for lines in the plane.
The following theorem makes this statement precise. Theorem.to - one correspondence between continuous maps from For any topological space S, there is a one - S to H and isomorphism classes of continuous families of marked elliptic curves parametrized by there is a one - to - one correspondence between analytic S. Similarly, maps from any complex manifold S to H and isomor- phism classes of analytic families of marked elliptic curves parametrized by S.
point, it simply tells us that the points oftion with the isomorphism classes of marked elliptic If we apply the theorem in the case where HSare in bijec-is a single curves, as we already knew. However, it contains more information: it says that H, with its topology and complex structure, tic curves and the ways in which they can modulate. Atembodies the structure of marked el lip the other extreme, we could take S to H by the identity map.
This expresses the fact that S = H itself, mapping Hthe collection of Riemann surfaces defined by itself carries a family of marked elliptic curves, i.e.,ω \in Hfit together into a complex manifold fibering over H with elliptic curve fibers. This family is called the family, since by the theorem any family is “deduced”universal (or pulled back) from this one universal example.
2.3 From Teichmüller Spaces to Moduli Spaces We have arrived at a complete and satisfying picture for the classification of elliptic curves when we choose in addition a marking (that is, an oriented basis of the associated lattice$L = π (E))$. What can we say about elliptic curves themselves, with out the choice of mark - ing? We some how need to “forget” the marking, by1 regarding two points of H as equivalent if they correspond to two different markings of the same elliptic curve.
Z⊕Now, given any two bases of the group (or lattice)Z, there is an invertible 2 . imes 2 matrix with integer entries that takes one basis to the other. If the two bases are oriented, then this matrix will have determinant 1, which means that it is an element A = ac bd \in SL2(Z) IV.8. Moduli Spaces of the group of invertible unimodular matrices over Z. Similarly, given any two oriented bases(ω , ω ) andas oriented identifications of(ω1, ω2) of a lattice L, which can be thought of L with Z ⊕ Z, there is (a1)2 matrix$ω = Acω\in + SLdω2(Z)$.
If we now consider the normal-such that ω1 = aω1 + bω2 and ized basesω2^ = ω^ /ω1(1^ , then we obtain a transformation of the$, ω) and2 (1, ω)$, where ω = ω1/ω2 and upper half-plane. It is given by the formula1 2ω^ = aωcω ++ db.

That is, the group Sl plane by linear fractional (or Möbius) transformations2(Z) is acting on the upper half- with integer coefficients, and two points in the upper half-plane correspond to the same elliptic curve if one can be turned into the other by means of such a transformation. If this is the case, then we should regard the two points as equivalent: that is how we formalize the idea of “for getting” the marking.
Note also that the scalar matrix-Id in SL (Z), which negates both ω andωfact get an action of PSL2, acts trivially on the upper half-plane, so that we in2 (Z) = SL (Z)/{± Id} on H1.
to isomorphism) are in bijection with orbits ofon the upper half-plane, or equivalently with points of So we come to the conclusion that2 2 elliptic curves (up PSL2(Z) the quotient spacea natural quotient topology, and in fact can be given a H$/ PSL^{2}(Z)$. This quotient space has complex-analytic structure, which, it turns out, identi-fies it with the complex plane C itself.
To see this one uses the classicala complex-analytic function on modular function H which is invariant[IV.1 §8](/part-04/number-theory)j(z), under the modular group Psl defines a natural coordinate H2/(ZPSL) and which therefore(Z) \to  C. lem for elliptic curves: we have a topological, and even complex-analytic, space It appears that we have solved the moduli prob-M=2 H/ PSL (Z) whose points are in one-to-one correspondence with isomor-phism classes of elliptic curves.
This already qualifies1,1 2 M1,1 as the coarse moduli space for elliptic curves, which means it is as good a moduli space as we can hope for. However, M fails an important test for a moduli space thatit is not true, even for the circle(T1()\\\{}},\\){1}passed (as we saw in section 2.2):1$,1 S = S1$, that every con- tinuous family of elliptic curves overa map from S to M . S corresponds to phisms. These are equivalences from The reason for this failure is the problem of automor - 1,1 Eto itself: that is, complex-analytic maps from basepointe.
Equivalently, they are given by complex - E to E that preserve the analytic self-maps of C that preserve 0 and the lattice 415 Lby some complex number. Such a map must be a rotation: that is, multiplication. ambda of modulus 1. It is easy to check that for most lattices tion that sends L to itself is multiplication by L in the plane, the only rota-λ = −1. Note that this is the same - 1 that we quotiented out by to pass from SLtwo special lattices that have greater symmetry. These2(Z) to PSL2(Z).
However, there are are the square lattice$L = Z · 1 ⊕ Z · i$, corresponding to the fourth root of unity i, and the L = Z · 1 ⊕ Z · (e2()π){i}/ 6, corresponding to a sixth root ofhexagonal lattice unity. (Note that the hexagonal lattice is also repre-sented by the pointω = (e2()π){i}/ 3.) The square lattice, which corresponds to the elliptic curve formed by gluing the opposite sides of a square, has as its symmetries the group Z/4 Z of rotational symmetries of the square.
The hexagonal lattice, which corresponds to the ellip-tic curve formed by gluing the opposite sides of a regular hexagon, has as its symmetries the group Z$/6Z of$ rotational symmetries of a hexagon. We see that the number of automorphisms of an elliptic curve jumps discontinuously at the special pointsω = i and ω = (e2()π){i}/ 6. This already suggests that some- thing might be wrong with M1,1 as a moduli space. Note that we avoided this problem with the moduli T of marked elliptic curves, since there are no auto- morphisms of an elliptic curve that also preserve the marking.
Another place we might have observed this1$, {}^{1}$ problem with H$/ PSL (Z)$. We avoided the automorphism M1^,1 is when we passed to the quotientλ = −1 by quotienting by PSLthe two special points i and e2 2(Z) rather than SL2^πi^/6 are preserved by2(Z). However, integer Möbius transformations of H other than the identity, and they are the only points with that prop-erty. This means that the quotient H$/ PSL (Z) naturally$ comes with conical singularities at the points corre-sponding to these two orbits:
one looks like a cone with2 angle see why this is plausible, imagine the following simplerπ, and the other like a cone with angl(e2)3π. (To instance of the same phenomenon. If for every complex num berz you identify z with -z, then the result is to wrap the complex plane around into a cone with a sin-gularity at 0. The reason 0 is singled out is that it is preserved by the transform at io nz → −z.
Here the angle would beto-one away from the singularity andπbecause the identification of points is two-π is half of 2π.) It is possible to massage these singularities away using the$j$-function, but they are indicating a basic difficulty. So why do automorphisms form an obstacle to the existence of “good” moduli spaces? We can demon-strate the difficulty by considering an interesting con-

416

tinuous family of marked elliptic curves parametrized by the circle S = S1. Let E(i)be the “square” elliptic curve that we considered earlier, based on the lattice of integer combinations of 1 and i. Next, for every between 0 and 1, let Et be a copy of E(i). Thus, we havet taken the constant, or “trivial,” family of elliptic curves over the closed unit interval[0, 1], where every curve in the family is E(i). Now we identify the elliptic curves at the two ends of this family, not in the obvious way, butby using the automorphism given by a 90◦ rotation, or multiplication by i.
This means that we are looking atthe family of elliptic curves over the circle where each member of the family is a copy of the elliptic curve but these copies twist by 90◦ as we go around the circle. E(i), family of elliptic curves by means of a map from the space It is easy to see that there is no way to capture this M . Since all of the members of the family$S^{1} to$ are isomorphic, each point of the circle should map tothe same point in1,1 M (the equivalence class of i in Hthe).
But the constant map trivial family S1 . imes 1(E,)1 of elliptic curves over S1 → {i} \in (M1(),){1}classifies S1, thati

is, the family where every curve is equal tothe curves do not twist as we go around! Thus, there E(i) but are more families of elliptic curves than there are mapsto M ; the quotient space H/ PSL (Z) cannot handle the complications caused by automorphisms. A variant of this construction applies to complex-analytic fami-1,1 2 lies with S1 replaced by C. imes . This is a very general phe- nomenon in moduli problems: whenever objects have nontrivial automorphisms, we can imitate the construction above to get nontrivial families over an interesting parameter set, all of whose members are the same.
As a result, they cannot be classified by a map to the set of all isomorphism classes. What do we do about this problem? One approach is to resign ourselves to having coarse moduli spaces, which have the right points and right geometry but do not quite classify arbitrary families. Another approachis the one that leads to$T$: we can fix markings of one kind or another, which “kill” all automorphisms. In other words, we choose enough extra structure on1,1 our objects so that there do not remain any (nontriv-ial) automorphisms that preserve all this decoration.
In fact, one can be far more economical than picking a basis of the lattice$L$and obtaining the infinite coveringto some congruence (for example, of T1\\\{}},\\\\\\\\\\\\\\\\\\\}1 of M1\\\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\\}1: one can fix a basis of$L/2L)$. Finally, we L only up can simply learn to come to terms with the automorphisms, keeping them as part of the data, resulting in“spaces” where points have internal symmetries. This is

IV. Branches of Mathematics

the notion of an which is flexible enough to deal with essentially all orbifold [IV.4 §7](/part-04/algebra), or stack [IV.4 §7](/part-04/algebra), moduli problems. 3 Higher-Genus Moduli Spaces and Teichmüller Spaces We would now like to generalize as much as possi-ble of the picture of elliptic curves and their moduli to higher-genus Riemann surfaces. For each would like to define a space M , called the mod ulig we space of curves of genus mann surfaces of genus gg, that classifies compact Rie-and tells us how they modu-$g$ late.
Thus, the points of Mg should correspond to our objects, compact Riemann surfaces of genus be more accurate, equivalence classes of such surfaces, g, or, to where two surfaces are considered to be equivalent if there is a complex-analytic isomorphism between them. In addition, we would likeit can to embody the structure of continuous fami-Mg to do the best lies of genus-M parametrizing “g surfaces. Likewise, there are spac esn-punctured” Riemann surfaces of genus surfaces, but Riemann surfaces together with a “deco-g, n g.
This means we consider not “bare” Riemann ration” or “marking” byn distinct labeled points (punc- tures). Two of these are considered to be equivalent if there is a complex-analytic isomorphism between them that takes punctures to punctures and preserves labels. Since there are Riemann surfaces with automorphisms, we do not expect M to be able to classify all families of Riemann surfaces: that is, we will expect examples similar to the twisted square-lattice construction dis-$g$ cussed earlier.
However, if we consider Riemann sur-faces with enough extra markings, then we will be able to obtain a moduli space in the strongest sense. Oneway to choose such markings is to consider M with nto mark generators of the fundamental group, leading large enough (for fixedg). Another approach will beg, n to the Teichmüller spaces Tg and Tg, n. We now out line this process. To construct the space M , we return to the uniformization theorem.
Any compact surfac eg > 1 has as its universal cover the upper half-planeg X of genus H, so it is represented as a quotient X = H/Γ, where Γ is a representation of the fundamental group ofsubgroup of conformal self-maps of H. The group of all X as a conformal automorphisms of linear fractional transformations with real coefficients. H is PSL2(R), the group of The fundamental groups of all compact genus-mann surfaces are isomorphic to a fixed abstract groupg Rie- IV.8. Moduli Spaces Γtion: that the product of all commutators$g$, with 2 g generators Ai$, Bi (i = 1$, . . .
, g) and one rela-A B (A-1 B)-1 is the identity. A subgroup such a way that the quotientΓ ⊂HPSL/Γ is a Riemann surface2(R) that acts o(ni()i)i Hiin (technically, the action should have no fixed points and should be properly discontinuous) is known as a fuchsian grouptation of elliptic curves by lattices[III.28](/part-03/fuchsian-groups). Thus, the analogue of the re pre sen-L ≃ Z⊕Z in the plane is the representation of higher-genus Riemann surfacesas H/Γ , where Γ is a Fuchsian group.
faces is the space that solves the moduli problem for genus-The Teichmüller spaceg surfaces when they come with a mark-Tg of genus-g Riemann sur- ing of their fundamental group. This means that our objects are genus-g surfaces X plus a set of generators Aπi,(X)Bi ofandπ1Γ(X), up to conjugation., which give an isomorphism between1 Our equivalences are complex-analytic maps that preserve the markings.1$g$ Finally, our continuous (respectively, complex-analytic)families are continuous (complex-analytic) families of Riemann surfaces with continuously varying markingsof the fundamental group.
In other words, we are asserting the existence of a topological space/complex manifold T , with a complex-analytic family of marked Riemann surfaces over it, and the following strong property.$g$ The characteristic property ofcal space (respectively, complex manifold)$T^{g}$. For any topologi-S, there is a bijection between continuous maps (respectively, holo-morphic maps)S → T and isomorphism classes of continuous (respectively, complex-analytic) families of marked genus-$g \text{surfaces parametrized by}^{g} S$.

3.1 Digression: “Abstract Nonsense”

It is interesting to note that, while we have yet tosee why such a space exists, it follows from general, nongeometric principles—“abstract nonsense”—that it is completely and uniquely category theory [III.8](/part-03/categories) or determined, both as a topological space and as a com-plex manifold, by this characteristic property. In a very abstract way, every topological space M can be uniquely reconstructed from its set of points, the set of paths between these points, the set of surfaces spanning these paths, and so on.
To put it differently, we can choice of a basepoint, choosing a path from1. Note that while the fundamental group of$xπto^{1}(X$, x)y, and the different choices are related byandπ1(X, y)may be identified by X depends on the conjugation by a loop. Thus, if we are willing to identify sets of gener-ators$A^{i}$, Biwhen they differ only by a conjugation, then we can ignore the choice of a basepoint.

417

think ofical space MSas a “machine” that assigns to any topolog-the set of continuous maps from S to M. This machine is known as the “functor of points of Similarly, a complex manifold M provides a machine M.” that assigns to any other complex manifold S the set of complex-analytic maps from ery of category theory (the Yoneda lemma S to M. A curious discov-) is that for very general reasons (having nothing to do with geometry), these machines (or functors) uniquely determine M as a space, or a complex manifold.
(giving objects, equivalences, and families) also gives Any moduli problem in the sense we have described such a machine, where toilies over S, up to isomorphism. So S we assign the set of all fam-just by setting up the moduli problem we have already uniquely determined the topology and complex structure on Teichmüllerspace. The interesting part then is to know whether or not there actually exists a space giving rise to the same machine we have constructed, whether we can con-struct it explicitly, and whether we can use its geometry to learn interesting facts about Riemann surfaces.

3.2 Moduli Spaces and Representations

Coming back to earth, we discover that we have a fairly concrete model of Teichmüller space at our disposal. Once we have fixed the markingπ (X) ≃ Γ , we are simply looking at all ways to represents ian subgroup of PSL(R). Ignoring the Fuchsian condi-1 Γg as a Fuch-g tion for a moment, this means finding 2(up to± Id) A , B \in 2 PSL (R) satisfying the commuta-g real matrices tor relation of i Γg i. This gives an explicit set of (alge-2 braic!) equations for the entries of the 2 which determine the space of all represent at i onsg matrices,Γ \to PSLPSL2((RR)).
We must now quotient out by the action ofthat simultaneously conjugates all 2 g matri cesg to obtain the This is analogous to considering lattices in2 representation variety Rep(ΓCg, up to rota - PSL2(R)). tion, and is motivated by the fact that the quotientsof H by two conjugate subgroups of PSL(R) will be isomorphic. tions ofmüller space as the subset of the representation vari-Once we have described the space of all representa-$Γ^{g} \text{into PSL}^{2}(R)$, we can then single out Teich- ety that consists of Fuchsian representations of PSL(R).
Luckily this subset is open in the re pre sen-Γg into tation variety, which gives a nice realization ofa topological space—in fact,2 T is homeomorphic to Tg as R6 g - 6. (This can be seen very explicitly in terms ofg the Fenchel–Nielsen coordinates, which parametrize a 418 surface in3 g - 3 lengths and 3 Tg via a cut - and-paste procedure involvingg - 3 angles.) We may now try to “forget” the marking uli space M of unmarked Riemann surfaces.
In otherπ1(X) Γg, to obtain the mod- words, we would like to takeg Tg and identify any two points that represent the same underlying riemann surface with different markings. This identification is achieved by the action of a group, the genus-g mapping class group T , which generalizes the modular group PSLMCGg or Teichmüller modular group(Z) that, on acts on g H = (T1()\\\{}}$,\\){1}$.
(The mapping class group is defined2 as the group of all self-diffeomorphisms of a genus-surface—remember that all such surfaces are topolog-$g$ ically the same—modulo those diffeomorphisms that act trivially on the fundamental group.) As in the case ofelliptic curves, Riemann surfaces with automorphisms correspond to points in Tgfixed by some subgroup of MCGM= Tg, and give rise to singular points in the quotient/ MCG .
sentations, are an important and concrete class of mod-Representation varieties, or moduli spaces of repre-(gg)g uli spaces that arise through out geometry, topology, and number theory. Given any (discrete) groupΓ , we ask (for example) for a space that parametrizes homo-morphisms ofΓ into the group of n . imes  n matrices. The notion of equivalence is given by conjugation by GLand that of families by continuous (or analytic, or alge-n, braic, etc.) families of matrices. This problem is inter-esting even when the groupΓ is Z.
Then we are sim-ply considering invertibleof 1\in  Z) up to conjugacy. It turns out that there isn . imes  n matrices (the image no moduli space for this problem, even in the coarse sense, unless we consider only “nice enough” matrices: for example, matrices that consist of only a single Jordan block. This is a good example of a ubiquitous phenomenon in moduli problems: one is often forced to throw out some “bad” (unstable) objects in order tohave any chance of obtaining a moduli space. (See the paper by Mumford and Suominen (1972) for a detailed discussion.)

3.3 Moduli Spaces and Jacobians

The upper half-plane of PSL(Z), gives an appealingly complete picture of the H = (T1(),){1}, together with the action moduli problem for elliptic curves and its geometry. The same cannot be said, unfortunately, for the pic-2 ture of Tg as an open subset of the representation vari- ety. In particular, the representation variety does not even carry a natural complex structure, so we cannot

IV. Branches of Mathematics

see from this description the geometry ofplex manifold. This failure reflects some of the ways Tg as a com- in which the study of moduli spaces is more compli-cated for genus greater than 1. In particular, the moduli spaces of higher-genus surfaces are not described purely by linear algebra plus data about orientation, as is the case in genus 1. that the fundamental group Part of the blame for this complexity lies with the factΓg ≃ π1(X) (g > 1) is no longer Abelian, and in particular it is no longer equal tothe first homology group H(X, Z). A related problem is that X is no longer a group.
A beautiful solution to this1 problem is given by the construction of the Jacobi an Jac(X), which shares with elliptic curves the properties of being a torus (homeomorphic to(S1()2)g), an Abelian group, and a complex (in fact complex-algebraic) man-ifold. (The Jacobi an of an elliptic curve is the elliptic curve itself.) The Jacobi an captures the “Abelian” or“linear” aspects of the geometry of X.
There is a mod- uli space Ag for such complex-algebraic tori (known as Abelian varieties er ties and linear algebraic description of the moduli of), which does share all of the nice pr op elliptic curves theorem—is that by assigning to each Riemann surface M1,1 = A1. The good news—the Torelli Xanalytic subset ofits Jacobi an we embed A . The interesting Mg as a closed, complex-news—the Schottky problem—is that the image is quite complicated$g$ to characterize intrinsically. In fact, solutions to this problem have come from as far afield as the study of nonlinear partial differential equations!

3.4 Further Directions

In this section we give hints at some interesting questions about, and applications of, moduli spaces. Deformations and degenerations.topics in moduli spaces ask which objects are very near Two of the main to a given one, and what lies very far away. Deforma-tion theory is the calculus of moduli spaces: it describes their infinitesimal structure. In other words, given an object, deformation theory is concerned with describ-ing all its small perturbations (see Mazur (2004) for a beautiful discussion of this). At the other extreme, wecan ask what happens when our objects degenerate?
Most moduli spaces, for example the moduli of curves, are not compact, so there are families “going off toinfinity.” It is important to find “meaningful” compactificatio ns of moduli spaces, which classify the possi-ble degenerations of our objects. Another advantage of

IV.9. Representation Theory

compactifying moduli spaces is that we can then calcu-late integrals over the completed space. This is crucial for the next item. Invariants from moduli spaces.cation of moduli spaces in geometry and topology is An important a pp li inspired by quantum field theory, where a particle, rather than following the “best” classical path between two points, follows all paths with varying probabilities(see mirror symmetry [IV.16 §2.2.4](/part-04/mirror-symmetry)).
Classically, one calculates many topological invariants by picking a geo-metric structure (such as a metric) on a space, calculating some quantity using this structure, and finally prov-ing that the result of the calculation did not depend on the structure we chose. The new alternative is to lookat all such geometric structures, and integrate some quantity over the space of all choices. The result, ifwe can show convergence, will manifestly not depend on any choices.
String theory has given rise to many important applications of this idea, in particular by giving a rich structure to the collection of integrals obtained in this way. Donaldson and Seiberg–witten theories use this philosophy to give topological invariants of four-manifolds. Gromov–Witten theory applies it to the topology of symplectic manifolds [III.88](/part-03/symplectic-manifolds), and to counting problems in algebraic geometry, suchas, How many rational plane curves of degree 5 pass through fourteen points in general position?
(Answer:87 304.) Modular forms.mathematics, the Langlands program, relates number One of the most profound ideas in theory to function theory (harmonic analysis) on very special moduli spaces, generalizing the moduli space of elliptic curves. These moduli spaces (Shimura vari-eties) are expressible as quotients of symmetric spaces (such as modular forms H) by arithmetic groups (such as PSL[III.59](/part-03/modular-forms) and automorphic forms are2(Z)). special functions on these moduli spaces, describedby their interaction with the large symmetry groups of the spaces.
This is an extremely exciting and activearea of mathematics, which counts among its recent triumphs the proof ofthe Shimura–Taniyama–Weil conjecture (Wiles, Taylor–fermat’s last theorem [V.10](/part-05/fermats-last-theorem) and Wiles, Breuil–Conrad–Diamond–Taylor).

Further Reading

For historical accounts and bibliographies on moduli spaces, the following articles are highly recommended. with an emphasis on the notion of deformations, is A beautiful and accessible over view of moduli spaces,

419

given by Mazur (2004). The articles by Hain (2000) and Looijenga (2000) give excellent introductions to the study of the moduli spaces of curves, perhaps the old-est and most important of all moduli problems. The article by Mumford and Suominen (1972) introduces the key ideas underlying the study of moduli spaces in algebraic geometry. Hain, R. 2000. Moduli of Riemann surfaces, transcendental aspects. In School on Algebraic Geometry, Trieste, 1999, pp. 293–353. ICTP Lecture Notes Series, no. 1. Trieste: The Abdus Salam International Centre for Theoretical Physics. Looijenga, E. 2000.
A minicourse on moduli of curves. In School on Algebraic Geometry, Trieste, 1999, pp. 267–91. ICTP Lecture Notes Series, no. 1. Trieste: The Abdus Salam International Centre for Theoretical Physics. Mazur, B. 2004. Perturbations, deformations and variations(and “near-misses”) in geometry. Physics and number theory.41(3):307–36.Bulletin of the American Mathematical Society Mumford, D., and K. Suominen. 1972. Introduction to the theory of moduli. In Algebraic Geometry, Oslo, 1970: Proceedings of the Fifth Nordic Summer School in Mathemat-ics, edited by F. Oort, pp. 171–222. Groningen:
Wolters Noordhoff. IV.9 Representation Theory

Ian Grojnowski

1 Introduction

It is a fundamental theme in mathematics that many objects, both mathematical and physical, have symmetries. The goal oferal, and representation theory in particular, is to study group [I.3 §2.1](/part-01/fundamental-definitions) theory in gen these symmetries. The difference between representa-tion theory and general group theory is that in representation theory one restricts one’s attention to symmetries ofto explain why this is sensible and how it influences our vector spaces [I.3 §2.3](/part-01/fundamental-definitions).
I will attempt here study of groups, causing us to focus on groups with certain nice structures involving conjugacy classes. 2 Why Vector Spaces? The aim of representation theory is to understand how the externally internal as a collection of symmetries. In the other structure of a group controls the way it acts direction, it also studies what one can learn about a group’s internal structure by regarding it as a group of symmetries.

420

what we mean by “acts as a collection of symmetries.”The idea we are trying to capture is that if we are given We begin our discussion by making more precise a group each element G and an obje ctg of G some symmetry of X, then we can associate with X, which we callφ(g)of symmetries to work properly: that is,. For this to be sensible, we need the compositionφ(g)φ(h) (the result of applyingφ(h) and then φ(g)) should be the same symmetry asof X is a particular kind ofφ(gh). if permutation X is a set, then a symmetry[III.68](/part-03/permutation-groups) of its elements.
Let us denote by Aut mu tat i ons of X. Then an action(X)of Gthe group ofon Xis defined toall perbe a homomorphism from G to Aut(X). If we are given such a homomorphism, then we say that The image to have in mind is that$G$“does things” to G acts on X.Xand vividly by for getting about. This idea can often be expressed more convenientlyφin the notation: thus, instead of writingφ(g)(x)for the effect onx of the symmetry associated withas a permutation and write ggx, we simply think of. However, some times weg itself do need to talk about wish to compare two different actions ofφas well:
for instance, we might G on X. Here is an example. Take as our object X a square in the plane, centered at the origin, and let its vertices be A, B, C, and D (see figure 1). A square has eight symmetries: four rotations by multiples of 90◦and four reflections. Letmetries; this group is often called G be the group consisting of these eight sym-D , or the dihedral group But it also acts on the set ofof order 8. By definition, vertices G acts on the square.8 of the square: for instance, the action of the reflection through they-axis is to switch A with B and C with D.
It might seem as though we have done very little here. After all, we defined much effort to associate a symmetry with each element G as a group of symmetries so it does not take oftations of the set$G$. However, we did not define$\\{A}$, B, C, D\\\\\\\\\\\\\\\\\\\\\}, so we have at least done G as a group of permu- something.
sets on which we can build sufficiently naturally from the square. To make this point clearer, let us look at some other G acts, which will include any set that For instance,$\\{A}$, B, C, D\\\\\\\\\\\\\\\\\\\\\}, but on the set of edges G acts not only on the set of vertices{AB, BC, CD, DA} and on the set of cross-diagonals\\\\\\\\\\\. . \1, BD\\\\\\\\\\\\} as well. Notice in the latter case that some of the elements of Gact in the same way: for example, a clockwise rotation through 90 does a counter clockwise rotation through 90◦ interchanges the two diagonals, as◦.
If all the elements offaithful. Gact differently, then the action is called IV. Branches of Mathematics A B D C Figure 1 A square and its diagonals. through thecan be applied to the whole Cartesian plane Notice that the operations on the square (“reflec ty - axis,” “rotate through 90◦,” and so on)R2. Therefore, acts. To call R2 is another (and much larger) set on which R2 a set, though, is to forget the very$G$interesting fact that the elements in R2 can be added together and multiplied by real numbers: in other words, R2 is a vector space. Further more, the action ofture.
For instance, if G is well-behaved with respect to this extra struc - g is one of our symmetries and v1 andsumvv2 are two elements of + v yields the sum g(v R2, then) + g(vg applied to the). Because of this, we say that When V1 is a vector space, we denote by GL2 G acts linearly on the vector spac(e1)2 (V ) the set R2. of invertible linear maps from tor space Rn, this group is the familiar group GLV to V. If V is the vec-(R) of invertible when V = Cnnit is the group of invertible matrices with. imes  nmatrices with real entries; similarly,$n$ complex entries.
Definition.space V is a homomorphism from A representation of a group G to GLG(V )on a vector. a group as a collection of permutations, while a repre-sentation is the special case where these permutations In other words, a group action is a way of regarding are invertible linear maps. One some times sees repre-sentations referred to, for emphasis, as linear representations.
In the representation ofdescribed above, the homomorphism from D8 on GRto GL2 that we(R) took the symmetry “clockwise rotation through 90 the matrix(0 1 )and the symmetry “reflection through$\circ^{2}$” to the Given one representation of$y$-axis” to the matrix-1 0 (-0 11 0 )G. , we can produce oth- ers using natural constructions from linear algebra.
For example, ifρ is the representation of G on R2 described above, then its morphism from determinant G to R* (the group of nonzero real[III.15](/part-03/determinants) det ρ is a homo- numbers under multiplication), since . et (ρ(gh)) = . et (ρ(g)ρ(h)) = . et (ρ(g)). et (ρ(h)),

IV.9. Representation Theory

by the multiplicative property of determinants. This makes detρ a one-dimensional representation, since each nonzero real number element “multiply byt” of GLt can be thought of as the(R). If ρ is the re pre sen- tation ofthat rotations act as the identity and reflections act as D8 just discussed, then under det1 ρwe find multiplication by-1. The definition of “representation” is formally very similar to the definition of “action,” and indeed, since every linear automorphism of V is a permutation on the set of vectors inform a subset of the actions of V , the representations of G on V .
But the set of G on V representations is in general a much more interesting object. We see here an instance of a general principle: if a set comes equipped with some extra structure (asa vector space comes with the ability to add elements together), then it is a mistake not to make use of that structure; and the more structure the better. In order to emphasize this point, and to place representations in a very favorable light, let us start by considering the general story of actions of groups on sets. Suppose, then, that X.
For each x, the set of all elements of the form G is a group that acts on a setgx, asgto show that the orbits form a partition of ranges over G, is called the orbit of x. It is not hard X. Example.the set X of Let ordered pairs G be the dihedral group of vertices of the square, of D8 acting on which there are sixteen. Then there are three orbits of G on X, namely \. . \1, BB, CC, DD\\}, {AB}, BA, BC, CB, CD, DC, DA, AD, and \. . \1, CA, BD, DB\\. one orbit.
In other words, it is transitive if for everyx An action ofand y in XGyou can find an element on X is called transitive if there is justg such thatgx = y. When an action is not transitive, we can con- sider the action of effectively breaks up the action into a collection of G on each orbit separately, which transitive actions on disjoint sets. So in order to study all actions of Gon sets it suffices to study transitive actions; you can think of actions as “molecules” and transitive actions as the “atoms” into which they can be decomposed.
We shall see that this idea of decomposing into objects that cannot be further decomposed is fundamental to representation theory. source of such actions comes from subgroups Given a subgroup What are the possible transitive actions? A rich H of G, a left coset of H is a set of H of G. the form{gh}: h \in H, which is commonly denoted byg Hleft cosets form a partition of. An elementary result in group theory is that the G (as do the right cosets, 421 if you prefer them). There is an obvious action ofthe set of left cosets of H, which we denote by G/HG: ifon gcoset^  is an element of(g^ g)H.
G, then it sends the coset g H to the Given a transitive action ofx It turns out that every transitive action is of this form!\in  X and let H be the subgroup of G on a set XG, choose some consisting of all elements stabilizer ofxh.) Then one can check that the action ofsuch thatx hx = x. (This set is called the G on For example, the action of X is the same1 as that of D8 Gon the first orbit above ison the left cosets of Hx. isomorphic to the action on the left cosets of the two-element subgroup Hgenerated by a reflection of the square through its diagonal.
If we had made a different choice ofx, for example the point x^  = gx, then the subgroup ofa so-called conjugate subgroup Gfixingx^ would just be, and it gives a differ entg Hxg - 1. This is description of the same orbit, this time as left cosets ofg H g - 1. between transitive actions ofof subgroups (that is, collections of subgroups conju-It follows that there is a one - to-one correspond enc ex G and conjugacy classes gate to some given subgroup).
Ifset X in a nontransitive way, then we can break G acts on our original X up into a union of orbits, each of which, as a result of this correspondence, is associated with a conjugacy class ofsubgroups. This gives us a convenient “bookkeeping” mechanism for describing the action ofkeep track of how many times each conjugacy class of G on X: just subgroups arises. Exercise.orbits correspond (respectively) to a two-element sub-Check that in the example earlier the three group Rgenerated by reflection through a diagonal, the trivial subgroup, and another copy of the group R. act on sets.
The internal structure that controls the action is the This completely solves the problem of how groups subgroup structure of G. to the problem of how groups act on vector spaces. First, let us just stare at sets for a while and see why, In a moment we will see the corresponding solution though we have answered our question, we should not feel too happy about it.2 group is The problem is that the subgroup structure of ajust horrible. casual reader may read this as “the same,” while the more careful reader should stop here and work out, or look up, precisely what is1.
By “the same” we mean “isomorphic as sets with G - action.” The meant.2. Exercise: go back to the example of D8 and list all the possible transitive actions. 422 of the theorem,” which follows by considering the action of For example, any finite group of order symmetric group [III.68](/part - 03/permutation - groups)Sn(this is “Cayley’sn is a subgroup Gsubgroups of the symmetric group on itself), so in order to list the conjugacy classes of Sn one must under- stand all finite groups of size less than$n$.3 Or consider the cyclic group Z/n Z.
The subgroups correspond to the divisors ofthe cyclic groups behave quite differently asn, a subtle property of n that makesn varies. Ififnn is prime, then there are very few subgroups, while is a power of 2 there are quite a few. So number theory is involved even if all we want to do is under-stand the subgroup structure of a group as simple as a cyclic group. With some relief we now turn our attention back to linear representations. We will see that, just as with actions on sets, one can decompose representations into “atomic” ones.
But, by contrast with the case ofsets, these atomic representations (called “irreducible” representations, or some times simply “irreducibles”)turn out to exhibit quite beautiful regularities. The nice properties of representation theory come largely from the following fact. While elements of the symmetric group Sn can be multiplied together, ele- ments of GLas multiplied. (But beware: the sum of two elements of(V ), being matrices, can be added as well$GL$(V ) is not necessarily an element of GL(V ), because it may not be invertible.
It is, however, an element of the endomorphism algebra End(V )$. When V = C^{n}$, End(V ) is just the familiar algebra of all$n \times n \text{matrices with}$ complex entries, both invertible and not.) sider the cyclic groupωTo see the difference it makes to be able to add, con-n = 1, we get a representation G = Z/n Z. For eachχ of G onωC\in by asso-C with ciat ing the element$ω^{r}$, which we think of as a linear map from the one-r \in  Z/n Z with multiplication by^ω dimensional space C to itself.
This gives us$n$different one-dimensional representations, one for each root of unity, and it turns out that there are no others.$nth$ More over, ifρ: G \to  GL(V ) is any representation of$Z$/n Z, then we can write it as a direct sum of these rep- re sent at i ons by imitating the formula for finding the Fourier mode of a function. Using the representation ρNow let us define a linear map, we associate with eachr in Z/np Z a linear map:$V \to V \text{by the}ρ(r )$.ω

allow us to estimate the gacy: it is a result of Pyber that 23. the classification of finite simple groups number((γ1 n^/16 of subgroups of^)+o(1^))n2^⩽ γ [V.7](/part-05/the-classication-of-finite-simple-groups) does at least^⩽S24 n^((up to conju-1^/6^)+o(1^))n2.n

Equality is expected for the lower bound.

IV. Branches of Mathematics

formula

pω = n(10()⩽){r} <n ω-r ρ(r ).

Thenpω is an element of End(V ), and one can check that it is actually aspace Vω of V . In fact, this subspace is an projection[III.50 §3.5](/part-03/linear-operators-and-their-properties) onto a sub-eigenspace [I.3 §4.3](/part-01/fundamental-definitions): it consists of all vector sv such that ρ(1)v =ωvρ(r )v, which implies, since= ωr v. The projectionρ is a representation, thatp should be thought of as the analogue of thea (f ) of a function f (θ)nthon the circle;
note the formal fourier coefficientω [III.27](/part-03/the-fourier-transform) similarity of the above formula to the Fourier expansion formul an a (f ) = e-2^πi nθf (θ) dθ.ff Now the interesting thing about the Fourier series ofis that, under favorable circumstances, it adds up to itself: that is, it decomposesn f into trigonometric functions the subspaces[III.92](/part-03/trigonometric-functions). Similarly, what is interesting about V is that we can use them to decom- pose the representation distinct projectionsω p is 0, from which it can be shownρ. The composition of any two thatωV = - V.ω

We can write each subspace dimensional spaces, which are copies ofω Vω as a sum of one-C, and the restriction ofple representationρ to any one of these is just the sim-χdefined earlier. Thus,ρ has been decomposed as a combination of very simple “atoms”χ $.^{4}^{ω}ω$

quence. Let a finite group space This ability to add matrices has a very useful conse-V . A subspace W of GVact on a complex vector is called G-invariant ifg W = W for every g \in  G. Let W be a G-invariant sub- space, and letone such that every element U be a complementary subspace (that is, v of V can be written in exactly one way as$w + u with w \in W and u \in U )$. Letφexercise to show that the linear map 1 be an arbitrary projection onto U. Then it is a simple/|G| gφ is also a projection onto a complementary subspace, but with the added advantage that it is G - invariant.
This lat-g \in G ter fact follows because applying an ele me ntg to the sum just rearranges its terms. The reason this is so useful is that it allows us to decompose an arbitrary representation into a direct sum of irreducible representations, which are representations with out a G-invariant subspace. Indeed, if ρ is transform is not just analogy—decomposing a representation into its irreducible summands is a notion that includes both this example and4. To summarize the rest of this article: the similarity to the Fourier the Fourier transform.

IV.9. Representation Theory

not By the above remark, we can write irreducible, then there is a G-invariant subspace G = W ⊕ W^  with W.W^  also G-invariant. If either W or W^  has a further Gther, and so on. We have just seen this done for the-invariant subspace, then we can decompose it fur- cyclic group: in that case the irreducible representa-tions were the one-dimensional representationsχ . The irreducible representations are the basic build-ω ing blocks of arbitrary complex representations, justas the basic building blocks for actions on sets are the transitive actions.
It raises the question of what the irre-duc i ble representations are, a question that has been answered for many important examples, but which is not yet solvable by any general procedure. To return to the difference between actions and representations, another important observation is that any action of a group Gon a finite set X can be linearized in the following sense. Iflook at the X [III.37](/part-03/bayesian-analysis)has n elements, then we can L2(X) of all complex- valued functions defined on given by the “delta functions”hilbert space Xδ.
This has a natural basisx, which send x to 1 and all other elements ofof G on X into an action of X to 0. Now we can turn the action G on the basis in an obvious way: we just define definition by linearity, since an arbitrary functiongδx to be δgx. We can extend thisf is a linear combination of the basis functionsus an action of G on L2(X), which can be defined by aδx. This gives simple formula: ifthe function defined byf is a function in(gf )(x) = Lf (g2(X)-1, thenx). Equiva-gf is lently, on sets can be thought of as an assignment of a verygf does to gx what f does to x.
Thus, an action special matrix to every group element, namely a matrix with only 0 s and 1 s and precisely one 1 in each row and each column. (Such matrices are called matrices.) By contrast, a general representation assigns permutation an Now, even when arbitrary invertible matrix. X itself is a single orbit under the action of G, the above representation on L^2(X) can break up into pieces. For an extreme example of this phenomenon, consider the action of Z/n Z on itself by multiplication.
We have just seen that, by means of the“Fourier expansion” above, this breaks up into a sum ofn one-dimensional representations. Gm ult i pl ic at i on. That is, we shall associate with each ele-Let us now consider the action of an arbitrary group on itself by multiplication, or, to be more precise, left mentgh. This action is obviously transitive. As an action ong the permutation of G that takes each h in G to a we set linearize it cannot be decomposed any further. But when this action to a representation of G on the

423

vector space L2(G), we have much greater flexibility to decompose the action. It turns out that, not only does it break up into a direct sum of many irreducible rep-re sent at i ons, but every irreducible representationρ of Gand the number of times that occurs as one of the summands in this direct sum,ρ appears is equal to the dimension of the subspace on which it acts. The representation we have just discussed is called the left regular representation of G. The fact that every irreducible representation occurs in it so regularly makes it extremely useful.
Notice that it is easier to decompose representations on complex vector spaces than on real vector spaces, since every automorphism of a complex vector space has an eigenvector. So it issimplest to begin by studying complex representations. orem about complex representations of finite groups. This theorem tells us how many irreducible representa-The time has now come to state the fundamental the tions there are for a finite group, and, more colorfully, that representation theory is a “non-Abelian analogueof Fourier decomposition.” Letρ: G \to End(V ) be a representation of G.
The charactera function fromχρ of ρGis defined to be its trace: that is, to C andχ (g) = tr(ρ(g)) for eachχρ isg in B, we have G. Since trχ(AB)(hgh=-tr1)(BA)= χfor any two matricesρ(g). Therefore, χ is very A and far from an arbitrary function onis constant on each$ρ \text{conjugacy class}^{ρ} G$: it is a function that. Let$K^{G} \text{denote the}^{V}$ vector space of all complex-valued functions onthis property; it is called the representation ring Gof with G. a group form a very important set of data about the group, which it is natural to organize into a matrix.
The The characters of the irreducible representations of columns are indexed by the conjugacy classes, the rowsby the irreducible representations, and each entry is the value of the character of the given representation at the given conjugacy class. This array is called the table of the group, and it contains all the important character information about representations of the group: it isour periodic table. The basic theorem of the subject is that this array is a square. Theorem (the character table is square).a finite group.
Then the characters of the irreducible Let G be representations form an orthonormal basis of$K^{G}$. When we say that the basis of characters is orthonormal by we mean that the Hermitian inner product defined

χ$, ψ = |G|^{-}1 χ(g)ψ(g)g \in G$

424

is 1 whenχ = ψ and 0 otherwise. The fact that it is a basis implies in particular that there are exactly as many irreducible representations as there are conjugacy classes in classes of representations to G, and the map from isomorphism K that sends each ρ to its character is an injection. That is, an arbitrary rep-resentation is determined up to isomorphism by its$G$ character. The internal structure of a group G that controls how it can act on vector spaces is the structure of conju-gacy classes of elements of G.
This is a much gentler structure than the set of all conjugacy classes of groups of G. For example, in the symmetric groups ub-S two permutations belong to the same conjugacy class if and only if they have the same cycle type. Therefore,$n$ in that group there is a bijection between conjugacy classes and partitions of$n$.5 count subgroups, conjugacy classes are much easier to handle. For instance, since they partition the group, we Further more, where as it is completely unclear how to have the formul are sent at i on side, there is a similar formula, which arises|G| =C a conjugacy class|C|.
On the rep- from the decomposition of the regular representation L2(G)into irreducibles:|G| = (. im V )2. It is inconceivable that there might be a similarly simple formula for sums over all subgroups of a group.$V^{i}rreducible$ general structure of the representations of a finite group We have reduced the problem of understanding the G to the problem of determining the character table of G. When G = Z/n Z, our description of the n irreducible representations above implies that all the entries of this matrix are roots of unity.
Here are the character tables formetries of the square, and, just for contrast, for the$D^{8} (\text{on the left})$, the group of sym- group Z$/3Z$(on the right): 11 11 11$-11 - 11 11 1z z1^{2}$ 1 1$-1 1 - 1 1 z^{2} z$ 1 1-1 -1 1$2$-2 0 0 0 where$z = \exp (2πi/3)$. from?—indicates the main problem with the theorem: though it tells us the shape of the character table, it The obvious question—Where did the first table come leaves us no closer to understanding what the actual object, it is far smaller than the set of all subgroups of[VI.73](/part-06/godfrey-harold-hardy-18771947) and5.
Not only is the set of all partitions a sensible combinatorial ramanujan. qrt [VI.82](/part-06/srinivasa-ramanujan-18871920) showed that the number of partitions. qrt{S}n: hardy ofn is about (1/4 n 3)(eπ()(){2}n/ {}3).

IV. Branches of Mathematics

character values are. We know tions there are, but not what they are, or even what how many represent a their dimensions are. We do not have a general method for constructing them, a kind of “non-Abelian fourier transform.” This is the central problem of representation theory. Let us see how this problem can be solved for the group$D^{8}$. Over the course of this article, we have already encountered three irreducible representations of this group. The first is the “trivial” one-dimensional representation: the homomorphism takes every element of D to the identity.
The second isρ:$D^{8} \to GL^{1} that$ the two-dimensional representation we wrote down inthe first section, where each element of8 D acts on R2 in the obvious way. The determinant of this re pre sen-tation is a one-dimensional representation that is8 not trivial: it sends the rotations to 1 and the reflections to-1. So we have constructed three rows of the character table above.
There are five conjugacy classes inial, reflection through axis, reflection through diagonal,$D^{8} (triv-$ 90◦ rotation$, 180^{\circ} rotation)$, so we know that there are just two more rows. The equality|G| = 8 = 22 + 1 + 1 + (. im  V )2 +(are one dimensional. One way of getting the missing. im  V5)2 implies that these missing representations4 character values is to use orthogonality of characters. A slightly (but only slightly) less ad hoc way is to decompose the pair of diagonals L2(X) for small\\\\\\\\\\\. . \1, BDX\\\\\\\\\\\\}, we have.
For example when L2(X) = V X⊕Cis, where C is the trivial representation. some more modern topics in representation theory. Ofnecessity, we will use language from fairly advanced We are now going to start pointing the way toward mathematics: the reader who is familiar with only someof this language should consider browsing the remaining sections, since different discussions have different prerequisites. In general, a good, but not systematic, way of finding representations is to find objects on which and “linearize” the action. We have seen one exam-G acts, ple of this:
when the linearized action on G acts on a set L2(X). Recall that the irre-X we can consider duc i ble group of GG-sets are all of the form. As well as looking at G/HL2(G/H), for , we can con-H some sub- sider, for every representation$L^{2}(G/H$, W ) = {f}$: G \to W | Wf (gh)of H$, the vector space= h-1 f (g)$, g \in G$, h \in H; in geometric language, for those who prefer it, this is the space of sections of the associated Wthe-bundle on induced representation G/H. This representation ofof W from H to GG. is called

IV.9. Representation Theory

ifconsider how it acts on homology classes and hence GOther linearizations are also important. For example, acts continuously on a topological space X, we can on the case of this is the map homology groups$z$[IV.6 §4](/part-04/algebraic-topology) of$\to z$ ̄ of the circle X.6 The simplest S1. Since this map squares to the identity map, it gives us an action of Z$/2Z on S^{1}$, which becomes a representation ofas multiplication by 1 and the other element of Z/2 Z on H1(S1) = R (which represents the identity Z/2 Z as multiplication by-1).
character tables of all finite Methods like these have been used to determine the simple groups [I.3 §3.3](/part-01/fundamental-definitions), but they still fall short of a uniform description valid for all groups. ter table that hint at properties of the desired non-Abelian Fourier transform. For example, the size of a There are many arithmetic properties of the ch ar ac conjugacy class divides the order of the group, andin fact the dimension of a representation also divides the order of the group.
Pursuing this thought leads toan examination of the values of the characters modp, relating them to the so-called are groups of the form N(Q)/Qp, where-local subgroups Q is a subgroup. These of N(Q)G, the number of elements ofis the normalizer of Q(defined to be the largest Q is a power of p, and subgroup of When the so - called “G that contain sp-Sylow subgroup” of Q as a normal subgroup).G is Abe - lian, beautiful conjectures of Broué give us an essen-tially complete picture of the representations of G.
But in general these questions are at the center of a great deal of contemporary research.
3 Fourier Analysis We have justified the study of group actions on vector spaces by explaining that the theory of representations has a nice structure that is not present in the theory of group actions on sets. A more historically based account would start by saying that spaces of functions very often come with natural actions of some group G, and many problems of traditional interest can be related to the decomposition of these representations of G.Gthis case many of the nice features of the representa-In this section we will concentrate on the case where is a compact lie group[III.48
§1](/part - 03/lie - theory). We will see that in tion theory of finite groups persist. consist of formal sums of homology classes with integer coefficients. Here, where a vector space is required, we are taking real coefficients.6. The homology groups discussed in the article just referred to

425

The prototypical example is the space L2(S1) of square-integrable functions on the circle$S^{1}$. We can think of the circle as the unit circle in C, and there by identify it with the group of rotations of the circle(since multiplication by eiθ rotates the circle by θ). This action linearizes to an action on$L^{2}(S^{1})$: if$f$ is a square- integrable function defined on circle, then(w · f )(z)is defined to be S1 and wf (wbelongs to the-1 z). That is, w · f does to wz what f does to z. space tions:
the functions Classical Fourier analysis expands functions in the L2(S1) in terms of a basis of trigonometric func-zn for n \in Z. (These look more “trigonometric” if one writes e If we fixw and write φ (z) =i θznfor, thenz and e(wi·nθφ for)(z)zn=.)φtiple ofn(w - 1 z)φ =for eachw - nφn(z)wn, so the one-dimensional sub-. In particular, w · φn is a mul - n space generated by S1. In fact, nevery irreducible representation ofφn is invariant under the action of S1 is of this form, as long as we restrict attention to continuous representations. ization of the above situation:
we shall replace 1 byand try to understand Now let us consider an innocuous-looking general- L2(Sn), the space of complex-n valued square-integrable functions on the$n - sphere S^{n}$. The SO(nn+-sphere is acted on by the group of rotations1). As usual, this can be converted into a rep- resentation of SO$(n + 1) \text{on the space} L^{2}(S^{n})$, which we would like to decompose into irreducible repre-sentations; equivalently, we would like to decompose L2(Sn) into a direct sum of minimal SO(n+1)-invariant subspaces. similar to the proof for finite groups.
In particular, a compact group such as SOThis turns out to be possible, and the proof is very(n + 1) has a natural proba- bility measure [III.71 §2](/part-03/probability-distributions) on it (called Haar measure) in terms of which we can define averages. roughly speaking, the only difference between the proof for SO(n + 1)and the proof in the finite case is that we have to replace a few sums by integrals. is the following.
If The general result that one can prove by this method G is a compact group that acts con- tinuous ly on a compact space permutationφ(g) of X is continuous, and also that X (in the sense that eachφ(g) varies continuously with g)$, then L^{2}(X) splits$ up into an orthogonal direct sum of finite-dimensional minimal ear iz ed action of$G$-invariant subspaces; equivalently, the lin-G on L2(X) splits up into an orthog- onal direct sum of irreducible representations, all of which are finite dimensional. The problem of finding a

426

Hilbert space basis of L2(X) then splits into two sub- problems: we must first determine the irreducible representations of X, and then determine how many times each of these G, a problem which is independent of irreducible representations occurs in When$G = S^{1}$(which we identified with SO$L^{2}(X)$. (2)) and X = S1 as well, we saw that these irreducible repre- sentations were one dimensional. Now let us look atthe action of the compact group SO$(3) on S^{2}$.
It can be shown that the action of$G on L^{2}(S^{2}) \text{commutes with}$ the Laplacian, the differential operator. elta on L2(S2) defined byΔ = ∂x∂2 2 + ∂y∂2 2 + ∂z∂2 2.

That is, g(Δf ) = Δ(gf ) for any g \in  G and any (sufficiently smooth) functionan eigenfunction for the Laplacian (which means thatf . In particular, if f isΔf = . ambda f for some λ \in  C), then for each g \in  SO(3) we have

. elta gf = g. elta f = g. ambda f = . ambda gf,

sogf is also an eigenfunction for Δ. Therefore, the space eigenvalue V. ambda of all eigenvectors for the Laplacian with. ambda is G-invariant. In fact, it turns out that ifducible representation. Further more, each irreducible V. ambda is nonzero then the action of G on V. ambda is an irre- representation of SOMore precisely, we have a Hilbert space direct sum,(3) arises exactly once in this way. L2(S2) =n-⩾ 0(V2)n(2 n +2 ),

and each eigenspace Note that this is a case where the set of eigenvalues(V2)n( {}2 n + 2) has dimension 2 n + 1. is discrete. (These eigenspaces are discussed further in spherical harmonics The nice feature that each irreducible representation[III.87](/part-03/spherical-harmonics).) appears at most once is rather special to the exam-ple$L^{2}(S^{n})$. (For an example where this does not hap- pen, recall that with the regular representation L2(G) of a finite group occurs dimρ times in G each irreducible representation L2(G).) However, other featuresρ are more generic:
for example, when a compact Lie group acts differentiably on a space X, then the sum of all the G - invariant subspaces of L2(X) corresponding to a particular representation is always equal to the setof common eigenvectors of some family of commuting differential operators. (In the example above, there was just one operator, the Laplacian.) Interesting special functions [III.85](/part-03/special-functions), such as solutions of certain differential equations, often admit rep-resentation-theoretic meaning, for example as matrix

IV. Branches of Mathematics

coefficients. Their properties can then easily be de-duced from general results in functional analysis and representation theory rather than from any calculation. Hypergeometric equations, Bessel equations, and many integrable systems arise in this way. the representation theory of compact groups and thatof finite groups. Given a compact group There is more to say about the similarities between G and an irreducible representation its trace (since it is finite dimensional) and therebyρ of G, we can again take define its characteron each conjugacy class. Finally, “the character table$χ^{ρ}$.
Just as before, χρ is constant is square,” in the sense that the characters of the irre-duc i ble representations form an orthonormal basis of the Hilbert space of all square-integrable functions that are conjugation invariant in this sense. (Now, though, the “square matrix” is infinite.) When$G = S^{1} \text{this is the}$ Fourier theorem$; whensection 2.$ Gis finite this is the theorem of 4 Noncompact Groups, Groups in Character i st i cp, and Lie Algebras The “character table is square” theorem focuses our attention on groups with nice conjugacy-class structure.
What happens when we take such a group but relax the requirement that it be compact?A paradigmatic noncompact group is the real numbers R. Like$S^{1}$, R acts on itself in an obvious way (the real number$s \to s + t)$, so let us linearize that action in the usual wayt is associated with the translation and look for a decomposition of$L^{2}(R) into R - invariant$ subspaces. In this situation we have a continuous family of irreducible one-dimensional representations: for each real number. ambda we can define the functionχ by χ (x) =$e2$πi . ambda x .
These functions are not square integrable, bu(tλ). ambda despite this difficulty classical Fourier analysis tells usthat we can write an L2-function in terms of them. However, since the Fourier modes now vary in a con-tinuous family, we can no longer decompose a function as a sum: rather we must use an integral. First, we define the Fourier transform ˆf of f by the formul af (λ)fˆ is then= f (x)f (x)(e2)π = {}i. ambda x df (λ)ˆx. The desired decomposition of(e-2()π){i}. ambda x dλ. This, the Fourier in version formula of the functionsχ, tells us that.
We can also think of it as some-f is a weighted integral thing like a decomposition of$\lambda L^{2}(R)$ as a “direct integral” (rather than direct sum) of the one-dimensional subspaces generated by the functions$χ^{λ}$. However,

IV.9. Representation Theory

we must treat this picture with due caution since the functionsχ do not belong to L2(R). This example indicates what we should expect in gen-. ambda eral. Ifously on it in a way that preserves the measures of sub-X is a space with a measure and G acts continu- sets of X (as translations did with subsets of R), then the action ofon the set of all irreducible representations, and G on X gives rise to a measure \mu Xdefined L2(X) can be decomposed as the integral over all irreducible representations with respect to this measure.
A theorem that explicitly describes such a decomposition is called a Plancherel theorem for X. let us look at the action of SL2. imes For a more complicated but more typical example,2 matrices with determinant 1) on2(R) (the group of real R2 and see how to decompose functions defined on L2(R2)S. As we did when we looked at2, we shall make use of a differential operator. This involves the small technicality thatwe should look at smooth functions, and we do not ask for them to be defined at the origin.
The appropriate differential operator this time turns out to be the Euler vector field that iffsatisfies the conditionx(. artial/. artial x) + y(. artial/. artial y). It is not hard to checkf (tx, ty) = tsf (x, y) for every of this operator with eigenvaluex, y, and t > 0, then sf, and indeed all func-is an eigenfunction tions in the eigenspace with this eigenvalue, which we shall denote by W , are of this form. We can also splits Ws up as (Ws)+ ⊕ (Ws)-, where (Ws)+ and (Ws)- consist of the even and odd functions in The easiest way of analyzing the structure of$Ws$, respectively.
Ws is to compute the action of the For those readers unfamiliar with Lie algebras, we will lie algebra [III.48 §2](/part - 03/lie - theory) sl2. say only that the Lie algebra of a Lie group G keeps track of the action of elements ofimally close to the identity,” and that in this case the$G$that are “infinit es Lie algebra matrices of trace 0, withsl2 can be identified with the space of 2(a b )acting as the differential . imes 2 operator Every element of(-ax - by)(. artial/. artial x)W is a function onc - a+ (-cx + Ray)(. artial/. artial y)2.
If we restrict.s these functions to the unit circle, then we obtain a map from Wto the space of smooth functions defined on s S1, which turns out to be an isomorphism. We already know that this space has a basis of Fourier modes which we can now think of as(x + iy)m, defined when zm, xfunction defined on2+ y2 = 1. There is a unique extension of this from a S1 to a function in W , namely thes

function$w^{m}(x$, y) = (x + iy)m(x2 + y2)(s-m)/2. One can then check the following actions of simple matri-ces on these functions (to do so, recall the association of the matrices with differential operators given in the

427

previous paragraph):

0-i$i 0$· wm = mwm,1 i i-1 · wm = (m - s)(wm)+2,$1$-i-i -1 · wm = (-m - s)wm^-2.

It follows that iftionw in W+ swe can produce all the others using is not an integer, then from any func- the action of SLon W+m. Similarly, it acts irreducibly o(ns)2(R). Therefore, SL2(R) acts irreducibly W-. We have therefore encountered a significant difference between this and the finite/compact case: when s Gsis not com- pact, irreducible representations of dimensional. Gcan be infinite Looking more closely at the formulas for W whenss \in Z, we see more disturbing differences.
In order to understand these, let us distinguish carefully between representations that are reducible and representations that are that have nontrivial decomposable G. The former are representations-invariant subspaces, where as the latter are representations where one can decom-pose the space on which G acts into a direct sum of Gare obviously reducible. In the finite/compact case, we-invariant subspaces. Decomposable representations used an averaging process to show that reducible rep-re sent at i ons are decomposable.
Now we do not have a natural probability measure to use for the aver - aging, and it turns out that there can be reducible representations that are not decomposable. Indeed, ifs is a nonnegative integer, then the sub- spaces no men on. They are indecomposable (in fact, this is true(Ws)+ and (Ws)- give us an example of this phe- even when they contain an invariant subspace of dimensions is a negative integer not equal to - 1) buts + 1. Thus, we cannot write the representation as a direct sum of irreducible representations. (One can do something a little bit weaker, however:
if we quotient outby the(s + 1)-dimensional subspace, then the quotient representation can be decomposed.) these indecomposable but reducible representations we worked not in the space It is important to understand that in order to produce L2(R2) but in the space of smooth functions on R2 with the origin removed. For instance, the functions grable. If we look just at representations ofwm above are not square inte - G that act on subspaces of L2(X), then we can split them up into a direct sum of irreducibles: given aspace, its orthogonal complement is also G-invariant sub-G-invariant.

428

It might therefore seem best to ignore the other, rather subtle representations and just look at these ones. But it turns out to be easier to study and only later ask which ones occur inside all representations L2(X). For SL(which were subquotients of2(R), the representations we have just constructed W±) exhaust all the irre-s

duc i ble representations, mula for L2(R2) that tells us which ones appear in7 and there is a Plancherel for-L2(R2)and with what multiplicity:$\infty L^{2}(R^{2}) = {}^{−}$. nfty(W-1()+i)t (ei)t dt.

longer take averages overquences: To summarize: if G is not compact, then we can no G. This has various conse- Representations occur in continuous families.decomposition of L2(X) takes the form of a direct The Representations do not split up into a direct sum ofintegral, not a direct sum.irreducibles. Even when a representation admits a on finite composition series, as with the action of SL$W^{±}$, it need not split up into a direct sum. So2(R)s

to describe all representations we need to do more than just describe the irreducibles—we also need to describe the glue that holds them together. pact group tures of the compact case. But one thing does survive: So far, the theory of representations of a noncom-G seems to have none of the pleasant fea- there is still an analogue of the theorem that the char-acter table is square. Indeed, we can still define characters in terms of the traces of group elements.
But nowwe must be careful, since the irreducible representation may be on an infinite-dimensional vector space, sothat its trace cannot be defined so easily. In fact, characters are not functions on[III.18](/part-03/distributions). The character of a representation determines G, but only distributions the semi simplification of a representationρ:
that is, it tells us which irreducible representations are part ofbut not how they are glued together.8ρ, dra in the 1950 s in an extraordinary series of works that completely described the representation theory of Lie These phenomena were discovered by Harish-Changroups such as the ones we have discussed (the precise by “isomorphic.” Because many different topological vector spaces can have the same underlying7. To make this precise requires some care about what we meansl2 -module, the correct notion is of infinitesimal Harish-Chandra modules equivalence.
Pursuing this notion leads to the category of, a category with good finiteness properties. defines a character is given bythe semisimple elements of the group.8. It is a major theorem of Harish-Chandra that the distribution that analytic functions on a dense subset of

IV. Branches of Mathematics

condition is that they should be real and reductive—a concept that will be explained later in this article) and the generalizations of classical theorems of fourier analysis to this setting.9 tigated the representation theory of finite-dimensional vector spaces over fields of char-Independently and slightly earlier, Brauer had inves-finite groups on acteristicp. Here, too, reducible representations need not decompose as direct sums, though in this case the problem is not lack of compactness (obviously, since everything is finite) but an in ability to group:
we would like to divide by|Gave rage|, but often this over the is zero. A simple example that illustrates this is the action of Z/p Z on the space F2 that takes x to the 2 . imes  2 matrix tor(1)(is fixed by the action, and therefore generates11 0 x ). This is reducible, since the column vec-p an invariant subspace. However, if one could decom-pose the action, then the matrices0(1 x ) would all be1 0 diagonalizable, which they are not. It is possible for there to be infinitely many indecomposable representations, which again may vary in fam-ilies.
However, as before, there are only finitely many irreducible a “character table is square” theorem in which the rows representations, so there is some chance of of the square are parametrized by characters of irreducible representations. Brauer proved just such a the-orem, pairing the characters withp-semisimple conju- gacy classes in whose order is not divisible by G: that is, conjugacy classes of element sp. Harish-Chandra and of Brauer.
The first is that the cat-We will draw two crude morals from the work of egory of representations of a group is always a reason-able object, but when the representations are infinite dimensional it requires serious technical work to set itup.
Objects in this category do not necessarily decompose as a direct sum of irreducibles (one says that the category is not families, but irreducible objects pair off in some precise semisimple), and can occur in infinite way with certain “diagonalizable” conjugacy classes inthe group—there is always some kind of analogue of “the character table is square” theorem.
in more general contexts—Lie algebras acting on vec-tor spaces, quantum groups, It turns out that when we consider representations$p$-adic groups on infinite dimensional complex or these qualitative features stay the same.$p$-adic vector spaces, etc.— tat i ons for real reductive groups has still not been solved; the most complete results are due to Vogan.9. The problem of determining the irreducible unitary re pre sen-

IV.9. Representation Theory

for some “non-Abelian Fourier transform”: that is, a The second moral is that we should always hope set that parametrizes irreducible representations and a description of the character values in terms of this set. In the case of real reductive groups Harish-Chandra’s work provides such an answer, generalizing the weyl character formula for compact groups; for arbitrary groups no such answer is known.
For special classes of groups, there are partially successful general princi-ples (the orbit method, Broué’s conjecture), of which the deepest are the extraordinary circle of conjec-tures known as the Langlands program, which we shall discuss later. 5 Interlude: The Philosophical Lessons of “The Character Table Is Square” Our basic theorem (“the character table is square”) tells us to expect that the category of all irreducible representations of class structure of GGis interesting when the conjugacy-is in some way under control.
We will finish this essay by explaining a remarkable fam-ily of examples of such groups—the rational points of reductive re sent at i on theory, which is described by the algebraic groups—and their conjectured rep-Langlands program. group GLthe matrix coefficients. For example, the determinant An affine algebraic groupnthat is defined by polynomial equations inis a subgroup of some of a matrix is a polynomial in the matrix coefficients, so the group SLn, which consists of all matrices in GLn with determinant 1, is such a group.
Another is So which is the set of matrices with determinant 1 thatn, satisfy the equation AAT = I. ficients we were allowing for the matrices. That vague-ness was deliberate. Given an algebraic group The above notation did not specify what sort of coef-G and a fieldk, let us write G(k) for the group where the coefficients are taken to have values inple, SL(F ) is the set of n . imes  nmatrices with coeffi-k. For exam- cients in the finite field group is finite, as is SO nq (FFq), while SLand determinant 1. This(R) and SO (R) are Lie groups. More over, SOSL(R)is not.
So among affine algebraic groups over(nq)n(R) is compact, whil(en)n fields one already finds all three types of groups wehave discussed: finite groups, compact Lie groups, and$n$ noncompact Lie groups. We can think of SL(R) as the set of matrices in Sl there is another involution on SLn(C) that are equal to their complex conjugates.n (C) that is a sortn

429

of “twisted” form of complex conjugation, where wesend a matrix A to the complex conjugate of (A-1)T. The fixed points of this new involution (that is, the determinant-1 matrices A such that A equals the com- plex conjugate of This is also called a(A-1 real form)T) form a group called SUof SL (C),10 and it isn(R).n

compact. The groups SL(F ) and SO (F ) are almost simple groups; us, mysteriously, that all but twenty-six of the finite11 the classification of finite simple groups tells(nq()n){q} simple groups are of this form. A much, much easier theorem tells us that the connected compact groups are also of this form. Now, given an algebraic group G, we can also con- sider the instancesp-adic numbers, and also G(Qp G(), where Q). For that matter, we may Qpis the field of consider tion field of an algebraic variety G(k)for any other fieldk, such as the[V.30](/part-05/the-resolution-of-singularities).
The les-func- son of section 4 is that we may hope for all of these many groups to have a good representation theory, but that to obtain it there will be serious “analytic” or“arithmetic” difficulties to over come, which will depend strongly on the properties of the fieldk. point out that not every affine algebraic group has anice conjugacy-class structure. For example, let Lest the reader adopt too optimistic a viewpoint, we Vn bethe set of upper triangular matrices in Gl along the diagonal, and letk be F . For large nn, the con-with 1 s jugacy classes inlies:
to parametrize them sensibly one needs more than Vn(Fq) form large and complex fami-qnof dimension greater than parameters (in other words, they belong to familiesn, in an appropriate sense), and it is not in fact known how to parametrize them even for a smallish value of obvious that this is a “good” question though.)n, such as 11. (It is not conjugacy-class structure, even when the groups them-selves are “sensible.” So we might expect their repre-More generally, solvable groups tend to have horrible sentation theory to be similarly horrible.
The best wecan hope for is a result that describes the entries of the character table some kind of non-Abelian Fourier integral. For certain in terms of this horrible structure— p-groups Kirillov found such a result in the 1960 s, as SLcan be described as a subgroup of some group of real matrices that10. When we say that SL n( C), what is meant more precisely is that in both cases the groupn(R) and SUn(R)are both “real forms” of consists of all solutions to a set of polynomial equations, and that when the same set of equations is applied instead to the group of complex11.
Which is to say that the quotient of these groups by their center matrices the result is isomorphic to SLn(C). is simple.

430

an example of the “orbit method,” but the general result is not yet known. nected compact groups do have a nice conjugacy-class structure: in particular, finite simple groups do. An On the other hand, groups that are similar to con algebraic group is called reductive if G(C) has a com- pact real form. So, for instance, SLexistence of the real form SU(R). The groups GLn is reductive by theand SOLet us examine the conjugacy classes in the groupn are also reductive, but (Vn)n is not.12 n SUtwo conjugate matrices have the same eigenvalues, upn.
Every matrix in SUn(R) can be diagonalized, and to reordering. Conversely, any two matrices in SUwith the same eigenvalues are conjugate. Therefore, then(R) conjugacy classes are parametrized by the quotient of the subgroup of all diagonal matrices by the action of Sn that permutes the entries. nected group has a subgroup isomorphic to a product of circles. (In the pre-This example can be generalized.
Any compact con-maximal torus T , that is, a maximal vious example it was the subgroup of diagonal matri-ces.) Any two maximal tori are conjugate in G, and any conjugacy class in G intersects T in a unique W-orbit on T(where, where N(T )W is theis the normalizer of Weyl group, the finite group T)$. N(T )/T$ The description of conjugacy classes in G(k) ̄ , for an algebraically closed fiel. ar{d}cated. Any ele me ntg \in  G(k, is only a little more compli-k) ̄ admits a position wheres is conjugate to an element of[III.43](/part-03/jordan-normal-form):
it can be written as jordan decom-$g T (=k)$ ̄$suand = uusis$, unipotent when considered as an element of GL(A matrix A is unipotent if some power of A -n($\bar{I}$ k)is. zero.) Unipotent elements never intersect compact sub-groups. When G = GL this is the usual Jordan decom- position; conjugacy classes of unipotent elements are parametrized by partitions ofn n, which, as we men- tioned in section 2, are precisely the conjugacy classes of W = S .
For general reductive groups, unipotent con- jugacy classes are again almost the same thing as con-jugacy classes inn W .13 In particular, there are finitely many, independent o. ar{f}Finally, whenk is not algebraically closed, one de-k. scribes conjugacy classes by a kind of Galois descent; connected groups can be easily classified. Each one is essentially a product of circles and non-Abelian simple compact groups. The latter12.
The miracle, not relevant for this discussion, is that compact are parametrized by SO$n$, and five others, denoted dynkin diagrams$E^{6}$, E7$, E8$[III.48 §3](/part-03/lie-theory). They are SU,$F^{4}$, and G2. That is it!$n$, S(p2)n, binatorial data, Lusztig’s Weyl group.13. They are different, but related. Precisely, they are given by com-two-sided cells for the corresponding affine

IV. Branches of Mathematics

for example, in gl determined by their characteristic polynomial, but then(k), semisimple classes are still fact that this polynomial has coefficients ins trains the possible conjugacy classes.k con- in such detail is to describe the representation theory in analogous terms.
A crude feature of the conjugacy-The point of describing the conjugacy-class structure class structure is the way it decouples the field finite combinatorial data that is attached to G but inde-k from pendent of$k$—things like$W$, the lattice defining T, roots, and weights. The “philosophy” suggested by the theorem that the character table is square suggests that the re pre sen-tation theory should also admit such a decoupling:
it should be built out of the representation theory of$k^{*}$, which is the analogue of the circle, and out of the combinatorial structure of G(k) ̄ (such as the finite groups“Jordan decomposition”: W ). More over, representations should have a14 the “unipotent” representations should have some kind of combinatorial com-plexity but little dependence onk, and compact groups should have no unipotent representations.
the lines laid out above, but it goes beyond any of the The Langlands program provides a description along results we have suggested in that it also describes the entries of the character table. Thus, for this class of examples, it gives us (conjecturally) the hoped-for “non Abelian Fourier transform.” 6 Coda: The Langlands Program And so we conclude by just hinting at statements. If G(k) is a reductive group, we want to describe an appropriate category of representations for least the character table, which we may think of as a G(k), or at “semi simplification” of that category.
jugacy classes in sent at i ons. But something not so far off is conjectured, Even when kis finite, it is too much to hope that con-G(k) parametrize irreducible repre- as follows. To a reductive group G over an algebraically closed field, Langlands attaches another reductive group LG, the tions of Langlands dual G(k) will be parametrized by conjugacy classes, and conjectures that representa- Steinberg. However, the notion of Jordan decomposition for charac-ters originates with Brauer, in his work on modular representation14.
The first such theorems were proved for GL n (F q) by Green and theory.
It is part of his modular analogue of the “character table is square” theorem, which we mentioned in section 3.

IV.10. Geometric and Combinatorial Group Theory inof elements LG(C).15 of However, these are not conjugacy classes LG(C), as before, but of homomorphisms from the Galois group ofk to LG. The Langlands dual was originally defined in a combinatorial manner, but there is now a conceptual definition. A few examples of pairs(SL , PGL(G,)$.^{L}G) are (GL^{n}$, GLn), (S(O2()n)+1, S(p2)n), and resentation theory as built out of the structure ofthe arithmetic of In this way the Langlands program describes the rep-$n^{n} k$. G and the conjectures, it is not quite correct as stated.
For instance, one has to modify the Galois group Although this description indicates the flavor of16 in such a way that the correspondence is true for the group GL$(k) = k^{*}$. When k = R, we get the representation theory ofanalysis; on the other hand, when1 R* (or its compact form S1 k), which is Fourier is a p-adic local field, the representation theory of$k^{*} \text{is described by}$ local class field theory. We already see an extraordinary aspect of the Langlands program:
it precisely unifies and generalizes harmonic analysis and number theory. The most compelling versions of the Langlands program are “equivalences of derived categories” between the category of representations and certain geomet-ric objects on the spaces of Langlands parameters. These conjectural statements are the hoped-for fourier transforms. Though much progress has been made, a large part of the Langlands program remains to be proved. For finite reductive groups, slightly weaker statements have been proved, mostly by Lusztig.
As all but twenty-six of the finite simple groups arise from reductive groups, and as the sporadic groups have had their character tables computed individually, this work already determines the character tables of all the finite simple groups. For groups over R, the work of Harish-Chandra and later authors again confirms the conjectures. But for other fields, only fragmentary theorems have been proved. There is much still to be done.

Further Reading

A nice introductory text on representation theory is Alperin’sversity Press, Cambridge, 1993). As for the Langlands Local Representation Theory (Cambridge Uni plex spaces over some field15. The vector spaces; if we were looking at representations on vector C here is because we are looking at representations on F, we would take LG(F). com- Deligne group.16.
The appropriately modified Galois group is called the Weil– 431 program, the 1979 American Mathematical Society vol-ume titled Automorphic Forms, Representations, and$L$ Proceedings”) is more advanced, and as good a place - functions (but universally known as “The Corvallis to start as any. IV.10 Geometric and Combinatorial Group Theory Martin R. Bridson 1 What Are Combinatorial and Geometric Group Theory?
Groups and geometry are ubiquitous in mathematics, groups because the symmetries (or automorphisms [I.3 §4.1](/part - 01/fundamental - definitions)) of any mathematical object in any context form a group and geometry because it allows one to think intuitively about abstract problems and to organize families of objects into spaces from which one may gain some global insight. to the study of infinite, discrete groups.
I shall discuss The purpose of this article is to introduce the reader both the combinatorial approach to the subject that held sway for much of the twentieth century and the more geometric perspective that has led to an enormous flowering of the subject in the last twenty years. Ihope to convince the reader that the study of groups is a concern for all of mathematics rather than something that belongs particularly to the domain of algebra.
interaction of geometry/topology and group theory, The principal focus of geometric group theory is the through group actions and through suitable transla-tions of geometric concepts into group theory. One wants to develop and exploit this interaction for the benefit of both geometry/topology and group theory. And, in keeping with our assertion that groups are important through out mathematics, one hopes to illu-minate and solve problems from elsewhere in mathematics by encoding them as problems in group theory.
Geometric group theory acquired a distinct identity in the late 1980 s but many of its principal ideas have their roots in the end of the nineteenth century. At that time, low-dimensional topology and combinatorial group theory ing, combinatorial group theory is the study of groups emerged entwined. Roughly speak defined in terms of generators and relations. In order to follow the rest of presentations, that is, by means of this introduction the reader must first understand what these terms mean.
Since their definitions would require 432 an unacceptably long break in the flow of our discus - sion, I will postpone them to the next section, but I strongly advise the reader who is unfamiliar with the meaning of the expressionΓ = a, . . . , a | r , . . . , r to pause and read that section before continuing with this one. 1(n1)m The rough definition of combinatorial group theory just given misses the point that, like many parts of mathematics, it is a subject defined more by its core problems and its origins than by its fundamental defi - ni tions.
The initial impetus for the subject came from the description of discrete groups of hyperbolic isome-tries and, most particularly, the discovery of the fundamental group poincaré [VI.61](/part - 06/jules - henri - poincar - 18541912) in 1895. The group-theoretic issues[IV.6 §2](/part - 04/algebraic - topology) of a manifold [I.3 §6.9](/part - 01/fundamental - definitions) by that emerged were brought into sharp focus by the work of Tietze and Dehn in the first decade of the twentieth century and drove much of combinatorial group theory for the remainder of the century. topology:
other areas of mathematics threw up funda-Not all of the epoch-defining problems came from mental questions as well. Here are some of the forms they took: Does there exist a group of the following type? Which groups have the following property? What are the subgroups of ...? Is the following group infinite? When can one determine the structure of a group from its finite quotients? In the sections that follow I shall attempt to illustrate the mathematical culture associ-ated with questions of this kind, but let me immediately mention some easily stated but difficult classical problems.
(i) Let Gbe a group that is finitely generated and suppose that there is some positive integer such thatxn = 1 for every x in G. Must Gbe finite? n(ii) Is there a finitely presented group tive homomorphismφ:Γ \to Γ such thatΓ and a surjec-φ(γ) = 1 for someγ . eq1? (iii) Does there exist a finitely presented, infinite, group isomorphic to a subgroup of a finitely generated simple group [I.3 §3.3](/part - 01/fundamental - definitions)? (iv) Is every countable group, or even a finitely presented group?
in 1902 and the second by Hopf in connection with The first of these questions was asked by Burnside his study of degree - 1 maps between manifolds. I shall present the answers to all four questions (in section 5) to illustrate an important aspect of both combinatorial and geometric group theory: one develops techniques that allow the construction ofscribed properties. Such constructions are of particular explicit groups with pre interest when they illustrate the diversity of possible phenomena in other branches of mathematics. IV.
Branches of Mathematics Another kind of question that raises basic issues in combinatorial group theory takes the form: Does there exist an algorithm to determine whether or not a group (or given elements of a group) has such - and-such a property? For example, does there exist an algorithm that can take any finite presentation and decide in a finite number of steps whether or not the group presented is trivial?
Questions of this type led to a profound and mutually beneficial interaction between group theory and logic, given full voice by the Hig-man embedding theorem, which we shall discuss in section 6. More over, via the conduit of combinatorial group theory, logic has influenced topology as well: one uses group-theoretic constructions to show, for example, that there is no algorithm to determine which pairs of compact triangulated manifolds are homeo-morphic in dimensions 4 and above.
This shows that certain kinds of classification results that have been obtained in two and three dimensions do not have higher-dimensional analogues. theory as the attempt to develop algebraic techniques One might reasonably regard combinatorial group to solve the types of questions described above, and inthe course of doing so to identify classes of groups that are worthy of particular study. This last point, the ques-tion of which groups deserve our attention, is tackled head-on in the final section of this article.
are intrinsically combinatorial in nature, but many Some of the triumphs of combinatorial group theory more have had their true nature revealed by the intro-duction of geometric techniques in the past twenty years. A fine example of this is the way in which Gro - mov’s insights have connected algorithmic problems in group theory to so-called filling problems in Rie-mannian geometry. More over, the power of geometric group theory is by no means confined to improv-ing the techniques of combinatorial group theory: it naturally leads one to think about many other issues of fundamental importance.
For example, it provides a context in which one can illuminate and vastly extend classical rigidity theorems [V.23](/part - 05/mostows - strong - rigidity - theorem), such as that of Mostow. The key to applications such as this is the idea that finitely generated groups can usefully be regarded as geometric objects in their own right. This idea has its origins in the work of cayley [VI.46](/part-06/arthur-cayley-18211895) (1878) and Dehn (1905) but its full force was recog-nized and promoted by Gromov, starting in the 1980 s. It is the key idea that underpins the later sections ofthis article.

IV.10. Geometric and Combinatorial Group Theory 2 Presenting Groups How should one describe a group? An example will illustrate the standard way of doing so and give some idea of why it is often appropriate. by equilateral triangles. How might you describe the Consider the familiar tiling of the Euclidean plane full group motions of the plane that send tiles to tiles? Let us focusΓΔ of symmetries of this tiling, i.e., the rigid on a single tile this to pick out three symmetries.
The first, which we T and a particular edge e of T, and use shall callα, is the reflection of the plane in the line that contains tions in the lines that join the endpoints ofe and the other two, β and γ, are the reflec-e to the midpoints of the opposite edges inone can convince one self that every symmetry of the$T$. With some effort tiling can be obtained by performing these three operations repeatedly in a suitable order. One expresses thisby saying that the set$\\{α}$, β, γ\\\\\\\\\\\\\\\\\\\\\} generates the group ΓΔ. the operatio nn al position:
that is, A further useful observation is that if one performsα twice, the tiling is returned to its origi-α2 = 1. Likewise, β2 = γ2 = 1. One can also verify that(αβ)6 = (αγ)6 = (βγ)3 = 1. mined by these facts alone, a statement that we sum-marize by the notation It turns out that the groupΓ. elta is completely deter-Γ. elta = α, β, γ | α2, β2, γ2, (αβ)6, (αγ)6, (βγ)3. The aim of the rest of this section is to say in more detail what this means. we can deduce others:
for example, bearing in mind thatβ2 To begin with, notice that from the facts we are given= γ2 = (βγ)3 = 1, we can show that(γβ)3 = (γβ)3(βγ)3 = 1

as well (where the last equality follows after repeat-edly canceling pairs of the formββ or γγ). We wish to convey the idea that in between the generators except those that follow fromΓΔ there are no relationships the facts above by this kind of argument. Now let us try to say this more formally. We define a set of generators for a groupΓ to be a subset S ⊂ Γ such that every element ofelements of S and their inverses. That is, every elementΓ is equal to some product of can be written in the formis an element of S and each(s1)εε1 (sε)2 is 1 or2 · · · (sε)n-n, where each1. We then callsii

a product of this kind a identity inΓ . relation if it is equal to the about “the product” of some elements ofas though we are referring to another element of There is an awkward ambiguity here. When we talkΓ , it soundsΓ , but

433

we certainly did not mean this at the end of the last paragraph: a relation is not the identity element ofΓ but rather a string of symbols such asa(b-1 a)-1 bc that yields the identity inas generators in the setΓ when you interpret S. In order to be clear abouta, b, and c this, it is useful to define another group, known as the free group F(S). with three generators, taking our set A typical element is a “word” in the elements of For concreteness we shall describe the free group$S \text{to be} \\{a}$, b, c\\\\\\\\\\\\\\\\\\\\. \1.
and their inverses, such as the expressiona(b-1 a)-1 bc considered in the previous paragraph. However, wesometimes regard two words as the same: for instance, abcc-1 ac and abab-1 bc are the same because they become identical when we cancel out the inverse pairs$cc^{-1} and b^{-1b}$. More formally, we define two such words to befree group are the equivalent equivalence classes and say that the elements of the[I.2 §2.3](/part-01/language-and-grammar). To multiply words together, we just concatenate them:
for instance, the product ofab-1 and bcca is ab-1 bcca, which we can shorten to“empty word.” This is the free group on three genera-acca. The identity is the torsa, b, and c. It should be clear how to generalize it to an arbitrary setthe set S = \\{a, b, c S, though we shall continue to discuss\\}. onproperty A more abstract way of characterizing the free groupa, b, and: ifc Gis to say that it has the followingis any group and φ is any function from universal S = \\{a, b, c\\} to G, then there is a unique homomor- phismandc toΦ φ(c)from.
Indeed, if we want F(S) to G that takesΦato have these prop-to φ(a), b to φ(b), erties, then our definition is forced upon us: for exam-ple,Φ(ab-1 ca) will have to be φ(a)φ(b)-1φ(c)φ(a), by the definition of a homomorphism. So the unique-ness is obvious. The rough reason that this definition really does give rise to a well-defined homomorphism is that the only equations that are true in F(S) are ones that are true in all groups: in order forΦ not to be a homomorphism, one would need a relation to hold in F(S) that did not hold in G, but this is impossible.
to prove that it is (isomorphic to) the “freest” group with generators Now let us return to our exampleα, β, and γthat satisfies the relationsΓΔ. We would likeα2 = β2 = γ2 = (αβ)6 = (αγ)6 = (βγ)3 = 1. But what exactly is this “freest” group that we are claimingis isomorphic to$Γ^{\Delta}$? γare trying to construct that will turn out to be iso-To avoid confusion about the meaning of(are they elements of ΓΔ or of the group that weα, β, and morphic to$Γ^{\Delta}$?) we shall use the letters a, b, and c

434

when we answer this question. Thus, we are trying to build the “freest” group with generatorsa, b, and c that satisfies the relations(ac)6 = (bc)3 = 1, which we denote bya2 = b2 = c G2 == (ab)a, b, c6 =|a2, b2$, c2$, (ab)6$, (ac)6$, (bc)3. to imitate the above discussion of the free group itself, except that now we say that two words are equivalent There are two ways of going about this task. One is if you can get from one to the other by inserting ordeleting not just inverse pairs but also one of the words $a^{2}$, b2$, c2$, (ab)6$, (ac)6$, or (bc)3.
For example, ab2 c is equivalent tothe set of equivalence classes of words with the product ac in this group. Gis then defined to be coming from concatenation. A neater way to obtain G is more conceptual and ex- ploits the universal property of the free group. Asis to be generated bya, b, and c, the universal prop-G erty of the free group F(S) tells us that there will have to be a unique homomorphism such thatΦ(a) = a, Φ(b) = b, andΦΦ(c)from = F(S)c. More - to G over, we require that all ofand(bc)3 must map to the identity element ina2, b2$, c2$, (ab)6, (ac)G.
It6, follows that the[I.3 §3.3](/part - 01/fundamental - definitions) of kernel F(S)[I.3 §4.1](/part - 01/fundamental - definitions) ofthat contains the set$Φ \text{is a normal} R = subgroup${a2}$, b2$, c2$, (ab)6$, (ac)6, (bc)3. Let us write R for the smallest normal subgroup of R (or equivalently the intersection of all normal sub-F(S) that contains groups of F(S) that contain R). Then there is a sur- jective homomorphism from the F(S)/ R to any group that is generated byquotient a[I.3 §3.3](/part-01/fundamental-definitions), b, andc(ac)and satisfies the relations6= (bc)3 = 1.
This quotient itself is the group wea2 = b2 = c2 = (ab)6 = are looking for: it is the largest group generated bya, b, and Our assertion aboutcthat satisfies the relations inΓ. elta is that it is isomorphic to the R. group$G = a$, b, c | a2$, b2$, c2, (ab)6, (ac)6, (bc)3 that we have just described (in two ways). More precisely, the map from F(S)/ R to ΓΔ that takes a to α, b to β, and The above construction is very general. If we are givenc to γ is an isomorphism.
a groupatesΓ , together with a setΓ , then a presentation R ⊂of F(S)Γ is a setof relations, such S that gener- thatΓ is isomorphic to the quotient F(S)/ R . If both Sis finite. A group isand Rare finite sets, one says that the presentation finitely presented if it has a finite presentation. We can also define presentations in the abstract, with out mentioning a group set S and any subset R ⊂ F(S)Γ, we just define in advance: given any S | R to be the group F(S)/ R. This is the “freest” group

IV. Branches of Mathematics

generated byrelations that hold in Sthat satisfies the relations in S | R are the ones that can be R: the only deduced from the relations A psychological advantage of switching to this more R. abstract setting is that, where as previously we began with a groupΓ and asked how we might present it, we can now write down group presentations at will, start-ing with any set S and prescribing a set of words R in the symbols(S±)1. This gives us a very flexible way of constructing a wide variety of groups.
We might, for example, use a group presentation to encode a question from elsewhere in mathematics.
 We could then ask about the properties of the group thus defined, and see what they had to tell us about our original problem. 3 Why Study Finitely Presented Groups? Groups arise through out the whole of mathematics as groups of automorphisms. These are maps from an object to itself that preserve all of the defining structure: two examples are the invertible ear maps [I.3 §4.2](/part-01/fundamental-definitions) from a vector space [I.3 §2.3](/part-01/fundamental-definitions) tolinitself, and the homeomorphisms from aspace [III.90](/part-03/topological-spaces) to itself.
Groups encapsulate the essence topological of symmetry and for this reason demand our attention. We are driven to understand their general nature, identify groups that deserve particular attention, and develop techniques for constructing new groups (from old ones, or from new ideas). And, reversing the process of abstraction, when given a group, we want to find concrete instances of it. For example, we might like to realize it as the group of automorphisms of some interesting object, with the aim of illuminating the nature of both the object and the group.
(See the article onthis theme.)representation theory [IV.9](/part - 04/\text{representation} - theory) for more on 3.1 Why Present Groups in Terms of Generators and Relations? The short answer is that this is the form in which groups often “appear in nature.” This is particularly true in topology. Before looking at a general result that illustrates this point, let us examine a simple example. Consider the group D of all isometries of R that are generated by the reflections at the points 0, 1, and 2:
that is, the group generated by the three functionsα ,α1$, and α2$, which take x to - x, 2 - x, and 4 - x, respec - 0 tively. You may recognize this group to be the infinite dihedral group, and you may notice that the generator α2 is superfluous, since it can be generated fromα0 IV.10. Geometric and Combinatorial Group Theory andα1. But let us close our eyes to these observations as we let a presentation emerge from the action. To this end, we choose an open interval U with the property that the images of cover the whole of the real line, say U under the maps in U = (-1,3).
Now D let us record two pieces of data: the only elements of2 2 $D$pletely off itself are(apart from the identity) that fail to moveα and α , and, among all prod-U com- ucts of length at most 3 in those two letters, the only nontrivial ones that act as the identity on0 1 R areα^2 andαpresentation of^2^1. You may like to prove that D. α^0, α^1 | α^2^0, α^2^1^0 is a we now state.
(The proof of it is some what involved.) Let This is in fact a special case of a general result, which $X$[IV.6 §1](/part-04/algebraic-topology) andbe a topological space that is both simply connected [III.93](/part-03/universal-covers), and let path connectedΓ be a group of homeomorphisms from choice of path-connected open subset X to itself. Then any U ⊂ X such that the images oftionΓ = S | RU cover all of, where S = {X γgives rise to a present a-\in  Γ | γ(U) ∩ U = ∅} and3 such that R consists of all wordsw = 1 in Γ.
Thus, the identification of aw \in  F(S) of length at most suitable subset U provides one with a presentation ofΓnature of the group from this information., and the task of a group theorist is to determine the consider the groups To see how difficult this task is, you might like to Gn = a1, . . . , an | (a - i)1(ai)+1 ai(a - i)+2 1, i = 1, . . . , n , where we interpret Gis trivial and the other is infinite. Can you decide i + 1 as 1 when i = n. One of G3 and which is which?4 finitely presented group that we perhaps feel we under - stand:
the group To illustrate a more subtle point, let us consider aΓ. elta that we were discussing earlier. If we want to describe this group to a blind friend unfa-miliar with the triangular tiling of the plane, what can we say to make her understand the group, or at least convince her that we understand the group? ments of our group, so we begin to describe them as Our friend might reasonably ask us to list the ele products (words) in the given generators. But as we begin to do so we hit a problem:
we do not want to list any element more than once and in order to avoid redundancy we have to know which pairs of words wwe must be able to recognize which words1, w2 represent the same element of Γ. elta; equivalently, w - 1 w are relations in the group. Determining which words are1 2 relations is called the word problem for the group. Even

435

in quickly find ourselves at a loss.Γ. elta this takes some work, and in the groups Gn we Note that as well as allowing one to list the elements of the group effectively, a solution to the word prob-lem also allows one to determine the multiplication table, since deciding whether as deciding whether w w w - 1 w = 1 w1.2 = w3 is the same 1 2 3 3.2 Why Finitely Presented Groups? The packaging of infinite objects into finite amounts of data arises through out mathematics in the various guises ofis basically a compactness condition:
a group can be compactness [III.9](/part - 03/compactness - and-\text{compactication}). Finite presentation finitely presented if and only if it is the fundamental group of a reasonable compact space, as we shall see later. Another good reason for studying finitely presented groups is that the Higman embedding theorem (to bediscussed later) allows us to encode questions about arbitrary about such groups and their subgroups.turing machines [IV.20 §1.1](/part-04/computational-complexity) as questions 4 The Fundamental Decision Problems In exploring the geometry and topology of low-dimen-sional
manifolds at the beginning of the twentieth century, Max Dehn saw that many of the problems thathe was wrestling with could be “reduced” to questions about finitely presented groups. For example, he gavea simple formula for associating with a knot diagram [III.44](/part-03/knot-polynomials) a finite presentation of a group. There was one relation for each crossing in the diagram and he argued that the resulting group would be isomorphic to Z if and only if the knot was the unknot: that is, if and onlyif it could be continuously deformed into a circle.
It is extremely hard to tell by staring at a knot diagram whether it is actually the unknot, so this seems like a useful reduction until one realizes that it can be just as hard to tell whether a finitely presented group is iso-morphic to Z. For example, here is the presentation of Z that Dehn’s recipe associates with one of smallest possible pictures of the unknot, namely a diagram with just four crossings:

$a1$, a2, a3, a4, a5 |(a - 1)1 a3(a - 4)1$, a2(a - 3)1a1$, a3(a - 4)1(a - 2)1$, a4(a - 5)1a4(a - 3)1$. Thus Dehn’s investigations led him to understand how difficult it is to extract information from a group presentation. In particular, he was the first to identify the fundamental role of the word problem, which we

436

alluded to earlier, and he was one of the first to begin to understand that there are fundamental problems associated with the challenge of developing algorithms that extract knowledge from well-defined objects such as group presentations. In his famous article of 1912 Dehn writes: The general discontinuous group is given byators andmrelations between them. ... Here there aren gener- above all three fundamental problemsis very difficult and which will not be possible with out whose solution a penetrating study of the subject.

1. The identity [word] problem: group is given as a product of generators. One An element of the is required to give a method where by it may be decided in a finite number of steps whether this

2. The transformation [conjugacy] problem: element is the identity or not.elements S and T of the group are given. A method Any two is sought for deciding the question whether T can be transformed into each other, i.e., whether S and there is an element relation U of the group satisfying the S = UT U-1.

3. The isomorphism problem: is to decide whether they are isomorphic or not (and Given two groups, one further, whether a given correspondence between the generators of one group and elements of the other is an isomorphism or not). for three lines of enquiry.
First, we shall work toward an out line of the proof that all of these problems are, in We shall take these problems as the starting point a strict sense, unsolvable for general finitely presented groups. The second use that we shall make of Dehn’s problems is to hold them up as fundamental measures of complexity for each of the classes of groups that we subsequently encounter.
If we can prove, for example, that the isomorphism problem is solvable in one class of groups but not in another, then we will have given genuine substance to previously vague assertions to the effect that the second class is “harder.”Finally, I want to make the point that geometry lies at the heart of the fundamental issues in combinatorial group theory: it may not be immediately obvious, but its implicit presence is nonetheless a fundamental trait of group theory and not something imposed for reasons of taste.
To illustrate this point I shall explain how the study of the large-scale geometry of least-area disks in riemannian manifolds [I.3 §6.10](/part - 01/fundamental - definitions) is intimately connected with the study of the complexity ofword problems in arbitrary finitely presented groups. IV. Branches of Mathematics 5 New Groups from Old Suppose that you have two groups, to combine them to form a new group. The first method G1 and G2, and want that is taught in a typical course on group theory isto take the Cartesian product$G \times G$:
a typical element has the form and the product of(g$, h)(g, h)withwith(gg1, h \in)G2$ is defined to be1 and$h \in G2$,(gg^ , hh). The set of elements of the form (g, e) (whereeand similarly the set of elements of the formis the identity of G2) is a copy of G1 inside(e, h)G1 . imes  is a G2, copy of These copies have nontrivial relations between their$G^{2}$. elements: for example,(e$, h)(g, e) = (g, e)(e, h)$. We would now like to take two groupsbine them in a different way to form a group called the$Γ^{1} and Γ^{2} \text{and com}-$ free productΓ2 and as few additional relations as possible.
That is,Γ1 * Γ2, which contains copies of Γ1 and we would like there to be embeddings so that$i (Γ ) \text{and i} (Γ ) generate Γ^{*}iΓ^{j}$: but they areΓj "\to (Γ1)* Γ2 not intertwined in any way. This requirement is neatly encapsulated by the following universal property: given1 1 2 2 1 2 any groupandφ:ΓG\to and any two homomorphisms G, there should be a unique homomor-φ1:$Γ^{1} \to G$ phism(Less formally,2Φ:Γ2 1 * ΓΦ2 \to behaves like G such thatφΦon the copy of◦ ij = φj for j Γ= 1 and,2.
behaves like It is easy to check that this property characterizesφ2 on the copy of Γ1 2.)1Γquestion of whether1^* Γ2 up to isomorphism, but it leaves open theΓ^* Γ actually exists. (These are the standard pros and cons of defining an object by1 2 means of a universal property.) In the present setting, existence is easily established using presentations:
let a presentation of define A1 | RΓ1^*be a presentation ofΓ to beΓ2 A, with%AA1| RandΓ%1 ARand let2 disjoint, and then(where A%2 |denotes R2 be a union of disjoint sets).More intuitively, one can define1 2 1 2 1Γ2* Γ to be the set of alternating sequences belonging toΓ and each ab1 bbe long ing to1 · · · (a1)n(bn)2 with eachΓ , with theai extra condition that none of the identity, except possibly1(a1)j or b(an)i. The group opera - and (bj)2 equals the tions inway:
for example,Γ1 and Γ2(a extend to this set in an obvi ousb a )(a^ b^ ) = a b a^ b^ , where a cancels down to2 = a2 a1, except that ifa b1, wher(e1)2 a2 a(b1)1 1== b1 then the productb1.1 2 1 topological spaces p Free products occur naturally in topology: if one has\in  X , then the fundamental group1(X2)1, X2 with marked point(s2)1 1[IV.6 §2](/part - 04/algebraic - topology) of the$p1 \in X1,$ space2(X2)1 ∨ X2 obtained from X1 % X2 by making the

IV.10. Geometric and Combinatorial Group Theory identification andπ (X , p p). The Seifert–van Kampen theorem tells1 = p2 is the free product of π1(X1, p1) one how to present the fundamental group of a space obtained by gluing1 2 2 X and X along larger subspaces. If the inclusion of the subspaces gives rise to an injec - 1 2 tion of fundamental groups, then one can express the fundamental group of the resulting space as an amalgamated free product LetΓ1 and Γ2 be two groups. If some other group, which we now define. contains copies of those copies must contain the identity element.
TheΓ1 and Γ2, then the intersection of free product build that was subject to this minimal constraint. NowΓ1* Γ2 was the freest group we could we shall insist that the copies of nontrivially, specify which of their subgroups must lieΓ1 and Γ2 intersectin the intersection, and build the freest group that satisfies this constraint. Suppose, then, that A1 is a subgroup of Γ1 and that φ is an isomorphism fromin the example of the free product, one can define the A1 to a subgroup A2 of Γ2. As “freest product that identifies of a universal property.
Again, one can establish the$A^{1} and A^{2}$” by means existence of such a group using presentations: if S | R and Γ = S | R , the group we seek takesΓ1 =the form1 1 2 S % S2 | R2 % R % T . Here, that represents T = {ua va(a-1)1 in (the presentation of)| a2\in  (A1)1}, where2 ua is some wordΓ1 and va is a word that represents This group is called theφ(a)amalgamated free product ofin Γ2.Γcasual and ambiguous notation1 and Γ2 along A1 and A2.
It is often described by theΓ* Γ , or evenΓ1 Unlike with free products, it is no longer obvious that*A Γ2, where A Aj is an abstract group.1 A 1 = A 2 2 the mapsΓi \to Γ1 * A Γ2 implicit in this construction are injective, but they do turn out to be, as was shown by Schreier in 1927. Neumann in 1949 answers the following question: given a group A related construction of Higman, Neumann, andΓ and an isomorphism ψ:
B \to Bbetween subgroups ofa bigger group so thatψΓ , can one always embed becomes the restriction to1 Γ Bin2 of a conjugation?By now, having seen the idea in the context of both free products and amalgamated free products, the reader may guess how one goes about answering this question: one writes down the presentation of a universal candidate for the desired enveloping group, denotedΓ*, and then one sets about proving that the natural map fromψ Γ to Γ* ψ (which takes each word

437

to itself) is injective. Thus, givenduce a sym bolt ∉ A (usually called theΓ = As table letter| R , we intro-), we choose for each and  ̃$b = ψ(b) in bΓ$, and we define$\in B^{1}$ words ˆb, ̃$b \in F(A)$ with ˆb = b(Γ*)ψ = A, t | R, tbtˆ$- {}^{1}b$ ̃$- {}^{1} (b \in B^{1})$. This is the freest group we can build from ing a new ele men tt and requiring it to satisfy all theΓ by adjoin- equations we want it to, namely$t$ˆ$bt^{-1} =$ ̃b for everyb \in  B1 (which we can think of as saying that tbt-1 =ψ(b)Higman, Neumann, and Neumann).).
This group is called an HNN extension of Γ (afterΓand regard it as an element of*Now we must show that the natural map fromψ is injective. That is, if you take an elementΓ*, you should not beγ ΓoftoΓ able to uset and the relations in Γψ * ψ to cancel γ down to the identity. This is proved with the help of the fol-lowing more general result known as Britton’s lemma. Suppose that the only circumstances under which it can give rise tow is a word in the free group F(A, t).
Then the identity in the group in vol vet and represents the identity inΓ* ψ are if either it does notΓ or it involve st ing a “pinch.” A pinch is a subword of the form but can be simplified in an obvious way by contain- tbt-1, where of B1 (in which case we can replace it byb is a word in F(A) that represents an elementψ(b)), or one of the formt - 1 b^ t, where b^ represents an element of Bif you are given a word that involves2 (in which case we can replace it by ψt-and contains1(b^ )). Thus, no pinches, then you know that it cannot be canceled down to the identity.
gamated free product to A similar noncancellation result holds for the amal-Γ but not to A andΓ1(h*)A, $. . . , h1 = A 2 Γ2$. Ifbelong tog1, . . . , gΓnbut not be long tothe identity in(A1)2, then the wordΓ^*1=g1 hΓ1 1 g.2 h2 · · ·n gnhn cannot equal2 These noncancellation results do far more than show1$(A1)A 2 2$ that the natural homomorphisms we have been con-side ring are injective: they also demonstrate further aspects of freeness in amalgamated free products and HNN extensions.
For example, suppose that in the amalgamated free product ment$g of Γ^{1}$that generates an infinite group that inter-Γ1 * A 1=A 2 Γ2 we can find an elesectsthe same for A1 in the identity and an element A . Then the subgroup of Γh of* Γ2 that doesΓ gen- erated byerators. With a little more effort, one can deduce thatg and2 h is the free group on those two gen-1 A 1=A 2 2 any finite subgroup ofΓ1 * A 1=A 2 Γ2 has to be conjugate to a subgroup of the obvious copy of either Similarly, the finite subgroups of$Γ^{*} \text{are conjugates}Γ^{1} or Γ^{2}$.ψ

438

of subgroups of constructions that follow.Γ . We shall exploit these facts in the have not mentioned here. I have chosen to focus on amalgamated free products and HNN extensions partly There are many ways of combining groups that I because they lead to transparent solutions of the basic problems discussed below but more because of their primitive appeal and the way in which they arise naturally in the calculation of fundamental groups. They also mark the beginning of arboreal group theory, which we will discuss later.
If space allowed, I would goon to describe semidirect and wreath products, which are also indispensable tools of the group theorist. Before turning to some applications of HNN extensions and amalgamated free products, I want to return to the Burnside problem, which asks if there exist finitely generated infinite groups all of whose ele-ments have a given finite order. This question generated important developments through out the twenti-eth century, particularly in Russia.
It is appropriate to mention it here because it provides another illustration of the fact that it can be useful to study a universal object in order to solve a general question.

5.1 The Burnside Problem

Given an exponentby considering them free Burnside group, one clarifies the problem at hand Bn, m given by the presentation of allmth powers in the free groupa1, . . . , an | Rm$, where F(a1$, . . . , a Rm cons is tsn). It is clear that generators in which every element has order dividing$B^{n}$, m maps onto any group with at most nm group with all elements of the same finite order if and. Therefore, there exists a finitely generated infinite only if, for suitable values ofn and m, the group B is infinite.
Thus, a question that takes the form, Does there exist a group such that ...?, becomes a questionn, m about just one group. nite when the exact range of values for which Novikov and Adian showed in 1968 thatn ⩾ 2 and m ⩾ 667 is odd. Determining B^n, mis infinite is B^n, mis infian active area of research. Of far greater interest is the open question of whether there exist finitely presented infinite groups that are quotients ofwas awarded the Fields Medal for proving that each$B^{n}$, m. Zelmanov Bn, mhas only finitely many finite quotients.

5.2 Every Countable Group Can Be Embedded

in a Finitely Generated Group

Given a countable group$g0$, g1, g2, . . . , taking g0 to be the identity. We can then G we can list its elements,

IV. Branches of Mathematics

take a free product ofs. um  Z. Let Σ be the set of all elements of Gwith an infinite cyclic group G* Z of the formsn = (gn)1 sn with n ⩾ 1. Then the subgroup Σ1 generated by Similarly, if we letΣ1 is isomorphic to the free groupΣ = \\{s , s , . . . \\} (so it is Σ with the F(Σ1). element F(Σ ). It follows that the maps1 = g1 s removed), the(n2()2)3ψ(s Σ)2= sis isomorphic to gives rise to1 an isomorphism from extension2(G* Z)* , whose stable letter we denote byΣ1 to Σ2 n. Now take the HN(Nn)+1 t More over, since we have ensured that.
This group contains a copy ofψ G, as we noted before.ts t - 1 = s for everyn ⩾ 1, it can be generated by just the three ele - n n + 1 ments countable group into a group with three generators. (We$s1$, s, and t. Thus, we have embedded an arbitrary leave the reader to think about how one can vary this construction to produce a group with two generators.) 5.3 There Are Uncountably Many Nonisomorphic Finitely Generated Groups This was proved by B. H. Neumann in 1932. Since there are infinitely many primes, there are uncountably many nonisomorphic groups of the formis an infinite set of primes.
We have seen that each of p \in P Zp, where P these groups can be embedded in a finitely generated group, and our earlier comments on finite subgroupsof HNN extensions show that no two of the resulting finitely generated groups are isomorphic.

5.4 An Answer to Hopf’s Question

A group G is called Hopfian if every surjective homomorphism from familiar groups have this property: for example, finite G to G is an isomorphism. Most groups obviously do, as do Zn (as you can prove using linear algebra) and free groups. So too do groups ofmatrices such as SL(Z), as we shall discuss in a moment. A simple example of a non-Hopfian group isthe group consisting of all infinite sequences of inte-$n$ gers (under pointwise addition), since the function that takes(a , a , a , . . . ) to (a , a , a , . . .
) is a surjective homomorphism that contains But is there a finitely presented example? The answer1 2 3 2(31, 04, 0, . . . ) in its kernel. is yes, and Higman was the first to construct one. the following examples are due to Baumslag and Solitar. Letp ⩾ 2 be an integer and identify Z with the free group subgroupsa generated by a single generatorp Z and (p + 1)Z of Zare identified with thea. Then the powers ofap and ap+1, respectively. Let ψ be the iso- morphism between these subgroups that takes(ap)+1 and consider the corresponding HNN extensionap to

IV.10. Geometric and Combinatorial Group Theory B. This has presentation B = a, t | ta-pt-1(ap)+1. The homomorphismψ: B \to  Bdefined byt \to  t, a \to  ap is clearly a surjection but its kernel contains, for exam-ple, the ele men tc = ata-1 t-1 a-2 tat-1 a, which does not contain a pinch and is therefore not equal to the identity, by Britton’s lemma. (If you want to convince your self how useful this lemma is, set$p = 3 \text{and try to}$ prove directly that group Bjust defined.)c is not equal to the identity in the

5.5 A Group That Has No Faithful

Linear Representation

One can show that a finitely generated group G of matrices over any field isthat for each nontrivial element residually finiteg \in G , which means there exists a finite group Q and a homomorphism π: G \to  Q withπ(g)g \in  SL≠(Z1. For example, if you are given an element), then you can pick an integer m bigger than the absolute values of all the entries inn . imes  nn matrix) and consider the homomorphism fromg (which is an SLmodn(Zm). The image ofto SLn(Z/m Z)gthat reduces the matrix entries in the finite group SL(Z/m Z)n

is clearly nontrivial.

Non-Hopfian groups are not residually finite, and hence are not isomorphic to a group of matrices over any field. One can see that the non-Hopfian group Bdefined above is not residually finite by considering what happens to the nontrivial ele men tc. We saw that there was a surjective homomorphismψ(c) = 1. Let c be an element such thatψ:ψBn \to (c B)with = c (which exists sincen ψ is a surjection). If there weren a homomorphismπ(c) =1, then we would have infinitely many distinctπ from Bto a finite group Q with homomorphisms fromtionsπ ◦ψn;
these are distinct because B to Q, namely the com posi-π . ircψm(c ) = 1$if$ m > n and π . irc ψn(cn) = π(c) = 1. This is a con-n tradiction, since a homomorphism from a finitely gen-erated group to a finite group is determined by what it does to the generators, so there can only be finitely many such homomorphisms.

5.6 Infinite Simple Groups

Britton’s lemma actually tells us more than thatc ≠$1$: the subgroupΛ of B generated by t and c is in fact a free group on those generators. Thus we may form the amalgamated free productΓ of two copies of B, denotedofΛ with the isomorphism B1 and B2, by gluing together the two copiesc \to  t , t \to  c . We have 1 2 1 2

439

seen that in any finite quotient ofmentsc (= t ) and c (= t ) must have trivial image,Γ = B1^*^Λ B2, the ele- and it is easy to deduce from this that in fact the quo-tient must be trivial. Thus1 2 2Γ1 is an infinite group with no finite quotients. It follows that the quotient of maximal proper normal subgroup is also infinite (andΓ by any it is simple by maximality).The simple group that we have constructed is infinite and finitely generated but it is not finitely presentable. Finitely presented infinite simple groups do exist, but they are much harder to construct.
6 Higman’s Theorem and Undecidability We have seen that there are uncountably many (non - isomorphic) finitely generated groups. But as there are only countably many finitely only countably many finitely generated groups can bepresented groups, subgroups of finitely presented groups. Which ones are they?
a beautiful and deep theorem proved by Graham Hig-man in 1961, which says, roughly, that the groups that A complete answer to this question is provided by arise are all those that are algorithmically describable.(If you have no idea what this means, even roughly, then you might like to read halting problem [V.20](/part - 05/the - insolubility - of - the - halting - problem) before continuing with this the insolubility of the section.)A set Sof words over a finite alphabet A is called recursively enumerable more formally, Turing machine) that can produce aif there is some algorithm (or complete
list of the elements oflar interest is when A is just a singleton, in which case S. A case of particu- a word is determined by its length and we can think of S as a set of nonnegative integers. The elements of Salgorithm that produces an exhaustive list ofneed not be listed in a sensible order, so having an S does not mean that one can use the algorithm to determine that some given wordw does not belong to S:
if you imagine standing by your computer as it enumerates S, there will not in general come a time when you can say to your self, “If it was going to appear, then it would have done so by now,” and therefore be certain that it is not inproperty, then you need the stronger notion of a S. If you want an algorithm with this furtherrecur- sive set, which is a set S such that S and its complement arethe elements that belong toboth recursively enumerable. Then you can list all S and you can also list all the elements that do not belong to A finitely generated group is said to be S.
recursively presentable if it has a presentation with a finite number 440 of generators and a recursively enumerable set of defin-ing relations. In other words, such a group is not necessarily finitely presented, but at least the presentation of the group is “nice” in the sense that it can be generatedby some algorithm. generated group if it is isomorphic to a subgroup of a finitely presented Higman’s embedding theorem states that G is recursively presentable if and onlya finitely group.
consider the following presentation of the group of all rationals under addition, in which the generator To get a feeling for how nonobvious this is, you might ancorresponds to the fraction 1$/n!:$ Q = a1$, a2$, · · · | (an)n = an-1 ∀n ⩾ 2. Higman’s theorem tells us that Q can be embedded in a finitely presented group, but no truly explicit embedding is known. ease with which it implies the celebrated undecidabil-ity results that were rightly regarded as watersheds The power of Higman’s theorem is illustrated by the of twentieth-century mathematics.
In order to make this case convincingly, I shall give a complete proof(except that I shall assume some of the facts mentioned earlier) that there exist finitely presented groups with unsolvable word problems, and also that there are sequences of finitely presented groups among which one cannot decide isomorphism. We shall also see how these group-theoretic results can be used to translate undecidability phenomena into topology. The basic seed of undecidability comes from the fact that there are recursively enumerable subsets S ⊂ N that are not recursive.
Using this fact one can readily construct finitely generated groups with an unsolv-able word problem: given such a set of integers S we consider $J = a$, b, t | t(bnab-n)t-1 = bnab-n ∀n \in S . This is the HNN extension of the free group associated with the identity map L \to  L, where LF(a, b)is the subgroup generated by${bnab^{-}n}$:$n \in S$.
Britton’s lemma tells us that the word $wm = t(bmab^{-}m)t^{-}1(bma^{-}1b^{-}m) equals 1$\in  J if and only if m \in  S, and by definition there is no algorithm to decide ifm \in S, so we cannot decide which of the unsolvable word problem.wm are relations. Thus J has an That there exist finitely presented groups for which the word problem is unsolvable is a much deeper fact, but with Higman’s embedding theorem at hand the

IV. Branches of Mathematics

proof becomes almost trivial: Higman tells us that Jcan be embedded in a finitely presented groupΓ , and it is a relatively straightforward exercise to show that if one cannot decide which words in the generators ofnot decide for arbitrary words in the generators of J represent the identity, then one can-Γ either. Once one has a finitely presented group with an unsolvable word problem, it is easy to translate unde-cid ability into all manner of other problems. For example, suppose thatΓ = A | Ris a finitely presented group with an unsolvable word problem, where\\{a , . . .
, a \\} and no a equals the identity in Γ . For each A =$word1$ w made out of the letters i(nn)i A and their inverses, define a groupΓw to have presentation A, s, t | R, t-1(sia s-i)t(siws-i)$, i = 1$, . . . , n .i

It is not hard to show that iffree group generated bys andw t=. If1 inw Γ=then1, thenΓw is theΓ is an HNN extension. In particular, it contains a copy ofΓ , and hence has an unsolvable word problem, whichw means that it cannot be a free group. Thus, since there is no algorithm to decide whether$w = 1 in Γ$, one can- not decide which of the groups which others.$Γ^{w} \text{are isomorphic to}$ algorithm to determine whether or not a given finitely A variant of this argument shows that there is no presented group is trivial.
We shall see in a moment that every finitely presented grouppact four-dimensional manifold. By following a stan-G is the fundamental group of some com- dard proof of this theorem with considerable care, Markov proved in 1958 that in dimensions 4 and above there is no algorithm to decide which compact mani-folds (presented as simplicial complexes, for example) are homeomorphic.
His basic idea was to show that if there were an algorithm to determine which triangulated 4-manifolds are homeomorphic, then one could use it to determine which finitely presented groups are trivial, which we know is impossible. In order to implement this idea one has to be careful to arrange that the4-manifolds associated with different presentations of the trivial group are homeomorphic: this is the delicate part of the argument. which compact three-dimensional manifolds are iso-Strikingly, there does exist an algorithm to decide morphic.
This is an extremely deep theorem that relies in particular on Perelman’s solution to thurston’s geometrization conjecture [IV.7 §2.4](/part-04/dierential-topology).

IV.10. Geometric and Combinatorial Group Theory 7 Topological Group Theory Let us change perspective now and look at the sym-bols P ≡ a , . . . , a | r , . . . , r through the eyes of a topologist. Instead of interpreting constructing a group, we regard it as a recipe for con-1 2 1 m P as a recipe for struc ting a ically a two-dimensional complex topological space [III.90](/part-03/topological-spaces), or more specif-. Such spaces consist of points, called directed paths, called vertices edges, some of which are linked by, or 1 - cells.
If a collection of such 1-cells forms a cycle, then it can be filled in with adisk with a directed cycle as its boundary.face, or 2 - cell: topologically speaking, each face is a standard presentation(This is generated by To see what this complex is, let us first consider thea P and≡ a, bb and the relation tells| aba - 1 b - 1 of Z2. us thatab = ba.) We begin with a graph K1 that has a single vertex and two edges (which are loops)that are directed and labeled a and b.
Next, we take a square labeled[a0,, b1], . imes a-[01,, 1 b]-, the sides of which are directed and1 as we proceed around the bound - ary. Imagine gluing the boundary of the square to the graph so as to respect the labeling of edges: with a bit of thought, you should be able to see that the result is a torus, that is, a surface in the shape of a bagel. An observation that turns out to be important is that the fundamental group of the torus is Z2, the group we started with. attaching maps boundary of the square The idea of “gluing” is made precise by the use of:
we take a continuous map S to the graph K1φthat sends from the the corners of the square to the vertex of K1 and sends each side (minus its vertices) homeomorphic ally ontoan open edge. The torus is then the quotient of$K^{1} \\\\% S$ by the equivalence relation that identifies eachx in the boundary of the square with its imageφ(x). see how the above construction generalizes to arbitrary presentations: given a presentation With this more abstract language in hand, it is easy to$P$ ≡ a $, . . . , a |r^{1}$, . . .
, rm, one takes a graph with a single vertex an(d1)nnfor each oriented loops, which are labeledr one attaches a polygonal disk by gluing itsa1, . . . , an. Thenj

boundary circuit to the sequence of oriented edges that traces out the word In general, the result will not be a surface as it was for$r^{j}$.a, b | ab(a-1 b)-1. Rather, it will be a two-dimensional complex with singularities along the edges and at the vertex. You may find it instructive to do some more examples. From from$a$, b, c, d | aaba| (a-2)1 bone gets the projective plane;$- {}^{1}$, cdc-1 d one gets a torus

441

and a Klein bottle stuck together at a point. picturing the 2-complex for$a$, b | a2, b3, (ab)3 is already rather difficult. logical group theory(mentioned earlier) implies that the fundamental group The construction of. The Seifert–van Kampen theorem K(P ) is the beginning of topo- ofno longer sits inertly in the form of an inscrutable K(P ) is the group presented by P .
But the group presentation—now it acts on the[III.93](/part-03/universal-covers) of K(P )by homeomorphisms known as “deck universal covering transformations.” Thus, through the simple con struc-tion of K(P ) (and the elegant theory of covering spaces in topology) we achieve our aim of realizing an abstract finitely presented group as the group of symmetries ofan object with a potentially rich structure, on which we can bring global geometric and topological techniques to bear.
group, we can embeda finite To obtain an improved topological model for our[III.34] in K(P )R^3 in) and consider the compact R^5 (just as one can embed four-dimensional manifold points that are a small fixed distance from the image.graph M obtained by taking all (I am assuming that the embedding is suitably “tame,”which one can arrange.) The mental picture to strive for here is a higher-dimensional analogue of the surface(sleeve) one gets by taking the points in R3 that are a small fixed distance from an embedded graph.
The fundamental group ofso now we have our arbitrary finitely presented group M is again the group presented by P, acting on a manifold (the universal cover of allows us to use the tools of analysis and differential M). This geometry. difficult implication of the theorem, promised earlier, that a group can be finitely presented if and only if The constructions of K(P ) and M establish the more it is the fundamental group of a compact cell com-plex and of a compact 4-manifold. This result raises several natural questions.
First, are there better, more informative, topological models for an arbitrary finitely presented group say about the classes of groups defined by the natu-Γ? And if not, then what can one ral constraints that arise when one tries to improve the model? For example, we would like to construct a lower-dimensional manifold with fundamental groupΓ , enabling us to exploit our physical insight into three- dimensional geometry. But it turns out that the fun-da mental groups of compact three-dimensional manifolds are very special;
this observation lies near the heart of a great deal of mathematics at the end ofthe twentieth century. Other interesting fields open up

442

when one asks which groups arise as the fund a men-tal groups of compact spaces satisfying curvature [III.13](/part-03/curvature) conditions, or constraints coming from complex geometry. A particularly rich set of constraints comes from the following question. Can one arrange for an arbitrary finitely presented group to be the fundamental group of a compact space (a complex or manifold, perhaps) whose universal cover isis a natural question from the point of view of topology contractible [IV.6 §2](/part-04/algebraic-topology)?
This because a space with a contractible universal cover is, up to homotopy [IV.6 §2](/part-04/algebraic-topology), completely determined by its fundamental group. If the fundamental group isΓ , then such a space is called aits homotopy-invariant properties provide a rich array classifying space forΓ and of invariants for the group gross dependence that K(P ) Γhas on(getting away from the P rather than Γ ). If our earlier discussion of how hard it is to recognize Γdependence can actually be removed, then your skep-from P has left you very skeptical about whether this ticism is well-founded:
there are many obstructions tothe construction of compact classifying spaces for an arbitrary finitely presented group; the study of them (under the generic name are a at the interface of modern group theory, topology, finiteness conditions) is a rich and homological algebra. One aspect of this area is the search for natural conditions that ensure the existence of compact classifying spaces (not necessarily manifolds). This is oneof several places where manifestations of nonpositive curvature play a fundamental role in modern group theory. More combinatorial conditions also arise.
For example, Lyndon proved that for any presentation A | rwhere the single defining relationr \in  F(A)P ≡is not a nontrivial power, the universal cover of contractible. K(P ) is cerns questions of uniqueness and rigidity for classi-A neighboring and highly active area of research conf ying spaces.
(Here, as is common, the wordis used to describe a situation in which requiring two rigidity objects to be equivalent in an apparently weak sense forces them to be equivalent in an apparently stronger sense.) For example, the (open) Borel conjecture asserts that if two compact manifolds have isomorphic funda-mental groups and contractible universal covers, then those manifolds must be homeomorphic. I have been talking mostly about realizing groups as fundamental groups, which led to certain free actions.
That is, we could interpret the elements of the group as symmetries of a topological space and none of these

IV. Branches of Mathematics

symmetries had any fixed points. Before moving on togeometric group theory I should point out that there are many situations in which the most illuminating actions of a group are not free: one instead allows wellunderstood stabilizers. (Theset of all symmetries in the group that leave that point stabilizer of a point is the fixed.) For example, the natural way in which to studyΓΔ is by its action on the triangulated plane, each vertex of which is left unmoved by twelve symmetries. A deeper illustration of the merits of seeking insight into algebraic structure through nonfree actions onsuitable
topological spaces comes from the Bass–Serre theory of groups acting on trees, which subsumes the theory of amalgamated free products and HNN exten-sions, whose potency we saw earlier. (This theory and its extensions often go under the heading of group theory.) arboreal A tree is a connected graph that has no circuits in it. It is helpful to regard it as awhich each edge has length 1. The group actions that metric space [III.56](/part-03/metric-spaces) in one allows on trees are those that take edges to edges isometrically, never flipping an edge.
If a groupΓ acts on a set X (in other words, if it can be regarded as a group of symmetries of orbit of a pointx \in  X is the set of all its images X), then thegx with gf ree product\in  Γ . A group A^*Γ can be expressed as an amalgamated B if and only if it acts on a tree in such a way that there are two orbits of vertices, one orbit of Cedges, and stabilizers stabilizers of adjacent vertices and intersect in A, B, C (where A and BCare the, which is the edge stabilizer). HNN extensions correspond to actions with one orbit of vertices and one orbit of edges.
Thus, amalgamated free products and HNN extensions appear asof Bass–Serre theory. These objects allow one to recover graphs of groups, which are the basic objects groups acting on trees from the quotient data of the action, i.e., the quotient space (which is a graph) and the pattern of edge and vertex stabilizers. and instructive proof that any finite subgroup ofis conjugate to a subgroup of either An early benefit of Bass–Serre theory is a transparent A or B: given any set(A*)C BVpointof vertices in a tree, there is a unique vertex or mid-x minimizing max\\{d(x, v) | v \in  V \\};
one applies this observation withxprovides a fixed point for the action of the subgroup; Van orbit of the finite subgroup; and any point stabilizer is conjugate to a subgroup of either A or B. Arboreal group theory goes much deeper than this first application suggests. It is the basis for a decompo-sition theory of finitely presented groups from which

IV.10. Geometric and Combinatorial Group Theory it emerges, for example, that there is an essentially canonical maximal splitting of an arbitrary finitely presented group as a graph of groups with cyclic edge stabilizers. This provides a striking parallel with the decomposition theory of 3-manifolds, a parallel that extends far beyond a mere analogy and accounts for much of the deepest work in geometric group theory in the past ten years. If you want to learn more about this, search the literature formay also want to search for complexes of groups JSJ decompositions, which.
You provide the appropriate higher-dimensional analogue for graphs of groups. 8 Geometric Group Theory Let us refresh the image ofby thinking again about the presentation K(P )in our mind’s eye P ≡ a, b |aba-1 b-1 of Z. The complex K(P ), as we saw earlier, is a torus. Now the torus can be defined as the quotientof the Euclidean plane R2 by the action of the group Z2 (where the point(m, n) \in  Z^2 acts as the translation(x, y) \to  (x + m, y + n)): in fact, R2, with an appropriate square tiling, is the universal cover of the torus.
Ifwe look at the orbit of the point 0 under this action, it forms a copy of large-scale geometry of Z2, and one can there by see the Z2 laid out for us. We can make the idea of the “geometry of Z2” precise by decreeing that edges of the tiling have length 1 and defining the graph distance between vertices to be the length of the shortest path of edges connecting them. As this example shows, the construction of K(P ) involves the two main (intertwined) strands of geomet-ric group theory.
In the first and more classical strand, one studies actions of groups on metric and topologi-cal spaces in order to elucidate the structures of both the space and the group (as with the action of Z2 on the plane in our example, or the action of the fundamental group of K(P ) on its universal cover in general). The quality of the insights that one obtains varies accord-ing to whether the action has or does not have certain desirable properties. The action of Z2 on R2 consists of isometries on a space with a fine geometric structure, and the quotient (the torus) is compact.
Such actions are in many ways ideal, but some times one accepts weaker admission criteria in order to obtain a more diverse class of groups, and some times one demands even more structure in order to narrow the focus and study groups and spaces of an exceptional, but for that reason interesting, character. with the second. In the second strand, one regards This first strand of geometric group theory mingles

443

finitely generated groups as geometric objects in their own right equipped with word metrics, which are defined as follows. Given a finite generating set S for a group each elementΓ, one defines theγ \in  Γ by an edge to each element of the Cayley graph of Γ by joining formγs or γs-1 with s \in  S (which is the same as the graph formed by the edges of the universal coveringof K(P )). The distance d (γ , γ ) between γ and γ is then the length of the shortest path from edges have length 1. Equivalently, it is the length of the(S1)2 γ1 1 to γ2 if all2 shortest word in the free group onγ-1γ in Γ .
S that is equal to 1 The word metric and the Cayley graph depend on the2 choice of generating set but their large-scale geometry does not. In order to make this idea precise, we introduce the notion of alence relation that identifies spaces that are similar on quasi-isometry. This is an equivaa large scale. If quasi-isometry from X and XYtoare two metric spaces, then a Y is a function φ: X \to Ywith the following two properties. First, there are pos-itive constantsc, C, and such that cd(x, x^ ) - ⩽d(φ(x), φ(x^ )) ⩽ Cd(x, x^ ) +:
this says thatφ dis- torts sufficiently large distances by at most a constant factor. Second, there is a constant C^  such that for everyy \in  Y there is some x \in  X for which d(φ(x), y) ⩽ C^: this says that every element ofφis a “quasi-surjection” in the sense that Y is close to the image of an element of Consider for example the two spaces$X$. R2 and Z2, where the metric on defined earlier. In this case the map Z2 is given by the graph distanceφ$: R2$\to  Z^2 that takes(x, y) to ( x!, y !) (where  x!
denotes the largest integer less than or equal tox) is easily seen to be a quasi-isometry:
if the Euclidean distance two points(x, y) and (x^ , y^ ) is at least 10, say, thend between the graph distance between will certainly lie between 1$(d xand 2!$, y !d). Notice how lit - and ( x^ !, y^ !) tle we care about the local structure of the two spaces:2 the map continuous.φ is a quasi-isometry despite not even being from X It is not hard to check that ifthat “quasi-inverts”X to Y , then there is a quasi-isometryφ, in the sense that everyφ is a quasi-isometryψ fromx Yin to X is at most a bounded distance fromin Y is at most a bounded distance fromψφ(x)φψ(y)and every.
Oncey one has established this, it is easy to see that quasi-isometry is an equivalence relation. Returning to Cayley graphs and word metrics, it turns out that if you take two different sets of generators forthe same group, then the resulting Cayley graphs will be

444

quasi-isometric. Thus, any property of a Cayley graph that is invariant under quasi-isometry will be a property not just of the graph but of the group itself. When dealing with such invariants we are free to think ofas a space (since we do not care which Cayley graph weΓ itself form), and we can replace it by any metric space thatis quasi-isometric to it, such as the universal cover of a closed Riemannian manifold with fundamental groupΓ (whose existence we discussed earlier). Then the tools of analysis can be brought to bear on it.
many people and often called the provides a crucial link between the two main strands A fundamental fact, discovered independently by Milnor–Švarc lemma, of geometric group theory. Let us call a metric space X a length space if the distance between each pair of points is the infimum of the lengths of paths joining them.
The Milnor–Švarc lemma states that if a groupΓ acts “properly discontinuously” as a set of isometries of a length spaceΓis finitely generated and quasi-isometric to X, and if the quotient is compact, then X (for any choice of word metric).We have seen an example of this already: Z2 is quasiisometric to the Euclidean plane. Less obviously, the same is true ofelementα of Γ Γto the point of^Δ. (Consider the map that takes each Z2 nearest α(0).) manifold is quasi-isometric to the universal cover of The fundamental group of a compact RiemannianΔ that manifold.
Therefore, from the point of view of quasi-isometry invariants, the study of such manifolds is equivalent to the study of arbitrary finitely presented groups. In a moment we will discuss some nontrivial consequences of this equivalence. But first let us reflect on the fact that, when finitely generated groups are considered as metric objects in the framework of large-scale geometry, they present us with a new challenge: we should quasi-isometry.
classify finitely generated groups up to less serves as a beacon in modern geometric group theory, one that has guided us toward many beauti-This is an impossible task, of course, but never the ful theorems, particularly under the general heading ofrigidity. For example, suppose that you come across a finitely generated groupΓ that is reminiscent of Zn on a large scale: in other words, quasi-isometric to it.
Weare not necessarily given any algebraically defined map between this mystery group andspires that such a group must contain a copy of Zn, and yet it tran-Zn as a subgroup of finite index. growth theorem At the heart of this result is, a landmark theorem published in Gromov’s polynomial-

IV. Branches of Mathematics

1981. This theorem concerns the number of points within a distancerof the identity in a finitely generated group interested in how the functionΓ . This will be a function f (r )f (r ), and Gromov was grows as r tends to infinity, and what that tells us about the group IfΓ is an Abelian group with d generators, then it isΓ . not hard to see thatf (r ) is at most (2 r + 1)d (since each generator is raised to a power between-r and r ). Thus, in this casemial inr .
At the other extreme, iff (r ) is bounded above by a polyno-Γ is a free group with two generators large, since all sequences of length a and b, say, then f (r )r that consist ofis exponentially as$and$ bs (and not their inverses) give different elements of Given this sharp contrast in behavior, one might won-Γ . der whether requiringa polynomial forcesΓ to exhibit a great deal of com-f (r ) to be bounded above by mutativity. Fortunately, there is a much-studied definition that makes this idea precise.
Given any group G and any subgroup H of G, the commutator [G, H] is the subgroup generated by all elements of the form$ghg^{-1}h^{-1}$, where g belongs to G and h belongs to H. If G is Abelian, then [G, H] contains just the identity. If G is not Abelian, then ta ins other elements be sides the identity, but it may be[G, G] forms a group G1 that con- that two-step nilpotent group. In general, a[G, G1] is trivial.
In that case, one says thatk-step nilpotent G is a group G = GGandis one where, if you form a sequence by setting G = [G, G ] for each i, then you even- tually reach the trivial group, and the first time you doso is at0 G . A nilpotenti+1 group is a group that isi k-step nilpotent for somek k. mial growth if and only if it has a nilpotent subgroupof finite index. This is a quite extraordinary fact: the Gromov’s theorem states that a group has polyno polynomial-growth condition is easily seen to be inde-pendent of the choice of word metric and to be an invariant of quasi-isometry.
Thus the seemingly rigid and purely algebraic condition of having a nilpotent subgroup of finite index is in fact a quasi-isometry invariant, and therefore a flabby, robust characteristic of the group. orems have been established for many other classes of groups, including lattices in semisimple Lie groups In the past fifteen years quasi-isometric rigidity theand the fundamental groups of compact 3-manifolds(where the classification up to quasi-isometry involves more than algebraic equivalences), as well as various classes defined in terms of their graph of group decompositions.
In order to prove theorems of this type, one

IV.10. Geometric and Combinatorial Group Theory must identify nontrivial invariants of quasi-isometry that allow one to distinguish and relate various classes of spaces. In many cases such invariants come from the development of suitable analogues of the tools of algebraic topology, modified so that they behave well with respect to quasi-isometries rather than continuous maps. 9 The Geometry of the Word Problem It is time to explain the comments I made earlier about the geometry inherent in the basic decision problems of combinatorial group theory.
I shall concentrate exclusively on the geometry of the word problem. mate connection between the highly geometric study Gromov’s filling theorem describes a startlingly intiof disks with minimal area in[I.3 §6.10](/part-01/fundamental-definitions) and the study of word problems, which riemannian geometry seems to belong more to algebra and logic. On the geometric side, the basic object of study is the isoperimetric function nian manifold M . Given any contractible closed path of Fill M (l) of a complete Rieman- length by that path.
The largest such area, over all closed pathsl, there is a disk of minimal area that is bounded of length metric function is the smallest function of which it isl, is defined to be Fill M(l). Thus, the isoperi- true to say that every closed path of len gthl can be filled by a disk of area at most Fill M (l). if one twists a circular wire of length The image to have in mind here is that of a soap film:
l in Euclidean space and dips it in soap, the film that forms has area atmostl2/4π, where as if one performs the same experi- ment in hyperbolic space [I.3 §6.6](/part-01/fundamental-definitions), the area of the film is bounded by a linear function ofthe isoperimetric functions of En land. Correspondingly, Hn (and quo- tients of them by groups of isometries) are quadratic and linear, respectively. In a moment we shall discuss what types of isoperimetric functions arise when one considers other geometries (more precisely, compact Riemannian manifolds).
To state the filling theorem we need to think about the algebraic side as well. Here, we identify a function that measures the complexity of a direct attack on the word problem for an arbitrary finitely presented groupΓ = A | R . If we wish to know whether a word w equals the identity in insight into the nature ofΓ and do not have any furtherΓ , then there is not much we can do other than repeatedly insert or remove the given relations r\in R. 445 In this group prove this? Well, Consider the simple exampleaba2 b represents the identity.
How do weΓ = a, b | b2 a, baba .aba2 b = a(b2 a)ba2 b = ab(baba)ab = abab = a(baba)a - 1 = aa - 1 = 1. Now let us think about the proof geometrically, via the Cayley graph. Sinceaba2 b = 1 in the group Γ , we obtain a cycle in this graph if we start at the identity and go along edges labeled a, b, a, a, b, in that order (in which case we visit the vertices 1, aba2 b = 1). The equalities in the proof can be thought a, ab, aba, aba2, of as a way of “contracting” this cycle down to the iden-tity by means of inserting or deleting small loops:
for instance, we could insert directions, since baba is a relation, or we could deleteb, a, b, a into the list of edge a trivial loop of the form$a$, a-1. This contraction can be given a more topological character if we turn our Cayley graph into a two-dimensional complex by filling in each small loop with a face. Then the contraction of the original cycle consists in gradually moving it across these small faces.
equals the identity is intimately connected with the Thus, the difficulty of demonstrating that a word$w$ area algebraically as the smallest sequence of relations youofw, denoted Area(w), which can be thought of need to insert and delete to turn geometrically as the smallest number of faces you needw into the identity, or to make a disk that fills the cycle represented by The Dehn functionδ: N \to N bounds Area(w)w. inΓ terms of the length|w| of the word w:δ (n) is theΓ largest area of any word of length at most1 inΓ .
If the Dehn function grows rapidly, then then that equals word problem is hard, since there are short words that are equal to the identity, but their area is very large, so that any demonstration that they are equal to the identity has to be very long. Results bounding the Dehn function are called isoperimetric inequalities. different finite presentations of the same group willin general yield different Dehn functions. This ambi-The subscript onδΓ is some what misleading since guity is tolerated because it is tightly controlled:
if the groups defined by two finite presentations are isomorphic, or just quasi - isometric, then the corresponding Dehn functions have similar growth rates. More precisely, they are times called the equivalent standard equivalence relation, with respect to what is some-“≃” of geometric group theory: given two monotone functionsf$, g:[0$, . nfty ) \to [0, . nfty ), one writes f g if there exists a constant C > 0 such that f (l) ⩽ Cg(Cl + C)+Cl + C for 446 all this relation to include functions from l ⩾ 0, and f ≃ g if f g and g f; and one extends N to[0,. nfty ).
You will have noticed a resemblance between the definitions of Fill relates them precisely: it states that$M (l) and δ^{Γ} (n)$. The filling theorem if M is a smooth compact manifold, then fundamental groupπ MFillof MM(l)$. ≃ δ^{Γ} (l)$, where Γ is the the torusδZFor example, since(l) is quadratic. T = R2/(Z2)1, which has Euclidean geometry, Z2 is the fundamental group of

9.1 What Are the Dehn Functions?

We have seen that the complexity of word problems is related to the study of isoperimetric problems in Riemannian and combinatorial geometry. Such insights have, in the last fifteen years, led to great advances inthe understanding of the nature of Dehn functions. For example, one can ask for which number st io nn^ρ is a Dehn function. The set of all such numbers,ρ the func- which can be shown to be countable, is known as the isoperimetric spectrum, denoted IP, and it is now largely understood.
son proved that the closure of IP is Following work by many authors, Brady and Brid-1 ∪ [2,\infty
). The finer structure of IP was described by Birget, Rips, and Sapir in terms of the time functions of Turing machines. A further result by the same authors and Ol’shanskii explains how fundamental Dehn functions are to understanding the complexity of arbitrary approaches to the word problem for finitely generated groupsΓis a subgroup of a finitely presented group with poly-Γ: the word problem forΓ lies in NP if and only if nomial Dehn function. (Here, NP is the class of prob-lems in the famous “P versus NP” question: see computational complexity this class.) [IV.20 §3](/part - 04/computational - complexity) for a description of The structure of IP raises an obvious question: What can one say about the two classes of groups singled outas special—those with linear Dehn functions and those with quadratic ones? The true nature of the class of groups with a quadratic Dehn function remains obscure for the moment but there is a beautifully definitive description of those with a linear Dehn function: they are thein the next section.word hyperbolic groups, which we shall discuss Not all Dehn functions are of the form nα: there are Dehn functions such as nα
. og n, for example, and others that grow more quickly than any iterated

IV. Branches of Mathematics

exponential, for example that of

$a$, b | ab(a-1 bab()-1 a()-1 b)-2.

If the word problem forΓ is unsolvable, then δ (n)Γ

will grow faster than any recursive function (indeed this serves as a definition of such groups). 9.2 The Word Problem and Geodesics Athat locally minimizes distance, such as a loop formed closed geodesic on a Riemannian manifold is a loop by an elastic band when released on a perfectly smooth surface. Examples such as the great circles on a sphere or the waist of an hourglass show that manifolds may contain closed geodesics that areis, they can be moved continuously until they are null - homotopic: that reduced to a point.
But can one construct a compact topological manifold with the property that no matter what metric one puts on it there will always be infinitely many such geodesics? (Technically, if you go around a geodesic loopntimes, then you get a geodesic; we avoid this by counting only “primitive” geodesics.) ing problem: all specific metric information has been stripped away and one has to deal with an arbitrary From a purely geometric point of view this is a dauntmetric on the floppy topological object left behind. But group theory provides a solution:
if the Dehn function of the fundamental group22 n , then in any Riemannian metric onπ1 M grows at least as fast as M there will be infinitely many closed geodesics that are null-homotopic The proof of this is too technical to sketch here. . 10 Which Groups Should One Study? Several special classes of groups have emerged from our previous discussion, such as nilpotent groups, 3-manifold groups, groups with linear Dehn functions, and groups with a single defining relation.
Now we shall change viewpoint and ask which groups present themselves for study as we set out to explore the universe ofall finitely presented groups, starting with the easiest ones. the finite groups. Finite groups are discussed in vari-ous other places in this volume, so I shall ignore them The trivial group comes first, of course, followed by in what follows and adopt the approach of large-scale geometry, blurring the distinction between groups that have a common subgroup of finite index. The first infinite group is surely Z, but what comes next is open to debate.
If one wants to retain the IV.10. Geometric and Combinatorial Group Theory safety of commutativity, then finitely generated Abe-lian groups come next. Then, as one slowly relinquishes commutativity and control over growth and construct i bility, one passes through the progressively larger classes of nilpotent, polycyclic, solvable, and elementary amenable groups. We have already met nil-potent groups in our discussion of Gromov’s polynomial-growth theorem.
They crop up in many contexts as the most natural generalization of Abelian groups and much is known about them, not least because one can prove a great deal by induction on thearek-step nilpotent. One can also exploit the fact thatk for which they Gis built from the finitely generated Abelian groups Gpolycyclic groups is built in a similar way, while finitely i/(Gi)+1 in a very controlled way. The larger class of generated solvable groups are built in a finite number of steps from Abelian groups that need not be finitely generated. This last class is not only larger but wilder;
the isomorphism problem is solvable among polycyclic groups, for example, but unsolvable among solvable groups. By definition a group series, defined inductively by GGis solvable if its(n) = [G((n - 1))$, Gderived((n - 1))] with$(G(()0){)} = G, terminates in a finite number of steps. tant link between geometry, analysis, and group theory. Solvable groups are amenable but not vice versa.
It is The concept known as amenability forms an impor not quite the case that a finitely presented group isamenable if and only if it does not contain a free subgroup of rank 2, but for a novice this serves as a good rule of thumb. Now, let us return to Z in a more adventurous frame of mind, throw away the security of commutativity, and start taking free products instead. In this more liberated approach, finitely generated free groups appear after Z as the first groups in the universe. What comes next?
Thinking geometrically, we might note that free groups are precisely those groups that have a tree as a Cayley graph and then ask which groups have Cayley graphs that are A key property of a tree is that all of its triangles are tree - like. degenerate: if you take any three points in the tree and join them by shortest paths, then every point in one of these paths is contained in at least one other path as well. This is a manifestation of the fact that trees are spaces of infinite negative curvature.
To get a feeling for why, consider what happens when one rescales the metric on a space of bounded negative curvature such as the hyperbolic plane H2. If we replace the standard distance function letn tend to . nfty , then the curvature of this space (ind(x, y) by (1/n)d(x, y) and 447 the classical sense of differential geometry) tends to−. nfty. This is captured by the fact that triangles look increasingly degenerate: there is a constantδ(n) \to 0 as n →. nfty, such that any side of a triangle inδ(n), with the scaled hyperbolic space$(H^{2}$, (1/n)d) is contained in the sides.
More colloquially, triangles inδ(n)-neighborhood of the union of the other two H2 are uniformly thin and get increasingly thin as one rescales the metric. away from trees by asking which groups have cayley graphs in which all triangles are uniformly thin. (It With this picture in mind, one might move a little makes little sense to specify the thinness constantδ since it will change when one changes generating set.)The answer is Gromov’s hyperbolic groups. This is a fascinating class of groups that has many equivalent definitions and arises in many contexts.
For example, we have already met it as the class of groups that have linear Dehn functions. (It is not at all obvious that these two definitions are equivalent.)Gromov’s great insight is that because the thin-triangles condition encapsulates so much of the essence of the large-scale geometry of negatively curved manifolds, hyperbolic groups share many of the rich proper-ties enjoyed by the groups that act nicely by isometries on such spaces.
Thus, for example, hyperbolic groups have only finitely many conjugacy classes of finite subgroups, contain no copy of Z2, and (after accounting for torsion) have compact classifying spaces. Their conjugacy problems can be solved in less than quadratic time, and Sela showed that one can even solve the isomorphism problem among torsion-free hyperbolic groups.
In addition to their many fascinating properties and natural definition, a further source of interest in hyperbolic groups is the fact that in a precise sta-tistical sense, a random finitely presented group will be hyperbolic. Spaces of negative and nonpositive curvature have played a central role in many branches of mathematics in the last twenty years. There is no room even to begin to justify this assertion here but it does guide us in where to look for natural enlargements of the class of hyperbolic groups:
we want nonpositively curved groups, defined by requiring that their Cayley graphs enjoy a key geometric feature that cocompact groups of isometries inherit from simply connected spaces of nonpositive curvature (“CATtrast to the hyperbolic case, the class of groups that one(0)spaces”). But in con obtains varies considerably when one perturbs the definition, and delineating the resulting classes and their(rich) properties has been the subject of much research.

448

one moves from negative to nonpositive curvature are exemplified by the fact that the isomorphism problem The added complications that one encounters when is unsolvable in one of the most prominent classes that arises: the so-called Let us now return to free groups and ask which combable groups. hyperbolic groups are the groups.
Remarkably, this vague question has a convinc-immediate neighbors of free ing answer. One of the great triumphs of arboreal group theory is the proof that there is a finite description of the set Hom finitely generated group(G, F) of homomorphisms from an arbitrary G to a free group F . The basic building blocks in this description are what Sela calls limit groups. One of the many ways of defining a limit group Lis that for each finite subset X ⊂ L there should exist a homomorphism to a finitely generated free group that is injective on X . first-order logic group in a precise sense.
To see how first-order logic Limit groups can also be defined as those whose[IV.23 §1](/part-04/logic-and-model-theory) resembles that of a free can be used to say something nontrivial about a group, consider the sentence

∀x, y, z(xy ≠ yx) ∨ (yz ≠ zy) ∨ (xz = zx) ∨ (y = 1). A group with this property isx commutes with y ≠ 1, and commutative transitivey commutes with z, then: if xhave this property but a direct product of non-abelian commutes with z. Free groups and Abelian groups free groups, for example, does not. It is a simple exercise to show that free Abelian groups are limit groups. But if one restricts attentionto groups that have precisely the same first-order logic as free groups, one gets a smaller class consisting onlyof hyperbolic groups.
The groups in this class are the subject of intense scrutiny at the moment. They all have negatively curved two-dimensional classifying spaces, built from graphs and hyperbolic surfaces in a hierar-chical manner. The fundamental groupsΣ of closed surfaces of genus stance to the traditional opinion in combinatorial groupg ⩾ 2 lie in this class, lending sub-g theory that, among nonfree groups, it is the groups that resemble free groups Fn most closely.
Σg sion, we arrive at the view that the groups free groups Incorporating this opinion into our earlier discus-F , and the groups Σ are the most basic Zn, the of infinite groups. This is the start of a rich vein of ideas involving the automorphisms of these groups.$n^{g}$ In particular, there are many striking parallels between

IV. Branches of Mathematics

their outer automorphism groups GLMod Out(Σ ) (the mapping class group)$. These^{n}(Z)$, Out(Fn), and three classes of groups play a fundamental role across a broad spectrum of mathematics. I have mentioned$g^{g}$ them here in order to make the point that, beyond the search for knowledge about natural classes of groups, there are certain “gems” in group theory that merit adeep and penetrating study in their own right.
Other groups that people might suggest for this category include Coxeter groups (generalized reflection groups, for whichlarly braid groupsΓΔ is a prototype) and Artin groups (particu-[III.4](/part-03/braid-groups), which again crop up in many branches of mathematics).I have thrown classes of groups at you thick and fast in this last section. Even so, there are many fas-cin at ing classes of groups and important issues that I have ignored completely.
But so it must be, for as Higman’s theorem assures us, the challenges, joys, and frustrations of finitely presented groups can never be exhausted.

Further Reading

Bridson, M. R., and A. Haefliger. 1999.Non-Positive Curvature. Grundlehren der Mathematis-Metric Spaces of Gromov, M. 1984. Infinite groups as geometric objects. Inchen Wissenschaften, volume 319. Berlin: Springer. Proceedings of the International Congress of Mathematicians, Warszawa, Poland, 1983 Warsaw: PWN. , volume 1, pp. 385–92. Geometric Group Theorycal Society Lecture Note Series, volume 182. Cambridge:. 1993. Asymptotic invariants of infinite groups. In, volume 2. London Mathemat i Lyndon, R. C., and P. E. Schupp. 2001.Cambridge University Press. Theory. Classics in Mathematics.
Berlin:
Springer. Combinatorial Group IV.11 Harmonic Analysis

Terence Tao

1 Introduction

Much of analysis tends to revolve around the study of general classes of[III.50](/part-03/linear-operators-and-their-properties). The functions are often real-valued or complex-functions [I.2 §2.2](/part-01/language-and-grammar) and operators valued, but may take values in other sets, such as a vector space [I.3 §2.3](/part-01/fundamental-definitions) or a manifold [I.3 §6.9](/part-01/fundamental-definitions). An operator is itself a function, but at a “second level,”because its domain and range are themselves spaces of functions:
that is, an operator takes a function (or per-haps more than one function) as its input and returns a transformed function as its output. Harmonic analysis

IV.11. Harmonic Analysis

focuses in particular on the such functions, and how these quantitative properties quantitative properties of change when various operators are applied to them.1 are two important examples. First, a function is saidto be What is a “quantitative property” of a function? here uniformly bounded if there is some real number M such that |f (x)| ⩽ M for every x. It can often be useful to know that two functions formly close,” which means that their differencef and gare “uni-f - g is uniformly bounded with a small bounda function is called square integrable if the integral M.
Second,|f (x)|2 dxis finite. The square integrable functions are important because they can be analyzed using the theory of hilbert spaces [III.37](/part - 03/bayesian - analysis). be the following: if a function integrable, its gradient A typical question in harmonic analysis might then. abla f exists, and all thef: R$n \to R \text{nis squarecompo}-$ nents of. abla f are also square integrable, does this imply thatn = 1, and no, but only just, when fis uniformly bounded? (The answer is yes when$n =$2;
this is a special case of theof fundamental importance in the analysis of Sobolev embedding theorem, which is partial differential equations precise bounds one can obtain? That is, given the inte-[IV.12](/part-04/analysis).) If so, what are the grals of$|f |^{2} and |(\nabla f ) |^{2}$, what can you say about thei

uniform bound Real and complex functions are of course very famil-M that you obtain for f? iar in mathematics, and one meets them in high school. In many cases one deals primarily with special functions ric functions, and other very concrete and explicitly[III.85](/part-03/special-functions): polynomials, exponentials, trigonomet defined functions. Such functions typically have a very rich algebraic and geometric structure, and many questions about them can be answered exactly using tech-niques from algebra and geometry. deal with functions that are not given by an explicit formula.
For example, the solutions to ordinary and However, in many mathematical contexts one has to partial differential equations often cannot be given inan explicit algebraic form (as a composition of familiar functions such as polynomials, tions [III.25](/part-03/the-exponential-and-logarithmic-functions), and trigonometric functions exponential func-[III.92](/part-03/trigonometric-functions)). In such cases, how does one think about a function? The able harmonic analysisanalysis1. Strictly speaking, this sentence describes the field of, which is primarily concerned with how real- or complex-.
There is another field called abstract harmonic real-varivalued functions (often on very general domains) can be studied using symmetries such as translations or rotations (for instance, via the Fourier transform and its relatives); this field is of course related toreal-variable harmonic analysis, but is perhaps closer in spirit to representation theory and functional analysis, and will not be discussed here.

449

answer is to focus on its deduced from them: even if the solution of a differ en-properties and see what can be tial equation cannot be described by a useful formula, one may well be able to establish certain basic facts about it and be able to derive interesting consequences from those facts. Some examples of properties that one might look at are measurability, boundedness, continuity, differentiabili ty, smoothness, analyticity, integra-bility, or quick decay at infinity. One is thus led to consider interesting general classes of functions:
to form such a class one chooses a property and takes the setof all functions with that property. Generally speaking, analysis is much more concerned with these general classes of functions than with individual functions. (See also This approach can in fact be useful even when one function spaces [III.29](/part-03/function-spaces).) is analyzing a single function that is very structured and has an explicit formula.
It is not always easy, oreven possible, to exploit this structure and formula in a purely algebraic manner, and then one must rely (at least in part) on more analytical tools instead. A typical example is the Airy function. nfty Ai$(x) =−$. nfty(ei)(xξ+ ξ 3 ) dξ. Although this is defined explicitly as a certain integral, if one wants to answer such basic questions as whether Aiintegral goes to zero as(x) is always a convergent integral, and whether thisx → ±. nfty, it is easiest to proceed using the tools of harmonic analysis.
In this case, onecan use a technique known as the principle of stationary phase although there is the rather surprising fact that the Airyto answer both these questions affirmatively, function decays almost exponentially fast asbut only polynomially fast as$x$ → −$\infty$. x → +. nfty, ticular ly concerned not just with qualitative proper-ties like the ones mentioned earlier, but also with Harmonic analysis, as a subfield of analysis, is par quantitative bounds instance, instead of merely knowing that a function that relate to those properties. For fit is.
That is, what is theis bounded, one may wish to know smallest M ⩾how0 such that bounded|ber is known as thef (x)| ⩽ M for all (or almost all)sup norm or Lx. nfty -norm\in  R; this num-off , and is denoted square integrable one can quantify this by intro duc in gf L. nfty  . Or instead of assuming that f is theone can quantify L2-norm f Lp2 th-power integrability for 0= ( |f (x)|2 dx()1()/){2}; more generally$< p < \infty$ via the most of the other qualitative properties mentioned Lp - norm (f L)p = ( |f (x)|p dx()1)/p.
Similarly, above can be quantified by a variety of norms [III.62](/part-03/normed-spaces-and-banach-spaces), 450 which assign a nonnegative number (or+. nfty) to any given function and which provide some quantitative measure of one characteristic of that function.
be sides being of importance in pure harmonic analysis, quantitative estimates involving these norms are also useful in applied mathematics, for instance in performing an error analysis of some numerical algorithm. Functions tend to have infinitely many degrees of freedom, and it is thus unsurprising that the number of norms one can place on a function is infinite as well: there are many ways of quantifying how “large” a func-tion is. These norms can often differ quite dramatically from each other.
For instance, if a function large for just a few values, so that its graph has tall, f is very thin “spikes,” then it will have a very large L . nfty - norm, but|f (x)| dx, its L1-norm, may well be quite small. Conversely, ifthen it is possible forf has a very broad and spread-out graph,|f (x)| dx to be very large even if large|f (x)L1|-norm but a small is small for every L. nfty x-norm. Similar examples: such a function has a can be constructed to show that the times behaves very differently from either the L2 - norm some - L1 - normor the L. nfty -norm.
However, it turns out that the L2-norm lies “between” these two norms, in the sense that if one controls both the L1-norm and the L. nfty -norm, then one also automatically controls thereason is that if the L. nfty -norm is not too large then one L2-norm. Intuitively, the eliminates all the spiky functions, and if the L1 - norm is small then one eliminates most of the broad functions; the remaining functions end up being well-behaved in the intermediate L2-norm.
More quantitatively, we have the inequality(f L)2 ⩽ (f1()L()/){1}2 (f1()L)/ . nfty2, which follows easily from the trivial algebraic fact thatif|f (x)| ⩽ M, then |f (x)|2 ⩽ M |f (x)|. This inequality is a special case ofis one of the fundamental inequalities in harmonichölder’s inequality [V.19](/part - 05/inequalities), which analysis.
The idea that control of two “extreme” norms automatically implies further control on “intermediate” norms can be generalized tremendously and leads to very powerful and convenient methods known as interpolation The study of a single function and all its norms, which is another basic tool in this area. eventually gets some what tiresome, though. Nearly all fields of mathematics become a lot more interesting when one considers not just objects, but also between objects.
In our case, the objects in question maps are functions, and, as was mentioned in the intro duc - tion, a map that takes functions to functions is usually IV. Branches of Mathematics referred to as an called a transform operator[III.91](/part - 03/transforms).) Operators may seem like. (In some contexts it is also fairly complicated mathematical objects—their inputs and outputs are functions, which in turn have inputs and outputs that are usually numbers—but they are infact a very natural concept since there are many situations where one wants to transform functions.
For example, differentiation can be thought of as an operator, which takes a function This operator has a well-known (partial) inverse, f to its derivative df /inte-dx. gration, which takesf to the function Fthat is defined by the formula

$F(x) = {}^{−}\infty^{x} f (y)dy$.

A less intuitive, but particularly important, example is the fourier transform [III.27](/part-03/the-fourier-transform). This takesf to a function ˆf , given by the formula. nftyf (x)ˆ=−. nfty (e-2()π){i}xy f (y)dy.

It is also of interest to consider operators that take two or more inputs. Two particularly common examples are theg are two functions, then their pointwise product pointwise product and convolution. If f andf g is defined in the obvious way:

$(f g)(x) = f (x)g(x)$.

The convolution, denoted$f^{*} g$, is defined as follows: $f^{*} g(x) = {}^{−}$. nfty$\infty f (y)g(x - y) dy$. This is just a very small sample of interesting opera-tors that one might look at. The original purpose of harmonic analysis was to understand the operators that were connected to Fourier analysis, real analysis, and complex analysis. Nowadays, however, the subject has grown considerably, and the methods of harmonic analysis have been brought to bear on a much broader set of operators.
For example, they have been particularly fruitful in understanding the solutions of vari-ous linear and nonlinear partial differential equations, since the solution of any such equation can be viewed as an operator applied to the initial conditions. They are also very useful in analytic and combinatorial number theory, when one is faced with understanding the oscillation present in various expressions such as exponential sums.
Harmonic analysis has also been applied to analyze operators that arise in geometric measure theory, probability theory, ergodic theory, numerical analysis, and differential geometry. A primary concern of harmonic analysis is to obtain both qualitative and quantitative information about

IV.11. Harmonic Analysis

the effects of these operators on generic functions. A typical example of a quantitative estimate is the inequality

f* g L . nfty ⩽ (f L)2 (g L)2,

which is true for all$f$, g \in L2. This result, which is a special case ofjust writes out the definition of Young’s inequality$f$, is easy to prove: one${}^{*} g(x) \text{and applies}$ the cauchy–schwarz inequality [V.19](/part - 05/inequalities). As a consequence, one can draw the qualitative conclusion that the convolution of two functions in$L^{2} \text{is always con}-$ tinuous.
Let us briefly sketch the argument, since it is an instructive one. A fundamental fact about functions in$L^{2} \text{is that any}$ such function(in the$L^{2}$-norm) by a function  ̃f can be approximated arbitrarily wellf that is continuous and compactly supported$f$ ̃ takes the value zero every where out side some inter-. (The second condition means that val$f$ ̃ and  ̃[-M, M]g be approximations of this kind.
It is an exercise.) Given any two functions f and g in L2, let in real analysis to prove that  ̃$f^{*} g$ ̃ is continuous, and it follows easily from the inequality above that  ̃close tof* g in the L. nfty -norm, since f* g ̃ is $f^{*} g - f$ ̃${}^{*} g$ ̃$= f^{*} (g - g) ̃$+ (f - f ) ̃${}^{*} g$. ̃ Therefore, in the L. nfty -norm by continuous functions. A standardf* g can be approximated arbitrarily well result in basic real analysis (that a uniform limit of con-tinuous functions is continuous) now tells us that$f^{*} g$ is continuous. occurs frequently in harmonic analysis.
First, one iden-Notice the general structure of this argument, which tifies a “simple” class of functions for which one can easily prove the result one wants. Next, one proves that every function in a much wider class can be approximated in a suitable sense by simple functions. Finally, one uses this information to deduce that the result holds for functions in the wider class as well.
In our case, the simple functions were the continuous func-tions of finite support, the wider class consisted of square-integrable functions, and the suitable sense of approximation was closeness in the$L^{2} - norm$. tive and quantitative analysis of operators in the next We shall give some further examples of qu al it a section. 2 Example: Fourier Summation To illustrate the interplay between quantitative and qualitative results, we shall now sketch some of the

451

basic theory of summation of Fourier series, which his-tori cally was one of the main motivations for studying harmonic analysis. In this section, we shall consider functionsf that are periodicf (x + 2π)with period 2 = f (x) for allπ: that is, functions such thatx. An example of such a func- tion isf (x) = 3 + . in (x) - 2 cos(3 x). A function like this, which can be written as a finite linear combina-tion of functions of the form sin(nx) and cos(nx), is called a trigonometric polynomial.
The word “polynomial” is used here because any such function can beexpressed as a polynomial in sin(x) and cos(x), or alternatively, and some what more conveniently, as apolynomial in eix and (e-i)x. That is, it can be written asficients$N^{n}=−(c^{N} c^{n}e$: inx-Nfor some⩽ n ⩽ NN)and some choice of coef-. If we know that f can be expressed in this form, then we can work out the coefficient ncn quite easily: it is given by the formula

cn = 21(π0()2){π} f (x)(e-i)nx dx.

can say something similar about a much wider class offunctions—if, that is, we now allow It is a remarkable and very important fact that weinfinite linear combinations. Suppose that also continuous (or, more generally, thatf is a periodic function that isf is absolutely integrable, meaning that the integral of|f (x)| between 0 and 2 ficientsπf (n)ˆ is finite). We can then define theoff , using exactly the formula we had Fourier coef- above for$c^{n}$:

f (n)ˆ= 21(π0()2){π} f (x)(e-i)nx dx.

The example of trigonometric polynomials now sug-gests that one should have the identity

$f (x) = n=−\infty\infty f (n)$ˆ einx,

expressing nomial,” but this is not always true, and even when it is$f$as a sort of “infinite trigonometric poly true it takes some effort to justify it rigorously, or even to say precisely what the infinite sum means. To make the question more precise, let us introduce for each natural number operator$S^{N}$. This takes a function N the Dirichlet summationf to the function SN fthat is defined by the formula

SN f (x) =n=−N N f (n)ˆ einx.

The question we would like to answer is whether converges tof as N → $\infty$. The answer turns out to SN f be surprisingly complicated: not only does it depend

452

on the assumptions that one places on the function but it also depends critically on how one defines “con-f , vergence.” For example, if we assume thatf is con- tinuous and ask for the convergence to be uniform, then the answer is very definitely no: there are examples of continuous functions even converge pointwise toff. However, if we ask forfor which SN f does not a weaker form of convergence, the answer is yes:
will necessarily converge tof in the Lp topology for SN f any 0< p < . nfty , and even though it does not have to converge pointwise, it will converge where, meaning that the set ofx for which almost every-SN f (x) does not converge toone assumes only thatx has measuref is absolutely integrable, then[III.55](/part-03/measures) zero. If instead it is possible for the partial sums SNf to diverge at every single point Lp topology for everyx, as well as being divergent in thep such that 0 < p ⩽ . nfty .
The proofs of all of these results ultimately rely on very quantitative results in harmonic analysis, and in particular on various Lp -type estimates on the Dirichlet sum SN f (x), as well as estimates connected with the closely related function sup maximal operator|S f (x)|. , which takes f to the discuss a simpler result, in which the Dirichlet summa-tion operators As these results are a little tricky to prove, let us first N>S0 are replaced by the NFejér summation operators age of the first FN. For each NNDirichlet operators:
that is, it is given N, the operator FN is the aver- by the formula

FN = N1 (S0 + · · · + (SN)-1).

It is not hard to show that ifso does FN f . However, by averaging the SN f converges to SN f we allowf , then cancellations to take place that some times make it pos-sible for F f to converge to f even when S f does not. Indeed, here is a sketch of a proof thattof whenever N fis continuous and periodic—which, as(FN)Nf converges we have seen, is far from true of In its basic structure, the argument is similar to the$S^{N} f$. one we used when showing that the convolution oftwo functions in L2 is continuous.
Note first that the result is easy to prove when nomial, since then S f = ff for every is a trigonometric poly-N from some point onward. Now theorem says that every continuous periodic function N Weierstrass approximation the-f can be uniformly approximated by trigonometric poly-nomials: that is, for everyε > 0 there is a trigonomet- ric polynomial such thatf - g L. nfty  ⩽ ε. We know that Fpolynomial), and would like to deduce the same for N g is close to g for large N (since g is a trigonomet ri cf .

IV. Branches of Mathematics

manipulation to prove the identity The first step is to use some routine trigonometric FN f (x) = {}-ππ N . in . in2( {}212(Ny)1 y) f (x - y) dy. The precise form of this expression is less important than two properties of the function2

u(y) = N. in . in2(2 1 2(Ny()1)2 y)

that we shall use. One is that ative and the other is thatπ u(y)u(y)dis always nonneg-y = 1. These two-^π

facts allow us to say that

FN h(x) =- π π u(y)h(x - y) dy⩽ h L . nfty - π π u(y) dy = h L . nfty .

That is, FN h L. nfty  ⩽ h L. nfty  for any bounded function h. nomial Then we find that To apply this result, we choose a trigonometric poly-g such that Ff h- g. nfty L= . nfty  ⩽Fε fand let- F gh =. nfty  ⩽f -ε asg. well. As mentioned above, if we choose then$F g - g ⩽ ε^{N}$, and then we use th(e L)N Nn large enough, L inequality N [V.19](/part-05/inequalities) to say that L. nfty  triangle FN f - f L. nfty⩽ FN f - FNg L. nfty  + FN g - g L. nfty  + g - f L. nfty . Since each term on the right-hand side is at most this shows that F f - f is at most 3ε.
And sinceε,εconverges tocan be made arbitrarily small, this shows thatf .N L. nfty  FN f inequality shows that A similar argument (using[V.19](/part-05/inequalities) instead of the triangle inequality)F f ⩽ fminkowski’s integral for all 1⩽ p ⩽ . nfty , fify the above argument to show that\in  Lp, and NN⩾ 1. As a consequence, one can mod-Lp Lp Ff converges tomore difficult result (relying on a basic result in har-f in the Lp topology for every f \in NLp.
A slightly monic analysis known as themal inequality) asserts that, for every 1 Hardy–Littlewood maxi-$< p ⩽ \infty$, there exists a constant. up  |F f | ⩽CCp such that one has the inequalityf for all f \in  Lp; as a consequence, one can show that every where for every(NN)Lppf L. np FNLfp converges toand 1 < p f⩽almost. nfty . A slight modification of this argument also allows oneto treat the endpoint case whenf is merely assumed to be absolutely integrable; see the discussion on the Hardy–Littlewood maximal inequality at the end of this article.

IV.11. Harmonic Analysis

Using some fairly sophisticated techniques in harmonic analysis (such as Calderón–Zygmund theory) one can Now let us return briefly to Dirichlet summation. show that when 1< p < . nfty the Dirichlet operators S are bounded in eve ryp in this range there exists a positive real num-Lp uniformly in N. In other words, for N bertion Cfp insuch that Lp and every nonnegative integer SN (f L)p ⩽ Cp (f L)p for every func-N. As a consequence, one can show thatin the Lp topology for all f in L(Sp)Nand everyf converges top suchf that 1 on S < p <fails at the endpoints. nfty .
However, the quantitative estimatep = 1 and p = $\infty$, and from this one can also show that the convergence$N$ result also fails at these endpoints (either by explic-itly constructing a counterexample or by using general results such as the so-called principle). uniform boundedness What happens if we ask for SN f to converge tof does not follow from convergence in almost every where? Almost-every where convergence Lp when p <. nfty , so we cannot use the above results to prove it.
It turns out to be a much harder question, and was a famous open problem, eventually answered by carleson’s theorem Carleson proved that one has an estimate of the form[V.5](/part - 05/carlesons - theorem) and an extension of it by Hunt. Hunt generalized the proof to cover allp <. up N. nfty |S. This result implies that the Dirichlet sums N f (|L)p ⩽ Cp (f L)p in the case pp = with 12, and< of an Lp function do indeed converge almost every- where when 1 estimate fails at the endpoint< p ⩽ . nfty .
On the other hand, thisp = 1, and there is in fact an example due to absolutely integrable function whose Dirichlet sums kolmogorov [VI.88](/part - 06/andrei - nikolaevich - kolmogorov - 19031987) of an are every where divergent. These results require a lotof harmonic analysis theory. In particular they use many decompositions of both the spatial variable andthe frequency variable, keeping the Heisenberg uncertainty principle in mind. They then carefully reassemble the pieces, exploiting various manifestations of orthogonality.
To summarize, quantitative estimates such as$Lp$estimates on various operators provide an important route to establishing qualitative results, such as convergence of certain series or sequences. In fact there area number of principles (notably the uniform boundedness principle and a result known asprinciple) which assert that in certain circumstances Stein’s maximal this is the only route, in the sense that a quantitative estimate must exist in order for the qualitative result to be true. 453 3 Some General Themes in Harmonic Analysis:
Decomposition, Oscillation, and Geometry One feature of harmonic analysis methods is that they tend to be local rather than global. For instance, if one is analyzing a function pose it as a sumf = f +· · ·+f it is quite common to decom - f , with each function f “localized” in the sense that its support (the set of val-uesx for which f (x)1 = 0) has a small diameter. Thi(sk)ii would be called localization in the spatial variable. One can also localize in thethe process to the Fourier transform ˆfrequency variablef ofby applyingf .
Having split the pieces separately and then recombine them later.f up like this, one can carry out estimates for One reason for this “divide and conquer” strategy isthat a typical function ftends to have many different features—for example, it may be very “spiky,” “dis-continuous,” or “high frequency” in some places, and “smooth” or “low frequency” in others—and it is diffi-cult to treat all of these features at once. A well-chosen decomposition of the function tures from each other, so that each component has onlyf can isolate these fea- one salient feature that could cause difficulty:
the spiky part can go into onef , the high-frequency part intoi

another, and so on. In reassembling the estimates from the individual components, one can use crude tools such as the triangle inequality or more refined tools, for instance those relying on some sort of orthogonality, or perhaps a clever algorithm that groups the com-pone nts into manageable clusters. The main drawback of the decomposition method (other than an aesthetic one) is that it tends to give bounds that are not quite optimal;
however, in many cases one is content with anestimate that differs from the best possible one by a multiplicative constant. To give a simple example of the method of decomposition, let us consider the Fourier transform ˆfunction$f$: R$\to C$, defined (for suitably nice functionsf (ξ) of af ) by the formul af (ξ)ˆ= R f (x)(e-2()π){i}xξ dx.

What we can say about the size of ˆf , as measured by suitable norms, if we are given information about the size of$f$, as measured by other norms? question. First, since the modulus of eequal to 1, it follows that Here are two simple observations in response to this|f (ξ)ˆ| is at mos(t-2()π){i}xξ|f (x)is always|dx. This tells us that particular, ˆf \in  L. nfty . Secondly, the Plancherel theorem, afˆL . nfty ⩽ (f L)1, at least if R f \in  L1. In very basic fact of Fourier analysis, tells us that$f$ˆ$L2 is$

454

equal tothen so does ˆ$f Lf2$.if f \in L2. Therefore, if f belongs to L2 an intermediate if 1 We would now like to know what happens if$< p <$2? Since Lp space. In other words, what happens Lp is not contained in eitherf lies in L1 ordirectly. However, let us take a function$L2$, one cannot use either of the above two resultsf \in  Lp and consider what the difficulty is. The reason lie in L1 is that it may decay too slowly: for instance, f may not the functionf (x) = (1 + |x|)-3/4 tends to zero more slowly than 1/x as x → . nfty, so its integral is infinite.
However, if we raise function(1 + |x|)-9/8 f which decays quickly enough toto the power 3/2 we obtain the have a finite integral, sof does belong to L3/2. Similar examples show that the reason L2 is that it can have places where it tends to infinit yf may fail to belong to slowly enough for the integral ofnot slowly enough for the integral of|f |p|fto be finite but|2 to be finite. ent. Therefore, we can try to decompose Notice that these two reasons are completely differ-f into two pieces, one consisting of the part where the other consisting of the part wheref fis small.
Thatis large and is, we can choose some thresholdbe$f (x) when |f (x)| < λ$and 0 otherwise, and define. ambda and definef1(x) tof Then2(x)fto be+ f f (x)= f , and whe nf|f (x)and|f⩾are the “small part”$\lambda\text{and} 0 otherwise$. and “large part” of Because1$|f2 (x)| < \lambda f$, respectively.for every1 x2, we find that $|f1(x)(|2)1= |f1(x)(|2)-p |f1(x)|p < λ2 - p|f1(x)|p$. Therefore, Similarly, becausef1 belongs to|f (x)|L⩾2 and. ambda whenever(f1)L 2 ⩽f λ(x)2-p = f0, w(e1)L p.
have the inequalityx, which tells us that|2 ff2(x)belongs to| ⩽ |f2(x)L1 |and thatp /. ambda p 2 -1 for everyf ⩽ 2 2 L1 f From our knowledge about th(e2()L)p /. ambda p -1. L2 - norm of f and thethe L(L1)2 - norm of-norm of ˆff2 we can obtain upper bounds forand the L. nfty-norm of ˆ$f$, by our1 remarks above. By using this strategy for every combining the results in a clever way, one can obtain1 2. ambda and the assertion. Let Hausdorff–Young inequalityp lie between 1 and 2 and let, which is the followingp^  be the dual exponent ofp, which is the number p/(p - 1).
Then there is a constant tion$f \in L^{p}$, one has the inequality Cp such that, for every func-fˆ⩽ C f . The particular decomposition method we have used to obtain this result is formally known as the method of(Lp()p()L)p real interpolation value of C , which turns out to be. It does not give the best possible(p1()/){2}p /(p^ ()1()/){2}p^ , but that requires more delicate methods.$p$

IV. Branches of Mathematics

attempt to quantify the elusive phenomenon oftion Another basic theme in harmonic analysis is the. Intuitively, if an expression oscillates wildly, then oscil la we expect its average value to be relatively small in magnitude, since the positive and negative parts, or inthe complex case the parts with a wide range of different arguments, will cancel out. For instance, if a 2 periodic functionf is smooth, then for large n theπ-

Fourier coefficient

f (n)ˆ= 21(π-()π){π} f (x)(e-i)nx

will be very small since- {}ππ (e-i)nx = 0 and the com- paratively slow variation instop the cancellation occurring. This assertion can eas-f (x) is not enough to ily be proved rigorously by repeated integration by parts. Generalizations of this phenomenon include the so-called principle of stationary phase, which among other things allows one to obtain precise control onthe Airy function Ai(x) discussed earlier.
It also yields the Heisenberg uncertainty principle, which relates the decay and smoothness of a function to the decay and smoothness of its Fourier transform. A some what different manifestation of oscillation lies in the principle that if one has a sequence of func-tions that oscillate in different ways, then their sum should be significantly smaller than the bound that follows from the triangle inequality. Again, this is the result of cancellation that is simply not noticed by the triangle inequality.
For instance, the Plancherel theo-rem in Fourier analysis implies, among other things, that a trigonometric polynomial L2 - norm o(f N)n=−N cn(ei)nx has an 2(πN()2){1}/ 2 N 1 / 2 2(π0)n=−N cn(ei)nx = n=−N |cn|2. This bound (which can also be proved by direct calcu-lation) is smaller than the upper bound of N |c | that would be obtained if we simply applied the trian-gle inequality to the functionsc (ei)nx.
This identity cann=−N n be viewed as a special case of the Pythagorean theo-rem, together with the observation that the harmonics$n$ einx are all orthogonal to each other with respect to the inner product [III.37](/part-03/bayesian-analysis)

$f$, g = 21π0 2 π f (x)g(x) dx.

This concept of orthogonality has been generalized ina number of ways. For instance, there is a more general and robust concept of “almost orthogonality,” which roughly speaking means that the inner products of acollection of functions are small but not necessarily 0.

IV.12. Partial Differential Equations

point, involve a combinatorial statement about certain types of geometric objects such as cubes, balls, or Many arguments in harmonic analysis will, at some boxes. For instance, one useful such statement is the Vitali covering lemma, which asserts that, given any collection will be a subcollection$B^{1}$, . . . , Bk of balls in Euclidean space B , . . . , B of balls that are dis-Rn, there joint, but that nevertheless contain a significant frac-tion of the volume covered by the original balls.
To be(i1()i)m precise, one can choose the disjoint balls so that vol$j$.m=1 (Bi)j ⩾ 5-n volj$.=k 1Bj$.(The constant 5-n can be improved, but this will not concern us here.) This result is obtained by a “greedy algorithm”: one picks balls one by one, at each stage choosing the largest ball among the B that is dis jointj

from all the balls already selected. One consequence of the Vitali covering lemma is the briefly describe. Given any function Hardy–Littlewood maximal inequalityf \in , which we will L1(Rn)$, anyx \in Rn$, and any r > 0, we can calculate the average$of$|f | in the n-dimensional sphere B(x, r ) of center x and radius F of f by lettingr. Next, we can define the F(x) be the largest of all these aver-maximal function ages asprecisely, one takes the supremum.) Then, for each pos-r ranges over all positive real numbers.
(More itive real number. ambda one can define a set X. ambda to be the set of all i mal inequality asserts that the volume ofx such that F(x) > λ. The Hardy–Littlewood max-$X^{λ} \text{is at most}$ 5 n To prove it, one observes that(f L)1/λ.2 X can be covered by balls B(x, r ) on each of which the integral ofλ |f | is at least then apply the Vitali covering lemma, and the result. ambda vol(B(x, r )). To this collection of balls one can follows. The Hardy–Littlewood maximal inequality isa quantitative result, but it has as a qualitative consequence the asserts the following.
If Lebesgue differentiation the or emf is any absolutely integrable, which function defined on Rn, then for almost every x \in  Rn the averages

f (y) dy vol(B(x, r ))B(x, r ) ofasfr over the Euclidean balls about \to 0. This example demonstrates the impor - x tend to f (x) different from the one mentioned briefly in the previous section, butone can deduce that inequality from this one by the real interpolation2. This version of the Hardy–Littlewood inequality looks some what method discussed earlier. 455 tance of the underlying geometry (in this case, the combinatorics of metric balls) in harmonic analysis. Further Reading Stein, E. M. 1970.Properties of Functions Singular Integrals and differentiabili ty. Princeton, NJ:
Princeton University Press.. 1993. Harmonic Analysis. Princeton, NJ: Princeton Wolff, T. H. 2003.University Press.by I. Łaba and C. Shubin. University Lecture Series, vol-Lectures on Harmonic Analysis, edited ume 29. Providence, RI: American Mathematical Society. IV.12 Partial Differential Equations Sergiu Klainerman Introduction Partial differential equations (or PDEs) are an important class ofor systems of equations, in which the unknowns are functional equations: they are equations, functions of more than one variable.
As a very crude analogy, PDEs are to functions as polynomial equations (such asx2 + y2 = 1, for example) are to num - bers. The distinguishing feature of PDEs, as opposed tomore general functional equations, is that they involve not only unknown functions, but also various derivatives of those functions, in algebraic combina-partial tion with each other and with other, fixed, functions.
Other important kinds of functional equations are gral equations, which involve various integrals of the in te unknown functions, and(ODEs), in which the unknown functions depend onordinary differential equations only one independent variable (such as a time variable td) and the equation involves only ordinary derivatives/dt, d2/dt2$, d3/dt3$, . . . of these functions. hope to do is to give a very crude perspective on some Given the immense scope of the subject the best I can of the main issues and an even cruder idea of the mul-titude of current research directions.
The difficulty one faces in trying to describe the subject of PDEs starts with its very definition. Is it a unified area of mathematics, devoted to the study of a clearly defined set of objects (in the way that algebraic geometry studies solutions of polynomial equations or topology studies manifolds, for example), or is it rather a collection ofseparate fields, such as general relativity, several complex variables, or hydrodynamics, each one vast in its own right and centered on a particular, very difficult, equation or class of equations? I will attempt to argue

456

below that, even though there are fundamental diff i cul-ties in formulating a general theory of PDEs, one can nevertheless find a remarkable unity between various branches of mathematics and physics that are centeredon individual PDEs or classes of PDEs. In particular, certain ideas and methods in PDEs have turned out to be extraordinarily effective across the boundaries of these separate fields. It is thus no surprise that the most successful book ever written about PDEs did not mention PDEs in its title:
it was Methods of Mathematical Physics by As it is impossible to do full justice to such a huge courant [VI.83](/part-06/richard-courant-18881972) and hilbert [VI.63](/part-06/david-hilbert-18621943). subject in such limited space I have been forced to leave out many topics and relevant details; in particular, I have said very little about the fundamental issue ofbreakdown of solutions, and there is no discussion of the main open problems in PDEs.
A longer and more detailed version of the article, which includes these topics, can be found at http://press.princeton.edu/titles/8350.html 1 Basic Definitions and Examples The simplest example of a PDE is the tion [I.3 §5.4](/part - 01/fundamental - definitions) laplace equa$\Delta u = 0$.
(1) Here, that transforms functions. elta is the Laplacian, that is, theu = u(xd if fer en ti al operator, x , x )defined 1 2 3 from R3 to R according to the rule$\Delta u(x1$, x2$, x3)= \partial1 2 u(x1$, x2$, x3)+ \partial2 2 u(x1$, x2$, x3) +\partial3 2 u(x1$, x2$, x3)$, wheretial derivatives$\partial^{1}$, ∂2, ∂3∂/∂xare standard shorthand for the par-1, . artial/. artial x2, ∂/∂x3. (We will use this shorthand through out the article.) Two other funda-mental examples (also described in [I.3 §5.4](/part-01/fundamental-definitions)) are the heat equation and the wave equation:

$-\partial u + k\Delta u = 0$, (2)t-∂2 u + c2Δu = 0. (3)t

In each case one is asked to find a function satisfies the corresponding equations. For the Laplaceu that equation other two it will depend onu will depend ontxas well. Observe that equa-1$, x2$, and x3, and for the tions (2) and (3) again involve the symbolΔ, but also partial derivatives with respect to the time variable The constantsk (which is positive) and care fixed andt. represent the rate of diffusion and the speed of light, respectively. However, from a mathematical point of

IV. Branches of Mathematics

view they are not important, since ifa solution of (3), for example, thenv(t$, xu(t, x^{1}$, x, x2, x, x3)) is=u(t, xc = 1. Thus, when one is studying the equations one1/c, x2/c, x3/c)satisfies the same equation with1 2 3 can set these constants to be 1. Both equations are called evolution equations because they are supposed to describe the change of a particular physical object as the time parametert varies. Observe that (1) can be interpreted as a particular case of both (2) and (3):
ifu = u(t, x , x , x ) is a solution of either (2) or (3) thatis independent of1 2 3 t, then ∂ u = 0, so u must satisfy (1).t

assume that the solutions we are looking for are suffi-In all three examples mentioned above, we tacitly ciently differentiable for the equations to make sense. As we shall see later, one of the important developments in the theory of PDEs was the study of more refined notions of solutions, such as distributions [III.18](/part-03/distributions), which require only weak versions of differentiabili ty. Here are some further examples of important PDEs. The first is the schrödinger equation [III.83](/part-03/the-schrdinger-equation), i$\partial u + k\Delta u = 0$, (4)t

whereu is a function from R . imes  R3 to C. This equation describes the quantum evolution of a massive particle,$k = /2m$, where >0 is Planck’s constant andm is the mass of the particle. As with the heat equation, onecan setk to equal 1 after a simple change of variables. Though the equation is formally very similar to the heat equation, it has very different qualitative behavior. this illustrates an important general point about PDEs: that small changes in the form of an equation can lead tovery different properties of solutions. A further example is the Klein–Gordon equation

-. artial2 u + c2. elta u - m(c2)2 u = 0. (5)t

This is the relativistic counterpart to the Schrödinger equation: the parameter tat i on of mass andmc2 mhas the physical interpreta-has the physical inter pre- tion of rest energy (reflecting Einstein’s famous equa-tion E = mc2). One can normalize the constants c andmc^2/ so that they both equal 1 by applying a suitable change of variables to time and space. Though all five equations mentioned above first appeared in connection with specific physical phenom-ena, such as heat transfer for (2) and propagation of electromagnetic waves for (3), they have, miraculously, a range of relevance far
beyond their original applica-tions. In particular there is no reason to restrict their study to three space dimensions: it is very easy to

IV.12. Partial Differential Equations

generalize them to similar equations inx , x , . . . , x . n variables 1 All the PDEs listed so far obey a simple but funda-2 nmental property called theu and u are two solutions to one of these equations, principle of superposition: if then any linear combination tions is also a solution. In other words, the space of all1 2 a1 u1 + a2 u2 of these solu-solutions is aobey this property are known as vector space [I.3 §2.3](/part - 01/fundamental - definitions). Equations that homogeneous linear equations(that is, a translate of a vector space) rather than a vec-.
If the space of solutions is an affine space tor space, we say that the PDE is an linear equation; a good example is Poisson’s equation in homogeneous:

$\Delta u = f$, (6)

where$u$: R3$\to f R$: Ris the unknown function. Equations that are3\to  R is a function that is given to us and neither homogeneous linear nor in homogeneous linear are known as nonlinear. The following equation, the minimal surface equation nonlinear: [III.94 §3.1](/part-03/variational-methods), is manifestly

$\partial^{1}u\partial$

1(1 + |∂1 u|2 + |∂2 u|2()1()/){2}+ ∂2 (1 + |∂1 u|∂2 2+ |u ∂y u|2()1()/){2} = 0. (7) The graphs of solutions$u$: R2\to  R of this equation are area-minimizing surfaces (like soap films)$.Equations (1)$, (2), (3), (4), (5) are not just linear: they are all examples of This means that they can be expressed in the form constant-coefficient linear equations. P[u] = 0, (8)

where Pis a differential operator that involves linear combinations, with constant real or complex coeffi-cients, of mixed partial derivatives ofu. (Such oper- ators are called operators.) For instance, in the case of the Laplace equa-constant-coefficient linear differential tion (1)$, equation (3)$, P is simply the Laplacian P is thed’Alembertian. elta, while for the wave P = = −. artial2 t + . artial1 2 + . artial2 2 + . artial3 2. The characteristic feature of linear constant-coefficient operators is translation invariance.
Roughly speaking, this means that if you translate a function translate Pu in the same way. More precisely, ifu, then youv(x) is defined to bethe value ofvu(xat x-+a)a; note that(so the value ofx anduaatbelong tox becomes R3 here), then Pv(x) is equal to Pu(x - a). As a conse- quence of this basic fact we infer that solutions to the homogeneous, linear, constant-coefficient equation (8) are still solutions when translated. 457 PDEs we should stop for a moment to make a general Since symmetries play such a fundamental role in definition. A symmetry of a PDE is any invertible opera - tion T:
u \to T (u) from functions to functions that pre- serves the space of solutions, in the sense thatu solves the PDE if and only ifwith this property is then said to be T (u) solves the same PDE. A pde invariant under the symmetry T. The symmetry T is often a linear opera - tion, though this does not have to be the case.
The com-position of two symmetries is again a symmetry, as is the inverse of a symmetry, and so it is natural to view acollection of symmetries as forming a group [I.3 §2.1](/part - 01/fundamental - definitions) (which is typically a finite- or infinite-dimensional lie group [III.48 §1](/part - 03/lie - theory)).
nected with Because the translation group is intimately con-the fourier transform [III.27](/part - 03/the - fourier - transform) (indeed, the latter can be viewed as the representation theory of the former), this symmetry strongly suggests that Fourier analysis should be a useful tool to solve constant-coefficient PDEs, and this is indeed the case. Laplacian Our basic constant-coefficient linear operators, theΔand the d’Alembertian , are formally similar in many respects.
The Laplacian is fund a men-tally associated with the geometry of euclidean space [I.3 §6.2](/part-01/fundamental-definitions) R3 and the d’Alembertian is similarly associated with the geometry of R1$+3$. This means that the Laplacian commutes with minkowski space[I.3 §6.8](/part-01/fundamental-definitions) all the rigid motions of the Euclidean space R3, while the d’Alembertian commutes with the corresponding class of Poincaré transformations of Minkowski spacetime.
In the former case this simply means that invari-ance applies to all transformations of R3 that preserve the Euclidean distances between points. In the case of the wave equation, the Euclidean distance has tobe replaced by the spacetime distance between points (which would be called ti vi ty): if P = (t, x , x , xeve nts) andin the language of rela-Q(s, y , y , y ), then the distance between them is given by the formula1 2 3 1 2 3

d M (P , Q)2= −(t - s)2 + (x1 - y1)2 + (x2 - y2)2 + (x3 - y3)2. As a consequence of this basic fact we infer that all solutions to the wave equation (3) are invariant under translations and lorentz transformations [I.3 §6.8](/part-01/fundamental-definitions). invariant under rotations of the space variables(x Our other evolution equations (2) and (4) are clearly1, x2, x3) \in  R3, when tis fixed. They are also x =Galilean invariantof the Schrödinger equation (4), that whenever, which means, in the particular case$u$ = 458

u(t, x)(ei)((x·)v)(ei)tis a solution so is the functio(n|()v){|}2(t, x -vt) for any vector v \in  R3 u.v (t, x) = example of a equation Poisson’s equation (6), on the other hand, is an, which means that it takes the form constant-coefficient in homogeneous linear

$P[u] = f (9)$

for some constant-coefficient linear differential opera-tor P and known function f . To solve such an equation requires one to understand the invertibility or other-wise of the linear operator P: if it is invertible then$u$ will equal P-1 f , and if it is not invertible then either there will be no solution or there will be infinitely many solutions. In homogeneous equations are closely related to their homogeneous counterpart;
for instance, ifu both solve the in homogeneous equation (9) withu1, the same inhomogeneous termence2 u - u solves the corresponding homogeneousf, then their differ equation (8).1 2 superposition but they do not have to be translation invariant. For example, suppose that we modify the Linear homogeneous PDEs satisfy the principle of heat equation (2) so that the coefficient constant but rather an arbitrary, positive, smooth func-k is no longer tion ofof heat in a medium in which the rate of diffusion(x1$, x2$, x3). Such an equation models the flow varies from point to point.
The corresponding space of solutions is not translation invariant (which is not surprising as the medium in which the heat flows isnot translation invariant). Equations like this are called linear equations with variable coefficients difficult to solve them and describe their qualitative.
It is more features than it is for constant-coefficient equations.(See, for example, stochastic processes [IV.24 §5.2](/part - 04/stochastic - processes) for an approach to equations of type (2) with variablek.) Finally, nonlinear equations such as (7) can often still be written in the form (8), but the operator P is now a nonlinear differential operator. For instance, the relevant operator for (7) is given by the formula  P[u] = {}2 . artial i (1 + |. artial u1 |2()1()/){2}. artial iu, where are clearly not linear.
However, because they are ulti-|. artial u|2 = (. artial1 u)i = {}12+(. artial2 u)2. Operators such as these mately constructed from algebraic operations and par-tial derivatives, both of which are “local” operations, we observe the important fact that P is at least still a “local” operator. More precisely, if$u1 and u2 are$ two functions that agree on some open set expressions P[u ] and P[u ] also agree on this set. In D, then the 1 2

IV. Branches of Mathematics

particular, ifthen whenever P[u0]vanishes on a domain,= 0 (as is the case in our example), P[u] will also vanish on that domain. take place in the whole of a space such asor So far we have tacitly assumed that our equations R$\times R^{3}$. In reality one is often restricted to a fixed R3, R$+ \times R^{3}$, domain of that space. Thus, for example, equation (1) is usually studied on a bounded open domain of R3 subject to a specified basic examples of boundary conditions.boundary condition.
Here are some Example.on an open domain of The Dirichlet problem$D ⊂ R3$is the problem of finding for Laplace’s equation a function boundary ofu Dthat behaves in a prescribed way on theand obeys the Laplace equation inside.udefined on the closur. ar{e}0 More precisely, one specifies a continuous function:∂D \to  R and looks for a continuous function D of D, that is twice continu-u, ously differentiable inside D and solves the equations⎫Δu(x) = 0 for all x \in  D, ⎬

(10)

 u(x) = u0(x) for all x \in . artial D.⎭

A basic result in PDEs asserts that if the domain D has a sufficiently smooth boundary, then there is exactly one solution to the problem (10) for any prescribed functionu0 on the boundary ∂D. Example. The Plateau problem is the problem of finding the surface of minimal total area that bounds agiven curve. some suitably smooth domain of the form When the surface is the graph of a function$\\{(x}$, y, u(x, y)):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.
\1(x, y), in other words a set\in  D, and theu on bounding curve is the graph of a function the boundary∂D of D, then this problem turns outu0 over to be equivalent to the Dirichlet problem (10), but with the linear equation (1) replaced by the nonlinear equation (7). For the above equations, it is also often natural to replace the Dirichlet boundary condi-tionu(x) = u (x) on the boundary . artial D with another boundary condition, such as the conditionn(x)0·∇ u(x) = u (x) on Neumann boundary. artial D, where n(x) is the outward normal (of unit length) to x1 D at x.
Generally speaking, Dirichlet boundary conditions correspond to“absorbing” or “fixed” barriers in physics, where as Neumann boundary conditions correspond to “reflecting”or “free” barriers. Natural boundary conditions can also be imposed for our evolution equations (2)–(4). The simplest one is toprescribe the values ofu when t = 0. We can think of IV.12. Partial Differential Equations this more geometrically. We are prescribing the values ofu at each spacetime point of form (0, x, y, z), and the set of all such points is a hyperplane in R1$+ {}^{3}$:
it is an example of an initial time surface.
Example.lem, some times abbreviated to IVP) for the heat equa-The Cauchy problem (or initial value prob tion (2) asks for a solution spacetime domain R$+ \times R^{3} = \\{u (t}$, x): R\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}$+ \times$: t >R3 \to 0, x R on the \in R3, which equals a prescribed function initial time surface{0}. imes R3 = . artial(R+ u . imes0 R:3 R).3 \to R on the In other words, the Cauchy problem asks for a sufficiently smooth functionof R+ . imes R3 and taking values inu, defined on the closure R, that satisfies the conditions -. artial tu(t, x) + k. elta u(t, x)for every = 0
(t, x) \in R+ . imes R3,⎫⎪⎪⎬ (11)$||\}u(0$, x) = u0(x) for every x \in R3. The functionu0 is often referred to as the initial con- ditions Under suitable smoothness and decay conditions, one, or initial data, or just data, for the problem. can show that this equation has exactly one solutio nu for each choice of data u0. Interestingly, this asser- tion fails if one replaces the\\\\{(t, x):\\\\}t$> 0$, x \in R3 by the future past domain domain RR+ - . imes . imes R(R3)3 ==\{(t, x)\}:$t < 0$, x \in R3.dinger equation (4), though in this case we can solve both to the past and to the future.
However, in the case A similar formulation of the IVP holds for the Schröof the wave equation (3) we need to specify not just the initial positionu(0, x) = u (x) on the initial time sur - facet = 0, but also an initial0 velocity . artial t u(0, x) = u1(x), since equation (3) (unlike (2) or (4)) cannot formally determine∂ u in terms of u. One can construct uniquet

smooth solutions (both to the future and to the past ofthe initial hyper planet = 0) to the IVP for (3) for very general smooth initial conditions$u^{0}$, u1. For instance, when analyzing the evolution of a wave Many other boundary-value problems are possible. in a bounded domain natural to work with the spacetime domain D (such as a sound wave), it is R . imes D and prescribe0. imes  D) and both Dirichlet or Neumann data (on the spatial Cauchy data (on the initial boundary boundary R. imes . artial D).
On the other hand, when the phys- ical problem under consider at i on is the evolution of awave out side a bounded obstacle (for example, an electromagnetic wave), one considers instead the evolutionin R. imes (R3 . \1) with a boundary condition on D. 459 tions for a given PDE is very important. For equations The choice of boundary condition and initial condiof physical interest these arise naturally from the con-text in which they are derived.
For example, in the case of a vibrating string, which is described by solutions ofthe one-dimensional wave equation. artial2 u - . artial2 u = 0 inthe domain. artial u = u at(a, b)t = t. imes Ramount to specifying the original, the initial conditionst ux = u0 and position and velocity of the string. The boundary con - ditiont u(a)1 = u(b)0 = 0 is what tells us that the two ends of the string are fixed. These are equations where there is only one unknown So far we have considered just scalar equations. function bers R or in the complex number su, which takes values either in the real num - C.
However, many important PDEs involve either multiple unknown scalar functions or (equivalently) functions that take values in a multi dimensional vector space such as Rm. In such cases, we say that we have aimportant example of a system is that of the system of PDEs. an cauchyriemann equations [I.3 §5.6](/part - 01/fundamental - definitions):$\partial1 u2 - \partial2 u1 = 0$, . artial1 u1 + . artial2 u2 = 0, (12) where plane.
It was observed by$u1$, u2$: R2$\to R are real-valued functions on the cauchy [VI.29](/part - 06/augustin - louis - cauchy - 17891857) that a com- plex functionw(x + iy) = u1(x, y)+iu2(x, y) is holo- mor ph ic parts$u1$,[I.3 §5.6](/part - 01/fundamental - definitions) if and only if its real and imaginary u2 satisfy the system (12). This system can still be represented in the form of a constant-coefficient linear PDE (8), but$u \text{is now a vector} ( {}^{u1} )$, and P is not a scalar differential operator, but rather aof operators$( {}^{-\partial2\partial1} )$.u 2 matrix unknowns.
This is the standard situation for a The system (12) contains two equations and two$\partial1^{\partial}2 deter-$ mined system over determined. Roughly speaking, a system is called if it contains more equations than unknowns and under determined if it contains fewer equations than unknowns. Under determined equations typically have infinitely many solutions for any given set of prescribed data;
conversely, over determined equations tend to have no solutions at all, unless some additional compatibility conditions are imposed on the prescribed data. Observe also that the Cauchy–Riemann operator$P$ has the following remarkable property:

P2[u] = P[P[u]] = . elta 1 eltau(u1)2.

Thus P can be viewed as a square root of the two- dimensional LaplacianΔ. One can define a similar type

460

of square root for the Laplacian in higher dimensions and, more surprisingly, even for the d’Alembertian operator in R1+^3. To achieve this we need to have$four 4$. imes  4 complex matrices γ^1$, γ^{2}$, γ3, γ4 that satisfy the property $γαγβ + γβγα = −2mαβI$.

Here,β = 1, I is the unit 4-1 when α . imes =4 matrix andβ = 1, and 0 otherwise. Usingmαβ =1 2 when α = the follows. Ifγ matrices we can introduce the2 u = (u , u , u , u ) is a function in Dirac operator (R1)+as3 with values into check that, indeed, C4, then we set1(D2)2 u3=4 Duu. The equation= iγα∂αu. It is easy Du = ku (13)

is called the free, massive, relativistic particle such as an electron. Dirac equation and it is associated with a unknowns that are not, strictly speaking, functions One can extend the concept of a PDE further to cover taking values in a vector space, but are instead sec-tions of a vector bundle [IV.6 §5](/part-04/algebraic-topology), or perhaps a map from onealized PDEs play an important role in geometry and manifold [I.3 §6.9](/part-01/fundamental-definitions) to another; such gener modern physics.
A fundamental example is given by the“vacuum,” case, they take the form einstein field equations [IV.13](/part-04/general-relativity-and-the-einstein-equations). In the simplest, Ric$(g) = 0$, (14) where Ricthe spacetime manifold(g) is the ricci curvature M = (M, g).
In this case the[III.78](/part-03/ricci-flow) tensor of spacetime metric itself is the unknown to be solved for. One can often reduce such equations locally to more traditional PDE systems by selecting a suitable choice of coordinates, but the task of selecting a “good” choice of coordinates, and working out how different choices are compatible with each other, is a nontrivial and important one. Indeed, the task of selecting a good set of coordinates in order to solve a PDE can end up being a significant PDE problem in its own right. science.
They provide the basic mathematical frame-work for some of the most important physical theo-PDEs are ubiquitous through out mathematics and ries: elasticity, hydrodynamics, ele ct ro magnetism, general relativity, and nonrelativistic quantum mechanics, for example. The more modern relativistic quantum field theories lead, in principle, to equations in an infi-nite number of unknowns, which lie beyond the scope of PDEs. Yet, even in that case, the basic equations preserve the locality property of PDEs.
More over, the start-ing point of a quantum field theory [IV.17 §2.1.4](/part-04/vertex-operator-algebras) is always a classical field theory, which is described by

IV. Branches of Mathematics

systems of PDEs. This is the case, for example, in the standard model of weak and strong interactions, which is based on the so-called Yang–Mills–Higgs field theory. If we also include the ordinary differential equations of classical mechanics, which can be viewed as one-dimensional PDEs, we see that essentially all of physics is described by differential equations.
As examples of PDEs underlying some of our most basic physical theo-ries we refer to the articles that discuss the euler and navier–stokes equations [III.23](/part-03/the-euler-and-navierstokes-equations), the heat equation the einstein equations[III.36](/part-03/the-heat-equation), the schrödinger equation[IV.13](/part-04/general-relativity-and-the-einstein-equations). [III.83](/part-03/the-schrdinger-equation), and An important feature of the main PDEs is their apparent universality.
Thus, for example, the wave equation, first introduced by d’alembert [VI.20](/part - 06/jean - le - rond - dalembert - 17171783) to describe the motion of a vibrating string, was later found to be connected with the propagation of sound and electro-magnetic waves. The heat equation, first introduced by fourier in many other situations in which dissipative effects[VI.25](/part - 06/jean - baptiste - joseph - fourier - 17681830) to describe heat propagation, appears play an important role. The same can be said about the Laplace equation, the Schrödinger equation, and many other basic equations.
It is even more surprising that equations that were originally introduced to describe specific physical phe-nomena have played a fundamental role in several areas of mathematics that are considered to be “pure,” such as complex analysis, differential geometry, topology, and algebraic geometry. Complex analysis, for example, which studies the properties of holomorphic functions, can be regarded as the study of solutions tothe Cauchy–Riemann equations (12) in a domain of R2.
Hodge theory is based on studying the space of solutions to a class of linear systems of PDEs on manifolds that generalize the Cauchy–Riemann equations: it plays a fundamental role in topology and algebraic geometry. the atiyah–singer index theorem lat ed in terms of a special class of linear PDEs on mani-[V.2](/part - 05/the - atiyahsinger - index - theorem) is formufolds, related to the Euclidean version of the Dirac operator. Important geometric problems can be reduced to finding solutions to specific PDEs, typically nonlinear. We have already seen one example:
the Plateau prob-lem of finding surfaces of minimal total area that pass through a given curve. Another striking example is the uniformization theorem faces, which takes a compact Riemannian surface[V.34](/part - 05/the-\text{uniformization} - theorem) in the theory of sur - S (a two-dimensional surface with a riemannian metric [I.3 §6.10](/part - 01/fundamental - definitions)) and, by solving the PDE$\Delta u + (e2)u = K (15)S$ IV.12.
Partial Differential Equations (which is a nonlinear variant of the Laplace equation(1)), uniformizes the metric so that it is “equally curved” at all points on the surface (or, more precisely, has constant scalar curvature [III.78](/part - 03/ricci - flow)) with out changing theing any of the angles subtended by curves on the sur-conformal class of the metric (i.e., with out distort face). This theorem is of fundamental importance tothe theory of such surfaces:
in particular, it allows one to give a topological classification of compact surfacesin terms of a single numberχ(S), which is called the euler characteristic three-dimensional analogue of the uniformization the-[I.4 §2.2](/part-01/general-goals) of the surface S. The orem, the Thurston, has recently been established by Perelman, geometrization conjecture [IV.7 §2.4](/part-04/dierential-topology) of who did so by solving yet another PDE; in this case, the equation is the ricci flow [III.78](/part-03/ricci-flow) equation

$\partial g = 2 Ric(g)$, (16)t

which can be transformed into a nonlinear version ofthe heat equation (2) after a carefully chosen change of coordinates. The proof of the geometrization con-jecture is a decisive step toward the total classification of all three-dimensional compact manifolds, in particular establishing the well-known poincaré conjecture details in establishing this conjecture, one needs to[IV.7 §2.4](/part-04/dierential-topology).
To over come the many technical make a detailed qualitative analysis of the behaviorof solutions to the Ricci flow equation, a task which requires just about all the advances made in geometric PDEs in the last hundred years. and geometry but also in many fields of applied sci-ence. In engineering, for example, one often wants to Finally, we note that PDEs arise not only in physics control some feature of the solutio nu to a PDE by care- fully selecting whatever components of the given data one can directly influence;
consider, for instance, how a violinist controls the solution to the vibrating string equation (closely related to (3)) by modulating the force and motion of a bow on that string in order to produce abeautiful sound. The mathematical theory dealing with these types of issues is called control theory. cannot possibly have complete information about the state of the system at any given time. Instead, one When dealing with complex physical systems, one often makes certain randomness assumptions about various factors that influence it.
This leads to the very important class of equations called stochastic differential equations the equation involve a(SDEs), where one or more components of random variable [III.71 §4](/part-03/probability-distributions) of some sort. An example of this is in the black–scholes

461

model cuss i on of SDEs can be found in[VII.9 §2](/part-07/the-mathematics-of-money) in mathematical finance. A general dis-stochastic processes [IV.24 §6](/part-04/stochastic-processes).The plan for the rest of this article is as follows. In section 2 I shall describe some of the basic notions and achievements of the general theory of PDEs.
The main point I want to make here is that, in contrast with ordinary differential equations, for which a gen-eral theory is both possible and useful, partial differential equations do not lend themselves to a useful gen-eral theoretical treatment because of some important obstructions that I shall try to describe. One is thus forced to discuss special classes of equations such as elliptic, parabolic, hyperbolic, and dispersive equations.
In section 3 I will try to argue that, despite the impossi-bility of developing a useful general theory that encompasses all, or most, of the important examples, there is nevertheless an impressive unifying body of concepts and methods for dealing with various basic equations, and this gives PDEs the feel of a well-defined area of mathematics.
In section 4 I develop this further by try-ing to identify some common features in the derivation of the main equations that are dealt with in the subject. An additional source of unity for PDEs is the central role played by the issues of regularity and breakdown of solutions, which is discussed only briefly here. In the final section we shall discuss some of the main goals that can be identified as driving the subject.
2 General Equations One might expect, after looking at other areas of mathematics such as algebraic geometry or topology, that there was a very general theory of PDEs that could be specialized to various specific cases. As I shall argue below, this point of view is seriously flawed and very much out of fashion. It does, however, have important merits, which I hope to illustrate in this section. I shall avoid giving formal definitions and focus instead on representative examples. The reader who wants more precise definitions can consult the online version of this article. systems of PDEs.
The simplest distinction, which wehave already made, is between scalar equations, such For simplicity we shall look mostly at determined as (1)–(5), which consist of only one equation and one unknown, and systems of equations, such as (12) and (13). Another simple but important concept is that of the derivative that appears in the equation; this concept is order of a PDE, which is defined to be the highest

462

analogous to that of the instance, the five basic equations (1)–(5) listed earlier degree of a polynomial. For are second order in space, although some (such as (2)or (4)) are only first order in time. Equations (12) and (13), as well as the Maxwell equations, are first order.1 nonlinear equations, with the linear equations being divided further into constant-coefficient and variable-We have seen that PDEs can be divided into linear and coefficient equations. One can also divide nonlinear PDEs into several further classes depending on the “strength” of the nonlinearity.
At one end of the scale, a semilinear equation is one in which all the nonlinear components of the equation have strictly lower order than the linear components. For instance, equation (15)is semilinear, because the nonlinear component eu is of zero order, i.e., it contains no derivatives, whereasthe linear component. elta u is of second order. These S

equations are close enough to being linear that they can often be effectively viewed as perturbations of a linear equation. A more strongly nonlinear class of equationsis that of quasilinear equations, in which the highestorder derivatives ofa linear manner but the coefficients attached to thoseu appear in the equation only in derivatives may depend in some nonlinear manner on lower-order derivatives.
For instance, the second-order equation (7) is quasilinear, because if one uses the product rule to expand the equation, then it takes the quasilinear form F11(. artial1 u, . artial2 u). artial2 1 u + F12(. artial1 u, . artial2 u). artial1. artial2 u + F22(. artial1 u, . artial2 u). artial2 2 u = 0 for some explicit algebraic functions$F11$, F12, F22 of the lower-order derivatives of tions can still some times be analyzed by perturb at i veu. While quasilinear equa - techniques, this is generally more difficult to accom-plish than it is for an analogous semilinear equation.
Finally, we haveno linearity properties whatsoever. A typical example is fully nonlinear equations, which exhibit the Monge–Ampère equation$\det (D2 u) = F(x, u, Du)$,

where$u$: Rn \to  R is the unknown function, Du is the gradient Hessian matrix[I.3 §5.3](/part-01/fundamental-definitions) ofof$u$, andu, DF2 u:=Rn(. artial 1 imesi. artial Rju). imes1(R⩽()n){i}, j^⩽. on Ris theis a given function. This equation arises in many geometric contexts, ranging from manifold-embedding problems tions, for converting higher-order equations into a lower-order (oreven first-order) system of equations by increasing the number of1. There is a simple trick, well-known in ordinary differential equa unknowns. See the discussion in dynamics [IV.14 §1.2](/part-04/dynamics).

IV. Branches of Mathematics

to the complex geometry of[III.6](/part-03/calabiyau-manifolds). Fully nonlinear equations are among the most calabi–yau manifolds difficult and least well-understood of all PDEs. Remark. Most of the basic equations of physics, such as the Einstein equations, are quasilinear. However, fully nonlinear equations arise in the theory of characteristics of linear PDEs, which we discuss below, and also in geometry.

2.1 First-Order Scalar Equations

It turns out that first-order scalar PDEs in any num-ber of dimensions can be reduced to systems of firstorder ODEs. As a simple illustration of this impor-tant fact consider the following equation in two space dimensions: a1(x1$, x2)\partial1 u(x1$, x2)+a2(x1$, x2)\partial2 u(x1$, x2)= f (x1$, x2)$, (17) wherex = (x(a1)1, x, a2)2,\in f Rare given real functions in the variables2.
We associate with (17) the first - order 2$\times 2 system$ d$x1 (s) = a1(x1(s)$, x2(s))$,\}|||\}$ d$s$(18) dd$xs2 = a2(x1(s)$, x2(s)).⎪⎪⎪⎭ To simplify matters, let us assume that Suppose now that$x(s) = (x^{1}(s)$, x2(s))f =is a solution0.$of (18)$, and let us consider how$u(x^{1}(s)$, x^2(s)) varies ass varies. By the chain rule we know that$dd$ s u = ∂^1 udds ddxs^1 + ∂^2 uddxs^2 , and equations (17) and (18) imply that this equals zero(by our assumption that$f = 0)$.
In other words, any solution$u = u(x^{1}$, x2) of (17) with f = 0 is con- stant along any parametrized curve of the form$(x^{1}(s)$, x2(s))that satisfies (18).$x(s) =$ which are called(17), then we can find all solutions to (17). I say “in prin-Thus, in principle, if we know the solutions to (18), characteristic curves for the equation ciple” because, in general, the nonlinear system (18) isnot so easy to solve.
Nevertheless, ODEs are simpler to deal with, and the fundamental theorem of ODEs, which we will discuss later in this section, allows us to solve (18) at least locally and for a small interval in The fact thatu is constant along characteristic curvess. allows us to obtain important qualitative information even when we cannot find explicit solutions. For exam-ple, suppose that the coefficients a1, a2 are smooth (or IV.12.
Partial Differential Equations real analytic) and that the initial data is smooth (or realanalytic) every where on the set Hwhere it is defined, except at some point the solutio nu remains smooth (or real analytic) atx0 where it is discontinuous. Then all points except along the characteristic curveΓ that starts at(18) that satisfies the initial condition x0, or, in other words, along the solution tox(0) = x . That is, the discontinuity atx0 propagates precisely along0Γtant principle, which we shall explain in more detail. We see here the simplest manifestation of an impor- later:
singularities of solutions to PDEs propagate along characteristics (or, more generally, hypersurfaces). cie nts but also on One can generalize equation (17) to allow the coeffi-$a1$, a2 u, and: f to depend not only on x = (x1$, x2)a1(x$, u(x))∂1 u(x)+a2(x, u(x))∂2 u(x) = f (x, u(x)).(19) The associated characteristic system becomes⎫$dd$ xs1 (s) = a1(x(s), u(s, x(s)))$,|||\}$(20) dd$xs^{2} (s) = a^{2}(x(s)$, u(s, x(s))).⎪⎪⎪⎭ As a special example of (19) consider the scalar equation in two space dimensions,. artial t u + u. artial x u = 0$, u(0, x) = u0(x)$, (21) which is called thea1(x, u(x)) =
1 and Burgers equationa2(x, u(x)) =. Here we have setu(x). With this choice ofrenaming$ax^{1}$,2 a(s)2, we can takeas x(s), we derive thex1(s) to be sch ar ac ter i st ic in (20). Then, equation in the form d$x(s) = u(s$, x(s))$. (22) d$ s

For any given solution curve(s, x(s)) we haveu(dof (21) and any characteristic/ds)u(s, x(s)) = 0. Thus, in principle, knowing the solutions to (22) should allow usto determine the solutions to (21). However, this argument seems worryingly circular, since in (22).u itself appears sider the IVP for (21): that is, look for solutions that satisfy To see how this difficulty can be circumvented, con- u(0$, x) = u (x)$. Consider an associated char- acteristic curve Then, sinceu is constant along the curve, we must havex(s)0 such that, initially, x(0) = x0.u(s, x(s))that dx/ds==uu0(x(x0)).
Hence, going back to (22), we infer and thus x(s) = x + su (x ). Wethus deduce that0 0 0 0 0 u(s$, x0 + su0(x0)) = u0(x0)$, (23)

463

which implicitly gives us the form of the solution We see once more, from (23), that if the initial data isu. smooth (or real analytic) every where except at a pointx of the line t = 0, then the corresponding solution is also smooth (or real analytic) every where in a smallneighborhood0 V of x0, except along the characteristic curve that begins atsary here because new singularities can form at large$x0$. The smallness of V is neces- scales. Indeed,$x + su (x)$, whose slopes depend onu has to be constant along the linesu (x).
At a point where these lines cross we would obtain different val-ues of$u^{0}$, which is impossible unless u becomes singular0 by this point smooth, nonconstant initial data. This blow-up phenomenon occurs for anyu . Remark.linear equation (17) and the quasilinear equation (19).There is an important difference between the The characteristics of the first depend only on the coef-ficients$a1(x)$, a2(x), while the characteristics of the second depend explicitly on a particular solution the equation.
In both cases, singularities can only prop-u of agate along the characteristic curves of the equation. For nonlinear equations, however, new singularities can form at large distance scales, whatever the smoothness of the initial data. lar equations in The above procedure extends to fully nonlinear sca-Rd such as the Hamilton–Jacobi equation $\partial^{t}u + H(x$, Du) = 0, u(0, x) = u0(x)$, (24) \text{where gradient of} u$: R . imes u R, and then \to  R is the unknown function, D[III.35](/part-03/hamiltonians) Hu:
is the R$d \times$ Rinstance, thed \to  R and the initial data eikonal equationhamiltonianu0∂: Rud= |\to  DRuare given. For| is a spec i alt

instance of a Hamilton–Jacobi equation. We associate with (24) the ODE system ddxti = ∂p∂ H(x(t), p(t))$, \}|||\}$ dd$pt^{i} = − \partial x^{i}\partial^{i} H(x(t)$, p(t))$,|||\} (25) \text{whereknown as a}$ i runs from 1 to Hamiltonian syst emd. The equations (25) areof ODEs. The rela- tion ship between this system and the corresponding Hamilton–Jacobi equation is a little more involved than in the cases discussed above.
Briefly, we can constructa solutio nu to (24) based only on the knowledge of the solutions the bi characteristic curves(x(t), p(t))of the nonlinear PDE$. Onceto (25)$, which are called again, singularities can only propagate along bichar-acteristic curves (or hypersurfaces). As in the case of

464

the Burgers equation, singularities will occur for moreor less any smooth data. Thus, a classical, continuously differentiable solution can only be constructed locally in time. Both Hamilton–Jacobi equations and Hamiltonian systems play a fundamental role in clas-sical mechanics as well as in the theory of the propagation of singularities in linear PDEs. The deep con-nection between Hamiltonian systems and first-order Hamilton–Jacobi equations played an important rolein the introduction of the Schrödinger equation into quantum mechanics.

2.2 The Initial Value Problem for ODEs

Before we can continue with our general presentation of PDEs we need first to discuss, for the sake of com-paris on, the IVP for ODEs. Let us start with a first-order

ODE. artial xu(x) = f (x, u(x)) (26) subject to the initial condition$u(x0) = u0$. (27) Let us also assume for simplicity that (26) is a scalar equation and thatu, such as f (x, u)f=is a well-behaved function ofu3 - u + 1 + . in x. From the initialx and$datainto (26)$.
If we now differentiate the equation (26) withu0 we can determine . artial x u(x0) by substituting x0 respect toequationx and apply the chain rule, we derive the. artial2 xu(x) = . artial x f (x, u(x)) + . artial uf (x, u(x)). artial x u(x), which for the example just defined works out to be$\cos x + 3u^{2}(x)\partial u(x) - \partial u(x)$. Hence, xx. artial x 2 u(x0) = . artial xf (x0, u0) + . artial uf (x0, u0)∂x u0, and since find that∂∂2 xu(xu(x0)) can also be explicitly calculated has already been determined we from the initial data the functionx fand its first partial derivatives.
Taking0$u^{0}$. This calculation also involves higher derivatives of the equation (26) we can recur-sively determine$\partial^{3}u(x )$, as well as all other higher derivatives of de term i neu(x)u with the help of the Taylor seriesatxx0. Therefore, one can in principle0 u(x) =k^⩾0 k1!. artia(lx)ku(x0)(x - x0)k = u(x0) + . artial x u(x0)(x - x0)+2!1$\partial x 2(x0)(x - x0)2 + · · ·$.

IV. Branches of Mathematics

We say “in principle” because there is no guarantee that the series converges. There is, however, a very important theorem, called the Cauchy–Kovalevskaya theoremlytic, as is certainly the case for our function, which asserts that if the functionf is real ana-f (x, u) =u3 - u + 1 + . in  x, then there will be some neighbor- hood J of x0 where the Taylor series converges to a real-analytic solutionto show that the solution thus obtained is the uni queu of the equation. It is then easy solution to (26) that satisfies the initial condition (27).To summarize:
iff is a well-behaved function, then the initial value problem for ODEs has a solution, at least in some time interval, and that solution is unique. The same result does not always hold if we consider a more general equation of the form a(x$, u(x))\partial^{x}u = f (x, u(x))$, u(x^0) = u^0. (28) Indeed, the recursive argument outlined above breaks down in the case of the scalar equation(x - x )∂ u =f (x, u)determine for the simple reason that we cannot even∂ u(x ) from the initial condition u((x0)x ) =uu0. A similar problem occurs for the equation)∂ u = f (x, u()x)0.
An obvious condition that allows us(u0 - to extend our previous recursive argument to (28) is to insist that0 x a(x , u ) ≠ 0. Otherwise, we say that the IVP (28) is characteristic0 0 . If botha and f are also real ana- lytic, the Cauchy–Kovalevskaya theorem applies again and we obtain a unique, real-analytic solution of (28) in a small neighborhood of system,$x0$. In the case of an N . imes  NA(x$, u(x))\partial x u = F(x, u(x))$, u(x0) = u0$, A = A(x$, u) is an N . imes  N matrix, and the non character- istic condition becomes

$\det A(x^{0}$, u0) ≠ 0. (29)

It turns out, and this is extremely important in the development of the theory of ODEs, that, while the nondegeneracy condition (29) is essential to obtain a unique solution of the equation, the analyticity con-dition is not at all important: it can be replaced by a simple to assume, for example, that their first partial deriva-local Lipschitz condition for A and F. It suffices tives exist and that they are locally bounded. This is always the case if the first derivatives of A and F are continuous.
Theorem (the fundamental theorem of ODEs).matrix A(x , u ) is invertible and if A and F are con-If the tinuous and have locally bounded first derivatives, then there is some time interval0 0 J ⊂ R that contains x , and a IV.12. Partial Differential Equations unique solution2 udefined on Jthat satisfies the initial conditionsu(x0) = u0. The proof of the theorem is based on the Picard iteration method approximate solutions. The idea is to construct a sequence ofu(n)(x) that converge to the desired solution.
With out loss of generality we can assume A to be the identity matrix.3 One starts by settingu(0)(x) = u0 and then defines, recursively,$\partial xu}(n)(x) = F(x$, u(n - 1)(x))$, u(n - 1)(x0) = u0$. Observe that at every stage all we need to solve is a very simple linear problem, which makes Picard iteration easy to implement numerically. As we shall see below, variations of this method are also used for solving nonlinear PDEs. Remark.sharp, in the sense that its conditions cannot be In general, the local existence theorem is relaxed.
We have seen that the invertibility condition for A(x , u ) is necessary. Also, it is not always pos- sible to extend the interval exists to the whole of the real line. As an example,0 0 J in which the solution consider the nonlinear equation tial datau = u at x = 0, for which the solution. artial x u = u2 with ini-uthe terminology of PDEs, it = u0/(1 - x(u0)0)becomes infinite in finite time: in blows up. mentioned above, one can define the main goals of the mathematical theory of ODEs as follows. In view of the fundamental theorem and the example (i) Find criteria for global existence.
In the case ofblow-up describe the limiting behavior. (ii) In the case of global existence describe the asymp-totic behavior of solutions and families of solutions. that achieves both goals (in practice one is forced torestrict one self to special classes of equations moti-Though it is impossible to develop a general theory vated by applications), the general local existence and uniqueness theorem mentioned above provides a powerful unifying theme. It would be very helpful if a similar situation were to hold for general PDEs.

2.3 The Initial Value Problem for PDEs

In the one-dimensional situation one specifies initial conditions at a point. The natural higher-dimensional may not be analytic, but it does have continuous first derivatives.2. Since we are not assuming that3. Since A is invertible we can multiply both sides of the equation A and F are analytic, the solution by the inverse matrix$A^{-1}$.

465

analogue is to specify them on hypersurfaces H ⊂ Rd, that is,(d - 1)-dimensional subsets (or, to be more pre- cise, submanifolds). For a general equation of orderk, that is, one that involves ify the values ofuand of its firstk derivatives, we need to spec-k - 1 derivatives in the direction normal to H. For example, in the case of the second-order wave equation (3) and the initial hyper planet = 0 we need to specify initial data for u and. artial u.t obtaining a solution, it is important that the data If we wish to use initial data of this kind to start should not be degenerate.
(We have already seen thisin the case of ODEs.) For this reason, we make the following general definition. Definition.linear system of equations, and the initial data comes Suppose that we have akth-order quasi- in the form of the firstk - 1 normal derivatives that a solution that the system isu must satisfy on a hypersurface non characteristic at a point H. We sayx of H if we can use the initial data to determine formally allthe other higher partial derivatives ofu at x , in terms0 of the data.
helpful to imagine an infinitesimally small neighbor-hood of As a very rough picture to have in mind, it may bex . If the hypersurface H is smooth, then its intersection with this neighborhood will be a piece ofa(d - 1)-dimensional affine subspace. The values of0 uand the firstk - 1 normal derivatives on this inter- section are given by the initial data, and the problem of determining the other partial derivatives is a problem in linear algebra (because everything is infinitesi-mally small).
To say that the system is non characteristic atx0 is to say that this linear algebra problem can be uniquely solved, which is the case provided that a certain matrix is invertible. This is the nondegeneracy condition referred to earlier. To illustrate the idea, let us look at first-order equations in two space dimensions. In this caseΓ , and since k - 1 = 0 we must specify the restriction H is a curve$of$ u to Γ ⊂ R2 but we do not have to worry about any derivatives. Thus, we are trying to solve the system $a^{1}(x$, u(x))∂1 u(x) + a2(x, u(x))∂2 u(x)= f (x, u(x))$, u|^{Γ} = u^{0}$, (30)

where(which belongs to$a^{1}$, a2, and Rf2) andare real-valued functions ofu. Assume that in a smallx neighborhood of a point parametrically as the set of point sp the curvex = Γ(xis described1(s)$, x2(s))$. We denote by$n(s) = (n^{1}(s)$, n2(s)) a unit normal to Γ .

466

would like to find conditions on As in the case of ODEs, which we looked at earlier, weΓ such that for a given point inthe datauΓ0 we can determine all derivatives of, the derivatives of u along Γ , and the equa-u from$tion (30)$. Out of all possible curvesΓ we distinguish in particular the encountered above (see (20)): characteristic ones we have already dd$xs1 = a1(x(s)$, u(x(s)))$,\}|||\}x(0) = p$.$ddxs2 = a2(x(s)$, u(x(s))),⎪⎪⎪⎭ One can prove the following fact: Along a characteristic curve, the equation (30) is degen - erate.
That is, we cannot determine the first-order derivatives ofu uniquely in terms of the data u0. there is a direction such that if the hypersurface, which In terms of the rough picture above, at each point in this case is a line, is along that direction, then the resulting matrix is singular. If you follow this direction, then you travel along a characteristic curve.
Conversely, if the nondegeneracy condition a1(p, u(p))n1(p) + a2(p, u(p))n2(p) . eq 0 (31) is satisfied at some pointp = x(0) \in Γ , then we can determine all higher derivatives of terms of the datau and its derivatives alongu at x0 uniquely inΓ . If the curve nonvanishing gradient DΓ is given by the equation0 ψ(p). eq 0, then the conditionψ(x1$, x2) = 0, with$(31) takes the form a1(p, u(p)). artial1ψ(p) + a2(p, u(p)). artial2ψ(p). eq 0. With a little more work one can extend the above discussion to higher-order equations in higher dimen-sions, and even to systems of equations.
Particularly important is the case of a second-order scalar equationin R$d$, daij(x)∂i∂ju = f (x, u(x))$, (32)i$, j=1

together with a hypersurface H in Rd defined by the equationψ(x) = 0, where ψ is a function with non- vanishing gradient Dpointx ∈ H to beψn. Define the unit normal at a= Dψ/|Dψ|, or, in compo- nent form,0 ni = ∂iψ/|∂ψ|. As initial conditions for (32) we prescribe the values oftiven[u](x) = n (x)∂ u(x) +u and its normal deriva-n (x)∂ u(x) + · · · +nd(x)∂d u(x) on H1: 1 2 2 $u(x) = u^{0}(x)$, n[u](x) = u1(x), x ∈ H .

IV. Branches of Mathematics

It can be shown that H is non characteristic (with respect to equation (32)) at a point determine all derivatives ofu at p in terms of the initialp (that is, we can data u0, u1) if and only ifdaij (p). artial iψ(p). artial jψ(p) . eq 0. (33) for (32) if On the other hand, i, j = 1 H is a characteristic hypersurface daij(x). artial iψ(x). artial jψ(x) = 0 (34)i, j = 1 for everyx in H . Example.tion If the coefficients a of (32) satisfy the condi - daij (x)ξiξj > 0, ∀ξ \in Rd, ∀x \in Rd$, (35)i$, j = 1 then clearly, by (34), no surface in Rd can be charac- teristic.
This is the case, in particular, for the laplace equationΔu = f . Consider also the minimal surface equation (7) written in the form

$h^{i}j (\partial u)\partial^{i}\partial^{j}u = 0$, (36)i, j=1 \\\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\\}2

withh12(∂u)h11(∂u)= h21=(∂u)1 += −(∂2 u)∂2 u∂, h22 u. It is easy to check(∂u) = 1 + (∂1 u)2, that the quadratic form associated with the symmetric matrixhij(∂u)is positive definite for every1 2∂u. Indeed, hij(. artial u)ξiξj= (1 + |. artial u|2)-1/2(|ξ|2 - (1 + |. artial u|2)-1(ξ · . artial u)2) > 0. Thus, even though (36) is not linear, we see that all surfaces in R2 are non characteristic. Example. Consider the wave equationu = f in R1+d. All hypersurfaces of the formψ(t, x) = 0 for which(. artial tψ)2 =i=d 1(. artial iψ)2 (37)

are characteristic. This is the famous eikonal equation, which plays a fundamental role in the study of wave propagation. Observe that it splits into two Hamilton Jacobi equations (see (24)):

. artial tψ = ±i = {}d1(. artial iψ()2()1()/){2}. (38)

The bi characteristic curves of the associated Hamiltonians are called bi characteristic curves of the wave equa-tion. As particular solutions of (37) we findψ+(t, x) =

IV.12. Partial Differential Equations

(twhose level surfaces- t0) + |x - x0| andψ ψ=-0 correspond to forward and(t, x) = (t - t0) − |x - x0|, backward light cones with their vertex at These represent, physically, the union of± all light raysp = (t0$, x0)$. emanating from a point source at given by the equation(t - t )ω = p(x. The light rays are - x ), for ω \in  R3 withof the bi characteristic curves of the Hamilton–Jacobi|ω| = 1, and are precisely the0 (t, x)0 components equations (38).
More generally, the characteristics ofthe linear wave equation $a^{0}0(t$, x)∂t 2 u - aij(t, x)∂i∂ju = 0, (39)i, j witha00 > 0 and aij satisfying (35), are given by the Hamilton–Jacobi equations: $-a^{0}0(t$, x)(∂tψ)2 + aij (x)∂iψ∂jψ = 0$or$, equivalently, . artial t ψ = ± (a00)-1 aij (x). artial iψ. artial jψ1 / 2. (40)i, j

The bi characteristics of the corresponding Hamiltonian systems are called bi characteristic curves of (39). Remark.(17) we have seen how knowledge of characteristics In the case of the first-order scalar equations can be used to find, implicitly, general solutions. Wehave also seen that singularities propagate only along characteristics. In the case of second-order equations the characteristics are not sufficient to solve the equa-tions, but they continue to provide important information, such as how the singularities propagate.
For example, in the case of the wave equation u = 0 with smooth initial data$p = (t$, x )$, \text{the solutionu}^{0}$, u^1 ueverywhere except at a point has singularities present at all points of the light cone0 0-(t - t0)2 + |x - x0|2 = 0 with vertex at shows that the singularities propagate along bicharac-$p$. A more refined version of this fact teristics. The general principle here is that singularities propagate along characteristic hypersurfaces of a Pde since this is a very important principle, it pays to give.
it a more precise formulation that extends to general boundary conditions, such as the Dirichlet condition for (1). Propagation of singularities. If the boundary conditions or the coefficients of a PDE are singular at some pointp, and otherwise smooth (or real analytic) every- where in some small neighborhood V of p, then a solu- tion of the equation cannot be singular in along a characteristic hypersurface passing through V exceptp.

467

In particular, if there are no such characteristic hyper-surfaces, then any solution of the equation must be smooth (or real analytic) at every point ofthanp. V other Remarks. (i) The heuristic principle mentioned above is in valid, in general, at large scales. Indeed, as we have shown in the case of the Burgers equation, solutions to nonlinear evolution equations can develop new sin-gularities whatever the smoothness of the initial conditions. Global versions of the principle can be formu-lated for linear equations based on the bi characteristics of the equation. See (iii) below.
(ii) According to the principle, it follows that any solu-tion of the equation. elta u = f, satisfying the bound- ary condition merely has to be continuous, is automatically smoo thu|. artial D = u0 with a boundary value u0 that every where in the interior of smooth there. More over, the solution is real analytic if D provided that f itself isf is real analytic. (iii) More precise versions of this principle, which playsa fundamental role in the general theory, can be given for linear equations.
In the case of the general wave equation (39), for example, one can show that singularities propagate along bi characteristics. These are the bi characteristic curves associated with the Hamilton Jacobi equation (40). 2.4 The Cauchy–Kovalevskaya Theorem In the case of ODEs we have seen that a non character is-tic IVP always admits solutions locally (that is, in some time interval about a given point). Is there a higher-dimensional analogue of this fact?
The answer is yes, provided that we restrict ourselves to the real-analytic situation, which is covered by an appropriate extension of the Cauchy–Kovalevskaya theorem. More pre - cisely, one can consider general quasilinear equations, or systems, with real-analytic coefficients, real-analytic hypersurfaces H , and appropriate real-analytic initial data on H .
Theorem (Cauchy–Kovalevskaya (CK)).analyticity conditions made above are satisfied and if If all the real the initial hypersurface then in some neighborhood of H is non characteristic atx there is a uniquex0,4 real-analytic solution equations and the corresponding initial conditions.u(x)that satisfies the system of0 condition (33).4. For second-order equations of the kind of (32), this is precisely

468

companion theorem, due to Holmgren, asserts that the analytic solution given by the CK theorem is unique in In the special case of linear equations, an important the class of all smooth solutions and smooth nonchar-acteristic hypersurfaces H. The CK theorem shows that, given the non characteristic condition and the ana-lyticity assumptions, the following straightforward way of finding solutions works: look for a formal expansionof the kindu(x) = C (x - x )α by determining the constant sl as arising from the equation and initial conditions on Cα recursively from simple algebraic formu-α α 0 H.
More precisely, the theorem ensures that the naive expansion obtained in this way converges in a small neighborhood ofx ∈ H . required by the CK theorem are much too restrictive, and therefore the apparent generality of the result It turns out, however, that the analyticity conditions0 is misleading. A first limitation becomes immediately apparent when we consider the wave equation$u = 0$.
A fundamental feature of this equation is propagation, which means, roughly speaking, that if at finite speed of some time set, then the same must be true at all later times.t a solution u is zero out side some bounded However, analytic functions cannot have this property unless they are identically zero (see some fundamental mathematical definitions it is impossible to discuss the wave equation properly[I.3 §5.6](/part-01/fundamental-definitions)). Therefore, within the class of real-analytic solutions.
A related problem, first pointed out bycerns the impossibility of solving the Cauchy problem, hadamard [VI.65](/part-06/jacques-hadamard-18651963), conin many important cases, for arbitrary smooth nonana-lytic data. Consider, for example, the Laplace equation . elta surf a ceu = 0 in HRis non characteristic, yet the Cauchy problemd. As we have established above, any hyper-ucon ditions|H = u0, un[u]0, u(|1)H, may admit no local solutions in a = u1, for arbitrary smooth initial neighborhood of any point ofbe the hyperplanex = 0 and assume that the Cauchy H .
Indeed, take H to problem can be solved for given nonanalytic smooth data in a domain that includes a closed ball1 B centered at the origin. The corresponding solution can also be interpreted as the solution to the Dirichlet problem in B, with the values of u prescribed on the boundary . artial B.
But this, according to our heuristic principle (which can easily be made rigorous in this case), must be real analytic every where in the interior of assumptions about the initial data. B, contradicting our equation any smooth initial data On the other hand, the Cauchy problem for the waveu = 0 in (Rd)+(u1)0, has a unique solution foru1 that is prescribed on

IV. Branches of Mathematics

aψ(t, x)spacelike hypersurface= 0 such that at every point. This means a hyper surfac ep = (t , x ) that belongs to it the normal vector at light cone (either in the future direction or in the pastp lies inside th(e0)0 direction). To say this analytically, |. artial tψ(p)| >i = {}d1 |. artial iψ(p)(|2()1()/){2}. (41) This condition is clearly satisfied by a hyperplane of the formt = t , but any other hypersurface close to this is also spacelike. By contrast, the IVP istimelike hypersurface, i.e., a hypersurface for which0 ill-posed for a

|. artial tψ(p)| <d |. artial iψ(p)(|2()1()/){2}.

That is, we cannot, for general non-real-analytic initial conditions, find a solution of the IVP. An example of a$i = 1$ timelike hypersurface is given by the hyperplane$x1 =$

0. Let us explain the term “ill-posed” more precisely. Definition.well-posed if both existence and uniqueness of solu-A given problem for a PDE is said to be tions can be established for arbitrary data that belongs to a specified large space of functions, which includes the class of smooth functions.5 More over, the solutions must depend continuously on the data. A problem thatis not well-posed is called ill-posed. port ant.
Indeed, the IVP would be of little use if very small changes in the initial conditions resulted in very The continuous dependence on the data is very im large changes in the corresponding solutions.

2.5 Standard Classification

The different behavior of the Laplace and wave equa-tions mentioned above illustrates the fundamental difference between ODEs and PDEs and the illusory generality of the CK theorem. Given that these two equations are so important in geometric and physical applications, it is of great interest to find the broadest classes of equations with which they share their main properties. The equations modeled by the Laplace equation are called elliptic, while those modeled by the wave equation are calledtant models are the heat equation (see (2)) and the hyperbolic.
The other two impor Schrödinger equation (see (4)). The general classes ofequations that they resemble are called parabolic and dispersive, respectively. in each given case.5. Here we are necessarily vague. A precise space can be specified IV.12. Partial Differential Equations iest to characterize: they are the ones that admit no characteristic hypersurfaces. Elliptic equations are the most robust and the eas Definition. A linear, or quasilinear, N . imes N system with no characteristic hypersurfaces is called elliptic.
Equations of type (32) whose coefficients aij satisfy condition (35) are clearly elliptic. The minimal surface equation (7) is also elliptic. It is also easy to verify that the Cauchy–Riemann system (12) is elliptic. As was pointed out by Hadamard, the IVP is not well-posed for elliptic equations. The natural way of parametrizing theset of solutions to an elliptic PDE is to prescribe conditions for derivatives will be roughly half the order of the equa - u, and some of its derivatives (the number of tion) at the boundary of a domain D ⊂ Rn.
These are called ple is the Dirichlet boundary condition boundary-value problems (BVPs). A typical exam - u| = u for the Laplace equation One can show that, if the domain. elta u = 0 in a domain Dsatisfies certain. artial DD ⊂0 Rn. mild regularity assumptions and the boundary valueu is continuous, then this problem admits a unique solution that depends continuously on0 u0. We say that the Dirichlet problem for the Laplace equation is well-posed.
Another well-posed problem for the Laplace equation is given by the Neumann boundary conditionn[u]| = f , where n is the exterior unit normal to the boundary. This problem is well-posed for all continu-ous functions. artial D fdefined on. artial D with zero mean aver- age. A typical problem of general theory is to classify all well-posed BVPs for a given elliptic system. As a consequence of our propagation-of-singularities principle, we deduce, heuristically at least, the follow-ing general fact:
Classical solutions of elliptic equations with smooth(or real-analytic) coefficients in a regular domain D are smooth (or real analytic) in the interior ofthe degree of smoothness of the boundary conditions. D, whatever6 the IVP is well-posed. In that sense, they provide the natural class of equations for which one can prove Hyperbolic equations are, essentially, those for which a result similar to the local existence theorem for ODEs. More precisely, for each sufficiently regular set of initial conditions there is a unique solution. We can well-posed.
More over, this heuristic principle holds, in general, only for classical solutions of a nonlinear equation. There are in fact exam-6. Provided that the boundary condition under consider at i on is ples of well-posed BVPs, for certain nonlinear elliptic systems, with noclassical solutions.

469

thus think of the Cauchy problem as a natural way of parametrizing the set of all solutions to the equations. on the particular hypersurface we are considering asthe initial hypersurface. Thus, in the case of the wave The definition of hyperbolicity depends, however, equation u = 0$, \text{the standard IVPu}(0, x) = u0(x)$, . artial tu(0, x) = u^1

is well-posed. This means that for any smooth initial data tion, which depends continuously on u0, u1 we can find a unique solution of the equa- u0, u1. As we have already mentioned, the IVP for posed if we replace the initial hypersurfaceu = 0 remains well - t = 0 by any spacelike hypersurfaceψ(t$, x) = 0 (see (41))$. However, it fails to be well-posed for timelike hypersurfaces, for which there may be no solution with prescribed, nonanalytic, Cauchy data. hyperbolicity.
Roughly speaking, hyperbolic equations are at the opposite end of the spectrum from ellip-It is more difficult to give algebraic conditions for tic equations: where as elliptic equations have no char-acteristic hypersurfaces, hyperbolic equations have as many as possible passing through any given point. Oneof the most useful classes of hyperbolic equations, which includes most of the important known examples, consists of equations of the form $A^{0}(t$, x, u)∂tu +i=d 1 Ai(t, x, u)∂iu = F(t, x, u)$, u|H = u0$, (42) where all the coefficients$A0$, A1, . . .
, Ad are symmetric N . imes  N matrices and H is given by ψ(t, x) = 0. Such a system is well-posed provided that the matrix A0(t, x, u)∂tψ(t, x) +i=d 1 Ai(t, x, u)∂iψ(t, x) (43) is positive definite. A system (42) that satisfies these conditions is called symmetric hyperbolic. In the particular case whenψ(t$, x) = t, \text{the condition} (43) becomes$(A0ξ, ξ) ⩾ c|ξ|2 ∀ξ \in  RN.

The following is a fundamental result in the theory of general hyperbolic equations. It is called the local existence and uniqueness of solutions for symmetric hyperbolic systems. Theorem (fundamental theorem for hyperbolic equa-tions). The IVP (42) is locally well-posed for symmetric hyperbolic systems with sufficiently smooth and Hand sufficiently smooth initial conditionsu A,. In F,

470

other words, if the appropriate smoothness conditions are satisfied, then for any pointp ∈ H there is a small neighborhood D of p7 inside which there is a unique, continuously differentiable solutio nu. Remarks.essential, just as it was for the general propagation-(i) The local character of the theorem is of-singularities principle discussed earlier, since the result cannot be globalized in the particular case ofthe Burgers equation (21), which fits trivially into the framework of general nonlinear symmetric hyperbolic systems.
A precise version of the theorem above gives a lower bound on how large D can be. (ii) The proof of the theorem is based on a variation ofthe Picard iteration method that we encountered earlier for ODEs. One starts by takinghood of$H$. Then one defines functions(u(()0){)} = uu0 in a neighbor - recursively(n)

as follows:

$A^{0}(t$, x, u((n-1)))∂tu(n) +i=d 1 Ai(t, x, u((n-1)))∂iu(n)= F(t, x, u((n-1)))$, u^{(}n)|H = u^{0}$.

Notice that at each stage of the iteration we have to solve a linear equation. Linearization is an extremely important tool in studying nonlinear PDEs. We can almost never understand their behavior with out linear iz-ing them around important special solutions. Thus, almost invariably, hard problems in nonlinear Pdes reduce to understanding specific problems in linear PDEs. (iii) To implement the Picard iteration method we needto get precise estimates concerningu in terms ofu((n-1)). This step requires energy type a priori esti-^(n) mates, which we will discuss in section 3.3.
Another important property of hyperbolic equations (which is not shared by elliptic, parabolic, or disper-sive equations) is finite speed of propagation, which was mentioned earlier in the case of the wave equa-tion (3). Consider this simple case again. The IVP can be solved explicitly by the so-called The formula allows us to conclude that if the initial Kirchhoff formula. data ata > 0 centered att = 0 is zero out side a ballx \in  R3, then at time Ba(x0)t >of radius0 the solution eral, finite speed of propagation can best be formulatedu is zero out side the ball0 Ba+ct(x0).
In gen- in terms of domains of dependence and influence of Similarly,7. By “point” we mean that D is a set of spacetime points.p is a spacetime point (t, x) \in R 1 +d.

IV. Branches of Mathematics

hyperbolic equations (see the online version for general definitions). as they are intimately tied to the relativistic nature Hyperbolic PDEs play a fundamental role in physics, of the modern theory of fields. Equations (3), (5), (13)are the simplest examples of linear field theories, and they are manifestly hyperbolic. Other basic examples appear in gauge field theories such as maxwell’s equations tions D[IV.13 §1.1](/part - 04/general - relativity - and - the - einstein - equations)αF = 0.
Finally, the Einstein equations (14) are. artialαFαβ = 0 or the Yang–Mills equa also hyperbolic.bolic equations arise in the physics of elasticity andαβ8 Other important examples of hyper- inviscid fluids. As examples of the latter, the Burgers equation (21) and the compressible Euler equation are hyperbolic. rally in describing time - independent, or more generally steady-state Elliptic equations, on the other hand, appear natu-, solutions of hyperbolic equations.
Elliptic equations can also be derived, directly, by well-defined variational principles [III.94](/part - 03/variational - methods). Schrödinger-type equations, which are intermediate Finally, a few words about parabolic equations and between the elliptic and hyperbolic ones. Large classes of useful equations of these types are given by

$\partial u - Lu = f (44)t$

and

i$\partial u + Lu = f$, (45)t

respectively, whereator. One looks for solutions L is an elliptic second-order oper-u = u(t, x), defined for $t ⩾ t^{0}$, with the prescribed initial conditionu(t0, x) = u0(x) (46)

on the hypersurface hypersurface is characteristic, since the order of the$t = t0$. Strictly speaking, this equation is 2 and we cannot determine$\partial t 2u at t = t0$ directly from the equation. Yet this is not a serious problem; we can still determine. artial2 uformally by diff ert entiating the equation with respect to(44) (or (45)) with initial condition (46) is well-posed, but∂t. Thus, the IVP not quite in the same sense as for hyperbolic equations. For example, the heat equation-. artial u+. elta u is well - posedt

for positive tion may also not have unique solutions for the IVPt but ill-posed for negative t. The heat equa- unless we make assumptions about how fast the initial data is allowed to grow at infinity. One can also show bol i city depends on the choice of gauge or coordinates. In the caseof the Yang–Mills equations, for example, one obtains a well-defined8. For gauge theories and Einstein equations the notion of hyper system of nonlinear wave equations only in the Lorentz gauge.

IV.12. Partial Differential Equations

that the characteristic hypersurfaces of the equation(44) are all of the form, and therefore parabolic equations are quite similar to elliptic equations. For exam-ple, one can show that if the coefficients aij and f are smooth (or real analytic), then the solution smooth (or real analytic inx) for t > t even if the ini - u must be tial datau0 is not smooth, which is consistent with our0 propagation - of-singularities principle. The heat equa-tion smooths out initial conditions. It is for this reason that the heat equation is useful in many applications.
In physics, parabolic PDEs arise whenever diffusion or dissipation phenomena are important, while in geometry and calculus of variations, parabolic PDEs often arise as gradient flows of positive-definite functionals. Ricci flow (16) can also be viewed as a parabolic PDE, after a suitable change of coordinates. Dispersive PDEs, of which the Schrödinger equation (4) is a fundamental example, are evolution equations that behave analogously to hyperbolic PDEs in many respects. For instance, the IVP tends to be locally well-posed both forward and backward in time.
How - ever, solutions to dispersive PDEs do not propagate along characteristic surfaces. Instead, they move at speeds that are determined by their spatial frequency; in general, high-frequency waves tend to propagate atmuch greater speeds than low-frequency waves, which eventually leads to a increasingly large areas of space. In fact, the speed dispersion of the solution into of propagation of solutions is typically infinite.
this behavior also differs from that of parabolic equations, which tend toof a solution (sending them to zero) rather than dis-dissipate the high-frequency components persing them. In physics, dispersive equations arise in quantum mechanics: they are the nonrelativistic limit c →. nftyof relativistic equations and they are also approximations to model certain types of fluid behav - ior. For instance, the korteweg–de vries equation [III.49](/part - 03/linear - and - nonlinear - waves - and - solitons),

. artial tu + . artial3 xu = 6 u. artial xu, is a dispersive PDE that models the behavior of small-amplitude waves in a shallow canal. 2.6 Special Topics for Linear Equations The greatest successes of the general theory have beenin connection with linear equations, especially those with constant coefficients, for which Fourier analysis provides an extremely powerful tool. While the related issues of classification, well - posedness, and propaga-tion of singularities have dominated the study of lin - 471 ear equations, there are other issues of interest as well, including the following.
2.6.1 Local Solvability This is the problem of determining the conditions ona linear operator P and given data f under which the equation (9) is locally solvable. The Cauchy–Kovalevskaya theorem gives a criterion for local solvability when fand the coefficients of P are real analytic, but it is a remarkable phenomenon that when one relaxes this assumption slightly, asking forf to be smooth rather than real analytic, serious obstructions to local solvability appear.
For instance, the Lewy operator P[u](t, z) = . artial u. artial$\bar{z}(t, z) - iz \partial u\partial t (t, z)$, defined on complex-valued functions$u$: R$\times C \to C$, has the property that equation (9) is locally solvable for real-analytic$f$but not for “most” smoot hf . The Lewy operator is intimately connected to the tangential Cauchy–Riemann equations on the Heisenberg group in C2. It was discovered in the study of the restriction of the two-dimensional analogue of the Cauchy–riemann operator P to a quadric in C^2.
This example was the starting point for the theory ofgoal is to characterize linear equations that are locally local solvability, whose solvable. The theory of Cauchy–Riemann manifolds—which has its origin in the study of restrictions of the Cauchy–Riemann equations (in higher dimensions)to real hypersurfaces, each of which comes with an associated “tangential Cauchy–Riemann complex”—is another extremely rich source of examples of inter-esting linear PDEs, which do not fit into the standard classification.

2.6.2 Unique Continuation

This concerns various ill-posed problems where solu-tions may not always exist, but one still has uniqueness. A fundamental example is that oftinuation: two holomorphic functions on a connected analytic condomainor an interval) must necessarily agree every where on D that agree on a nondiscrete set (such as a disk D. This fact can be viewed as a unique continuation result for the Cauchy–Riemann equations (12).
Another example in a similar spirit is Holmgren’s theorem, which asserts that solutions to a linear PDE (9) that has real-analytic coefficients and data are unique, even in the class of smooth functions. More generally, the study of

472

ill-posed problems (such as the wave equation with pre-scribed data on a timelike surface rather than a spacelike one) arises naturally in connection with control theory.

2.6.3 Spectral Theory

There is no way I can even begin to give an account of this theory, which is of fundamental importance not only to quantum mechanics and other physical theories, but also to geometry and analytic number theory [IV.2](/part-04/number-theory). Just as a matrix A can often be analyzed through itsby the tools of linear algebra, one can learn much about eigenvalues and eigenvectors [I.3 §4.3](/part-01/fundamental-definitions) a linear differential operator P and its associated PDE by understanding that operator’se i gen functions with the help of tools from spectrum
functional[III.86](/part-03/the-spectrum) and analysisis the eigenvalue problem[IV.15](/part-04/operator-algebras). A typical problem in spectral theory in R$d$:

$-\Delta u(x) + V (x)u(x) = \lambda u(x)$.

A function being bounded in theu that is localized in space (for example, by L2(Rd)-norm) and that satisfies this equation is mapped by the linear operator$-\Delta + V$ to the function with eigenvalue. ambda uλ.: we say thatu is an eigenfunctionφ(t, x)solution of the Schrödinger equation Suppose that we have an eigenfunction= (e-i). ambda tu(x). It is easy to check thatu and letφ is a$i$∂ φ + Δφ - V φ = 0. (47)t

More over, it has a very special form. Such solutions are called bound states of the physical system described by (47). The eigenvalues correspond to the quantum energy levels of the sys-λ, which form a discrete set, tem. They are very sensitive to the choice of potential V . The inverse spectral problem is also important: can one determine the potential V from knowledge of the corresponding eigenvalues? The eigenvalue problem can be studied in considerable generality by replacing the operator-Δ + V with other elliptic operators.
For instance, in geometry it is important to study the eigen-value problem for the Laplace–Beltrami operator, which is the natural generalization of the Laplace operator from Rn to general[I.3 §6.10](/part-01/fundamental-definitions). When the manifold has some arithmetic structure (for instance, if it is the quotient of the upper half-plane by riemannian manifolds a discrete arithmetic group), this problem is of major importance in number theory, leading, for instance, tothe theory of Hecke–Maas forms. A famous problem in differential geometry (“can you hear the shape of

IV. Branches of Mathematics

a drum?”) is to characterize the metric on a compact surface from the spectral properties of the associated Laplace–Beltrami operator.

2.6.4 Scattering Theory

This theory formalizes the intuition from quantum mechanics that a potential which is small or localizedis largely unable to “trap” a quantum particle, which is therefore likely to escape to infinity in a manner resem-bling that of a free particle. In the case of equation (47), solutions that scatter are those that behave freely ast → $\infty$. That is, they behave like solutions to the free Schrödinger equation i$\partial ψ + \Deltaψ = 0$. A typical prob - t

lem in scattering theory is to show that, ifto zero sufficiently fast as|x| → $\infty$, all solutions, except V (x) tends the bound states, scatter ast → $\infty$.

2.7 Conclusions

In the analytic case, the CK theorem allows us to solve the IVP locally for very general classes of PDEs. We have a general theory of characteristic hypersurfaces of PDEs and a good general understanding of how they relate to propagation of singularities. We can also distinguish in considerable generality the fundamental classes ofelliptic and hyperbolic equations and can define general parabolic and dispersive equations. The IVP for a large class of nonlinear hyperbolic systems can be solved locally in time, for sufficiently smooth initial conditions.
Similar local-in-time results hold for gen-eral classes of nonlinear parabolic and dispersive equations. For linear equations a lot more can be done. We have satisfactory results concerning the regularity of solutions for elliptic and parabolic equations and a good understanding of the propagation of singular-ities for a large class of hyperbolic equations. Some aspects of spectral theory and scattering theory and problems of unique continuation can also be studied in considerable generality. passage from local to global.
Important global featuresof special equations are too subtle to fit into a general The main defect of the general theory concerns the scheme. Rather, each important PDE requires special treatment. This is particularly true for nonlinear equations: the long-term behavior of solutions is very sen-sitive to the special features of the equation at hand. More over, general points of view may obscure, through unnecessary technical complications, the main proper-ties of the important special cases. A useful general framework is one that provides a simple and elegant

IV.12. Partial Differential Equations

treatment of a particular phenomenon, as is the case for symmetric hyperbolic systems and the phenomenon of local well-posedness and finite speed of propaga-tion. However, it turns out that symmetric hyperbolic systems are simply too general for the study of more refined questions about the important examples of hyperbolic equations.
3 General Ideas As one turns away from the general theory, one maybe inclined to accept the pragmatic point of view described earlier, according to which PDEs is not areal subject but is rather a collection of subjects such as hydrodynamics, general relativity, several complex variables, elasticity, etc., each organized around a special equation. However, this rather widespread view-point has its own serious drawbacks. Even though specific equations have specific properties, the tools that are used to derive them are intimately related.
In fact, there is an impressive body of knowledge relevant to all important equations, or at least large classes of them. Lack of space does not allow me to do anything more than enumerate them below.9

3.1 Well-Posedness

As is clear from the previous section, well-posed problems are at the heart of the modern theory of PDEs. Recall that these are problems that admit unique solutions for given smooth initial or boundary conditions, and that the corresponding solutions have to depend continuously on the data. It is this condition that leads to the classification of PDEs into elliptic, hyperbolic, parabolic, and dispersive equations. The first step inthe study of a nonlinear evolution equation is a proof of a local-in-time existence and uniqueness theorem, simi-lar to the one for ODEs.
Ill-posedness, the counterpart of well-posedness, is also important in many applications. The Cauchy problem for the wave equation (3), with data on the timelike hypersurface$z = 0$, is a typical example. Ill-posed problems appear naturally in con-trol theory, as we have mentioned, and also in inverse scattering. important functional analytic tools connected to Hilbert space meth-ods, compactness, the implicit function theorems, etc. I also fail to9.
I fail to mention in the few examples given above some of the mention the importance of probabilistic methods and the develop-ment of topological methods for dealing with global properties of elliptic PDEs.

473

3.2 Explicit Representations and Fundamental

Solutions

Our basic equations (2)–(5) can be solved explicitly. For example, the solution to the IVP for the heat equationin R1$+d$, that is, the problem of finding a functionu that satisfies$+-\partial^{t}u + \Delta u = 0$, u(0, x) = u0(x),$for$ t ⩾ 0, is given byu(t, x) =^R^d E^d(t, x - y)u^0(y) dy

for a certain function tal solution of the heat operator$E^{d}$, which is called the-∂ + Δ. This func-fund a men-t

tion can be defined explicitly: when and whent > 0 it is given by the formul at ⩽ E0 it is 0,(t, x) =(tion4πt)(--d/∂2+e−|Δx)(E|()2){/}4=t. Observe that0 in both regions Edsatisfies the equa-$t < 0 and^{d} t > 0$, t

but it has a singularity at satisfying the equation in the whole oft = 0, which prevents it from (R1)+d. In fact, we can check that for any function have 10φ \in C0 . nfty ((Rd)+1), we Ed(t, x)(∂tφ(t, x) + Δφ(t, x)) dt dx = φ(0, 0).$R$ d+1 (48) In the language of distribution theory [III.18](/part - 03/distributions), formula (48) means that the equation(-. artial + . elta)EEd, as a distribution, satisfies= δ, where δ is the Dirac distributionδ (φ) = φ(0 in, 0 R),1 t +∀dφsupported at the origin. That is,\in Cd. nf ty ((Rd()0){ + 1}).
A similar notion of0 fundamental solution can be defined for the Poisson, wave, Klein–Gordon, and Schrödinger equations.0 0 stant coefficients is based on A powerful method of solving linear PDEs with con-the fourier transform. artial - . elta[III.27](/part - 03/the - fourier - transform). For example, consider the heat equationu = 0 in one space dimension, with initial con-t

dition transform of$u(0$, x)u=relative to the space variable:$u^{0}$. Define ˆu(t, ξ) to be the Four i eru(t, ξ)ˆ$= {}^{−}$. nfty+. nfty(e-i)xξu(t, x) dx.

It is easy to see that ˆequationu(t, ξ)satisfies the differential ∂tu(t, ξ)ˆ$= −ξ^{2}u(t$, ξ), u(  0, ξ) = uˆ0(ξ). This can be solved by a simple integration, which results in the formula ˆu(t, ξ) = uˆ(ξ)(e-t()|)ξ| 2. Thus, with in10. That is, any function that is smooth and has compact support R1+d.

474

the help of the inverse Fourier transform, we derive a formula foru(t, x): u(t, x) = (2π()-1)−. nfty+. nfty (ei)xξ (e-t()|){ξ}| 2 uˆ0(ξ) dξ. Similar formulas can be derived for our other basic evo-lution equations. For example, in the case of the wave equation-. artial2 u + . elta u = 0 in three dimensions, sub jec tt

to the initial data that$u(0$, x) = u0$, \partial tu}(0$, x) =$0$, we find u(t, x) = (2π)^-3 R 3 (ei)xξ . os (t|ξ|)uˆ0(ξ) dξ. (49) After some work, one can reexpress formula (49) in the form u(t$, x) = \partial t (4πt)-1^{(}|x)-y^{|} = t u0(y) da(y)$, (50) where da is the area element of the sphere |x-y | = t of radius formula$t$. By contrast with (49), the integration here iscentered at x. This is the well-known Kirchhoff with respect to the physical variablest and x only. It is instructive to compare these two formulas.
Using the Plancherel identity it is very easy to deduce from (49) the L2 bound|u(t, x)|2 dx ⩽ C (u0()2)L2 ( R 3 ), while the possibility of obtaining such a bound from R3 (50) seems unlikely since the formula involves a deriva - tive. On the other hand, (50) is perfect for giving us information about the domain of influence. Indeed, we can see immediately from the formula that if out side the ball B = {|x - x | ⩽ a}, then uu(t, x)0 is zerois zero out side the balla (Ba)+(|t)| for any time0 t. This fact does not seem at all transparent in the Fourier-based formula (49).
The fact that different representations of solutions have different, even opposite, strengths and weaknesses has important consequences for con-struc ting approximate solutions, or parametrices, for more complicated equations, such as linear equations with variable coefficients or nonlinear wave equations. There are two possible types of constructions: those in physical space, which mimic the physical-space for-mula (50), and those in Fourier space, which mimic the formula (49).

3.3 A Priori Estimates

Most equations cannot be solved explicitly. However, if we are interested in qualitative information about a solution, then it is not necessary to derive it from an exact formula. But how else, one might wonder, can we

IV. Branches of Mathematics

extract such information? A priori estimates are a very important technique for doing this. maximum principle simplest example of the first type is the following iden-The best-known examples are, and monotonicity arguments energy estimates. The, the tity (which is a very simple example of a so-called Bochner-type identity): The left-hand side is shorthand for R d |. artial2 u(x)|2 dx = R d |. elta u(x)|2 dx.|. artial i. artial ju(x)|2 dx$R$ d1⩽i, j⩽d

and the identity holds for all functions twice continuously differentiable and tend to zero asu that are|x| → . nfty. This formula can be justified fairly simply by integrating by parts. As a consequence of the bochner identity, we obtain the a priori estimate that ifu is a smooth solution to the Poisson equation (6) with square-integrable dataf, and if it tends to zero at infinity, then the square integral of its second derivatives is bounded:
Thus we obtain the qualitative fact that, on average(in a mean-square sense), R$d |\partial^{2}u(x)|^{2} dx ⩽^{R}^{d}u|f (x)$has “two more degrees$|^{2} dx < \infty$. (51) of regularity” thanf .11 This is called an energy-type estimate because, in physical situations, the square ofthe L2-norm can often be interpreted as some type of kinetic energy. eral Riemannian manifolds than picks up some additional lower-order terms involving The Bochner identity can be extended to more gen-Rd, although one then the curvature of those manifolds.
Such identities playa major role in the theory of geometric PDEs on these manifolds. Energy-type identities and estimates also exist for parabolic, dispersive, and hyperbolic PDEs. For in-stance, they play a fundamental role in demonstrating the local existence, uniqueness, and finite speed of propagation for hyperbolic PDEs with smooth initial data. Energy estimates become particularly powerful when combined with inequalities such as the Sobolev embedding inequality , which allows one to convert version, is that the1 11.
A crucial fact, about which one can read more in the online$< p < \infty$, or Hölder-type norms. The first case corresponds L2-norms in (51) can be replaced by Lp-norms, to Schauder estimates Calderon–Zygmund estimates. Both are extremely important in the study of, while the second corresponds to regularity properties for solutions to second-order elliptic PDEs.

IV.12. Partial Differential Equations

the “pointwise (or “L2” information provided by these estimates into$L \infty$”) type information (see function spaces While energy identities and [[III.29 §§2.4, 3]](/part - 03/function - spaces)).$L^{2} estimates (which$, as in the above example, come from integration by parts)apply to all, or at least major classes of, PDEs, the maximum principle can be applied only to elliptic and parabolic PDEs. The following theorem is the simplest manifestation of it.
Note that the theorem provides us with important quantitative information about solu-tions to the Laplace equation even in the absence of any explicit representation for them. Theorem (maximum principle).solution to the Laplace equation (1) on a bounded con-Assume thatu is a nected domain D \in Rd with a smooth boundary . artial D. Assume also that and has continuous first and second partial derivative su is continuous on the closure of D in the interior ofand minimum values on the boundary. More over, if the D.
Then u must achieve its maximum maximum or minimum is also achieved at an interior point of D, then u must be constant in D. The method is very robust and can easily be extended to a large class of second-order elliptic equations. It can also be extended to parabolic equations and systems, and plays a crucial role in, for example, the study of Ricci flow. of a priori estimates.
The Sobolev inequalities, which are of prime importance in elliptic equations, have Let us briefly mention some other important classes several counterparts in linear and nonlinear hyperbolic and dispersive equations, including the estimates and bilinear estimates. In connection with Strichartz ill-posed problems and unique continuation, man estimates play a fundamental role.
Finally, sev-Carle eral a priori estimates arising from monotonicity for - mulas12—such as virial identities, Pohozaev identities, orbreakdown of regularity or the Morawetz inequalities—can be used to establish the blow-up of solutions to some nonlinear equations, and to guarantee global existence and decay of solutions to others. to say that a priori estimates play a fundamental rolein more or less every aspect of the modern theory of To summarize, it is not much of an exaggeration PDEs. nomenon is the asserts that, for many physical systems, the total12.
Perhaps the most familiar example of a monotonicity phe-second law of thermodynamics from physics, which entropy of the system is an increasing function of time. 475 3.4 Bootstrap and Continuity Arguments The er ful general philosophy, to derive a priori estimates bootstrap argument is a method, or rather a powfor nonlinear equations. According to this philosophy we start by making educated assumptions about the solutions we are trying to describe.
These assumptions allow us to think of the original nonlinear problem asa linear one whose coefficients satisfy properties consistent with the assumptions. We may then use linear methods, based on other a priori estimates that we already know, to try to show that the solutions to this linear problem behave as well as we have postulated—in fact, even better. One can characterize this powerful method, which allows us to use linear theory with out actually having to linearize the equation, as atual linearization.
It can also be regarded as a continu-concepity argument relative to some parameter, which might be the natural time parameter of an evolution problem, but it could also be an artificial parameter which we have the freedom to introduce ourselves. This latter situation is typical of applications to nonlinear elliptic equations. In the online version of this article we pro-vide a few examples to illustrate the method in both cases.
3.5 The Method of Generalized Solutions Since a PDE involves differentiation, it might seem obvious that in any discussion of PDEs we should restrict our attention to differentiable functions. However, it is possible to generalize the notion of differentiation so that it makes sense for a wider class of functions, and even for function-like objects, such as distributions, that are not functions at all. This allows us to make sense of a PDE in a broader context, and admits the possibility of generalized solutions.
PDEs and explain why they are important is through the The best way to introduce generalized solutions in Dirichlet principle. This originates in the observation that, out of all functions that are defined ona bounded domain D ⊂ Rd, that satisfy prescribed Dirichlet boundary conditionan appropriate functional spaceu|. artial DX , the functions = f , and that live inu that minimize the Dirichlet integral (or Dirichlet functional) d(u2)Dr = 12 D |∇u|2 = 12 = D |. artial iu|2 (52) are the harmonic functions (that is, solutions of the equation$\Delta u = 0)$.
It was riemann i[VI.49] who first had1 476 the idea of trying to use this fact to solve the dirichlet problem: in order to find a solution u to the problem. elta u = 0, u|. artial D = u0, (53) one should find (by some means other than solving the Dirichlet problem) a functionu that minimizes the Dirichlet integral while equaling one must specify the set by functions, or rather theu0 on . artial D. To do this, function space, over which the minimization is taking place. The history of how this choice was made is a fascinating one.
A natural choice is X = C1(D) ̄ , the space of continuously differentiable functions o. ar{n}the norm of a functionv is D, where(v C)1(D)^ ̄ = . upx\in D(|v(x)| + |∂v(x)|). In particular, the Dirichlet normv belongs to this space. In fact, Riemann chosev Dris finite when X =C2(D) ̄ (a similar space but designed for twice continuously differentiable functions). This bold but flawed attempt was followed by a penetrating criticism by weierstrass does not have to achieve its minimum in either[VI.44](/part-06/karl-weierstrass-18151897), who showed that the functional$C2(D)$ ̄ or$C^{1}(D)$ ̄ .
However, Riemann’s basic idea was revived, and it eventually triumphed after a long and inspir-ing process that involved defining appropriate function spaces, introducing the notion of generalized solutions, and developing a regularity theory for them. (The precise formulation of the Dirichlet principle also requires the definition of sobolev spaces [III.29 §2.4](/part-03/function-spaces).) been vastly extended so that it can be applied to a large class of linear Let us briefly summarize the method, which has since13 and nonlinear elliptic and parabolic equations. It is based on two steps.
In the first step one applies a minimization procedure. Although, as Weierstrass discovered, the natural function spaces may not contain functions that achieve the minimum, one canuse such a procedure to find a generalized solution instead. This may not seem very interesting, since wewere looking for a function that solves the Dirichlet problem (or one of the other problems to which the method can be applied). But this is where the second step comes in:
it is some times possible to show that the generalized solution must in fact be a classical solu-tion (that is, an appropriately smooth function) after all. This is the “regularity theory” mentioned earlier. In some situations, however, the generalized solution may turn out to have singularities and therefore notbe regular. Then the challenge is to understand the

13. A not able example for applications in geometry is Hodge theory.

IV. Branches of Mathematics

nature of these singularities and to prove realistic ti al regularity results. For instance, it is some times pos-par si ble to prove that the generalized solution is smooth every where apart from in a small “exceptional set.”Though generalized solutions are at their most effective for elliptic problems, their range of applicability encompasses all PDEs. For example, we have already seen that the fundamental solutions to the basic linear equations have to be interpreted as distributions, which are examples of generalized solutions.
successful for nonlinear evolution problems, such as systems of conservation laws in one space dimension. The notion of generalized solutions has also proved An excellent example is provided by the Burgers equa-tion (21). As we have seen, solutions to$\partial u + u\partial u =$ 0 develop singularities in finite time no matter how smooth the initial conditions are. It is natural to ask$t^{x}$ whether solutions continue to make sense, as general-ized solutions, even beyond the time when these singularities form.
A natural notion of generalized solutionis a function$u$ such that(∂tu + u∂x u)φ = 0

for every smooth function bounded set, since one can make sense of the integral R1+1 φ that is zero out side a even when ing this by parts (the first term with respect touis not a differentiable function. Integrat-t and the second with respect to formulation: x) one obtains the following It can be shown that, under additional conditions called R1+1 u. artial tφ + 1(2 R()1)+1 u2. artial xφ = 0 ∀φ \in C0 . nf ty ((R1)+1). entropy conditions admits a unique generalized solution that is, the IVP for the Burgers equation global: that is, valid for everyt \in  R.
Today we have a satis- factory theory of global solutions to a large class of hyperbolic systems of one-dimensional “conservation laws.” These systems, for which the above-mentioned theory applies, are called strictly hyperbolic. the question of what constitutes a good concept ofa generalized solution, though fundamental, is far For more complicated nonlinear evolution equations, murkier. For higher-dimensional evolution equations the first concept of a weak solution was introduced by Leray. Let us call a generalized solution not prove any type of uniqueness for it.
This unsatisfac-weak if one cantory situation may be temporary, i.e., the result of our technical inabilities, or unavoidable, in the sense that the concept itself is flawed. Leray was able to produce, by a compactness method, a weak solution of the IVP

IV.12. Partial Differential Equations

for the advantage of the compactness method (and its mod-navier–stokes equations [III.23](/part-03/the-euler-and-navierstokes-equations). The great ern extensions, which can, in some cases, cleverly cir-cumvent lack of compactness) is that it produces global solutions for all data. This is particularly important for supercritical or critical nonlinear evolution equations, which we will discuss later. For these we expect clas-sical solutions to develop singularities in a finite time. The problem, however, is that one has very little con-trol over such solutions.
In particular, we do not know how to prove their uniqueness.14 Similar types of solutions were later introduced for other important non-linear evolution equations. In most of the interesting cases of supercritical evolution equations, such as the Navier–Stokes equations, the usefulness of the types of weak solutions discovered so far remains undecided.

3.6 Microlocal Analysis, Parametrices, and

para differential Calculus

One of the fundamental difficulties of hyperbolic and dispersive equations is the interplay between geometric properties, which concern the physical space, and other properties, intimately tied to oscillations, that are best seen in Fourier space. Microlocal analysis is a general still-developing philosophy according to which one isolates the main difficulties by careful localizations in physical space or Fourier space or both.
An important application of this point of view is the construction of parametrices for linear hyperbolic equations and their use in proving results about the propagation of singu-larities. Parametrices, as we have already mentioned, are approximate solutions of linear equations with vari-able coefficients, with error terms that are smoother. The local analysis to nonlinear equations.
It allows one topara differential calculus is an extension of mi cro manipulate the form of a nonlinear equation by taking account of how large and small frequencies interact, and it has achieved a remarkable technical versatility.

3.7 Scaling Properties of Nonlinear Equations

A PDE is said to have are scales a solution in an appropriate way, one obtains scaling property if, whenever one another solution. Essentially, all basic nonlinear equa-tions have well-defined scaling properties. Take, for example, the Burgers equation (21),. artial tu + u. artial xu = 0. If other researchers after him, he was unable to prove uniqueness ofhis weak solution, he managed to show that it must coincide with a14. Leray was very concerned about this point. Though, like all classical one as long as the latter does not develop singularities.

477

uu is a solution of this equation, then so is the function defined byu (t, x) = u(. ambda t, . ambda x). Similarly, if u is a solution of the cubic nonlinear Schrödinger equation in R$d^{λ}$,λ$i$∂ u + Δu + c|u|2 u = 0, (54)t

then so is between the nonlinear scaling of the equation and$u^{λ}(t$, x) = . ambda u(λ2 t, . ambda x). The relationship the a priori estimates available for solutions to the equations leads to an extremely useful classification of equations into subcritical, critical, and supercritical equations. This will be discussed in more detail in the next section.
For the moment it suffices to say that subcritical equations are those for which the nonlinearity can be controlled by the existing a priori estimates of the equation, while supercritical equations are those for which the nonlinearity appears to be stronger. Critical equations are borderline. The definition of critical-ity and its relationship with the issue of regularity play a very important heuristic role in nonlinear PDEs. One expects supercritical equations to develop singularities and subcritical equations not to.
4 The Main Equations In the previous section we argued that, while there isno hope of finding a general theory of all PDEs, there is nevertheless a wealth of general ideas and techniques that are relevant to the study of almost all important equations. In this section we indicate how it may bepossible to identify the features that characterize the equations we call important. Most of our basic PDEs can be derived from simple geometric principles, which happen to coincide with some of the underlying geometric principles of modern physics.
These simple principles provide a unifying framework15 for the subject and help endow it with a sense of purpose and cohesion. They also explain why a very small number of linear differential opera - tors, such as the Laplacian and the d’Alembertian, are all - pervasive. Let us begin with the operators. The Laplacian is the simplest differential operator that is invariant under rigid motions of Euclidean space—a fact that we noted at the beginning of this article. This is important math-ematically and physically:
mathematically because it spite of the enormous number of PDEs studied by mathematicians, physicists, and engineers, there are nevertheless simple basic princi - 15. The scheme sketched below is only an attempt to show that, in ples that unite them. I do not want, by any means, to imply that the equations discussed below are the only ones worthy of our attention. 478 results in many symmetry properties and physically because many physical laws are themselves invariant under rigid motions.
The d’Alembertian is, simi - larly, the simplest differential operator that is invariant under the natural symmetries, or Poincaré transforma - tions, of Minkowski space. view of physics, the heat equation is basic because it isthe simplest paradigm for diffusive phenomena, while Now let us turn to the equations. From the point of the Schrödinger equation can be viewed as the Newtonian limit of the Klein–Gordon equation.
The geometric framework of the former is Galilean space, which itself is simply the Newtonian limit of Minkowski space.16 dinger, and wave equations are basic because the corre-sponding differential operators From a mathematical point of view, the heat, Schrö-. artial - . elta, (1/i). artial - . elta, and. artial2 - . elta are the simplest evolution operators that can b(et)tt built out of. elta. The wave operator, as just discussed, is basic in a deeper way because of the association between= −. artial2 + . elta and the geometry of Minkowskit space R1+n.
As for Laplace’s equation, one can view solutions to tions toφ . elta=φ0. Appropriate invariant and local def-= 0 as special time-independent solu- initions of square roots of. elta and, or - k2, corre- sponding to “spinorial representations” of the lorentz group, lead to the associated Dirac operators (see (13)). In the same vein we can associate with every Rie-mannian or Lorentzian manifold the operatorΔ or These equations inherit in a straightforward way the symmetries of the spaces on which they are defined.g, respectively, or the corresponding Dirac operators.g

4.1 Variational Equations

There is a general and extremely effective method for generating equations with prescribed symmetries that plays a fundamental role in both physics and geometry. One starts with a scalar quantity, called a Lagrangian, such as $L[φ] = {}^{\mu}$,ν3=0 mμν ∂μφ∂νφ - V (φ)$, (55) with$φa real-valued function defined on R1$+3 and V$ some real function of$φ^{3}$.
Here ∂ denotes the partial derivatives with respectφ such as, for example, V (φ) = to the coordinates as earlier, denotes the 4\mu x^μ, μ. imes =4 diagonal matrix with diago-0, 1, 2, 3, and m^μν = m^μν, nal entries(-1, 1, 1, 1), associated with the Minkowski diagletting16. This is done by starting with the Minkowski metric(-1 c/c→$\infty$2, 1.,1,1), where c corresponds to the velocity of light, andm =

IV. Branches of Mathematics

metric. We associate with L[φ] the so-called action integral: S[φ] =R 3 +1 L[φ].

Notice that both L[φ] and S[φ] are invariant under translations and Lorentz transformations. In other words, if$T$: R1+3 \to  (R1)+3 is a function that does not change the metric and we define a new function byψ(t$, x) = φ(T (t, x))$, then L[φ] = L[ψ] and S[φ] =S[ψ].

action integral. From this we wish to deduce that the derivative of We shall consider a function S at φ, in some appropriate sense, is zero,φ that minimizes the and hence to deduce other properties aboutφis a function that lives in an infinite-dimensionalφ. But space, so we cannot talk about derivatives in a com-pletely straightforward way. To deal with this problem, we define aparameter family of functions compact variation ofφφ(s)to be a smooth one-:
R1$+3 \to R$, defined for eachs in some interval (-, )$, \text{such that} φ( 0 )(x) =φ(x)every (s$, x)for every out side some bounded subset ofx \in  R3 and φ(s)(x) = Rφ(x()1)+3. This for allows us to differentiate with respect tos.$d$φGiven such a variation, we denote the derivative^(s)/ds|^s=0 by  ̇φ. Definition.respect to SA field if, for anyφ is said to be compact variationstationaryφ(s) ofwithφ, we have d d$s S[φ^{(}s)]^{s} = 0 = 0$.
The variational principle.or principle of least action, states that an acceptable The variational principle, solution of a given physical system must be stationary with respect to the action integral associated with the Lagrangian of the system. the given Lagrangian a system of PDEs, obtained from The variational principle enables us to associate with the fact that equations. We illustrate this by showing that the non-φ is stationary, called the Euler–Lagrange linear wave equation in R1+^3, namelyφ - V^ (φ) = 0, (56)

is the Euler–Lagrange equation associated with the Lagrangian (55). Given a compact variation$φ^{(}s) of φ$,$\text{we set} S(s) = S[φ(s)]$. Integration by parts gives d d s S(s)s = 0 =R 3 +1 [-m\mu\nu. artial\muφ. artial ̇$\nuφ - V (φ)φ] ̇$=^R^3^+^1 φ[ ̇$φ - V (φ)]$.

IV.12. Partial Differential Equations

In view of the action principle and the arbitrariness ofφ ̇ we infer thatφ must satisfy equation (56). Thus (56) is indeed the Euler–Lagrange equation associated with the Lagrangian$L[φ] = m^{\mu}\nu\partial φ\partial φ - V (φ)$. One can similarly show that the Maxwell equations$\mu^{\nu}$ of ele ct ro magnetism—along with their beautiful exten-sions to the Yang–Mills equations, wave maps, and the Einstein equations of general relativity—are also variational. That is, they too can be derived from a Lagrangian.
Remark.the acceptable solutions of a given system are sta-The variational principle asserts only that tion ary: in general, we have no reason to expect that the desired solutions minimize or maximize the action integral. Indeed, this fails to be the case for systems that have a time dependence, such as the Maxwell equations, Yang–Mills equations, wave maps, and einstein equations.
lems, corresponding to time-independent physical sys-tems or geometric problems, for which the desired However, there is a large class of variational prob solutions example is that of geodesics in a Riemannian mani-do turn out to be extremal. The simplest fold M , which are minimizers17 with respect to length. More precisely, the length functional takes a curveγ that passes through two fixed points of cia tes with it its length L(γ), which plays the role of M and asso- an action integral. In this case a geodesic is not just astationary point for the functional but a minimum.
We also saw earlier that, according to the Dirichlet prin-ciple, solutions to the Dirichlet problem (53) minimize the Dirichlet integral (52). Another example is providedby the minimal surface equation (7), the solutions of which are minimizers of the area integral. action integrals, is a venerable subject in mathematics that goes under the name of The study of minimizers of various functionals, i.e., calculus of variations (see variational methods Associated with the variational principle is another[III.94](/part-03/variational-methods) for further discussion). fundamental principle.
Alution PDE is a law that says that some quantity, typ-conservation law for an evo ically an integral quantity depending on the solution, must remain constant over time, for every solution of the equation. Noether’s principle.group of symmetries of the Lagrangian there corre-To any continuous one-parameter ones that pass through two points close to each other.17. This is true, in general, only for sufficiently short geodesics, i.e.,

479

sponds a conservation law for the associated Euler–Lagrange PDE. Examples of such conservation laws are the familiar laws of conservation of energy, conservation ofmomentum, and conservation of angular momentum, all of which have important physical meaning. (The one-parameter group of symmetries for energy, for example, is just translations in time.) In the case of equation(56), the law of conservation of energy takes the form

$E(t) = E(0)$, (57)

where the quantity E(t), which equalsΣt 1 2(. artial t φ)2 + 12 i = 1(. artial iφ)2 + V (φ) dx, (58) is called thethe set of all points total energy(t, x, y, z)at timeas (x, y, z)t. (We write ranges overΣt for R3.) Observe that (57) provides an extremely important a priori estimate for solutions to (56) in the case when V ⩾ 0. Indeed, if the energy of the initial data at t = 0 is finite (that is, if$E(0) < \infty )$, thenΣt 1 2(. artial tφ)2 + 12 i=1(. artial iφ)2 dx ⩽ E(0).
We say that the energy identity (57) is means that it leads to an absolute bound on all solu-coercive, which tions with finite initial energy.

4.2 The Issue of Criticality

For the most basic evolution equations of mathematical physics, there are typically no better a priori estimates known than those provided by the energy. Taking into account the scaling properties of the corresponding equations as well, one is led to the very important classification of our basic equations, mentioned earlier, into see how this is done, consider again the nonlinear subcritical, critical, and supercritical equations. To scalar equationbe(1/(p + 1))|φ|^pφ^+^1-. Recall that the energy integral is V^ (φ) = 0, and take V (φ) to given by (58).
If we assign to the spacetime variables the dimension of length, have dimension L-1 and therefore L, then the spacetime derivatives has the dimension of sides of the equation$L^{-2}$. To be able to balance the left- and right-handφ = |φ|p^-1φ, we need to assign a length scale toφ; we find this to be L2/(1-p). Thus the energy integral, E(t) = {}Rd(2-1|. artialφ|2 + |φ(|p)+1) dx,

480

has the dimension responding to the volume element d$L^{c}$, c = d-2+(4/(1 x-p))= d, withx1 dxd2 cor-· · · ds ub critical$x^{d}$, which scales likeif c < 0, critical Ld. We say that the equation isif c = 0, and supercritical$if$ c > 0. Thus, for example, φ - φ5 = 0 is critical in dimensiond = 3. The same sort of dimensional analy- sis can be done for all our other basic equations. an evolutionary PDE is said to be regular if all smooth finite-energy initial conditions lead to global smooth solutions.
It is conjectured that all subcritical equations are regular, but one expects supercritical equa-tions to develop singularities. Critical equations are important borderline cases. The heuristic reason for this is that the nonlinearity tends to produce singu-larities while the coercive estimates prevent it. In subcritical equations the coercive estimates are stronger, while for supercritical equations it is the nonlinearity that is stronger. However, there may be other, more subtle a priori estimates that are not accounted for byour crude heuristic argument.
Thus, some supercritical equations, such as the Navier–Stokes equations, may still be regular.

4.3 Other Equations

Many other familiar equations can be derived from the variational ones described above by the following procedures.

4.3.1 Symmetry Reductions

Some times a PDE is very hard to solve but becomes much easier if one places additional symmetry constraints on solutions. For example, if the PDE is rota-tion invariant and we look just for rotation-invariant solutionsas functions ofu(t, x)t , then we can regard these solutions and r = |x|, effectively reducing the dimension of the problem. By this procedure of symmetry reductionis much simpler than the original one. Another, some-one can then derive a new PDE that what more general, way of obtaining simpler equationsis to look for solutions that satisfy some further property.
For instance, one can assume that they are stationary (that is, that they do not depend on the time vari-able), spherically symmetric, self-similar (which means thatu(t$, x) \text{depends only on} x/t^{a})$, or traveling waves (which means thatu(t, x) depends only on x - vt for some fixed velocity vector obtained by such reductions have a variational struc-v). Typically, the equations ture themselves. In fact, the symmetry reduction canbe applied directly to the original Lagrangian. IV.
Branches of Mathematics 4.3.2 The Newtonian Approximation and Other Limits We can derive a large class of new equations asthe basic ones described above by taking one or more limits of characteristic speeds to infinity. The most important example is the letting the velocity of light go to infinity. As we have Newtonian limit, which is obtained by already mentioned, the Schrödinger equation can be derived in this way from the linear Klein–Gordon equation. Similarly, we can derive the Lagrangians for the equations of nonrelativistic elasticity, fluid dynamics, or magnetohydrodyn amics.
It is an interesting fact that the nonrelativistic equations tend to look more messy than the relativistic ones. The simple geometric structure of the original equations gets lost in the limit. The remarkable simplicity of the relativistic equations is a powerful example of the importance of relativity as a unifying principle. Once we are in the familiar world of Newtonian physics we can perform other well-known limiting procedures.
The famous tions [III.23](/part - 03/the - euler - and - navierstokes - equations) are obtained by taking the limit of the incompressible euler equa general nonrelativistic fluid equations as the speed of sound tends to infinity. Various other limits are obtained relative to other characteristic speeds of the system or in connection with specific boundary conditions, such as the boundary-layer approximation in fluids. For example, in the limit as all characteristic speeds tend to infinity, the equations of elasticity turn into the familiar equations of a rigid body in classical mechanics.
4.3.3 Phe no meno logical Assumptions Even after taking various limits and making symmetry reductions, the equations may still remain intractable. However, in various applications it makes sense to assume that certain quantities are sufficiently small tobe neglected. This leads to simplified equations that could be called phe no meno logical18 in the sense that they are not derived from first principles. Phe no meno logical equations are “toy equations” that are used to illustrate and isolate important physical phenomena in complicated systems.
A typical way of generating interesting phe no meno logical equations isto try to write down the simplest model equation that what different context. Also, some of the equations that I call phe-no meno logical below, e.g., dispersive equations, can be given formal18. I use this term here quite freely; it is typically used in a some asymptotic derivations. IV.12. Partial Differential Equations still exhibits a particular feature of the original sys - tem.
For instance, the self-focusing plane-wave effects of compressible fluids or elasticity can be illustrated by the simple-minded Burgers equation u + uu =0. Nonlinear dispersive phenomena, typical of fluids, can be illustrated by the famous Korteweg–de Vries tx equation$u^{t} + uu^{x} + u^{x}xx =$0. The nonlinear Schrödinger equation (54) provides a good model problem for nonlinear dispersive effects in optics. basic insights into the original equation itself.
For this reason, simplified model problems are also essential If it is well chosen, a model equation can lead to in the day-to-day work of the rigorous researcher into PDEs, who tests ideas on carefully selected model problems. It is crucial to emphasize that good results con-cerning the basic physical equations are rare; a very large percentage of important rigorous work in Pdes deals with simplified equations selected, for technical reasons, to isolate and focus our attention on some specific difficulties present in the basic equations.
sive equations These are in fact not variational, and therefore do In the above discussion we have not mentioned diffu-19 such as the Navier–Stokes equations. not quite fit into the above description. Though they could be viewed as phe no meno logical equations, they can also be derived from basic microscopic laws suchas those governing the Newtonian–mechanical interactions of a very large number of particle sc i ple,20 the equations of continuum mechanics, such N. In prin- as the Navier–Stokes equations, could be derived by letting the number of particles N → $\infty$.
connection with geometric problems. Geometric flows such as mean curvature, inverse mean curvature, har-Diffusive equations also turn out to be very useful in monic maps, Gauss curvature, and Ricci flow are someof the best-known examples. Diffusive equations can often be interpreted as the gradient flow for an associ-ated elliptic variational problem.
They can be used to construct nontrivial stationary solutions to the corre-sponding stationary systems, in the limit ast → $\infty$, or to produce foliations with remarkable properties, such as one that was used recently in the proof of a famous conjecture of Penrose. As we have already mentioned, this idea has recently found an extraordinary applica-tion in the work of Perelman, who has used Ricci flow to settle the three-dimensional Poincaré conjecture. One such as energy, are not conserved and may in fact decrease in time. These are typically of parabolic type.19.
That is, equations where some of the basic physical quantities,

20. To establish this rigorously remains a major challenge.

481

of his main new ideas was to interpret Ricci flow as a gradient flow.

4.4 Regularity or Breakdown

An additional source of unity for the subject of PDEsis the central role played by the problem of regularity or breakdown of solutions to the basic equations. It is intimately tied to the fundamental mathematical ques-tion of understanding what we actually mean by solutions and, from a physical point of view, to the issue of understanding the limits of validity of the corresponding physical theories.
Thus, in the case of the burgers equation, for example, the problem of singularities can be tackled by extending our concept of solutions to accommodate shock waves, which are solutions that are discontinuous across certain curves in the In this case one can define a function space of general-(t, x)-space. ized solutions in which the IVP has unique, global solutions.
Though the situation for more realistic physical systems is far less clear and far from being satisfactorily solved, the generally held opinion is that shock-wave-type singularities can be accommodated with out breaking the boundaries of the physical theory at hand. The situation for singularities in general relativity isradically different. The singularities one expects there are such that no continuation of solutions is possible with out altering the physical theory itself. The prevailing opinion here is that only a gravitational quantum field theory could achieve this.
5 General Conclusions What, then, is the modern theory of PDEs? As a first approximation, one could say that it is the pursuit ofthe following main goals. (i)equations of mathematical physics. Understand the problem of evolution for the basic The most pressing issue in this regard is to understand the local21 (with respect to time) smooth solutions of the when and how basic equations develop singularities criterion for distinguishing between regular theories. A simple-minded and those that may admit singular solutions is given by the distinction between subcritical and supercritical equations.
As mentioned earlier, it is widely believed ematics was the establishment of a general procedure that guaran-tees the existence and uniqueness of a local-in-time solution to broad21. One of the important achievements of the past century of math classes of initial conditions and large classes of nonlinear equations, including all those we have already mentioned above.

482

that ical equations are not subcritical equations are regular and that supercrit-. Indeed, many subcritical equations have been proved to be regular even though welack a general procedure for establishing regularity results of this kind. The situation with supercritical equations is far more subtle. To start with, an equation that we now call supercritical22 may in fact turn out to be critical, or even subcritical, upon the discov-ery of additional a priori estimates. Thus an important question concerning the issue of criticality, and conse-quently that of singular behavior, is:
are there other, stronger, local a priori bounds that cannot be derived from Noether’s principle? The discovery of such a bound would be a major event in both mathematics and physics. ties in our basic evolution equations is unavoidable, we Once we understand that the presence of singular i have to face the question of whether they can some-how be accommodated by a more general concept of what a solution is or whether their structure is such that the equation itself, indeed the physical theory that it under lies, becomes meaning less.
An acceptable concept of a generalized solution should, of course, preserve the deterministic nature of the equations: in other words, it should be uniquely determined from its Cauchy data. Finally, once an acceptable concept of generalized solutions is found, we would like to use it to deter-mine some important qualitative features, such as longterm asymptotic behavior. One can formulate a limit-less number of such questions, the answers to which will vary from equation to equation.
(ii)range of validity of various approximations. Understand in a rigorous mathematical fashion the The equations obtained by various limiting procedures or phe-no meno logical assumptions can of course be studied in their own right, as the examples that we have referred to above are. However, they present us with additional problems to do with the mechanics of how they are derived from equations that we regard as more fundamental.
It is entirely possible, for exam-ple, that the dynamics of a derived system of equations leads to behavior assumptions made in its derivation that is in compatible with the. Alternatively, a particular simplifying assumption, such as spherical sym-metry in general relativity or zero vorticity for compressible fluids, may turn out to be unstable at large coercive estimate available.22. What we call supercritical depends on the strongest a priori

IV. Branches of Mathematics

scales and therefore not a reliable predict or of the gen-eral case. These and other similar situations lead to important dilemmas: should we persist in studying the approximate equations even when, in many cases, we face formidable mathematical difficulties (some which may turn out to be quite pathological and are per-haps related to the nature of the approximation), or should we abandon them in favor of the original system or a more suitable approximation?
Whatever one may feel about this in any specific situation, it is clear that the problem of understanding, rigorously, the range of validity of various approximations is one of the fundamental goals in PDEs. (iii) Devise and analyze the right equation for studying the specific geometric or physical problem at hand.last goal is equally important even though it is neces-This sarily vague. The enormously important role played by PDEs in various branches of mathematics is more evi-dent than ever.
One looks in awe at how equations such as the Laplace, heat, wave, Dirac, Kd V, Maxwell, Yang Mills, and Einstein equations, which were originally introduced in specific physical contexts, turned out to have very deep applications to seemingly unrelated problems in areas such as geometry, topology, alge - bra, and combinatorics.
Other PDEs appear naturally in geometry when we look for embedded objects with optimal geometric shapes, such as solutions to isoperi-metric problems, minimal surfaces, surfaces of least distortion or minimal curvature, or, more abstractly, connections, maps, or metrics with distinguished prop - erties. They are variational in character, just like the main equations of mathematical physics. Other equations have been introduced with the goal of allowing one to deform a general object, such as a map, connection, or metric, to an optimal one.
They usually arise in the form of geometric, parabolic flows. The most famous example of this is Ricci flow, first introduced by Richard Hamilton, who hoped to use it to deform Riemannian metrics into Einstein metrics. Sim-ilar ideas were used earlier to construct, for example, stationary harmonic maps with the help of a harmonic heat flow, and self-dual Yang–Mills connections with the help of a Yang–Mills flow.
In addition to the successful use of Ricci flow to settle the Poincaré conjecture in three dimensions, another remarkable recent example of the usefulness of geometric flows is that of the inverse mean flow, first introduced by Geroch, to settle the so-called Riemannian version of the penrose inequality. IV.13. General Relativity and the Einstein Equations Further Reading Brezis, H., and F. Browder. 1998. Partial differential equa-tions in the 20 th century. Advances in Mathematics 135: Constantin, P. 2007. On the Euler equations of incompress - 76–144.ible fluids.
Bulletin of the American Mathematical Society Evans, L. C. 1998.44:603–21.ate Studies in Mathematics, volume 19. Providence, RI: Partial Differential Equations. Gradu John, F. 1991.American Mathematical Society. Springer. Partial Differential Equations. New York: Klainerman, S. 2000. PDE as a unified subject. In2000*, Visions in Mathematics—Towards 2000 (special*GAFA issue ofpp. 279–315.Geometric and Functional Analysis)$, part 1$, Wald, R. M. 1984.University Press. General Relativity. Chicago, IL:
Chicago IV.13 General Relativity and the Einstein Equations Mihalis Dafermos Einstein’s formulation of general relativity represents one of the great triumphs of modern physics and provides the currently accepted classical theory that uni-fies gravitation, inertia, and geometry. The Einstein equations are the mathematical embodiment of this theory. The definitive form of the equations, R\mu\nu - 1 2 Rg\mu\nu = 8πT\mu\nu, (1) was attained in November 1915;
this was the final act of Einstein’s eight-year struggle to generalize his principle of relativity so as to encompass gravitation, which had been described in the earlier “Newtonian” theory by the Poisson equation . artial \1 artialx2φ2 + . artial \1 artialy2φ2 + . artial \1 artialz2φ2 = 4π\mu (2) for the potentialφ and mass density \mu. (1) and the Poisson equation (2) is that the mysteri-An obvious contrast between the Einstein equations ous notation of the former makes it far less obvious what they even mean.
This has given the subject of general relativity a reputation for difficulty and impen-etr ability. However, this reputation is to some extent unwarranted. Both (1) and (2) represent the culmination of revolutionary theories whose formulations presup-pose a complicated conceptual framework. For better 483 or for worse, however, the structure necessary to for-mulate Poisson’s equation has been incorporated into our traditional mathematical notation and school edu - cation.
As a result, R3, with its Cartesian coordinate system, and notions such as functions, partial deriva - tives, masses, forces, and so on, are familiar to people with a general mathematical background, while the con-ceptual structure of general relativity is much less so, both with respect to its basic physical notions and with respect to the mathematical objects that are needed to model them.
However, once one comes to terms with these, the equations turn out to be more natural and, one might even dare say, simpler. Thus, the first task of this article is to explain in more detail the conceptual structure of general relativ - ity. Our aim will be to make it clear what the equations (1) actually denote, and, more over, why they are in a cer-tain sense the simplest equations one can write down, given the general framework of the theory.
This in turn will require us to review special relativity and its implications for the structure of matter, which will bring us to the unified concept of stress–energy–momentum, described by a Einstein in his inspired leap to the notion of a gen-tensorial object T . Finally, we will join eral four-dimensional Lorentzian manifold(M, g) that represents our space-time continuum. We shall see that equation (1) expresses a relationship between the tensor so - called T curvature and the geometry. of g as expressed in its merely knowing how to write down its governing equa - tions.
General relativity is associated with some of There is more to truly understanding a theory than the most spectacular predictions of twentieth-century physics: gravitational collapse, black holes, space-time singularities, the expansion of the universe. These phenomena (which were completely unknown in 1915 and thus played no role in the formulation of the equations (1)) revealed themselves only when the concep-tual issues surrounding the problem of global dynamics of solutions were understood.
This took a surprisingly long time, though the story is not as well-known as the heroic struggle to attain (1). The article will conclude with a very brief glimpse into the fascinating dynamics of the Einstein equations. 1 Special Relativity

1.1 Einstein, 1905

Einstein’s 1905 formulation of special relativity stipu-lated that all fundamental laws of physics should be

484

invariant under of reference defined by Lorentz transformation sx, y , z, and t. A Lorentz trans-of the frame formation is any composition of translations, rota-tions, and the Lorentz boost, which is given by the formulas

⎫x ̃$= 1x--vvt^{2}/c^{2}$, y ̃$= y$, ⎪⎪⎪⎬

(3)

 ̃$t = t1--vx/cv2/(c2)2$, z ̃$= z$, ⎪⎪⎪⎭

wherec is a certain constant and |v | < c. Thus, Ein- stein’s stipulation was that if one changes coordinates by means of a Lorentz transformation, then the formof all fundamental equations will remain the same. This set of transformations had already been identi-fied in the context of the study of the vacuum Maxwell equations$B$: for the electric field$\text{Eand magnetic field} ∇ · E = 0$, ∇ · B = 0, ⎫⎬

(4)

$c^{-1}\partial^{t}B + \nabla \times E = 0$, c-1∂t E - . abla . imes B = 0. ⎭ Indeed, the Lorentz transformations are precisely the transformations that keep the form of the above equa-tions invariant if we also transform E and B ap propri- ately. Their significance was emphasized by[VI.61](/part-06/jules-henri-poincar-18541912). However, it was Einstein’s profound insightpoincaré to elevate this invariance to the status of funda-mental physical principle, despite its in compatibility with what we now usually call which corresponds to takingc → $\infty$ Galilean relativity in (3).
A sur-, pr ising consequence of Lorentz invariance is that thenotion of simultaneity is not absolute but depends on the observer: given two distinct events that occur at(t, x, y, z) and (t, x, y, z), it is easy to find a Lorentz transformation such that the transformed events no longer have the samet-coordinate. ential equations known as theple It follows from a celebrated result in partial differ-, applied to (4), that electromagnetic disturbances in strong Huygens princi vacuum propagate with speed tify as the speed of light.
In view of Lorentz invariance, c, which we thus iden- this statement is independent of the frame! A further postulate of the principle of relativity is that physical theories should not allow massive particles to move at speeds (as measured in any frame) greater than or equal toc. 1.2 Minkowski, 1908 Einstein’s understanding of special relativity was “algebraic.” It was minkowski [VI.64](/part - 06/hermann - minkowski - 18641909) who first understood IV.
Branches of Mathematics its underlying geometric structure, namely, that the content of the principle was contained in the metric element$-c2 dt2 + dx2 + dy2 + dz2 (5)$ defined on R4 with coordinates(t, x, y, z). We call Rand denote it4 endowed with the metric (5)R3+^1. Points of Minkowski space-time R^3^+^1 are referred to as the events inner product. The expression (5) is classical notation for defined on tangent vector sv =((c-1 v)0, v1$, v2$, v3)$, w = ((c - 1w)0$, w1$, w2$, w3) on R4 by v, w = −v0 w0 + v1 w1 + v2 w2 + v3 w3.
(6) The Lorentz transformations constitute precisely the symmetry group of the geometry defined by (5). Einstein’s principle of relativity could now be understood as the principle that the fundamental equations of physics must refer to space-time only through geometric quantities: that is, quantities that can be defined purely in terms of the metric. For example, from this point of view the reason that the notion of absolute simultaneity is not allowed is that it depends on a privileged hyperplane through any given point of R3+1.
But there are Lorentz transformations that preserve the metric and send this hyperplane to another one through the given point, so nothing in the metric can pick out one particular hyperplane. Note that if a physi-cal theory makes use of geometric quantities only, then it is automatically invariant under Lorentz transformations: this observation renders many complicated calculations unnecessary.
Note that nonzero vectors the inner product Let us explore this geometric point of view further.· , · into three types, calledvare naturally classified bytimelike0, , vnull, v =, and0, or space li kev, v, according to whether> 0, respectively. Idealizedv, v < point particles traverse curvesγthrough space - time; these are called theing particles. The postulate (referred to earlier) that world lines of the correspond speed in any frame of reference is bounded by the speed of lightc can now be formulated as the fol- lowing statement:
ifγ is the world line of a particle, then the vector correspond to light rays in the geometric optics limitdγ/ds must be timelike. (Null lines$of (4)$.) This statement is independent of the parameter that ds oft/γd, but for world lines we shall always assumes > 0. To phrase this more geometrically, dγ/ds, (c - 1, 0, 0, 0) < 0, which we interpret as the statement thatγ is future - directed. IV.13. General Relativity and the Einstein Equations particle by We can now define the “length” of the world line of as2 L(γ) =s 1 -γ ̇,γ ̇ ds = s s 2 c2 ddst2 - ddxs2 - ddys2 - ddzs2 ds.
(7) Classically, the above expression would have been writ-ten simply as$L(γ) =γ -(-c2 dt2 + dx2 + dy2 + dz2)$, which explains the notation (5). We refer to the quan tit yc-1 L(γ) as proper time. This is the time that is relevant in local physical processes; in particular, ifparticle traversing the world lineγ, then c-1 you L(γare the) is the time that you will The metric (5) contains three-dimensional euclidean feel. geometry d$x^{2} + dy^{2} + dz^{2}$, restricted tot = 0, say.
More interestingly, it also contains non - Euclidean geometry 1- xr dx2 + 1 - yr dy2 + 1 - zr dz2 when it is restricted to the hypersurface$c^{-}1 x2 + y2 + z2$. It is hard to over estimate how revo-t = c-1 r = lutionary the notion was that the time of physical pro-cesses (including our very sensations) and the length of measuring rods are two interdependent aspects of a geometric structure that naturally lives on a four-dimensional space-time continuum.
Indeed, even Einstein initially rejected Minkowski space-time, pre-fer ring to retain the independent reality of a definite “space,” albeit a space with a relative notion of simul-taneity. Only as a result of his search for general relativity did he realize that this view is fundamentally untenable. We shall return to this in section 3. 2 Relativistic Dynamics and the unification of Energy, Momentum, and Stress Be sides the space-time concept and its geometriza-tion, the principle of relativity led to a profound rearrangement and unification of the fundamental con-cepts of dynamics:
mass, energy, and momentum. Einstein’s celebrated relation between mass and energy inthe rest frame,

$E0 = mc2$, (8)

is the best-known expression of one aspect of this unifi-cation. This relation arises naturally when one attempts

485

to generalize Newton’s second law$m(dv/dt) = f \text{to a}$ relation between 4-vectors in Minkowski space. fields standing it, let us look at continuous media. Now, General relativity has to be formulated in terms of rather than particles. As a first step toward under instead of particles we consider fic at i on of dynamical concepts encompasses what is matter fields; the uni known asied by the so-called stress, and its complete expression is embod-stress–energy–momentum tensor T . This tensor is fundamental to general relativity, so wehave no choice but to familiarize ourselves with it.
It will be the key to the form of the Einstein equations (1)as well as to the object on their right-hand side. For each point$q \in (R3)+1$, the stress–energy–momentum tensor field T gives us a map T$: R4$ q . imes (R4)q \to R (9)

defined by the formula

T (w, w ̃$) = {}^{α}$,β3=0 Tαβwαw ̃β.

Here, space of vectors Tαβ = Tβα for eachat q. (In Minkowski coordinates, weα and β. By (R4)q we mean the often identify R4 with R4 q, but it will be important to dis- tinguish between the two when considering arbitrary coordinates in section 3.2.) Bilinear maps of the form (9) are known as covariant 2-tensors. known as agiven by If the only matter present is described by what is perfect fluid, then the components of$T are T00 = (ρ + p)u0u0 - p$, (T0)i = (ρ + p)uiu0$, Tij = (ρ + p)uiuj + pδij$,

where such thatu is the 4-velocity, a timelike vector normalizedu, u = −c2, ρ is the mass–energy, p is the press urej range over 1, 2, 3. Greek indices will range over 0, 1,, and where δij = 1 if i = j, 0 if i = j, and i and 2, 3. We identify T00 with energy, (T0)i with momentum, and dependent. Finally, observe that Tij with stress. These notions are clearly frame-T (u, u) = ρc2.
This is the field-theoretic version of the famous equation (8).In general, T is derived from the totality of all the matter fields by constitutive functions that depend on the nature of the matter fields and their interactions. We need not worry here about such things. But, regard less of the nature of the matter fields involved, we always postulate that the following equations are satisfied:

-. artial0(T0)α + {}3 . artial i Tiα = 0.i=1 486 defining stein summation convention$\nabla0 = −\partial0$, . ablai = ∂i, under which summation, and introducing the Ein- is implicit when an index appears both upstairs and downstairs, we may rewrite this as

. abla\mu Tμν = 0. (10)

These equations are Lorentz invariant. The above relations embody the conservation of stress–energy–momentum grating (10) between homologous hypersurfaces andat a differential level. In te applying the Minkowski-space version of the diver-gence theorem, one obtains global balance laws. If one assumes that integrating between T^αβt =is compactly supported, then, t and t = t , one obtains 1 2 With respect to the chosen Lorentz frame, the zeroth component of the above equation represents thet=t 2 T0^α dx1 dx2 dx3 =t=t 1 T0^α dx1 dx2 dx3.
con-(11) servation of total energy, while the remaining components represent In the case of a perfect fluid, if we close the sys-conservation of total momentum. tem (10) by adjoining a conservation law for particle number

$\nabla^{α}(nu^{α}) = 0$

and postulate constitutive relations between ti cle number densityn, and entropy per particleρ, p, par-s, compatible with the laws of thermodynamics, then we arrive at the so-called relativistic Euler equations. 3 From Special to General Relativity With the elements of special relativity at hand, together with their deep implications for the nature of energy, momentum, and stress, we can now pass to the formulation of general relativity.

3.1 The Equivalence Principle

Einstein understood as early as 1907 that the most pro-found aspect of the gravitational force could not be described within the relativity principle as he had for-mulated it in 1905. This aspect is what he called the equivalence principle. ciple is that of the “test particle” with velocity a fixed gravitational field The easiest setting in which to understand this prin-φ. In this case, we have thatv(t) in the classical gravitational force is given by$f = −m \nabla φ$, and we may rewrite Newton’s second law$m(dv/dt) =f as$

d$v= −∇φ$. (12) d$t$

IV. Branches of Mathematics

Notice that the mass gravitational field accelerates all objects at a given posi-$m$has dropped out! Thus, the tion in the same way. This explains the fact, recorded already in late antiquity by Ioannes Philoponus and popularized in Western Europe by Galileo, that the time it takes objects to fall from a given height is independent of their weight. It was Einstein who first interpreted this property as a sort of covariance with respect to transformations toinstance, in the case of a constant gravitational field, noninertial, that is to say accelerated, frames.
For which corresponds to the case$φ(z) = f z$, we can pass to the accelerated frame

$z$ ̃$= z + {}^{12}f t^{2}$

and write (12) as

d$v = 0$. (13)

Similarly, one can reverse the argument to “simulate” a gravitational field when none is present by expressingd$t$ (13) in an accelerated frame.

3.2 Vectors, Tensors, and Equations in

General Coordinates

Exactly what the equivalence principle means in gen-eral is some what obscure and has been the subject of debate ever since Einstein introduced it. Never the-less, the above considerations suggest that, even in the absence of gravity, it would be useful to know how various objects and equations appear when expressedin arbitrary coordinate systems.
That is to say, let us change from our Minkowski coordinates$x^{0}$, x1$, x2$, x3 to the most general coordinate system, which we shall write a$\bar{s}x^{\mu} = x$ ̄$\mu (x0$, x1, x2$, x3)$, wher. ar{e}\mu ranges over 0, 1, 2, 3.Expressing scalar functions in arbitrary coordinates poses no problem. But what about vector fields? Ifis a vector field expressed in Minkowski coordinates$v$ as coordinate$\bar{s}(v^{0}$, v1$, vx2$, v^ ̄^μ?3), how do we express v in our new ally tor field One has to think a bit about what a vector field actu-is.
The correct point of view is to consider a vec-$v$as a first-order differential operator defined (using Einstein’s summation convention) byvμ∂ f . So we seek vμ^ ̄ such that v(f ) = vμ^ ̄∂ fv(f )for all= functions\mu f. The chain rule then gives us our answer:$\mu v^{\mu} = \partial 1artialxx$ ̄ ̄$\mu^{\nu} v^{\nu}$. (14)

mentum tensor What about tensors, such as the stress–energy–mo-T? In view of the definition (9), we seek IV.13. General Relativity and the Einstein Equations T\mu^ ̄^ ̄\nu such that T (u, v) = T\mu^ ̄^ ̄. uu\mu^ ̄v^ ̄\nu, (15) where the numbers respect to the coordinate. ar{s}u\mu^ ̄ are the components ofx\mu^ ̄ as we have just calculatedu with them above. (Note that these components depend onthe pointq. This is why it is now essential to distinguish R4$q$ from R4.) Again, the chain rule gives us the answer:
T^ ̄\mu \nu^ ̄ = T\mu\nu . artial x. artial. ar{x}$\nu \nu \partial x\partial x$\mu\mu^ ̄. Classically, we write  T = T\mu^ ̄\nu^ ̄. ar{d}x\mu^ ̄. ar{d}x\nu^ ̄ = T\mu\nu dx\mu dx\nu. One can interpret the above as a shorthand notation for(15), but it also tells us how to compute$T$ from Tμ^ ̄^ ̄ν μν

by formally applying the chain rule to $\bar{d}x^{\mu}$. sides There is another covariant symmetric 2-tensor be-T that is relevant here. This is the Minkowski met- ric itself. Indeed, the classical form of the minkowski metric (5) corresponds to the representation

η\mu\nu dx\mu dx\nu,

where thebyη = −η1,μνηfor Minkowski coordinates= 0, η = 1 if i = j, andxμηare given= 0 ifirefer to the Minkowski metric as= j00. To avoid the cumbersome notatio(n0()i)ij η. Following the above,· , ·ij, let us we may expressηin general coordinate. ar{s}xμ^ ̄ byημ^ ̄^ ̄ν. ar{d}xμ^ ̄. ar{d}xν^ ̄,

where chain rule.ημ^ ̄ν^ ̄ is computed by formal application of the tion such as (10) into general coordinates, then the components of It is clear that if one tries to transform an equa-η and their derivatives will appear in the equations. Einstein (always thinking “algebraically”) was seeking laws of motion for both matter and the gravitational field that would have the same form in all coordinate systems.
As he understood it, this meant that all objects that appear should transform as tensors and should be considered a priori “unknown.” Hereferred to this principle as “general covariance.” This suggests that metric 2-tensor. Let us call this 2-tensorη should be replaced by an unknowng. One can ofsym- course try to write down an equation for the “unknown”$g$that forces it to be the “known” Minkowski metricη. Thus, “general covariance” per se does not force one toabandonη.
But in view of the fact that g and T have the same number of components, it was a natural stepto con side rg as the embodiment of the gravitational field and to try to look for an equation that related and T directly. In this way, the framework of gener alg relativity was born.

487

3.3 Lorentzian Geometry

The profound insight of replacing the fixed Minkowskiη with a dynamic g brought Einstein to what we now callalizes Minkowski geometry following the blueprint of Lorentzian geometry. Lorentzian geometry gener riemann [VI.49]. That is, we replace the Minkowski metricη by a general mapg$: R4$ q . imes  (R4)q \to  R.

In other words, we replace2-tensor, which is expressed in arbitrary coordinatesη by a symmetric covariantx^\mu byg^μν dx^\mu dx^ν.

More over, we require that at each point ear formg(· , ·) can be diagonalized to the Minkowskiq the bilin-$form (6)$. Loosely speaking, a Lorentzian metric is one that “looks locally like the Minkowski metric,” just as a riemannian metric [I.3 §6.10](/part-01/fundamental-definitions) looks locally like the Euclidean metric.
Just as with the Minkowski metric, the bilinear form gas permits us to classify nonzero vectors timelike, null, or spacelike and to define proper time svq at a point q of world lines the formula (7), but with$γ(s) = (x0γ$ ̇(s)$, x, γ̇ \text{replaced by}1(s)$, x2(s), xg3(s))x ̇\mu x ̇byν . It is in this sense that we can speak of the geometryμν$of$ g.
In view of Minkowski’s formulation of the special relativity principle as the statement that the equationsof physics refer to space-time only through geometric quantities associated with the Minkowski metric, itis natural to look for a generalization of this principle, and indeed a suitable version immediately suggests itself. It is the principle that refer to the space-time coordinates only via geometric the equations of physics quantities naturally associated withg.
“test particles,” as formulated geometrically for the We saw earlier that the kinematic constraint on Minkowski metric, was that dthis makes sense for an arbitrary Lorentzian metric.γ/ds should be timelike; But how does one formulate differential equations? For instance, how does one formulate an analogue of (10) that refers only to$g$? natural geometric concepts suitable for the task had It turned out that in the Riemannian case, a set of already been developed in the nineteenth and early twentieth centuries by Riemann, Bianchi, Christoffel, Ricci, and Levi-Civita.
These carry over directly to the Lorentzian case.

488

bols One begins by defining the so-calledΓμν. ambda by Christoffel symΓμνλ =1 2 gλρ(∂\mu gρν + ∂νgμρ - ∂ρgμν ). Here, the numbersgμν are the components of the “inverse metric” oftion to the equation$g$: that is, they are the unique solu-$g^{\mu}\nu g = δ^{\mu}$, where, as usual,δμ λ = 1 if λ = \mu and 0 otherwise.
(It turns out thatνλ. ambda gμν is very useful for the calculational gymnastics that are typical of tensor analysis when it exploits the einstein summation convention.) One can then define a differential operator$\nabla^{\mu} called$ a connection, which acts on vector fields by . abla\mu vν = ∂\mu vν + Γμλν vλ (16) and on covariant 2-tensors by . abla. ambda T\mu\nu = . artial. ambda T\mu\nu - Γλ\muσ Tσ \nu - Γλ\nuσ T\muσ. (17) The left-hand sides of (16) and (17) define tensors that can be expressed in any coordinate system by a formal application of the chain rule.
With the help of this differential operator, one could now write the analogue of equations (10) for an arbi-trary metric g as . abla\mu T\mu\nu = 0, (18)

wherewithg.. ablaμ = gμν. ablaν refers to the connection associated If we consider a limit as the matter field becomes concentrated at a point, or rather as the stress–energy–momentum tensor T is nonzero only on a world line, then this curve will be aμν geodesic of g: that is, a curve that locally maximizes the proper time defined byg. These are the analogues of straight timelike lines in Minkowski space. In this limit, the motion of the matter does not depend on the nature of the stressenergy–momentum tensor, but only on the geometry of the metric that defines geodesics.
Thus, all objects fall in the same way. These considerations give a concrete realization to the equivalence principle in general relativity. Finally, it is important to remark that for a general metric vation laws (11) for “total energy” and “total momen-g, the identity (18) does not imply global conser- tum.” Such laws hold only ifg has symmetries. The fact that the fundamental conservation laws survive in general only at the infinitesimal level is an important insight into the nature of these principles in physics.

IV. Branches of Mathematics

3.4 Curvature and the Einstein Equations

It remains, then, to give a set of equations for the metric gwe expect these equations to be second order, and wethat relate it to T . In anticipation of a Newtonian limit, expect them to implement “general covariance” in the simplest way possible: they should refer to no other structure butg itself and T . tensorial objects that are invariantly associated with One can define the Again, Riemannian geometry provides ready-made Riemann curvature tensor$g$.Rμνλρ dx\mu dxν dx. ambda dxρ

with components given by

 R\mu\nuλρ = g\muσ (. artialρΓ\nuλσ - . artialλΓ\nuρσ + Γ\nuλτ Γτρσ - Γ\nuρτ Γτλσ ). One can also define the Ricci curvature

 R\mu\nu dx\mu dx\nu,

a covariant symmetric 2-tensor with components given by R\mu\nu = gλρR\mu\nuλρ,

and the scalar curvature

$R = g^{\mu}\nuR^{\mu}\nu$.

If surface ing were the induced (Riemannian) metric on a 2-R3, then R would just be twice the Gauss curvatureof as complicated tensorial generalizations of Gauss K. The above expressions should be thought curvature to several dimensions. the Einstein equations (1) is provided by the following constraint that Einstein demanded: whatever the equa-The final piece of the puzzle for the formulation of tion relating the metric and the stress–energy–momentum tensor of matter, (18) (the infinitesimal conser-vation of stress–energy–momentum) should hold as a consequence the so-called.
Now, it turns out that for Bianchi identities imply that any metricg,. abla^μ(R^μν -^1^2 g^μνR) = 0. (19)

It is thus natural to postulate a linear relation between T and the tensor R -1 g R. The formμν R -1 μνg R2=μν8πGc-4 T (20)μν2 μνμν

is then uniquely determined by the requirement thatit should give the correct Newtonian limit when one makes the identifications $g^{0}0 ∼ 1 + 2φ/c^{2}$, (g0)j ∼ 0, gij ∼ (1 - 2φ/c2)δij . The form (1) corresponds to the usual units$G = c = 1$.Note that (1), when written out explicitly, is nonlinearin the metric componentsgμν.

IV.13. General Relativity and the Einstein Equations side ring geodesic motion in solutions of the linearized equations (20), Einstein was able to determine the cor-Einstein did not stop at the Newtonian limit. By conrect value for thelion of Mercury, an effect that Newtonian theory was anomalous precession of the per i he unable to explain. Since (20) had no adjustable param-eters after determining the Newtonian limit, this was a genuine gravitational “bending” of light was observed. This had test of the theory.
A few years later the been calculated theoretically in the context of the geo-metric optics approximation where light rays follow null geodesics in a fixed space-time background. Post-Newtonian predictions of (1) have now been verified by various solar system tests, confirming general relativity in this regime to a high degree of accuracy. T^μνOne special case of (20) is when we postulate that= 0. The equations then simplify to R^μν = 0. (21)

These are known as thekowski metric (5) is a particular solution (but not the vacuum equations. The Min only one!). euler–lagrange equations the so-called The vacuum equations can be derived formally as the Hilbert Lagrangian[III.94](/part - 03/variational - methods) corresponding to:$L(g) = R - g dx0 dx1 dx2 dx3$.
(The expression ural volume form. qrt{-associated} withg dx0 dx1 dx2 dgx.)3 hilbert denotes the nat-[VI.63](/part - 06/david - hilbert - 18621943), who was following closely Einstein’s struggle to formu-late a theory of gravity with a dynamic metricg, arrived at his Lagrangian (actually a more general version of the above yielding the coupled Einstein–Maxwell sys - tem) very shortly before Einstein obtained the general equations (20). from the equations (20) are already present in the vac-uum case (21).
This is some what ironic, because it was Many of the most interesting phenomena that come the forms of T and (10) that dictated (20). Note, in con- trast, that in the Newtonian theory (2), the “vacuum”equations\mu = 0 and standard boundary conditions at infinity implyφ = 0. Thus, the Newtonian theory of the vacuum is trivial. forced to vanish from (21) is known as the vat ure The part of the curvature tensor. This curvature measures the “tidal” distortion R\mu\nuλρ that is not Weyl cur- of families of geodesics.
Thus, the “local strength” of gravitational fields in vacuum regions is related in the Newtonian limit to the tidal forces on macroscopic test matter, not the norm of the gravitational force. 489 3.5 The Manifold Concept We have been able to get this far with out really addressing the question of passing from the Minkowski metric to a general where the metric gis defined. Ing, Einstein did not originally have in mind replacing the domain R4.
But it is clear in the Riemannian case from the theory of surfaces that the natural object for a metric to live on is not necessarily R2 but a general surface.
 For instance, the metric dur ally lives on the sphere S2. In saying this, we areθ2 + . in θ dφ2 nat-to understand that one requires several coordinate systems of the type(θ, φ) to cover all of S2. The n - dimensional generalization of the object where Rie-mannian or Lorentzian metrics naturally live is a manifoldby consistently smoothly pasting together local coordi-[I.3 §6.9](/part - 01/fundamental - definitions).
Manifolds are the structures obtained nate systems. Thus, general relativity allows the space-time continuum not to be R4 but instead to be a general manifold a le nt to M, which may very well be topologically inequiv - R4, just as S2 is in equivalent to R2. We call the pair(M, g) a Lorentzian manifold. Properly put, the unknown in the Einstein equations is not just pair(M, g). g but the It is interesting that this fundamental fact, namely that the topology of space-time is not a priori de-termined by the equations, arises almost as an afterthought.
More over, it was a thought that took many years to be clarified. 3.6 Waves, Gauges, and Hyperbolicity When written out explicitly in arbitrary coordinates(try it!), the Einstein equations do not appear to be of any usual type, such as elliptic (like equation [IV.12 §1](/part - 04/analysis)), parabolic (like the heat equa-the poisson tion[I.3 §5.4](/part - 01/fundamental - definitions); see [IV.12 §2.5](/part - 04/analysis) for more about these differ-[I.3 §5.4](/part - 01/fundamental - definitions)), or hyperbolic (like the wave equation ent classes of PDEs).
This is related to the fact that, given a solution, one can form a “new” solution by composing the old solution with a coordinate transforma - tion. We can do this for new coordinate systems whose coordinate transformations differ from the identity only in a ball.
This fact, known as the confused Einstein and his mathematical collaborator hole argument, Marcel Grossmann, who were thinking algebraically in terms of the form of the equations in coordinates, and temporarily led them to reject “general covariance.” The resulting backtracking delayed the final correct formulation of (1) by about two years. The geometric 490 interpretation of the theory immediately suggests there solution to the dilemma: such solutions are to be considered “the same” because they are the same from the point of view of all geometric measurements.
In modern language, a solution to the Einstein vacuum equa - tions (say) is an equivalence class [I.2 §2.3](/part - 01/language - and - grammar) of space times(M, g), where two space-times are equivalent if there exists a diffeomorphism that in any open set the metric has the same coordinateφ between them such form when one identifies local coordinates byφ. over come, the Einstein equations can be viewed as hyperbolic. The easiest way to do this is to impose a It turns out that once these conceptual issues are gaugedinate system. Specifically, one requires the coordinate:
that is to say, a certain restriction on the coor functionsxα to satisfy the wave equationg xα = 0, where the formula d’Alembertian operator is defined by the g = . qrt{-1} g . artial\mu( -gg\mu\nu . artial\nu).

Such coordinates always exist locally and they are tradi-tion ally called harmonic coordinates, although the term wave coordinates would perhaps be more appropriate. The Einstein equation can then be written as a system

ggμν = Nμν ({gαβ}$, {\partial^{γ} g^{α}β})$,

where in the N∂γ μνgαβis a nonlinear expression that is quadratic. In view of the Lorentzian signature of the metric, the above system constitutes what is known as a second-order nonlinear (but quasilinear) hyperbolic system At this point, it is instructive to make a com par i-. son with the Maxwell equations. Suppose we are given an electric field Minkowski space. A 4$E$and a magnetic field-potential is a vector field Bdefined on A such that(Here Ei = −=∂1, andi A0 - c-1∂tis totally antisymmetric, i.e., it Ai$, \text{and Bi} = 3 j$, k=1 ijk∂j Ak.
transforms to its negative under permutation of anytwo indices.) If one wishes to view123 ijk A as the fund a men- tal physical object, then one notices that if A is replaced by the field  ̃$A$, defined by the formula $A$ ̃$= A + (-c^{-1}\partial^{t} ψ$, ∂1ψ, ∂2ψ, ∂3ψ), where potential forψ is an Ear bi tr ary and B. One can expect a determined function, then  ̃A is also a 4- equation foron it: that is, if one “fixes the gauge.” (The terminol-A only if one imposes further conditions ogy “gauge” is originally due toso-called Lorentz gauge weyl [VI.80](/part-06/hermann-weyl-18851955).) In the

$\nabla^{\mu}A^{\mu} = 0$,

IV. Branches of Mathematics

the Maxwell equations can be written

 A\mu = −c-2. artia(lt)2 A\mu + . artia(li)2 A\mu = 0, i

from which the wave properties are completely man-ifest. The gauge-symmetric point of view lived on to later twentieth century glory: the which are a nonlinear generalization of the Maxwell Yang–Mills equations, equations with a similar gauge symmetry, are the cen-tral part of the so-called standard model for particle physics. The hyperbolicity property of the Einstein equations has two important repercussions. The first is that there should exist gravitational waves.
This was noted by Einstein at least as early as 1918, essentially as a result ofa linearized version of the considerations in the above discussion. The second is that there is a initial value problem [IV.12 §2.4](/part-04/analysis) for the einstein well-posed equations (1) with the domain-of-dependence prop-erty, when these are coupled with appropriate matter equations. In particular, this is true in the vacuum case (21).
The proper conceptual framework to formulate the latter problem took a long time to get right, and was only completely understood through work of Choquet-Bruhat and Geroch in the 1950 s and 1960 s, based on the fundamental concept of global hyperbolicity could associate a unique solution (in the vacuum case, due to Leray. Well-posedness means that one a Lorentzian 4 - manifold(M, g) satisfying (21)) with a suitable notion of initial data. Of course, “initial data”does not mean “data at time$t =$0,” since the concept of t = 0 is not geometric.
Instead, the data take the form of some Riemannian 3-manifold covariant 2-tensor K. The triple(Σ,(Σ, g) ̄g, K) ̄with a symmetric has to satisfy the so-called notion, the fundamental problem of general relativity, Einstein constraint equations. But with this despite its revolutionary conceptual structure, is thor-oughly classical: to determine the relation of the solution to initial data, that is to say, to determine the future from knowledge of the “present.” This is the problem of dynamics.
4 The Dynamics of General Relativity In this final section we give a taste of our current math-ematical understanding of the dynamics of the Einstein equations.

4.1 Stability of Minkowski Space and the

Nonlinearity of Gravitational Radiation

In any physical theory in which one can formulate the problem of dynamics, the most basic question is the

IV.13. General Relativity and the Einstein Equations stability of the trivial solution. In other words, if wemake a small change to the “initial conditions,” will the resulting change to the solution be small as well? In the case of general relativity, this is the question of stability of the Minkowski space-time R3$+1$. This fund a men- tal result was proven for the vacuum equations (21) in1993 by Christodoulou and Klainerman. it possible to formulate theation The proof of the stability of Minkowski space made rigorously.
Gravitational radiation is yet to belaws of gravitational rad i observed directly, but it has been inferred, originally by Hulse and Taylor, from the energy loss of a binary system. This work gave them the only Nobel prize (1993) directly associated with the Einstein equations!The blueprint for the mathematical formulation of the radiation problem is based on work of Bondi and later Penrose. One associates with the space-time(M, g) an ideal boundary “at infinity,” known as denoted I+.
Physically, the points ofnull infinity I+ correspond and to observers who are far away from the isolated self-gravitating system but who are receiving its signals. Gravitational radiation can be identified with certain tensors defined on I+ from rescaled boundary limits of various geometric quantities. As Christodoulou was todiscover, the laws of gravitational radiation are themselves nonlinear, and the nonlinearity is potentially relevant for observation.

4.2 Black Holes

Perhaps no prediction of general relativity is better known today than that of black holes. The story of black holes begins with the so-called Schwarzschild metric:

- 1 - 2 rm dt2 + 1 - 2 rm-1 dr2+ r2(dθ2 + . in2 θ dφ2). (22) The parametera solution of the vacuum Einstein equations (21) thatm here is a positive constant. This is was found in 1916. The original interpretation of (22) was that it modeled the gravitational field in a vacuum region out side a star. That is to say, (22) was considered only in some coordinate range and the metric was matched atr > Rr = R0, for anto a “static” inte- R0 > 2 m, rior metric satisfying the coupled Einstein–Euler sys-tem in the coordinate range$r$ ⩽ R .
(This latter metric0 is again of the form (22), but withm \to 0 as r \to 0.) m0 = m(r ) such that poses itself. Suppose we do away with the star alto-From the theoretical point of view, a natural problem 491 gether and try to consider (22) for happens then to the metric (22) at rall = values of2 m? In ther . What(r , t) coordinates, the metric element appears to be singular. But this turns out to be an illusion! By a simple change of coordinates, one can easily extend the metric reg-ularly as a solution of (21) beyond r = 2 m.
That is, there exists a manifold M that contains both a re gionr >ular (null) hypersurface2 m and a region 0 < r <H+. The metric element (22)2 m, separated by a reg- is valid every where except on H+, where it must be rewritten in regular coordinates. It turns out that the hypersurface H+ can be char- acterized by an exceptional global property: it defines the boundary of the region of space-time that can send signals to null infinity I+, or, in the physical interpreta- tion, to distant observers.
In general, the set of points that cannot send signals to null infinity I+ is known as the0< r <black hole2 m is the black hole region of region of space-time. Thus, the region M, and H+ is known as the These issues took a long time to be sorted out, event horizon. partly because the language of global Lorentzian geom-etry was developed long after the original formulation of the Einstein equations. The global geometry ofthe extended space-time$M$was clarified by Synge in around 1950 and finally by Kruskal in 1960. The name“black hole” is due to the imaginative physicist John Wheeler.
From their beginnings as a theoretical curios-ity, black holes have become part of the accepted astrophysical explanation for a wide variety of phenomena, and in particular are thought to represent the end-state for the gravitational collapse of many stars.

4.3 Space-Time Singularities

A second natural problem poses itself in relation tothe Schwarzschild metric (22), now considered in the region happens at$r <r2 = m$0?of the extended space-time$M$: what scalar geometric invariant, it follows that, unlike the situation A computation reveals that as RμνλρRμνλρ blows up. Since this expression is ar \to  0, the Kretchmann$at$ r = 2 m, the space-time is not regularly extendable beyond 0.
More over, timelike geodesics (freely falling observers in the test particle approximation) entering the black hole region reach$r =$0 in finite proper time, so they are “incomplete” in the sense that they cannot be continued indefinitely. They thus “observe” the breakdown of the geometry of the space-time metric. More over, macroscopic observers approaching$r = 0$ are torn apart by the gravitational “tidal forces.”

492

this seemingly pathological behavior was connected tothe high degree of symmetry of the Schwarzschild met-In the early years of the subject, it was thought that ric and that “generic” solutions would not exhibit such phenomena. That this is not the case was shown by Penrose’s celebrated states that solutions to the initial value problem for incompleteness theorem of 1965. This the Einstein equations coupled to appropriate matter will geodesics if the initial data hypersurface is noncom-always contain such incomplete timelike or null pact and contains what is known as a closed trapped surface.
The Schwarzschild case may appear to suggest that such incomplete geodesics are associated with the curvature blowing up. However, the situation can infact be very different, as is apparent in the celebrated kerr solutions to the vacuum equations (21), discovered only solutions, a remarkable two-parameter family of in 1963, which are rotating versions of (22). In the Kerr solutions, incomplete timelike geodesics meet aso-called Cauchy horizon, a smooth boundary of the region of space-time that is uniquely determined by initial data.
The theorem of Penrose gives rise to two important conjectures. The first, known asship, says roughly that for generic physically plausi-weak cosmic cens or ble initial data for suitable Einstein-matter systems, geodesic incompleteness, if it occurs, is always confined to black hole regions. The second, strong cosmic censorship si ble initial data, incompleteness of the solution is, says roughly that for generic admisalways associated with a local obstruction to extend - ability, such as the blow-up of curvature.
The latter conjecture would ensure that the unique solution of the initial value problem is the only classical space-time that can arise from the data. That is to say, it would imply that classical determinism holds for the Einstein equations. Both conjectures are false if we drop the assumption that the initial data are generic, and this is one rea-son for their difficulty. Indeed, Christodoulou has constructed spherically symmetric solutions of the cou-pled Einstein-scalar field system (arising from regular initial data) that are geodesically incomplete but do not contain black hole regions.
Such space-times are said to contain naked singularities. not require that they arise from the collapse of regu-lar initial data. An example is the Schwarzschild metric Naked singularities are easy to construct if one does (22) for complete asymptotically flat Cauchy hypersurface. Thism < 0. This metric, however, does not admit a IV. Branches of Mathematics fact is related to the celebrated of Schoen and Yau. positive energy theorem 4.4 Cosmology The space - times(M, g) discussed previously are all idealized representations of isolated systems.
The “restof the universe” is excised and replaced by an “asymptotically flat end”; far-away observers are placed at an ideal boundary “at infinity.” But what if we are more ambitious and consider our space - time(M, g) as rep- re sent ing the whole universe? The study of this latter problem is known as cosmology. Observations suggest that on very large scales the universe is approximately homogeneous and isotropic. This is some times known as the Copernican principle. Interestingly, one cannot solve the Poisson equation (2)with a constant. abla φ and constant nonzero \mu on R4.
Thus, in Newtonian physics, cosmology never became a rational science.1 General relativity, on the other hand, does admit homogeneous and isotropic solutions aswell as their perturbations. Indeed, cosmological solutions of the Einstein equations were studied by einstein himself, de Sitter, Friedmann, and Lemaitre in the early years of the subject. When general relativity was formulated, the prevailing view was that the universe should be static. This led Einstein to add a termside of his equations, fine-tuned so as to allow forΛg\mu\nu to the left - hand such a solution.
The con st an tmo logical constant. The expansion of the universe isΛ is known as the cos- now considered to be an observational fact, beginning with the fundamental discoveries of Hubble. Expanding universes can be modeled to a first approximation by so-called Friedmann–Lemaitre solutions to the Einstein–Euler system, with various values ofΛ. In the past direction, these solutions are singular:
this singu-lar behavior is often given the suggestive name “the big bang.” 4.5 Future Developments The plethora of exact solutions of the Einstein equa-tions gives us a taste of what the qualitative behavior of more general solutions may be. But a true qualita-tive understanding of the nature of general solutions has been achieved only in a neighborhood of the very da tions of the Newtonian theory so as to describe the theory with anonmetric connection on, say,1. One can study “Newtonian cosmology” by modifying the foun - T3$\times R$.
But this step is of course inspired by general relativity (see section 3.5). IV.14. Dynamics simplest solutions. The question of the stability of the black hole solutions described above remains unanswered, as do the cosmic censorship conjectures andthe nature of the singularities that occur generically in general relativity. Yet these questions are fundamental to the physical interpretation of the theory, and indeed to assessing its very validity. answered by rigorous mathematics?
Problems con-cerning the singular behavior of nonlinear hyperbolic How likely is it that these questions can ever be partial differential equations are notoriously difficult. The rich geometric structure of the Einstein equations appears at first as a formidable additional complication, but it may also turn out to be a blessing. One can only hope that the Einstein equations will continue to reveal beautiful mathematical structure that answers fundamental questions about our physical world. Further Reading Christodoulou, D. 1999.
On the global initial value problem and the issue of singularities.
 Classical Quantum Gravity Hawking, S. W., and G. F. R. Ellis. 1973.16: A23–A35.ture of Space - Time. Cambridge Monographs on Mathe-The Large Scale Struc mat ical Physics, number 1. Cambridge: Cambridge Uni-ver sity Press. Penrose, R. 1965. Gravitational collapse and space-time singularities. Physical Review Letters 14:57–59. Rendall, A. 2008.Relativity. Oxford: Oxford University Press. Partial Differential Equations in General Weyl, H. 1919.published in English, in 1952, as Raum, Zeit, Materie Space, Time, Matter. Berlin: Springer. (Also. New York:
Dover.) IV.14 Dynamics Bodil Branner 1 Introduction Dynamical systems are used to describe the way sys-tems evolve in time, and have their origin in the laws of nature that newton [VI.14](/part - 06/isaac - newton - 16421727) formulated in Principia Mathemat i cam at ical discipline, the theory of dynamics, is closely(1687). The associated ma the related to many parts of mathematics, in particular analysis, topology, measure theory, and combinator-ics.
It is also highly influenced and stimulated by problems from the natural sciences, such as celes-tial mechanics, hydrodynamics, statistical mechanics, meteorology, and other parts of mathematical physics,

493

as well as reaction chemistry, population dynamics, and economics. Computer simulations and visualizations play an important role in the development of the theory; they have changed our views about what should be considered typical, rather than special and a typical. There are two main branches of dynamical systems: continuous and discrete. The main focus of this paper will be holomorphic dynamics, which concerns discrete dynamical systems of a special kind.
These systems are obtained by taking a[I.3 §5.6](/part-01/fundamental-definitions)$f$defined on the complex numbers and apply-holomorphic function ing it repeatedly. An important example is whenf is a quadratic polynomial.

1.1 Two Basic Examples

It is interesting to note that both types of dynamical system, continuous and discrete, can be well illustrated by examples that date back to Newton. solar system of the sun andin terms of differential equations. Each body is repre-(i) The N-body problem models the motion in the N - 1 planets, and does so sented by a single point, namely its center of mass, andthe motion is determined by Newton’s universal law of gravitation—also called the inverse square law.
This says that the gravitational force between two bodies is proportional to each of their masses and inversely proportional to the square of the distance between them. Let mass, andri denote the position vector of theg the universal gravitational constant. Then ith body, mi its the force on thegm m / r - r ith body due to the2, and its direction is along the line jth has magnitude from body by adding up all these forces fori (ri)j to (rj)j. We can work out the total force on thei j = i.
Since a unit ith vector in the direction from$r^{i} to r^{j} is (r^{j} - r^{i})/ r^{j} - r^{i}$, we obtain a force of

gj. eqi mimj r(rj)j--r(ri)i 3.

(There is a cube on the bottom rather than a square in order to compensate for the magnitude ofr - r .) A solution to the$N$-body problem is a set of differ en-$j^{i}$ tiable vector functions timet, that satisfy the (Nr1 differential equations(t), $. . . , r^{N} (t))$, depending onmiri^  (t) = (gj()≠){i} mimj r(rj)j(t)(t)--r(ri)i(t)(t)3, which result from Newton’s second law, which states that force$= mass \t\text{imes acceleration}$.

494

plicitly. By neglecting the influence of other planets, Newton was able to solve the two-body problem exhe derived the laws formulated by Johannes Kepler, which describe how each planet moves in an elliptic orbit around the sun. However, the jump to N > 2 makes an enormous difference to the complication ofthe problem: except in very special cases, the system of equations can no longer be solved explicitly (see the three-body problem ton’s equations are of great practical importance when[V.33](/part-05/the-three-body-problem)).
Nevertheless, Newit comes to guiding satellites and other space missions. tions is quite different and does not involve differ en-(ii) newton’s method [II.4 §2.3](/part - 02/algorithms) for solving equatial equations. We consider a differentiable functionof one real variable and wish to determine a zero offf, that is, a solution to the equation f (x) =0. Newton’s idea was to define a new function: Nf (x) = x - ff (x)^ (x). To put this more geometrically, N (x) is the x - coordi - f nate of the point where the tangent line to the graphy = f (x) at the point (x, f (x)) crosses the x - axis.
(Iff^ (x) = 0, then this tangent line is horizontal and Nf (x)is not defined.) of Under many circumstances, iff , then N (x)is significantly closer. Therefore, ifx is close to a zerof we start with some valuex0 and form the sequence obtained by repeated application of N , that is, thef sequence N (x ), and so on, we can expect that this sequencex0$, x1$, x2, $. . . , where x1 = Nf (x0)$, x2 = will converge to a zero of initial valuef1 xis sufficiently close to a zero, then the f. And this is true:
if the sequence does indeed converge toward that zero, and0 does so extremely quickly, basically doubling the num-ber of correct digits in each step. This rapid convergence makes Newton’s method very useful for numerical computations.

1.2 Continuous Dynamical Systems

We can think of atem of first-order differential equations, which deter-continuous dynamical system as a sys mine how the system evolves in time. A solution is called an orbit or trajectory, and is parametrized by a numbert, which one usually thinks of as time, that takes real values and varies continuously: hence the name “continuous” dynamical system. A periodic orbit of period T is a solution that repeats itself after time T, but not earlier.

IV. Branches of Mathematics

The differential equationx^ (t) = −x(t) is of sec- ond order, but it is nevertheless a continuous dynamical system because it is equivalent to the system oftwo first-order differential equations$x (t) = x (t) andx^{2}(t) = −x^{1}(t)$. In a similar way, the system of differ-1 2 ential equations of the into standard form by introducing new variables. The N-body problem can be brought equations are equivalent to a system of 6$N$first-order differential equations in the variables of the position vector sr = (x , x , x ) and the velocity vectors ri^ = ((yi)1$, (yi()i)2$, (yi()3)i)1.
Thus, th(ei)2 i 3 N-body problem is a good example of a continuous dynamical system. ofthe form In general, if we have a dynamical system consistingn equations, then we can write the ith equation inxi^ (t) = fi(x1(t), . . . , xn(t)), or alternatively we can write all the equations at oncein the form$x (t) = f (x(t))$, where x(t) is the vec- tor from$(x R^{1}(t)$, . . . , xn to Rn. Note thatn(t)) and ff =is assumed not to depend(f1, . . . , fn) is a function onstandard form by adding the variablet.
If it does, then the system can be brought intox = t and the differential equation dimension of the system from(xn)+1(t) =n1, which increases theto n +n1.+1 The simplest systems are linear ones, wheref is a linear map: that is, constantn . imes  n matri xf A(. The system above, x) is given by Ax for somex^  (t) =x2(t) and x2(t) = −x1(t), is an example of a linear1 system. Most systems, however, including the one forthe N-body problem, are nonlinear. If the function f is “nice” (for instance, differentiable), then uniqueness andtial point existence$x^{0}$.
That is, there is exactly one solution thatof solutions are guaranteed for any ini- passes through the pointx0 at time t = 0. For example, in theany given set of initial position vectors and initial veloc - N-body problem there is exactly one solution for ity vectors.
It also follows from uniqueness that any pair of orbits must either coincide or be totally disjoint.(Bear in mind that the word “orbit” in this context does not mean the set of positions of a single point mass, but rather the evolution of the vector that represents all the positions and velocities of all the masses.) nonlinear systems explicitly, we know that they exist, Although it is seldom possible to express solutions to and we call the dynamical system solutions are completely determined by their initial deterministic since conditions.
For a given system and given initial conditions it is therefore theoretically possible to predict its entire future evolution. IV.14. Dynamics 1.3 Discrete Dynamical Systems Ain jumps: “time,” in such a system, is best repre-discrete dynamical system is a system that evolves sented by an integer rather than a real number. A good example is Newton’s method for solving equations. Inthis instance, the sequence of points we saw earlier, xorbit0, x1 of, . . . , xx0. We say that it is obtained byk,. . .
, where xk = Nf ((xk)-1), is called the iteration of the function N , i.e., by repeated application of thef

function.

pingsan interval in the real axis, the plane, a subset of the This idea can easily be generalized to other map-F$: X \to X$, where X could be the real axis, plane, or some more complicated space. The important thing is that the output be used as the next input. This guarantees that the F(x) of any input x can orbit of anyx0 in Xis defined for all future times. That is, we can define a sequence, wherex = F(x ) for every k. If the functionx0$, x1$, . . . , xk, . .
.F, has an inverse and backwards and obtain thek (F-1()k)-, then we can iterate both forwards1 full orbit of x as the bi-infinite sequence$x = F(x ) and$, equivalently,. . . , x-2$, x - 1x$, x0$, x = 1F$, (x-1)2(x, . . .0), where, for all integer values.(kk()-1()k()-1)k itself after timex The orbit of . neq x for j x = k0, but not earlier, i.e., if1 is, . . . , kperiodic- 1.
The orbit is called of period kxif it re pea tsk = x0, butpre- periodic there existj0 if it is eventually periodic, in other words if⩾ 1 and k ⩾ 1 such that x is periodic of perio dk, but none of the x for 0 ⩽ j <  are peri-j

odic. The notion of pre-periodicity has no counterpart in continuous dynamics. the orbit of any given initial point determined once you know A discrete dynamical system is deterministic, since$x$. x0 is completely

1.4 Stability

The modern theory of dynamics was greatly influenced by the work of poincaré [VI.61](/part-06/jules-henri-poincar-18541912), and in particular by his prize-winning memoir on the three-body problem, succeeded by three more elaborate volumes on celestial mechanics, all from the late nineteenth century. The memoir was written in response to a competition where one of the proposed problems concerned stability of the solar system. Poincaré introduced the so-called restricted three-body problem, where the third body is assumed to have an infinitely small mass:
it does not influence the motion of the other two bodies but it is 495 influenced by them. Poincaré’s work became the pre-lude to topological dynamics, which focuses on topological properties of solutions to dynamical systems and takes a qualitative approach to them. tem. A periodic orbit is called Of special interest is the long-term behavior of a sys-stable if all orbits through points sufficiently close to it stay close to it at all future times. It is called asymptotically stable if all sufficiently close orbits approach it as time tends to infinity.
Let us illustrate this by two linear examples in discrete dynamics. For the real function F(x) = −x, all points have a periodic orbit: 0 has period 1 and all other xhave period 2. Every orbit is stable, but none is asymp-totically stable. The real function G(x) =1 x has only one periodic orbit, namely 0. Since has period 1, and we call it a fixed point G(0) =. If you take20, this orbit any number and repeatedly divide it 2, then the result-ing sequence will approach 0, so the fixed point 0 is asymptotically stable.
One of the methods introduced by Poincaré during his study of the three-body problem was a reduction from a continuous dynamical system, in dimensionn, say, to an associated discrete dynamical system, a map-ping in dimensionn - 1. The idea is as follows. Sup- pose we have a periodic orbit of period continuous system. Choose a pointx on the orbit and T > 0 in some a hypersurface hyperplane, such that the orbit cuts throughΣ through x0, for instance part of a0 Σ at x . For any point inΣthat is sufficiently close tox0, one0 can follow its orbit around and see where it next inter-sectsΣ.
This defines a transformation, known as the Poincaré map, which takes the original point to the next point of intersection of its orbit withlows from the fact that dynamical systems have uniqueΣ. It fol- solutions that every Poincaré map is injective in the neighborhood ofmap is defined. One can perform both forwards and$x^{0} (within Σ$) for which the Poincaré backwards iterations.
Note that the periodic orbit of $x$asymptotically stable) exactly when the fixed point0 in the continuous system is stable (respectively, x0 of the Poincaré map in the discrete system is stable (respectively, asymptotically stable).

1.5 Chaotic Behavior

The notion ofhas been used in different settings, and there is no sin-chaotic dynamics arose in the 1970 s. It gle definition that covers all uses of the term. However, the property that best characterizes chaos is the phe-nomenon of sensitive dependence on initial conditions.

496

Poincaré was the first to observe sensitivity to initial conditions in his treatment of the three-body problem. Instead of describing his observations let us look at a much simpler example from discrete dynamics. Take as a dynamical space X the half-open unit inter- valber and reduces it modulo 1. That is,[0, 1), and let F be the function that doubles a num-F(x) = 2 x when0 be a number in⩽ x <1 2 and F(x)X and let its iterates be = 2 x - 1 whe(n1)2 ⩽ x <x = 1. Let F(xx)0, x(2 k)2 x=. (The fractional part of a real number F(x1), and so on.
Then xk is the fractional part oft1 is what you0 get when you subtract the largest integer less than0 t.) qu en ce binary expansion of A good way to understand the behavior of the se-$x^{0}$, x1$, x2$, . . .x0. Suppose, for example, that thisof iterates is to consider the$begins 0$.110100010100111 . . .. To double a number when it is written in binary, all you have to do is shift every digit to the left (just as one does in the decimal system when multiplying by 10). So 2 a binary expansion that begins 1.10\,100\,010\,100\,111 x0 will have. . ..
To obtain of this, which we do by subtracting the initial 1. This$F(x0)$, we have to take the fractional part gives us process we find that$x^{1} = 0$.10100010100111 x = 0.0100010100111. . . . Repeating the. . . , x = 0.100\,010\,100\,111 . . ., and so on. (Notice that when w(e2)3 calculated since the first digit after the “decimal point” was a 0.)x3 from x2 there was no need to subtract 1, Now consider a different choice of initial number,0.110\,100\,010\,110\,110 . . .. The first nine digits after the$x0 =$decimal point are the same as the first nine digits ofx , so x^ is very close to x .
However, if we apply F ten times toits have shifted leftwards and become the first digits0 0 x0 and x0^ , then their respective eleventh dig - 0 of numbers differ by almostx10 = 0.00111 . . . and (x1)10^ , so they are not at all close.= 0.10110 . . . . These two digits and no more, then after In general, if we know(x2)0 to an accuracy ofk iterations of the mapk binary F we have lost all information: the interval[0, 1).
Therefore, even though the system isxk could lie any where in deterministic, it is impossible to predict its long-term behavior with out knowing$x^{0} \text{with perfect accuracy}$. term predictions in any part of a dynamical system that This is true in general: it is impossible to make long shows sensitivity to initial conditions unless the initial conditions are known exactly. In practical applications this is never the case.
For instance, when applying a mathematical model to perform weather forecasts, one does not know the initial conditions exactly, and this is why reliable long-term forecasting is impossible.

IV. Branches of Mathematics

strange attractors Sensitivity is also important in the notion of so-called. A set A is called an attractor if all orbits that start innearby points get closer and closer to A stay in A and if all orbits through A. In continuous systems, some simple sets that can be attractors are equilibrium points, periodic orbits (limit cycles), and surfaces such as a torus. In contrast to these examples, strange attractors have both complicated geometry and complicated dynamics: the geometry isdynamics sensitive. We shall see examples of fractals fractal and the later on.
tract or The best-known strange attractor is the. In the early 1960 s, the meteorologist Edward N.Lorenz at Lorenz studied a three-dimensional continuous dynam-ical system that gave a simplified model of heat flow. While doing so, he noticed that if he restarted his com-puter with its initial conditions chosen as the output of an earlier calculation, then the trajectory started to diverge from the one he had previously observed. The explanation he found was that the computer used more precision in its internal calculations than it showed in its output.
For this reason, it was not immediately apparent that the initial conditions were in fact very slightly different from before. Because the system was sensitive, this tiny difference eventually made a much bigger difference. He coined the poetic phrase “the but-terfly effect” to describe this phenomenon, suggesting that a small disturbance such as a butterfly flickering its wings could in time have a dramatic effect on the longterm evolution of the weather and trigger a to rna do thousands of miles away.
Computer simulations of the Lorenz system indicate that solutions are attracted toa complicated set that “looks like” a strange attractor. The question of whether it actually was one remained open for a long time. It is not obvious how trustworthy computer simulations are when one is studying sensitive systems, since the computer rounds off the numbers in each step. In 1998 Warwick Tucker gavea computer-assisted proof that the Lorenz attractor is in fact a strange attractor. He used met ic, where numbers are represented by intervals and interval a ri th estimates can be made precise.
For topological reasons, sensitivity to initial conditions is possible for continuous dynamical systems only when the dimension is at least 3. For discrete systems where the map must be at least 2. However, for noninjective mappings, F is injective, the dimension sensitivity can occur for one-dimensional systems, aswe saw with the example given earlier. This is one of

IV.14. Dynamics

the reasons that discrete one-dimensional dynamical systems have been intensively studied.

1.6 Structural Stability

Two dynamical systems are said to be equivalent if there is a homeomorphism (a continuous topologically map with continuous inverse) that maps the orbits of one system onto the orbits of the other, and vice versa. Roughly speaking, this means that there is a continuous change of variables that turns one system into the other. tem given by the real quadratic polynomial4 x(As an example, consider the discrete dynamical sys-1 - x). Suppose we were to make the substitution F(x) =y = −4 x + 2. How could we describe the system in terms of4 x(1 - x)y, which means that?
Well, if we applyy F= −, then we change4 x+2 changes F(x)x to to-4 F(x) + 2 = −16 x(1 - x) + 2. But - 16 x(1 - x) + 2 = 16 x2 - 16 x + 2= (-4 x + 2)2 - 2 = y2 - 2. Therefore, the effect of applying the polynomial func - tion F to xis to apply a different polynomial function toy, namely Q(y) = y2 - 2.
Since the change of vari- ables fromx to - 4 x + 2 is continuous and invertible, one says that the functions Because F and Q are conjugate, the orbit of any F and Q are conjugate.xthe orbit of the corresponding point0 under F becomes, after the change of variables, y = −4 x + 2 under two systems are topologically equivalent: if you want to Q. That is, for every k we have yk = −0 4 xk + 2.
The0 understand the dynamics of one of them, you can if you study the other, since its dynamics will be qualitatively the same. For continuous dynamical systems the notion of equivalence is slightly looser in that we allow a homeo-morphism between two topologically equivalent systems to map one orbit onto another with out respect-ing the exact time evolution, but for discrete dynamical systems we must demand that the time evolution isrespected as in the example above: in other words, we insist on conjugacy. Smale in the 1960 s and has taken off since then.
Smale evolved the theory of The term dynamical system robust systems, also named was coined by stephen structurally stable the 1930 s by Alexander A. Andronov and Lev S. Pon - systems, a notion that was introduced in tryagin. A dynamical system is called structurally sta-ble if all systems sufficiently close to it, belonging to 497 some specified family of systems, are in fact topolog-ically equivalent to it. We say that they all have the same qualitative behavior. An example of the kind of family one might consider is the set of all real quadratic polynomials of the formx2 + a.
This family is parametrized by polynomialx2 + aa, and the systems close to a given are all the polynomials x2 + a for which of structural stability when we discuss holomorphica is close to0 a0. We shall return to the question dynamics later. If a family of dynamical systems parametrized by a variable a is not structurally stable, it may still be that the system with parameter a le nt to all systems with parametera0 is topologically equiv-a in some region that contains a0.
A major goal of research into dynam- ics is to understand not just the qualitative structureof each system in the family, but also the structure of the such regions of stability. The boundaries that separate parameter space, that is, how it is divided up into these regions form what is called theifa0 belongs to this set, then there will be parameters bifurcation set:
a system has a different qualitative behavior.arbitrarily close toa0 for which the corresponding systems and a classification of possible bifurcations is A description and classification of structurally stable not within reach for general dynamical systems. How - ever, one of the success stories in the subject, holomorphic dynamics, studies a special class of dynamical systems for which many of these goals have been attained. It is time to turn our attention to this class.
2 Holomorphic Dynamics Holomorphic dynamics is the study of discrete dynam-ical systems where the map to be iterated is a holomorphic function[I.3 §1.5](/part - 01/fundamental - definitions). Complex numbers are typically denoted by[I.3 §5.6](/part - 01/fundamental - definitions) of the complex number sz.
In this article, we shall consider iterations of complex polynomials and rational functions (that is, functions like(z2 + 1)/(z3 + 1) that are ratios of polynomials), but much of what we shall say about them is true for more general holomorphic functions, such as exponential [III.25](/part-03/the-exponential-and-logarithmic-functions) and trigonometric [III.92](/part-03/trigonometric-functions) functions. of dynamical system, there will be tools that are spe-Whenever one restricts attention to a special kind cially adapted to that situation.
In holomorphic dynam-ics these tools come from complex analysis. When we concentrate on rational functions, there are more special tools, and if we restrict further to polynomials, then there are yet others, as we shall see.

498

functions? One answer arose in 1879, when Why might one be interested in iterating rational cayley [VI.46](/part-06/arthur-cayley-18211895) had the idea of trying to find roots of complex polynomials by extending Newton’s method, which we discussed in the introduction, from real numbers to complex numbers. Given any polynomial P , the corre- sponding Newton function given by the formula NP is a rational function$, NP (z) = z - PP (z) (z) = z P (z)P (z)- P (z)$. To apply Newton’s method, one iterates this rational function.
The study of the iteration of rational functions flourished at the beginning of the twentieth century, thanks in particular to work of Pierre Fatou and Gaston Julia (who independently obtained many of the same results). Part of their work concerned the study of the local behavior of functions in the neighborhoods of a fixed point. But they were also concerned about global dynamical properties and were inspired by the theory of so-called li shed by Paul Montel.
However, research on holomor-normal families, then recently estabphic dynamics almost came to a stop around 1930, because the fractal sets that lay behind the results wereso complicated as to be almost beyond imagination. The research came back to life in around 1980 with the vastly extended calculating powers of computers, and in particular the possibility of making sophisticated graphic visualizations of these fractal sets. Since then, holomorphic dynamics has attracted a lot of attention. New techniques continue to be developed and introduced.
simplest of polynomials, namely To set the scene, let us start by looking at one of the$z2.$2.1 The Quadratic Polynomialz2

The dynamics of the simplest quadratic polynomial,$Q (z) = z2$, plays a fundamental role in the under- standing of the dynamics of any quadratic polyno-mial. More over, the dynamical behavior of0 Q can be analyzed and understood completely. Ifz = r ei^θ, then z2 = r2 e2 i^θ, so squaring a complex number squares its modulus and doubles its argument. Therefore, the unit circle (the set of complex numbers of modulus 1) is mapped byof radiu sr < 1 is mapped onto a circle closer to the Q0 to itself, while a circle origin, and a circle of radiu sr > 1 is mapped onto a circle farther away.

IV. Branches of Mathematics

unit circle. A typical point in the circle, ep ar a me tr iz ed by its argument Let us look more closely at what happens to theθ, which we can take t(oi)θ, can be lie in the intervalwe obtain e2 iθ, which is parametrized by the number[0, 2π). When we square this number,2 that the argument, 2θ if 2θ < 2π, but if 2θ -θ ⩾2π2, still lies inπ, then we subtract 2[0, 2π). This isπ so strongly reminiscent of the dynamical system we considered in section 1.5. In fact, if we replace the argu - mentθ byits modified argumentθ/2π, which amounts to writing ethe same system.
Therefore, the behavior of2πi θ instead of (ei)θ, then it becomes exactlyz2 on the unit circle is chaotic. asymptotically stable fixed point, point As for the rest of the complex plane, the origin is anz inside the unit circle the iterates Q0(0) =z 0. For any converge to 0 asunit circle the distance0 ktends to infinity. For any point|z | between the iteratesz0 out side thek z and the origin tends to infinity asset of initial pointsz0 with bounded orbit is equal tok ktends to infinity.
The k the closed unit disk, i.e., all points for which Its boundary, the unit circle, divides the complex plane$|z^{0}| ⩽ 1$. into two domains with qualitatively different dynamical behavior. Some orbits of Q0 are periodic. In order to deter- mine which ones, we first notice that the only possi-bility out side the unit circle is the fixed point at the origin, since all other points, when you repeatedly square them, either get steadily closer and closer to the ori-gin, or get steadily farther and farther away.
So now let us look at the unit circle, and consider the pointe2(πi()θ){0}, with modified argumentθ . If this point is peri- odic with period that is,(2 k - 1)θ kmust be an integer. Because of this,, we must have (20)kθ0 = θ0(mod 1): it is convenient to parametrize a point on the unit circle by its modified argument. From now on, when we say0 “the pointθ,” we shall mean the point e2$πi^{θ}$, and when we say “argument” we shall mean modified argument. odic with period follows that there is one point of period 1, namely We have just established that the pointk only if (2 k - 1)θ is an integer.
Itθ is peri-θone orbit, namely0 = 0. There are two points of period 2, forming1 \to 2 \to 1. There are six points for period 3, forming two orbits, namely and 3$\to 6 \to 5 \to 3 3$. (At each stage, we double the num-3 3 1 7 \to 2 7 \to 4 7 \to 1 7 ber we have, and subtract 1 if that is needed to get usback into the interval7 7 7 7[0,1).) The points of period 4 are fractions with denominator 15, but the converseis not true: the fractions 3$=1 and6 = 2 \text{have the}$ lower period 2. The periodic points on the unit circle15 3 15 3 IV.14. Dynamics are close to any point is a periodic point.
This follows dense in the unit circle, meaning that arbitrarily from the observation that all repeating binary expansions, such as 0 periodic, and any finite sequence of 0 s and 1 s is the$.1,100,011,000,110,001,100,011,000 . . . are$ start of a repeating sequence. One can, in fact, show that the periodic points on the unit circle are exactly the points whose argument is a fraction withq odd. Any fraction with even denominator can bep/q in [0,1) written in the form After iterations, such a fraction will land on a peri - p/(2 q) for some odd number q.
odic point, so the initial point is pre - periodic. Points with rational argument in[0, 1)have a finite orbit, while points with irrational argument have an infinite orbit. The reason for taking modified arguments is now justified: the behavior of the dynamics depends on whetherθ0 is rational or irrational. dense inif one considers binary expansions. For instance, a very Whenθ[00, is irrational its orbit may or may not be1).
This is another fact that is easy to see special example of aθ0 with a dense orbit is given by the binary expansionθ0 = 0.0\,100\,011\,011\,000\,001\,010\,011\,100\,101\,110\,111 . . . , where one obtains this expansion by simply listing all finite binary sequences in turn: first the blocks of length one, 0 and 1, then the blocks of length two, 00, 01, 10, and 11, and so on. When we iterate, this binary expansion shifts to the left and all possible finite sequences appear at some time or another at the beginning of some iterateθk.

2.2 Character ization of Periodic Points

Letdo the iterates of points nearz0 be a fixed point of a holomorphic mapzbehave? The answer F. How depends crucially on a number of the fixed point, which is defined to beρ0, called the F^ (zmul tip lier). To see why this is relevant, notice that ifthen F(z)is, to a first-order approximation, equal toz is very close to0 z0, F(zyou apply0) + F^ (z F0 to a point near)(z - z0) = z0 z+, its difference from$ρ(z - z0)$. Thus, whenz approximately multiplies by points will get closer to$z^{0}$, in which caseρ0. If |ρ| < 1, then nearbyz0 is called0 anvery quickly and attracting fixed point.
Ifz is called super-attractingρ = 0, then this happens. If |ρ| > 1, then nearby points get farther away and repelling. Finally, if0|ρ| = 1, then one says thatz0 is call edz is indifferent. form Ifzρ0 is indifferent, then its multiplier will take the= (e2()π){i}θ, and near z0 the map F will be approx-

499

imately a rotation about behavior of the system depends very much on the pre-z0 by an angle of 2πθ. The cise value ofθ. We call the fixed point rationally or irrationally in different tive ly. The dynamics is not yet completely understood ifθ is rational or irrational, respec- in all irrational cases. A periodic pointz of period kwill be a fixed point of the define its multiplier bykth iterate Fk =0 F ◦ · · · ◦ρ = (FF ofk)^ F(z. For this reason we).
It follows from the chain rule that (Fk)^ (z0) =k j -=1 0 F^ (zj) and therefore that the derivative of Fk is the same at all points of the periodic orbit. This formula also implies that a super-attracting periodic orbit must contain a critical point (that is, a point where the derivative ofis zero): if(Fk)^ (z ) = 0, then at least one F^ (z ) must F0 j be 0.Note that 0 is a super-attracting fixed point of Q0, and that any periodic orbit ofunit circle has multiplier 2 k. All periodic orbits on the Q0 of period k on the unit circle are therefore repelling.
2.3 A One-Parameter Family of Quadratic Polynomials The quadratic polynomial Q0 sits at the center of the one-parameter family of quadratic polynomials of the form Q (z) = z2 + c. (We considered this family ear - c lier, but then For each fixed complex num berz and c were real rather than complex.)c we are interested in the dynamics of the polynomial Q under iteration. Thec reason we do not need to study more general quadratic polynomials is that they can be brought into this formby a simple substitutionw = az + b, similar to the substitution in the real example in section 1.6.
For any given quadratic polynomial Pwe can find exactly one sub st it ut io nw = az + b and one c such thata(P (z)) + b = (az + b)2 + c for all z. Therefore, if we understand the dynamics of the poly - nomials Q , then we understand the dynamics of allc quadratic polynomials. There are other representative families of quadratic polynomials that can be useful. One example is the family$F (z) = \lambda z + z2$. The substitution w = z + 1. ambda changes return to the expression of. ambda F. ambda into Qc, wherec in terms ofc = 1 2λ -1 4λλ2. We shall later on.
In2 the family of polynomials coincides with the only critical value$Qc$, the parameterof Qcin the plane: c = Qc(0)

500

NCZRzi RS

Figure 1 The Riemann sphere.

as we shall see later, critical orbits play an essential role in the analysis of the global dynamics. In the fam-ily of polynomials F the parameter . ambda is equal to the multiplier of the fixed point at the origin of$\lambda F^{λ}$, which some times makes this family more convenient.

2.4 The Riemann Sphere

To understand further the dynamics of polynomials it is best to regard them as a special case of rational functions. Since a rational function can some times be infinite, the natural space to consider is not the com-plex plane C but the extended complex plane, which is the complex plane together with the point “space is denoted ˆC= C ∪ {$\infty$}. A geometrical picture. nfty.” This (see figure 1) is obtained by identifying the extended complex plane with the Riemann sphere. This is simply the unit sphere\\{(x1}$, x2$, x3)$:\\$(x2)1 + (x2)2 + (x3)2 = 1 in three-dimensional space.
Given a number complex plane, the straight line join i ngz to the northz in the pole N = (0, 0, 1) intersects this sphere in exactly one place (apart from N itself). This place is the point in the sphere that is associated with bigger|z| is, the closer the associated point is toz. Notice that the N. We therefore regard Let us now think of N as corresponding to the point Q (z) = z2 as a function from. nfty . ˆC to ˆC. We have seen that 0 is a super-attracting fixed0 point ofwell? The classification we gave in terms of multipliers$Q^{0}$.
What about . nfty, which is a fixed point as does not work attion is to “move”. nfty . nfty to 0. If one wishes to understand the, but a standard trick in this situa- behavior of a function look instead at the function fwith a fixed point atg(z) = 1/f (1/z). nfty , one can, which has a fixed point at 0 (since 11$/$. nfty$= 0)$. When f (z) = z2, g(z)/f (1 is also/0) =z12/f (, so. nfty . nfty ) =is also a super-attracting fixed point of$Q^{0}.

IV. Branches of Mathematics

Figure 2 The Douady rabbit. The filled Julia set of Q wherec is the one root of the polynomial (c2 + c)2 +cc0 that has positive imaginary part. This corresponds to oneof the three poss i blec values for which the critical orbit 0 The critical orbit is marked with three white dots inside the\to  c \to  c2 + c \to  (c2 + c)2 + c = 0 is periodic of period 3. filled Julia set: 0 in the black, in the gray.
The corresponding three attracting basins ofc0 in the light gray, and (c0)2 +c0 QThe Julia set is the common boundary of the black, ligh(t3()c)0 are marked in black, light gray, and gray, respectively. gray, and gray basins of attraction as well as of(Ac)0 (. nfty ). it is natural to define trick, we obtain a rational function. For example, if In general, if P is any nonconstant polynomial, then P (. nfty ) to be . nfty . Applying the above P (z) = z2 + 1, then 1/P (1/z) = z2/(z2 + 1).
If P has degree at least 2, then. nftyis a super-attracting fixed point. The connection between ˆC and rational functions is expressed by the following fact: a function F: ˆC$\to C$ˆ is holomorphic every where (with suitable definitions at. nfty ) if and only if it is a rational function. This is not obvious, but is typically proved in a first course in complex analysis. Among the rational functions, the polynomials are the ones for which$F(\infty ) =$. nfty$=F^{-1}(\infty )$.

in the plane (not including the derivative A polynomial P^ P, counted with multiplicity. The criticalof degree. nfty d). These are the roots ofhas d - 1 critical points point at. nfty  has multiplicity d - 1, as can again be seen by looking at the map 1 polynomials have exactly one critical point in the plane./P (1/z). In particular, quadratic The degree of a rational function have no common roots) is defined to be the maximal$P /Q (where P and Q$ degree of the polynomials of degree$d has 2d -$2 critical points in ˆP and Q. A rational function C, as we have just seen for polynomials.

IV.14. Dynamics

2.5 Julia Sets of Polynomials

It can be shown that the only invertible holomorphic maps from C to C are polynomials of degree 1, that is, functions of the formaz + b with a . neq 0. The dynamical behavior of these maps is easy to analyze, simple, and hence not interesting. From now on, therefore, we shall consider only polynomials mials,$\infty P$ is a super-attracting fixed point, from which of degree at least 2.
For all such polynoit follows that the plane is split into two disjoint sets with qualitatively different dynamics, one consisting of points that are attracted to. nfty  and the other consist- ing of points that are not. The denoted by$A (\infty )$, consists of all initial points attracting ba si nz of such. nfty , P

that Pk(z) → . nfty as k → $\infty$. (Here, P^k(z) stands for the result of applying A (. nfty ) is called the Pfilled Julia settoz k times.) The complement of, and is denoted by K . It can be defined as the set of all points sequence P z, P (z)$, P^{2}(z)$, P3(z), . . . is bounded. (It is notz such that the P hard to show that sequences of this kind either tend to. nfty  or are bounded.) The attracting basin of. nfty  is an open set and the filled Julia set is a closed, bounded set (i.e., apact set [III.9](/part-03/compactness-and-compactication)).
The attracting basin of$\infty\text{isalwayscom}-$ connected. For this reason the boundary ofto the boundary of$A (\infty )$. The common boundary is K^P is equal P

called the three sets KJulia set, A (. nfty )of, and P and is denoted by J are completely invariant, JP. The i.e., by any iterate P (KP ) =PK(PP()k)P=, then the filled Julia set, the attracting$P^{-1}(K^{P} )$, and so on. If we replace P P basin of. nfty , and the Julia set of Pk are the same sets as those of P . filled Julia set is the closed unit disk, attracting basin of For the polynomial. nfty is its complement$, Q^{0}$, we showed earlier that thez:|zz|:⩽|z|1>; the1;
and the Julia set is the unit circle, z:$|z| = 1$.KPThe name “filled Julia set” refers to the fact thatis equal to JP with all its holes (or, more formally, the bounded components of its complement) filled in. The complement of the Julia set is called the Fatou set and any connected component of it is called acomponent. Fatou Figures 2–6 show different examples of Julia sets of quadratic polynomials$K = K$, A (. nfty ) = A (. nfty ), and Qc. For simplicity we set J = J .
Note that all Julia sets me try in the formula:(Qc)c (Jc)Qare symmetric around 0, owing to the sym-c Qc (-z) = (QQ)c(z), which impliesc that if a pointz belongs toc J , then so doesc -z.c

501

Figure 3 Julia set (including the critical point 0) is attracted (under The Julia set of(Q1()/){4}. Every point inside the repeated applications of fixed point 1 with multiplier Q1/4ρ) to the rationally indifferent$= 1$, which belongs to J . 2 1$/ {}^{4}$ Figure 4 around an irrationally indifferent fixed point of multiplier The Julia set of Qc with a so-called Siegel diskρ1 ρ=- (e1)2ρπ 2 i (. In the Siegel disk, the Fatou component contain-. qr(t5()-1))/2.
The corresponding c-value is equal to ing the fixed point, the action of change of variables, be expressed as2 4 Qc can, after a suitablew \to  ρw. The fixed point is marked and so are some orbits of points in its vicin-ity. The critical orbit is dense in the boundary of the Siegel disk.

2.6 Properties of Julia Sets

In this section we shall list several common properties of Julia sets. The proofs of these, which are beyond the scope of this article, mostly depend on the theory of normal families. • The Julia set is the set of points for which the system displays sensitivity to initial conditions, i.e., the chaotic subset of the dynamical system.

502

• The repelling orbits belong to the Julia set and form a dense subset of the set. That is, any point in the Julia set can be approximated arbitrarily wellby a repelling point. This is the definition originally used by Julia. (Of course, the name “Julia set”was used only later.) • For any point". nfty z in the Julia set, the set of iterated-k preimages the Julia set.
This property is used when one isk=1 F (z) forms a dense subset of• making computer pictures of Julia sets. In fact, for any point zin ˆC (with at most one or two exceptions), the closure of the set of iterated preimages contains the Julia set. • For any pointhood U of z, the iterated image sz in the Julia set and any neighbor-Fk(U ) cover all of ˆThis property demonstrates an extreme sensitivity C except at most one or two exceptional points.zz• to initial conditions. Ifpletely invariant (that is,Ω is a union of Fatou components that is com-F(Ω) = Ω = F-1(Ω)), then the boundary ofset.
This justifies the definition of the Julia setΩ coincides with the Julia of a polynomial as the boundary of the attracting basin of$\infty$. Compare also with figure 2, where the attracting basins ofof such completely invariant sets.(Q3()c)0 and (Ac)0(. nfty ) are examples• The Julia set is either connected or consists of un- countably many connected components. An exam-ple of the latter is shown in figure 6. •The Julia set is typically a fractal: when one zooms in on it, one finds that the complication of the setis repeated at all scales. It is also self-similar, in the following sense:
for any noncritical pointz in the Julia set, any sufficiently small neighborhood ofz is mapped bijectively onto F(Uz), a neighbor-Uz hood ofin F(U )F(z)look alike.. The Julia set in Uz and the Julia setz

All but the last two properties can easily be verified in the example are 0 and. nfty. Q0. In this case the exceptional points 2.7 Böttcher Maps and Potentials 2.7.1 Böttcher Maps Consider the quadratic polynomial Ifz belongs to the interval [-2,2], then Q - 2(z)z2 belongs to = z2 - 2. the interval val[-2,2]. It follows that this interval is contained in[0, 4], so Q - 2(z) also belongs to the inter- the filled Julia set K-2.

IV. Branches of Mathematics

(a)

$φ −2 \psi −2$

(b)

Figure 5 (a) Some equipotentials and external rays R (θ) of greater than 1. (b) The corresponding equipotentials and Q0 in A0(. nfty ), the set of complex numbers of modulus external rays numbers not in R-(K2)-(θ)=of J-Q-=2 [in-2A,^{-}2^{2}](. The external rays that\infty ), the set of complex are drawn have arguments2 2θ =121 p, where p = 0, 1, . . . , 11. alent to behaves in a similar way, since 2 is small compared The polynomial Q0(w) = Q(w - 2)2, but when(z) is not topologically equiv-z is big enough, it withz2.
We can express this similarity with an appro- priate holomorphic change of variables. Indeed, sup-pose thatz = w + 1/w. Then when w changes to w2, IV.14. Dynamics z changes to w2 + 1/w2. But this equals(w + 1/w)2 - 2 = z2 - 2 = Q-2(z).

The reason this does not show that Q0 and Q-2 are equivalent is that the change of variables cannot beinverted. However, in a suitable region it can. Ifz =wratic equation we find that+ 1/w, then w2 - wz +w1 ==10. Solving this quad-(z ± . qrt{z}2 - 4), which leaves us with the problem of which square root to take. It can be shown that for one choice2|w| < 1 and for the other choice|w| > 1, as long as z does not lie in the interval for which[-|w2,|2]>.
If we always choose the square root1, then it turns out that the resulting function ofphic) from the setz is a continuous function (in fact, holomor - C \ [-2,2] of complex numbers not$in[-2$, 2] to the set {w}:|w| > 1 of complex numbers of modulus greater than 1. ofas the behavior of Once this is established, it follows that the behavior Q-2 on the set CQ\ [-on the set2,2] is topologically the same{w}:$|w| > 1$. In particular, points outside0 C\ [-2,2] have orbits that tend to infinity under iteration by attracting basin A (. nfty ) of Q is QC-\2[.
Therefore, the-2,2], and the filled Julia setto[-2, 2]. (K-2)-and the Julia se(t2)-2 J-2 are both equal which we used to change variables, maps circles of Let us write$ψ^{-2}(w) for w + 1/w$. The function ψ-2, radius greater than 1 onto ellipses, and takes radial lines R (θ) that consists of all complex numbers of some given argument half-branches of hyperbolas. Since the ratio of0θ and modulus greater than 1 toψ^- (w) toasymptote of the corresponding hyperbola half-bra nchw tends to 1 as w →. nfty, each radial line will be the2(see figure 5).
It turns out that what we have just done for the polynomial mial$Q$. That is, for sufficiently large complex numbers Q-2 can be done for any quadratic polyno-c

there is a holomorphic function, denoted the Böttcher map, that changes variables in such a way$φ^{c}$, called that$φ (z)(Q2)c$. (The map turns into ψQ0, in the sense that described above is theφc(Qcin ver se(z)) = of the Böttcher map in the case$c^{-2} c = −2$, rather than the map itself.) After the change of variables, the new coordinates are called Böttcher coordinates.
More generally, for all monic polynomials P (i.e., poly- nomials with leading coefficient 1) there is a unique holomorphic change of variablesφP that converts P into the function sense thatφ (P (z))z \to = zφd (z)for large enoughd, and has the proper tyz, in the PP$503 thatwritten$(φPψ(z)/z)$. \to 1 as z →$. nfty. The inverse of φP is P

2.7.2 Potentials

As we have noted already, if one repeatedly squares a complex number it will escape to infinity. The larger the modulus ofz of modulus greater than 1, thenz, the faster the iterates will tend to infinity. If instead of squaring, one applies a monic polynomial P of degree that the iteratesd, then for large enoughz, P (z)$, P^{2}(z)$, . . . ztend to infinity. Itit is again true follows from the formulaφ (Pk(z)) = φ (z()d)k. Therefore, the speed at whichφP (P (z)) = φP (z)d that the iterates tend to infinity depends not onon P |φ (z)|:
the larger the value of P |φ (z)|, the faster|z| but the convergence. For this reason, the level sets of$P^{P} |φ |$, P

that is, sets of the form${z \in C}$:$|φ (z)| = r$, are P

important.

tion This function is called the For many purposes it is useful to look not at the func-φP itself but at the function potent i alg P (z)$, or=$ Green’s func-$\log |φ^{P} (z)|$. tion. It has the same level sets as|φ (z)|, but has the P

advantage that it is a Clearly, gis defined whenever harmonic functionφis defined. But[IV.24 §5.1](/part-04/stochastic-processes). we can in fact extend the definition ofof the attracting basin$P A (\infty )$. Given any^P g^P to the wholez for which P

the iterates$k$ such that Pφk(z)(Pktend to infinity, one chooses some(z))is defined and one setsg (z) to beφ (Pkd(z))-k . og d, so log|PφP (P|kφ(z))(P|k. Notice that+1(z))| = d . og φP|(Pφk+(P1(z))k(z))P =|, from which it is easy to deduce that the value ofd-P k . og  |φ (Pk(z))| does not depend on the choic(e P)PP

of The level sets ofk. g are called equipotentials. Notice P

that the equipotential of potentialby P onto the equipotential of potentialg P (z)gis mapped(P (z)) =Pdg (z). As we shall see, useful information about the P

dynamics of the polynomial P can be deduced from information about its equipotentials. Ifψis defined every where on the circle C of radius|φ (z)P| =r, for somer, which is the equipotential of poten - r > 1, then it maps it tor{z}: P

tial logr . For large enough r , this equipotential is a simple closed curve encircling decreases. It is possible for two parts of this curve to$K^{P}$, and it shrinks as r come together so that it forms a figure-of-eight shape and then splits into two, like an amoeba dividing, but this can happen only if the curve crosses a critical point of P . Therefore, if all the critical points of P belong to

504

Figure 6 The Julia set of a quadratic polynomial$Qc$

for which the critical point 0 escapes to infinity under iteration. The Julia set is totally disconnected. The figure-of-eight-shaped curve with 0 at its intersection point is the equipotential through 0. The simple closed curve surrounding it is the equipotential through the critical valuec. the filled Julia set0$\in K = [-2$, 2]), then it cannot happen. In this case, KP (as in the example Q-2, where the Böttcher map-2 φcan be defined on the whole of the

P

attracting basin to the attracting basin AP (. nfty ), and it is a bijection from A (. nfty ) = {w \in  C}:|w| >A1 P (. nfty of) the polynomial tial t for every zt >d. There are equipotentials of poten-0 and they are all simple closed0 curves. (Compare with figure 5.) As t approaches 0, the equipotential of potential forms a shape that gets closer and closer to the filledt, together with its interior, Julia set$KP$. It follows that KP is a connected set, as is the Julia set On the other hand, if at least one of the critical points$J^{P}$.
in the plane belongs to$A (\infty )$, then at a certain point P

the image of ticular, the equipotential containing the fastest escap-Cr splits into two or more pieces. In par- ing critical point (i.e., the critical point with the high-est value of the potentialg P ) has at least two loops, as is illustrated in figure 6. The inside of each loop is mapped by P onto the inside of the equipotential of the corresponding critical value, which is a simple closed curve (since the potential of the critical value is greater than the potential of any critical point). Inside each loop there must be points from the filled Julia setset must be disconnected.
The Böttcher map can always$K^{P}$, so this be defined on the out side of the equipotential of the fastest escaping critical point and can therefore always be applied to the fastest escaping critical value. to infinity under iteration, then the filled Julia set turns If Qc is a quadratic polynomial for which 0 escapes

IV. Branches of Mathematics

out to beconnected components of totally disconnected K are points. None of these, which means that thec

points is isolated: they can all be obtained as limits ofsequences of other points of$Kc$. A set which is compact, totally disconnected, and with no isolated points is called a cantor set [III.17](/part-03/dimension), since such a set is homeomorphic to Cantor’s middle-thirds set. Note that in this case$K = J$. For Qwe have the following dichotomy: the Julia setcc J is connected if 0 has a bounded orbit, cc

and it is totally disconnected if 0 escapes to infin-ity under iteration. We shall return to this dichotomy when we come to define the Mandelbrot set later in this article.

2.7.3 External Rays of Polynomials with Connected Julia Set We have just obtained information by looking at the images underψ of circles of radius greater than 1.P

We can obtain complementary information from the images of radial lines, which cut all these circles at right angles. If the Julia set is connected, then, as wesaw in the discussion of potentials, the Böttcher map φthe attracting basin of P is a bijection from the attracting basinzd, which is the complement AP (. nfty ) to{Rw(θ)}:|wde note the half-line that consists of all complex| > 1 of the closed unit disk. As before, let numbers of argument Because0(φ (z)/z) \to  1 asθ and modulus greater than 1.z → $\infty$, the image of R (θ) underψis a half-infinite curve consisting of points$P^{0}P$

with arguments getting closer and closer to curve is denoted by R (θ), and is known as the externalθ. This P

ray of argument ray of argumentθθ ofof Pz. Note thatd. R0(θ) is the external the potential function, and of external rays as the lines One can think of equipotentials as contour lines of of steepest ascent. Between the two of them, they pro-vide a parametrization of the attracting basin, just as modulus and argument provide a parametrization ofz:$|z| > 1$: if you know the potential at a certain complex number ray it lies on, then you know whatz, and you also know which ex ter nalz is.
More over, a ray of argumentθ is mapped by P onto the ray of argu- ment R (θ)dθ, then, just as, when a num be rzd lies on the half-linez lies on the half-line R (dθ). 0 We say that an external ray lands if0ψ (r e2πiθ) con - P verges to a limit asr & 1. If this happens, then the limit is called the landing point. However, it may happen that the end of the ray oscillates so much that there is a con-tinuum of different limit points. In this case the ray is IV.14. Dynamics nonlanding. It can be shown that all rational rays land.
Since a rational ray is either periodic or pre-periodic under iteration byray must be either a periodic or a pre-periodic point P, the landing point of a rational in the Julia set. Much of the structure of the Julia set can be picked up from knowledge about common landing points. In the example illustrated in figure 2, the closures of the three Fatou components containing the critical orbit have one point in common. This point is a repelling fixed point and the common landing point of the rays of argument 1, 2, 4 .
The rays of argument 17 and 27 are adjacent to the Fatou component contain - 7 7 7 ing the critical valuec0. These two arguments will show up again in the parameter plane and tell us where$c0 is$ situated. 2.7.4 Local Connectedness In the example illustrated in figure 5 the inverse of the Böttcher map (the function{w}:|w| > 1 of all complex numbersψ-2) is defined on the setw of mod- ulus greater than 1. However, it can be continuously extended to a function defined on the larger setw:|then we havew| ⩾ 1.
If we use the formulaψ (e2^πi^θ ) = 2 cosψ(2-2πθ)(w), which is the = w + 1/w, landing point of the external ray tr ary connected filled Julia set- 2 KR-, we have the fol - 2(θ). For an arbi-P

lowing result of Carathéodory: the inverseψ of the P

Böttcher map has a continuous extension from|w | > 1 to w:|w| ⩾ 1 if and only if K is local lyw:

P

connected. To understand what this means, imagine a set that is shaped like a comb. From any point in this set to any other point there is a continuous path that lies in the set, but it is possible for the two points to be very close and for the shortest path to be very long. This happens, for example, if the two points are the ends of neighboring teeth of the comb. A connected set X is called locally connected if every point has arbi- trarily small connected neighborhoods.
It is possible to build comb-like sets (with infinitely many teeth) that contain points for which all connected neighborhoods have to be large. The filled Julia sets in the examples in figures 2–5 are locally connected, but there are examples of filled Julia sets that are not locally connected. When K is locally connected, then all external rays P

land, and the landing point is a continuous function of the argument. Under these circumstances, we have a natural and useful parametrization of the Julia set$J^{P}$. 505 2.8 The Mandelbrot Set M

We shall now restrict our attention to quadratic poly-nomials of the form Q . These are parametrized by thec

complex numberc, and in this context we shall refer to the complex plane as the We would like to understand the family of dynamical parameter plane, orc-plane. systems that arise when we iterate the polynomials Our goal will be to do this by dividing the$c - \text{plane into} Q^{c}$. regions that correspond to polynomials with qualita-tively the same dynamics. These regions will be separated by their boundaries, which together form the so-called$c$-values: that is, values of bifurcation set.
This consists of “unstable”c for which there are other values arbitrarily nearby that give rise to qualitatively different dynamical behavior. In other words, a parameter bat i on ofc belongs to the bifurcation set if a small pertur-ccan make an important difference to the dynamics. setthe filled Julia set Recall the dichotomy that we stated earlier: the Julia Jc is connected if the critical point 0 belongs to Kc and is totally disconnected if 0 belongs to the attracting basin$A (\infty )$. This dichotomyc

motivates the following definition: the M consists of the c-values for which Jman del brot setis connected.c

That is,

$M = {c \in C | Q^{k}(0) \infty\text{as} k → }$. nfty.c

Since the Julia set represents the chaotic part of the dynamical system given by$Q^{c}$, the dynamical behavior is certainly qualitatively affected by whether to M or not. We have therefore made a start toward ourc belongs goal, but the division of the plane into M and C . \1 is very coarse, and it does not obviously give us the complete understanding we are looking for. ∂Mhas a number of “holes” (in fact, infinitely many). The The important set is in fact not, which is illustrated in figure 7.
Notice that this set M, but its boundary Mandelbrot set itself is obtained by filling in all these holes. More precisely, the complement of. artial M consists of an infinite collection of connected components, of which one, the out side of the set, stretches off to infinity, while all the others are bounded. The “holes” arethe bounded components. set of a polynomial. It is easy to define the filled Julia set, and the Julia set is then defined as its boundary. This definition is similar to the definition of the Julia The Julia set provides a lot of structure in the dynam-ical plane, thez-plane.
The Mandelbrot set is similarly easy to define, and its boundary provides a lot of struc-ture in thec-plane. Remarkably, even though each Julia506 Figure 7 The boundary. artial M of the Mandelbrot set. set concerns just one dynamical system, while the Man-del brot set concerns an entire family of systems, there are close analogies between them, as will become clear. and quadratic polynomials in particular was carried out in the early 1980 s by Adrien Douady and John H.Pioneering work on holomorphic dynamics in general Hubbard.
They introduced the name “Mandelbrot set”and proved several results about it. In particular, they defined a sort of Böttcher map, denoted byΦM, for the Mandelbrot set, which is a map from the complement of the Mandelbrot set to the complement of the closed unit disk. The definition ofΦMis actually quite simple: for each cfor the parameter let ΦM (c) equal φc. However, Douady and Hubbard didc (c), where φc is the Böttcher map more than merely define holomorphic bijection with holomorphic inverse.$Φ^{M}$: they proved that it is a just as we did with the Böttcher map.
For instance, Once we haveΦMwe can make further definitions, we can define a Mandelbrot set by setting potential GG(c)on the complement of the= g (c) = . og  |Φ (c)|. Anset of the form equipotential is then a level set of${c \in C}$:|Φ (c)c| =Φr M (that is, afor some Mr >{c \in 1) and the C}: arg(Φ (c))external ray of argument= 2πθ (that is, the inverse image M θ is the set of a radial line and it is asymptotic to the radial line of argument$MR^{0}(θ))$. The latter is denoted by RθM. The(θ) rational external rays are known to land (see figure 8).
It follows from the above that ast approaches zero, the equipotential of potential ri or, gets closer and closer to Mt, together with its inte-: that is, M is the inter- section of all such sets. Hence, M is a connected, closed, bounded subset of the plane. IV. Branches of Mathematics Figure 8 of arguments Some equipotentials ofθ of periods 1, 2, 3, and 4. In counterclock - M and the external rays wise direction the arguments between 0 and1 , 3 , 4 , 2 , 1 , 6 , 3 , and 7 ;
and symmetrically in clock - 12 are 0, 151 , 152 , wise direction they are 1 rays of argument7 15 15 7 3 151 7 and - 2 are landing at the root point ofθ15 with θ as above. The external the hyperbolic component that hasof the Douady rabbit in figure 2, as its center. The rays of7 7 c0, the parameter value argument copy of$M$shown in figure 9.153 and 154 are landing at the root point of the

2.8.1 J-Stability

As we have mentioned and as figure 7 suggests, the complement of∂Mhas infinitely many connected components. These components are of great dynamical sig-nificance: ifc and c^  are two parameters taken from the same component, then the dynamical systems arising from same. To be precise, they are Qc and Qc^  can be shown to be essentially the J-equivalent, which means that there is a continuous change of variables that con-verts the dynamics on one Julia set to the dynamics on the other.
Ifare parameter value sc belongs to the boundaryc^  arbitrarily close to∂M, then therec for which Qc and Qc^  are not J-equivalent, so ∂Mis the “bifurcation set with respect toon the global structural stability later.$J$-stability.” We shall comment

2.8.2 Hyperbolic Components

From now on, we shall use the word “component” to refer to the holes of the Mandelbrot set—that is, to the bounded components of the complement of∂M.$IV.14. Dynamics$ ction 2.3 that, after a suitable change of variables, one We start by considering the component containing= 0, the central component H0. Recall from sec- can change the polynomial polynomial$Q^{c}$, where the parameters F^λ(z) = . ambda z +. ambda zand2 into thec are related by the equation. ambda has a dynamical meaning: the origin is a fixed point$c = 1 2λ -1 4 λ2$. The parameter$of$ F^. ambda and . ambda is its multiplier.
This knowledge tells us that the corresponding plierλ; we denote the fixed point by$Q^{c}$ has a fixed point of multi-α $. For |λ| < 1 thec$

fixed point is attracting. The unit diskλ:|λ| < 1 corresponds to the central component et erc in H Hto the corresponding parameter0, and the function that takes a param-. ambda in the unit disk is called thebyρH. Thus,0 ρH (c)multiplier mapis the multiplier of the fixed, and is denoted point is a holomorphic isomorphism from(α0)c of the polynomial0 Qc. The multiplier map H to the unitρH 0 disk. As we have just seen, the inverse map is given by$ρ^{-}1 (λ) =1λ -1λ2$. This map extends continuously to0(H2)4

the unit circle, and there by gives us a parametrization of the boundary of the central component H by points. ambda mapof modulus 1. The image of the unit circle under theλ \to 1 λ-1λ2 is a cardioid. This explains the heart-0 like shape of the largest part of the Mandelbrot set, which can be seen in figure 7.2 4 count with multiplicity (in fact, two distinct ones unlessc =Any quadratic polynomial has two fixed points if we1 ). The central component H is characterized as the component ofing fixed point. For any4 c-values for whichc out side the cardioid,0 Qc has an attract-Q hasc

two repelling fixed points, but it may have an attracting periodic orbit of a period greater than 1. It is an important fact that the attracting basin of an attracting peri-odic orbit always contains a critical orbit. Therefore, for any quadratic polynomial there can be at most one attracting periodic orbit. hyperbolic component the polynomial We call a component Qc has an attracting periodic orbit. Forif, for every parameter H of the Mandelbrot set ac in H , any given hyperbolic component, the periods of the attracting periodic orbits will be the same.
There is a corresponding multiplier map unit disk, which assigns to each parameterρH, fromc Hin Hto thethe multiplier of the attracting periodic orbit. This multi-plier map is always a holomorphic isomorphism that extends continuously to the boundary The pointsρ-1(0) and ρ-1(1) are called the. artial H of Hcen ter. and thefor which the periodic orbit ofroot of HH.
The center of H HQc is the unique is super - attracting.c in H 507 As for the root, if the period of the component isthen it will be the landing point for a pair of externalk, rays of periodic arguments of period component H there is only one ray assigned.) Con - k. (For the central versely, every external ray with such an argument lands at the root point of a hyperbolic component of period0 k. Thus, the arguments of these rays give addresses to the hyperbolic components. This can be seen in figure 8, from which one can read off the mutual positions of allthe components of periods 1–4.
bolic components corresponding to a certain period can be determined both as the number of roots in the As a consequence of the above, the number of hyper - k polynomial< k and also as the number of pairs of rational(Qk)c(0) that are not roots in Qc(0) for some arguments with denominator 2 k - 1 that cannot be expressed with denominator 2 For any component H with center- 1 for somec let R  < k(θ ).and R^M (θ^+) be the pair of rays landing at the root point.^0^M^- Then, in the dynamical plane of$Q^{c}$, the pair of rays (Rc)0(θ^-) and (Rc)0 (θ^+) are adjacent to the Fatou com- ponent of point
of
that Fatou component.(Qc)0 containing c0, and they land at the root

2.8.3 Structural Stability

Suppose thatof perio dk, and let Qc has a super-attracting periodic orbitz0 be a point in this orbit. Then Qlows from the chain rule that there is at least on(ek)c (z0) = z0, and the derivative of (Qc)k at z0 is 0. It fol-zi

in the orbit at which the derivative of$Q$is 0: that is,

$c$

0 belongs to the orbit. Therefore, the center of a hyperbolic component cannot be structurally stable, since the critical orbit of the center-polynomial is finite, but it is infinite for all nearby polynomials. However, if were move from the complex plane not just∂M but also all the centers of hyperbolic components, then we obtain the splitting we have been looking for: any connected component of the remaining set forms a structurally stable region.
For any pair of parameter values c and c in such a component, ing that there is a continuous change of variables in$Q^{c} and Q^{c} \text{are conjugate}$, mean- the plane that converts the dynamics of one polynomial into those of the other.

2.8.4 Conjectures

The above discussion raises an obvious question: we have a good understanding of the hyperbolic com-pone nts of the complement of∂M , but are there components that are not hyperbolic? The following

508

conjecture expresses a widely held belief, but it is asyet unproved. The hyperbolicity conjecture.pone nts of the complement of∂MAll the bounded com-are hyperbolic. generality for rational functions, where it says that every rational function can be approximated arbitrarily The hyperbolicity conjecture can be stated in greater closely by abolic” means that the dynamics is expanding on the hyperbolic rational function. Here, “hyper Julia set. We shall not go further into this, but only mention that the dynamics on the Julia set is expanding for every Q with c in a hyperbolic component of M, c

and also in the unbounded component, the comple-ment of M . The Julia set Jc can in these cases be thought of as a “strange repeller”: the dynamics is chaotic andthe geometry is fractal (except for$c = 0)$. The main conjecture about the Mandelbrot set is, however, the following. The local connectivity conjecture.set is locally connected. The Mandelbrot tant for many reasons. To begin with, it is known thatit implies the hyperbolicity conjecture.
Second, if This conjecture, often referred to as MLC, is impor-M is locally connected, thena holomorphic bijection from the set out side the closed$Ψ^{M}$, the inverse of ΦM, which is unit disk to the complement of the Mandelbrot set, hasa continuous extension to the unit circle, and all external rays land in a continuous manner. This would give us a useful parametrization ofa beautifully simple abstract combinatorial description∂M .
One can then give of(Mitsuhiro Shishikura has proved that the M, despite the fact that ∂M is a complicated fractal.hausdorff dimension [III.17](/part-03/dimension) of∂M is the maximum possible in the plane, namely 2.)

2.9 Universality of$M$

The Mandelbrot set is remarkably ubiquitous. For example, homeomorphic copies of itself, as is apparent from figure 9. Inside other fam-M appear inside M ilies of holomorphic mappings that depend holomor-ph ically on some parameter, we again find homeomorphic copies of M . For this reason, M is said to be universal son behind the phenomenon of universality by defin-. Douady and Hubbard have captured the reaing a notion of aate of a quadratic polynomial is globally a polynomial quadratic-like mapping. Thekth iter-

IV. Branches of Mathematics

Figure 9 given by the arguments of the two external rays that+ land A copy of M within M. The address of the copy is at the cusp, the root point of the copy. Here the arguments are 3 and 4 . Compare with figure 8. The rays are drawn to indicate where the “decorations” should be cut off in order to have the bare copy of15 15 M. of degree 2 k, but locally it may behave like a quad- ratic polynomial. The same is true for a rational function or an iterate of it.
By a quadratic-like mapping wemean a triple(f , V , W ) where V and W are open sim- ply connected domains (that is, connected open sets with out holes),  ̄V ⊂ W , and f is a holomorphic map that maps V onto W with degree 2. (This means that every point inity, in V .) Such a map W has two preimages, up to multiplic-f has a single critical point ω in V , and behaves in many ways like a quadratic poly- nomial. The filled Julia set Kis defined as the set of

f

point sz in V for which the iterates fk(z) stay in V for$all$ k ⩾ 0. A dichotomy similar to the one for quadratic polynomials holds for quadratic-like mappings as well: K is connected if and only if the critical point ω isf

contained in K . For any quadratic-like mapping with af

connected filled Julia set, Douady and Hubbard have defined a strategy, called straightening, which associates with the mapping a unique family of quadratic-like mappings{cf-value in} the Mandel-M. For a brot set MΛis defined as the set ofλ. ambda for whichλ\inΛ (Kf). ambda is connected. We obtain through straightening a mappingΞ: M \to  M, which takes . ambda to the uniquely associatedc-value.Λ

IV.14. Dynamics

associated with In the copy of$c M = 0 in$ shown in figure 9, the “center”M corresponds to a polyno- mial Qc for which the critical point 0 is periodic of period 4, and for which a suitable restriction of the fourth it era tef = Q4 is quadratic-like from V to its image of$c \text{in theW}^{0}$. More over, there is a neighborhoodc-plane such that for an(yc)0 c 0 c in V0 the V0 restriction of0 fc = (Q4)c to V0 is a quadratic-like map0 from homeomorphism from V0 to its image Wc M, and such that the map V to M .
Ξ is a Mh owe ver, there is another phenomenon that pulls in The infinitely many copies ofmay suggest that M has a self-similarity property. M that appear inside the opposite direction. The ical point 0 is pre-periodic form a dense subset ofc-values for which the crit-∂M. If  ̃c is one of these special c-values, then there are two contexts in which one may look at magnifications of smaller and smaller neighborhoods of  ̃$c$: the first is the Julia set$z = c$ ̃, and the second is the Mandelbrot set in neighbor-Jc^ ̃ of the polynomial Q^ ̃c in neighborhoods of hoods of$c = c$ ̃.
It turns out that the pictures are asymptotically similar, which means that the greater the magnification, and the smaller the neighborhood, the more similar the two pictures become. seem to be impossible, since in any neighborhood of$c$ ̃ This is an extraordinary fact. Indeed, it may even the Mandelbrot set contains infinitely many copies of itself, while the Julia set is known to contain nosuch copies.
The explanation for the apparent paradox is that the copies of the Mandelbrot set get smaller very quickly as their distance to  ̃one magnifies a small enough neighborhood, the copiesc decreases. Hence, if that are there are practically invisible.

2.10 Newton’s Method Revisited

Let us return briefly to Newton’s method for polyno-mials. Consider any polynomial P of degree d ⩾ 2 that has only simple roots. Then the Newton function a rational function of deg reed, and each simple root of NP is Pis a super-attracting fixed point of N . For quadratic P

polynomials the number of roots ofthe number of critical points of$N (since 2P \text{coincides withd} - 2 = 2P$

whend = 2). For polynomials of degree d > 2 there are more critical points than the roots can account for. polynomials with two distinct roots r Cayley considered Newton’s method for quadratic). He showed that the function \mu(z)P (z)==(z(z--r r)/(z1)(z--ront(o2)2), which maps the root. nfty , provides a change of variables that turnsr1 onto 0 and the root1 r2$509$ Nsphere ˆP into the quadratic polynomial C.
When one translates the dynamics of Q0 on the Riemann Q to the dynamics of Newton’s method one finds that the unit circle corresponds to the bisector ofr1 and (r2)0 and that all points in the half-plane containing$r$, i = 1,2, i are therefore attracted tori under iteration by NP. Cayley announced that he would write about Newton’s iteration for cubic polynomials. However, it took about a hundred years before any such paper appeared. For a cubic polynomial Newton function$N$has three super-attracting fixed P with three simple roots the P

points, each of which gives rise to an attracting basin. The Julia set of NP is the common boundary of these three basins, and is therefore a complicated fractal set. More over, N has an extra critical point since 2 d-2 = 4 P$for$ d = 3. The extra critical point may be attracted to one of the roots under iteration, or it can have its own independent behavior.
In order to catch the behavior of all cubic polynomials under Newton’s iteration (except the one with one root of multiplicity three) it is sufficient to consider the one-parameter family of polyno-mials$P (z) = (z - 1)(z - {}^{1} - λ)(z - {}^{1} + λ)$. The extra critical point for the corresponding Newton function N then turns out to be at the origin. Suppose that w(eλ()2)2 associate three colors, for instance red, blue, and green, with the three roots 1,λ1 +λ,1 -λ. We can then color the. ambda as follows.
A parameter value-plane, which is the parameter plane in this context,2 2 . ambda is colored red, blue, or green if the critical point 0 is attracted under iteration byany of the three roots, then we color with a fourth color, N. ambda to the root of that color. If it is not attracted to yellow, say. The universality of the Mandelbrot set is there by demonstrated:
in the yellow copies of it, which one can explain by showingλ-plane one can observe that families of suitably restricted iterates ofquadratic-like. N\lambda are 3 Concluding Remarks We have illustrated several results in holomorphic dy-namics through examples, including the transferring of definitions and results from the dynamical planes to the parameter plane. The structures of the filled Julia sets and the Mandelbrot set are partly under-stood through analysis of their complements, linked together via the Böttcher maps tions that are used for changing variables in$φ^{c} and Φ^{M}$.
The func-J-stability and structural stability are examples of so-called quasiconformal mappings duced into holomorphic dynamics in the early 1980 s by. This is a concept that was intro-

510

Dennis Sullivan. They are indispensable for discussing change of complex structure, straightening, holomorphic motion, surgery, and many other phenomena. The interested reader is referred to the books listed below. The first two contain expository papers, the third is a graduate textbook, and the fourth is a collection of papers. They all contain many further references. Acknowledgments.cle were obtained from a program written by Christian The computer drawings in this arti Henriksen.

Further Reading

Devaney, R. L., and L. Keen, eds. 1989.tals. The Mathematics Behind the Computer Graphics Chaos and Frac-. Proceedings of Symposia in Applied Mathematics, volume 39.Providence, RI: American Mathematical Society. Behind the Mandelbrot and Julia Sets posi a in Applied Mathematics, volume 49. Providence, RI:. 1994. Complex Dynamical Systems. The Mathematics. Proceedings of Sym Lei, T., ed. 2000.American Mathematical Society.tions. London Mathematical Society Lecture Note Series, The Mandelbrot Set, Theme and Varia Milnor, J. 1999.volume 274. Cambridge: Cambridge University Press.baden:
Vieweg. Dynamics in One Complex Variable. Weis IV.15 Operator Algebras Nigel Higson and John Roe 1 The Beginnings of Operator Theory We can ask two basic questions about any equation, or system of equations: is there a solution, and, if there is, is it unique? Experience with finite systems of linear equations indicates that the two questions are interconnected. Consider for instance the equations 2$x + 3y - 5z = a$, x - 2 y + z = b,$3$ x + y - 4 z = c.

Notice that the left-hand side of the third equation isthe sum of the left-hand sides of the first two. As a result, no solution to the system exists unless But ifa + b = c, then any solution of the first two$a + b = c$. equations is also a solution of the third; and in any linear system involving more unknowns than equations, solutions, when they exist, are never unique. Inthe present case, if(x, y, z) is a solution, then so is(x + t, y + t, z + t), for any t. Thus the same phe- nomenon (a linear relation among the equations) that

IV. Branches of Mathematics

prevents the system from admitting solutions in some cases also prevents solutions from being unique in other cases. ness of solutions more precise, consider a general system of linear equations of the form To make the relation between existence and uniquek11 u1 + k12 u2 + · · · + (k1)nun = f1, k21 u1 + k22 u2 + · · · + (k2)nun = f2, .. . (kn)1 u1 + (kn)2 u2 + · · · + knnun = fn consisting ofn equations in n unknowns. The sc al a rsk solve for the ji form a matrix of coefficients and the problem is tou in terms of the f .
The general theorem illustrated by our particular numerical example above is that the number of linear conditions that the$i^{j} f mustj$

satisfy if a solution is to exist is equal to the number ofarbitrary constants appearing in the general solution when a solution does exist. To use a more technical vocabulary, the dimension of the kernel [I.3 §4.1](/part-01/fundamental-definitions) of the matrix cokernel. In the example, these numbers are both 1.K = {kji} is equal to the dimension of its [VI.66](/part-06/ivar-fredholm-18661927) made a study of A little more than a hundred years ago, integral equations of the type fredholm

 u(y) - k(y$, x)u(x) dx = f (y)$.

These arose from questions in theoretical physics, andthe problem was to solve for the functionu in terms of the function limit of finite sums, Fredholm’s equation is an infinite-f . Since an integral can be thought of as a dimensional counterpart of the finite-dimensional lin-ear systems considered above, in which vectors with nat infinitely many different points components are replaced by functions with value sx. (Strictly speaking, Fredholm’s equation is analogous to a matrix equationof the typeu-Ku = f rather than Ku = f .
The altered form of the left-hand side has no effect on the over all behavior of the matrix equation, but it does considerably alter the behavior of the integral equation. As we shall see, Fredholm was fortunate to work with a class of equations whose behavior mirrors that of matrix equations very closely.) A very simple example is

$u(y) - {}^{01} u(x) dx = f (y)$.

To solve this equation, it helps to observe that the quan-1 tityis a constant0 u(x) d. Thus in the homogeneous case (x, when thought of as a function off ≡ 0), y ,

IV.15. Operator Algebras

the only possible solutions for functions. On the other hand, for a general functionu(y) are the constant fdit i on, solutions exist if and only if the single linear con-1 f (y) dy =0 is satisfied. So in this example the dimension of the kernel and the dimension of the0 cokernel are both 1. Fredholm set out on a systematic exploration of the analogy between matrix theory and integral equations that this example suggests. He was able to prove that, for equations of his type, the dimen-sions of the kernel and of the cokernel are always finite and equal.
[VI.63](/part-06/david-hilbert-18621943), who made a detailed study of the Fredholm’s work sparked the imagination of hilbert integral operatorsin the special case where the real-valued function that transformu(y) into k(y, x)u(x) dxk, is symmetric, meaning thatk(x$, y) = k(y, x)$. The finite-dimensional counterpart of Hilbert’s theory is the theory of real symmetric matrices.
Now if K is such a matrix, then a standard result from linear algebra asserts that there is an orthonormal basis consisting of eigenvectors [I.3 §4.3](/part-01/fundamental-definitions) for K, or equivalently that there is a unitary matrix U such that U-1 T U is diago- nal. (the lengths of vectors: Unitary means that Uv U is invertible and preserves = v for all vectors v.) Hilbert obtained an analogous theory for all symmetric integral operators. He showed that there exist func-tions$u1(y)$, u2(y), . . . and real numbers λ1, λ2, . . . such that k(y, x)un(x) dx = . ambda nun(y).

Thus tor, with eigenvalue un(y) is an eigenfunctionλ . for the integral opera- explicitly, but calculationφ(x In most cases it is hard to calculate- y) for some periodic functionn is possible whenφ. If the ran geu nk(x, y)and λ=n of integration isthe eigenfunctions are cos[0,1] and the period of(2 kπy), k = 0,φ1,2 is 1, then, . . . , and. in (2 kπy), k = 1, 2, . . . .
In this case, the theory of fourier seriesf (y) on [0, 1] can be expanded as the sum of a series[III.27](/part-03/the-fourier-transform) tells us that a general function Hilbert showed that, in general, there is an analogous expansion(ak cos 2 kπy + bk sin 2 kπy) of cosines and sines.f (y) = anun(y)

in terms of the eigenfunctions for gral operator. In other words, the eigenfunctions form any symmetric intea basis, just as in the finite-dimensional case. Hilbert’s result is now called the integral operators. spectral theorem for symmetric

511

1.1 From Integral Equations to Functional Analysis Hilbert’s spectral theorem led to an explosion of activ-ity, since integral operators arise in many different areas of mathematics (including, for example, the dirichlet problem equations and the representation theory of com-[IV.12 §1](/part-04/analysis) in partial differential pact groups [IV.9 §3](/part-04/representation-theory)). It was soon recognized that these operators are best viewed as linear transforma-tions on the hilbert space [III.37](/part-03/bayesian-analysis) of all functionsu(y) such that|u(y)|2 dy < . nfty .
Such functions are called square-integrable denoted L2[0, 1]. , and the collection of all of them is able, it became convenient to examine a much broader With the important concept of Hilbert space avail range of operators than the integral operators ini-tially considered by Fredholm and Hilbert. Since Hilbert spaces are[III.56](/part-03/metric-spaces), it made sense to look first at operators from a vector spaces [I.3 §2.3](/part-01/fundamental-definitions) and metric spaces Hilbert space to itself that are both linear and continu-ous: these are usually called bounded linear operators.
The analogue of the symmetry conditionk(x, y) =k(y, x)bounded linear operatoron integral operators is the condition that a T be self-adjoint, which is to say that T u, v = u, T v for all vectors u and v in the Hilbert space (the angle brackets denote the inner product). A simple example of a self-adjoint operator is the multiplication operator by a real-valued function m(y)(Mu)(y); this is the operator$= m(y)u(y)$.
(The finite-dimensional coun-Mdefined by the formula ter part to a multiplication operator is a diagonal matrix Kthe matrix entry, which multiplies thekjj.) jth component of the vector by operators tells us that every such operator can be givena particularly nice form: with respect to a suitable Hilbert’s spectral theorem for symmetric integral “basis” of L2[0, 1], namely a basis of eigenfunctions, it will have an infinite diagonal matrix. More over, the basis vectors can be chosen to be orthogonal to each other. For a general self-adjoint operator, this is not true.
Consider, for instance, the multiplication operator from L2[0, 1] to itself that takes each square-integrable function has no eigenvector su(y) to the function[I.3 §4.3](/part - 01/fundamental - definitions), since ifyu(y). This operator. ambda is an eigen- value every y[I.3 §4.3](/part-01/fundamental-definitions), then we need, which implies thatu(y)yu(y)= 0 for every= . ambda u(y)y notfor equal toλ, and hence that |u(y)|2 dy = 0.
However, this example is not particularly worrying, since a multiplication operator of this kind is a sort of continuous analogue of the operator defined by a diagonal matrix.

512

It turns out that if we enlarge our concept of “diagonal”to include multiplication operators, then all self-adjoint operators are “diagonalizable,” in the sense that, after a suitable “change of basis,” they become multiplication operators. of theof complex numbers To make this statement precise, we need the notion spectrum [III.86](/part-03/the-spectrum) of an operator. ambda for which the operator T. This is the set T - . ambda I does not have a bounded inverse (here I is the iden- tity operator on Hilbert space).
In finite dimensions the spectrum is precisely the set of eigenvalues, but in infinite dimensions this is not always so. Indeed, where as every symmetric matrix has at least one eigenvalue, a self-adjoint operator, as we have just seen, need not. As a result of this, the spectral theorem for bounded self-adjoint operators is phrased not in terms of eigen-values but in terms of the spectrum.
One way of formulating it is to state that any self-adjoint operator T is unitarily equivalent to a multiplication operator(Mu)(y) = m(y)u(y), where the closure of the range of the functionm(y) is the spectrum of T. Just as in the finite-dimensional case, aible operator U that preserves the lengths of vectors. To unitary operator is an invert- say that there is some unitary map T and M are unitarily equivalent is to say that U, which we can think of as an analogue of a change-of-basis matrix, such that$U^{-1MU}$.
This generalizes the statement that any real T = symmetric matrix is unitarily equivalent to a diagonal matrix with the eigenvalues along the diagonal.

1.2 The Mean Ergodic Theorem

A beautiful application of the spectral theorem was found by von neumann [VI.91](/part-06/john-von-neumann-19031957). Imagine a checkerboard on which are distributed a certain number ofcheckers. Imagine that for each square there is designated a “success or” square (in such a way that notwo squares have the same success or), and that every minute the checkers are rearranged by moving each oneto its success or square. Now focus attention on a single square and each minute record with a 1 or 0 whether or not there is a piece on the square. This produces a succession of readings R1$, R2$, R3, . .
.like this: 00100110010110100100· · · . We might expect that over time, the average number of positive readings R = 1 will converge to the num-j

ber of pieces on the board divided by the number of squares. If the rearrangement rule is not complicated enough, then this will not happen. For example, in the most extreme case, if the rule designates each square

IV. Branches of Mathematics

as its own success or, then the read out will be either00000· · · or 111111 · · · , depending on whether or not we chose a square with a piece on it to begin with. But ifthe rule is sufficiently complicated, then the “time average”ber of pieces on the board divided by the number of(1/n()n)j=1 Rj will indeed converge to the num- squares, as expected. fact the only “sufficiently complicated” rules in this finite case are cyclic permutations of the squares of the The checkerboard example is elementary, since in board, and thus vation post in succession.
However, there are related all the squares move past our obs er examples where one observes only a small fraction ofthe data. For instance, replace the set of squares on a checkerboard with the set of points on a circle, and in place of the checkers, imagine that a subset S of a cir- cle is marked as occupied. Let the rearrangement rulebe the rotation of points on the circle through some irrational number of degrees.
Stationed at a point the circle, we record whe the rx belongs to S, the firstx of rotated copy ofso on to obtain a sequence of 0 or 1 readings as before. S, the second rotated copy of S, and One can show that (for nearly every of our observations will converge to the proportion ofx) the time average the circle occupied by Similar questions about the relationship between S.
time and space averages had arisen in thermodynamics and elsewhere, and the expectation that time and space averages should agree when the rearrangement ruleis sufficiently complex became known as the ergodic hypothesis Von Neumann brought operator theory to bear on. this question in the following way. Let H be the Hilbert space of functions on the squares of the checkerboard, or the Hilbert space of square-integrable functions on the circle. The rearrangement rule gives rise to a unitary operator U on H by means of the formula(Uf )(y) = f (φ-1(y)),

where Von Neumann’s ergodic theorem asserts that if no non-φ is the function describing the rearrangement. constant function inof saying that the rearrangement rule is “sufficiently His fixed by U (this is one way complicated”), then, for every functionf \in H, the limitn . im→. nfty n(1 j)n = 1 Ujf exists and is equal to the constant function whose value every where is the average value off . (To apply this to our examples, take the pointx is occupied and 0 otherwise.)f (x) to be the function that is 1 if IV.15.
Operator Algebras tral theorem for unitary operators that is analogous to Von Neumann’s theorem can be deduced from a spec the spectral theorem for self-adjoint operators. every unitary operator can be reduced to a multiplication operator, not by real-valued functions but by functions whose values are complex numbers of absolute value 1.The key to the proof then becomes a statement about complex numbers of absolute value 1: ifz is such a complex number, different from 1, then the expression(1/n)n zj approaches zero as n → . nfty.
This in turn is easily proved using the formula for the sum of a geo-metric series,$j = 1 n zj = z(1 - zn)/(1 - z)$. (More detail can be found injergodic theorems = 1 [V.9](/part - 05/ergodic - theorems).) 1.3 Operators and Quantum Theory Von Neumann realized that Hilbert spaces and their operators provide the correct mathematical tools to formalize the laws of quantum mechanics, introduced in the 1920 s by Heisenberg and Schrödinger. is the list of all the information needed to determine The state of a physical system at any given instant its future behavior.
If, for instance, the system con-sists of a finite number of particles, then classically its state consists of the list of the position and momentum vectors of all the constituent particles. By contrast, in von Neumann’s formulation of quantum mechanics one associates with each physical system a Hilbert space unit vector H, and a state of the system is represented by au in H.
(If u and v are unit vectors and v is a scalar multiple ofu, then u and v determine the same state.) the total energy of the system, or the momentum of one particle within the system) is a self-adjoint operator Associated with each observable quantity (perhaps Q on H whose spectrum is the set of all observed values of that quantity (hence the origin of the term “spec - trum”). States and observables are related as follows:
when a system is in the state described by a unit vectoru \in  H , the expected value of the observable quantity corresponding to a given self-adjoint operator inner product Qu, u . This may not be a value that Q is the is ever actually measured: rather, it is the average of values that are obtained from many repeated experiments with the system when it is in the given stateu. The relation between states and observables reflects the paradoxical behavior of quantum mechanics:
it is possible, and in fact typical, for a system to exist in a “superposed” state, under which repeated identical experiments produce distinct out comes. A measure-

513

ment of an observable quantity will produce a deter-minate out come if and only if the state of the system is an eigenvector for the operator associated with that quantity. operators associated with different observables typi-cally do not commute with one another. If two oper-A distinctive feature of quantum theory is that the ators do not commute, then they will typically have no eigenvectors in common, and, as a result, simultaneous measurements of two different observables will typi-cally not result in determinate values for both of them.
A famous example is provided by the operators Q associated with the position and momentum of a par-P and ticle moving along a line. They satisfy the commutation relation Heisenberg

$QP - P Q = i I$,

where stance of a general principle which relates the non-is a certain physical constant. (This is an in commutativity of observables in quantum mechanicsto the Poisson bracket of the corresponding observables in classical mechanics: see [[IV.16 §§2.1.3, 2.2.1]](/part-04/mirror-symmetry).) As a result, it is impossible for the mirror symmetry particle simultaneously to have a determinate momen-tum and position. This is the uncertainty principle. way of representing the Heisenberg commutation rela-tion using self-adjoint operators on Hilbert space:
the It turns out that there is an essentially unique Hilbert space-i d/dx; and the operator H must be L2(RQ); the operator must be multiplication P must be bythe observable operators for simple physical systems.x. This theorem allows one to determine explicitly For example, in a system consisting of a particle on aline subject to a force directed toward the origin which is proportional to the distance from the origin (as ifthe particle were attached to a spring, anchored at the origin), the operator for total energy is

E = − 2 m2 dd(x2)2 + k2 x2,

where strength of the force. The spectrum of this operatork is a constant which determines the over all is the set {(n + 1 2 ) (k/m)1/2}:$n = 0$,1,2, . . . . These are therefore the possible values for the total energy of the system. Notice that the energy can assume only a discrete set of values. This is another characteristic and fundamental feature of quantum theory. energy for the hydrogen atom. Like the operator above, Another important example is the operator of total

514

this may be realized as a certain explicit partial dif-ferential operator. It can be shown that the eigenvalues of this operator form a sequence proportional to$\\{−1}$, -1\\\\\\\\\\\\\\\\\\\}, -1, . . . . A hydrogen atom, when disturbed, may release a photon, resulting in a drop in its total4 9 energy. The released photon will have energy equal tothe difference between the energies of the initial and final states of the atom, and therefore it is propor-tional to a number of the form 1/n2 - 1/m2.
When light from hydrogen is passed through a prism or diffraction grating, bright lines are indeed observed at wavelengths corresponding to these possible energies. Spectral observations of this sort provide experimental confirmation for quantum mechanical predictions. So far we have discussed states of a quantum system only at a single instant. However, quantum systems evolve in time, just as classical systems do: to describe this evolution we need a law of motion. The time evo-lution of a quantum system is represented by a family of unitary operators$U$: H \to H, parametrized by thet

real numbers. If the system is in an initial state will be in the state Ut u after t units of time. Bec au seu, it the passage of units is the same as the passage ofs units of time followed bys + t units, the uni-t further tary operators An important theorem of Marshall Stone asserts that Ut satisfy the group law Us Ut = (Us)+t. there is a one-to-one correspondence between unitary groups{U } and self-adjoint operators E given by thet

formula

i E = dd U(tt)t=0 = . imt\to0 1 t (Ut - I). The quantum law of motion is that the responding in this way to time evolution is the opera-generator E cor- tor associated with the observable “total energy.” When$E$is realized as a differential operator on a Hilbert space of functions (as in the examples above), this state-ment becomes a differential equation, the Schrödinger equation.

1.4 The GNS Construction

The time-evolution operators satisfy the law U U = U. More generally, we define$U^{t} \text{of quantum mechanics}$ a family of unitary operators unitary representation(st)sof a+t Ugroup, one for each[I.3 §2.1](/part-01/fundamental-definitions)g G \in to be a G, sat- i sfy ing the law(Ug()1()g)2 = (Ug)1(Ug()g)2 for all g1, g2 \in  G.
Origi- nally introduced by study of finite groups, frobenius representation theory[VI.58](/part-06/ferdinand-georg-frobenius-18491917) as a tool for the[IV.9](/part-04/representation-theory) has become indispensable in mathematics and physics wherever the symmetries of a system must be taken into account.

IV. Branches of Mathematics

then law If UUσis a unitary representation of: g=→ U UUgv, vimplies thatis a function defined onσGhas an important and v is a vector, G. The positivity property, namely(g1)g 2 g 1 g 2(ag)1 (ag)2 σ (g1-1 g2) = ag Ugv2 ⩾ 0, for any scalars having this positivity property is said to beg1\\\{}},\\\\\\\\\\\\\\\\\\\} g2 \in G ag \in C. A function defined onpositive G and definite one can build a unitary representation. This.
Conversely, from a positive-definite function GNS construction and Irving Segal) begins by considering the group ele-(in honor of Israel Gelfand, Mark Naimark, ments themselves as basis vectors in an abstract vector space. We can attempt to define an inner product on this vector space by means of the formula

$g1$, g2 = σ ((g1)-1 g2).

The resulting object may differ from a genuine hilbert space in two respects. First, there may be nonzero vectors whose length, as measured by the inner product, iszero (although the hypothesis thatσis positive definite does rule out the possibility that there might be vectors of negative length). Second, the completeness axiom [III.62](/part - 03/normed - spaces - and - banach - spaces) of Hilbert space theory may not be satisfied. However, there is a “completion” procedure which fixes both these deficiencies.
Applied in the present case, it produces a Hilbert space Hσ that carries a unitary representation of G. areas of mathematics. They have the advantage that the functions on which the constructions are based are Versions of the GNS construction arise in several easy to manipulate. For instance, convex combinations of positive-definite functions are again positive definite, and this allows geometrical methods to be applied to the study of representations.
1.5 Determinants and Traces The original works of Fredholm and Hilbert borrowed heavily from traditional concepts of linear algebra, and in particular the theory ofview of the complicated definition of the determinant determinants [III.15](/part - 03/determinants). In even for finite matrices, it is perhaps not surprising that the infinite-dimensional situation presented extraordinary challenges. Very soon, much simpler alternative approaches were found that avoided determinants altogether.
But it is interesting to note that the determinant, or to be more exact the related notion of the trace, has played an important role in recent developments on which we will report later in this article. IV.15. Operator Algebras The trace of ann . imes n matrix is the sum of its diag- onal entries. As with the determinant, the trace of a matrix A is equal to the trace of BAB - 1 for any invert- ible matrixnant by the formula det B.
In fact, the trace is related to the determi-(. xp (A)) = . xp (tr(A)) (because of the invariance properties of trace and determinant, it is enough to check this for diagonal matrices, where it is easy). In infinite dimensions the trace need not make sense since the sum of the diagonal entries ofan. nfty × . nfty matrix may not converge. (The trace of the identity operator is a case in point:
the diagonal entries are all 1, and if there are infinitely many of them, then their sum is not well-defined.) One way to address this problem is to limit one self to operators for which thesum is well-defined. An operator T is said to be of trace class of pairwise orthogonal vectors of length 1, the sumif, for every two sequencesuj and vj . nfty

operator the sumj = {}1 T uj T, v . nftyhas a well-defined and finite trace, name lyj T uis absolutely convergent. A trace-class, u (which is independent of the choice of orthonormal basis j = {}1 jj {u }).j

Integral operators such as those appearing in Fredholm’s equation provide natural examples of trace-class operators. Ifk(y, x) is a smooth function, then the operator T u(y) = k(y, x)u(x) dx is of trace class, and its trace is equal tok(x, x) dx, which can be regarded as the “sum” of the diagonal elements ofthe “continuous matrix”k. 2 Von Neumann Algebras Theon a Hilbert space commutant of a set H is the collection S of bounded linear operators S^  of all operators oncommutant of any set is an H that commute with every operator in the set algebra of operators on S. The H.
That is, if T T and any linear combination T1 and T2 are in the commutant, then so area T + a T . 1 As mentioned in the previous section, a2 1 1 2 unitary rep-2 re sent at i on le ct i on of unitary operatorsof a group G on a Hilbert space U , labeled by elements of H is a col-G, with the property that for any two group elementsgg A1 von Neumann algebra and g2 the composition is any algebra of operators (Ug)1(Ug)2 is equal to (Ug()1()g)2. on a complex Hilbert spacetant of some unitary representation of a group on H which is the commu-H.
Every von Neumann algebra is closed under adjoints and under limits of nearly every sort. For example, it is closed under pointwise limits: ifoperators in a von Neumann algebra{Tn}Mis a sequence of, and if T v . on T v, for every vector v \in  H, then T \in  M. 515 Mmutant of the commutant of It is easy to check that every von Neumann algebra is equal to its own double commutant M).
Von Neumann proved M^   (the com- that if a self-adjoint algebra under pointwise limits, then MM is equal to the commu-of operators is closed tant of the group of unitary operators in its commutant, and is therefore a von Neumann algebra.

2.1 Decomposing Representations

Leton a Hilbert spaceg \to  U^g be a unitary representation of a group H. If a closed subspace H of HG is mapped into itself by all the operators Ug, then it0 is said to be antion. If H0 is invariant, then since the operators invariant subspace for the representa-Ug map Hre presentation of0 to itself, their restrictions to G, called a subrepresentati on H0 constitute another of the original. A subspace H0 is invariant for a representation, and so determines a subrepresentati on, if and only if the orthogonal projection operator P:$H \to H belongs$ to the commutant of that representation.
This points to a close connection between subrepresentati ons and0 von Neumann algebras. In fact, von Neumann algebra theory can be thought of as the study of the ways in which unitary representations can be decomposed into sub representations. ial invariant subspace. A representation that does havea nontrivial invariant subspace A representation is irreducible H0 if it has no nontriv-can be divided into two subrepresentati ons:
those associated with those associated with its orthogonal complement H0 Hand⊥. Unless both the representations duc i ble, we will be able to divide one or both of them H0 and (H0)⊥ are irre - 0 into still smaller pieces by repeating the process that was just carried out for His finite dimensional, then continuing in this way we H. If the initial Hilbert space will eventually decompose it into irreducible sub re pre-sentations.
In the language of matrices, we will obtain a basis forthe group are simultaneously block diagonal, in such a H with respect to which all the operators in way that each block represents an irreducible group of unitary operators on a smaller Hilbert space. sional Hilbert space into irreducible sub represent a-tions is a bit like decomposing an integer into a prod-Reducing a unitary representation on a finite-di men uct of prime factors. As with prime factorization, the decomposition process for a finite-dimensional unitary representation has only one possible end:
there is, up to ordering, a unique list of irreducible representations into which a given unitary representation decomposes.

516

But in infinite dimensions the decomposition process faces a number of difficulties, the most surprising of which is that there may be two decompositions ofthe same representation into entirely different sets of irreducible subrepresentati ons. In the face of this, a different form of decomposition suggests itself, which is roughly analogous to the factorization of an integer into prime powers instead of individual primes. Let us refer to the prime powers into which an integer is decomposed as its components. They have two characteristic properties:
no two com-pone nts share a common factor, and any two (proper) factors of the same component factor. Similarly, one can decompose a unitary repre-do share a common sentation intogous properties: no two distinct isotypical components isotypical components, which have analoshare a common (meaning isomorphic) subrepresentati on, and any two subrepresentati ons of the same isotypical component have themselves a common subsub representation.
Any unitary representation (finite dimensional or not) can be decomposed into isotypical components, and this decomposition is unique. In finite dimensions, every isotypical representation decomposes into a (finite) number ofducible subrepresentati ons (like the prime factors ofidentical irrea prime power). In infinite dimensions this is not so. In effect, much of von Neumann algebra theory is concerned with analyzing the many possibilities that arise. 2.2 Factors The commutant of an isotypical unitary representation is called a factor.
Concretely, a factor is a von Neumann algebra M that commute with every member of M whose center, the set of all operators in M , consists of nothing more than scalar multiples of the identity oper - ator. This is because projections in the center of M cor- respond to projections onto combinations of i so typical sub representations. Every von Neumann algebra can be uniquely decomposed into factors. A factor is said to be of type I if it arises as the commutant of an isotypical representation that is a multi-ple of a single irreducible representation.
Every type I factor is isomorphic to the algebra of all bounded oper-ators on a Hilbert space. In finite dimensions, every factor is of type I, since as we already noted every isotyp - ical representation decomposes into a multiple of one irreducible representation. The existence of unitary representations with more than one decomposition into irreducible components is IV. Branches of Mathematics related to the existence of factors that are Von Neumann, together with Francis Murray, invest i-not of type I.
gated this possibility in a series of papers that mark the foundation of operator algebra theory. They introduced an order structure on the collection of subrepresentati ons of a given isotypical representation or, toput it in terms of the commutant, on the collection of projections in a given factor. If re sent at i ons of the isotypical representation H0 and H1 are subrep - H, then we write sent at i on of H0 H( . Murray and von Neumann proved that H1 if H0 is isomorphic to a sub re pre- this is a total ordering: either or both, in which case1 H0 and H(H0)1 are isomorphic. For( H1;
or H1 ( H0; example, in a finite-dimensional type I situation, where H is a multiple of n copies of a single irreducible repre- sentation, each subrepresentati on is the sum ofm ⩽ n copies of the irreducible representation, and the order structure of the (isomorphism classes of) subrepresentati ons is the same as the order structure of the integers$\\{0}$,1, . . . , n\\\\\\\\\\\\\\\\\\\\\}. structures that can arise from factors are the following very simple ones: Murray and von Neumann showed that the only order Type I,$\\{0}$, 1,2, . . .
, n\\\\\\\\\\\\\\\\\\\\\} or \\\\\\\\\\\\\\\\\\\\\{0, 1, 2, . . . , \\\\\\\\\\\\\\\\\\\\\}$\infty$; Type II,[0, 1] or [0,. nfty ]; Type III,$\\{0}$,\\\\\\\\\}$\infty$. the structure of its projections according to this table.type of a factor is determined from the order is that of an interval of Any subrepresentati on of an isotypical representation In the case of factors of type II, the order structure real numbers, not integers. of type II can be divided into yet smaller sub represent a-tions:
we shall never reach an irreducible “atom.” Nevertheless, subrepresentati ons can still be compared insize by means of the “real-valued dimension” provided by Murray and von Neumann’s theorem. A not able example of a factor of type II may be obtained as follows. Let G be a group and let H =2(G) be a Hilbert space having basis vectors ing to the ele men tsg \in  G. Then there is a natural rep-[g] correspond- resentation ofplication law, called the G on H derived from the group multi-regular representation:
given an element is the linear operator that takes each basis vectorg of G, the corresponding unitary map[g Ug] in 2(G) to the basis vector [gg^ ]. The commutant of this representation is a von Neumann algebra M . If G is a commutative group, then all the operatorsin the center of$M$; but if G is far enough from com-Ug are mutativity (for instance, if it is a free group), then M

IV.15. Operator Algebras

will have trivial center and will therefore be a factor. It can be shown that this factor is of type II. There is a simple explicit formula for the real-valued dimensionof a subrepresentati on corresponding to an orthogonal projection ative to the basis P \in M. Represent[g] of H . Because Pby an infinite matrix rel-P commutes with the representation, it is easy to see that the diagonal elements of P are all the same, equal to some real num- ber between 0 and 1. This real number is the dimensionof the subrepresentati on corresponding to P .
theory has found unexpected applications in[I.3 §6.4](/part-01/fundamental-definitions). Many important topological concepts, such More recently, the Murray–von Neumann dimension topology as Betti numbers, are defined as the (integer - valued)dimensions of certain vector spaces. Using von Neumann algebras, one can define real-valued counterparts of these quantities that have useful additional properties. In this way, one can use von Neumann algebra theory to obtain topological conclusions.
The von Neumann algebras used here are typically obtained bythe construction of the previous paragraph from the fundamental group [IV.6 §2](/part - 04/algebraic - topology) of some compact space. 2.3 Modular Theory Type III factors remained rather mysterious for a long time;
indeed, Murray and von Neumann were at first unable to determine whether any such factors existed. They eventually managed to do so, but the fundamental breakthrough in the area came well after their pioneer-ing work, when it was realized that each von Neumann algebra has a special family of symmetries, its so-called modular automorphism group. sider once again the von Neumann algebra obtained from the regular representation of a group To explain the origins of modular theory, let us con - G.
We defined the operators Ug on2(G) by multiplying on the left have considered a representation defined by multiply-by elements of G; but we could equally well ingvon Neumann algebra.on the right. This would have yielded a different difference is unimportant, because the map[g So long as we deal only with discrete groups-1] is a unitary operator on H that interchanges the S: G[g]this . oleft and right regular representations. But for certain continuous groups the problem arises that the function f (g) may be square-integrable while f (g - 1) is not.
In this situation there is no simple unitary isomorphism analogous to the one for discrete groups. To remedy this, one must introduce a correction factor called the modular function of G. 517 thing analogous to the modular function can be con-struc ted for any von Neumann algebra. This object then The project of modular theory is to show that some serves as an invariant for all factors of type III, whether or not they are explicitly derived from groups. struc tion (section 1.4). Letof operators.
A linear functional Modular theory exploits a version of the GNS con-M be a self-adjoint algebraφ:$M \to C \text{is called a}$ state if it is positive in the sense that$φ(T^{*}T ) ⩾ 0$, for every T \in  M (this terminology is derived from the con- nection described earlier between Hilbert space theory and quantum mechanics). For the purposes of modular theory we restrict attention towhichφ(T*T ) = 0 implies T =faithful0. If φstates, those foris a state, then the formula T1, T2 = φ(T1*T2) defines an inner product on the vector space ing the GNS procedure, we obtain a Hilbert space M.
Apply - HM.
The first important fact aboutator T in M determines an operator on HM is that every oper-HM. Indeed, a vector M, and we can apply an operator V \in  HM is a limit V = \li(mn)→. nfty T \in Vn Mof elements into the vector V using the formula T V =n. im→. nfty T Vn,

where on the right-hand side we use multiplication inthe algebra M . Because of this observation, we can think ofan algebra of operators on whatever Hilbert space we M as an algebra of operators on HM, rather than as began with. Next, the adjoint operation equips the Hilbert space $\text{Hby the formula}^{M}$ with a natural “antilinear” operator1$S(V ) = V^{*}$. Since U* =SU:$H^{M}\text{for the} \to H^{M}$ regular representation, this is indeed analogous to the operator S we encountered in our discussion of contin-g g -1 uous groups.
The important theorem of Minoru Tomita and Masamichi Takesaki asserts that, as long as the original stateφsatisfies a continuity condition, the complex powers U = (S*S()i)t have the property thatt Ut The transformations of MU-t = M, for all t. M given by the formula T \to UAlain Connes proved that they depend only in a rathert T U-t are called the modular automorphisms of M. inessential way on the original faithful stateφ.
To be precise, changing ph is ms only by inner automorphismsφ changes the modular automor-, that is, trans for- ma tions of the form$T \to UT U^{-1}$, where U is a unitary a delicate matter.1. The interpretation of this formula on the completion HM of M is

518

operator in every von Neumann algebra M itself. The remarkable conclusion is that M has a canonical one- parameter group of “outer automorphisms,” which is determined byused to define it. M alone and not by the state φ that is The modular group of a type I or type II factor consists only of the identity transformation; however, the modular group of a type III factor is much more complex. For example, the set ${t \in R}$: T \to  Ut T U-t is an inner automorphism is a subgroup of R and an invariant of M that can be used to distinguish between uncountably many different type III factors.

2.4 Classification

A crowning achievement of von Neumann algebra theory is the classification of factors that are approximately finite dimensional in a certain sense limits of finite-dimensional algebras.. These are the factors that are Be sides the range of the dimension function, which sep-arates factors into types, the sole invariant is the module from the modular automorphism group.. This is a flow on a certain space that is assembled standing problem of distinguishing among the type IIfactors associated with the regular representations of A lot of attention is currently being given to the long groups.
Of special interest is the case of free groups [IV.10 §2](/part-04/geometric-and-combinatorial-group-theory), around which has flourished the subject offree probability theory. Despite intensive effort, some fundamental questions remain open: at the time of writing it is unknown whether the factors associated with the free groups on two and on three generators are isomorphic. theory Another important development has been, which attempts to classify the ways in which subfactor factors can be realized within other factors.
A remark-able and surprising theorem of Vaughan Jones shows that, in the type II situation, where continuous values of dimensions are the norm, the dimensions of subfactors can in certain situations assume only a discrete range of values. The combinatorics associated with this result have also appeared in other apparently quite unrelated parts of mathematics, notably knot theory [III.44](/part-03/knot-polynomials). 3$C^{*} - Algebras$ Von Neumann algebra theory helps describe the structure of a single representation of a group on a hilbert space.
But in many situations it is of interest to gain an

IV. Branches of Mathematics

understanding of all possible unitary representations. To shed some light on this problem we turn to a related but different part of operator algebra theory. Consider the collection B(H) of all bounded oper- ators on a Hilbert space ent structures: algebraic operations, such as addition,$H$. It has two very differ multiplication, and formation of adjoints; and analytic structures, such as the operator norm

$T = \sup {T u}$:$u ⩽ 1$.

These structures are not independent of one another. Suppose, for instance, that T < 1 (an analytic hypoth- esis). Then the geometric series

$S = I + T + T^{2} + T^{3} + · · ·$

converges in B(H), and its limit Ssatisfies S(I - T ) = (I - T )S = I.

It follows that I - T is invertible in B(H) (an algebraic conclusion). One can easily deduce from this that the spectral radius the greatest absolute value of any complex number inr (T ) of any operator T(defined to be the spectrum of The remarkable T ) is less than or equal to its norm.spectral radius formula goes much further in the same direction. It asserts that. im (Tn()1)/n. If T is normal (T T* = T*T), and inr (T ) = particular if(Tn)n =→. nfty T Tn. As a result, the spectral radius ofis self-adjoint, then it may be shown that T is precisely equal to the norm of T.
There is therefore a very close connection between the algebraic structureof B(H), particularly algebraic structure related to the adjoint operation, and the analytic structure. Not all the properties of B(H) are relevant to this connection between algebra and analysis. A$C^{*} - alge-$ bra ties for the argument of the previous two paragraphs to A is an abstract structure that has enough proper- remain valid.
A detailed definition would be out of place here, but it is worth mentioning that a crucial condition relating norm, multiplication, and${}^{*} - \text{operation isa}^{*}a = a^{2}$, a \in  A,

called the C*-identity for A. We also note that special classes of operators on Hilbert space (unitaries, orthog-onal projections, and so on) all have their counterparts in a general satisfiesuu*C*=-algebra. For example, au*u = 1, and a projection unitary ps at is fie su \in  Ap =A simple example of ap2 = p*. C* - algebra is obtained by starting with a single operator tion of all operators S ∈ B(H) that can be obtained as T ∈ B(H). The collec- limits of polynomials in T and T* is a C* - algebra said IV.15. Operator Algebras to be generated by T.
The C* - algebra generated by T is commutative if and only if Tis normal; this is one reason for the importance of normal operators$. 3.1 Commutative$ C* - Algebras If X is a compact [III.9](/part - 03/compactness - and-\text{compactication}) topological space [III.90](/part - 03/topological - spaces), then the collection X \to  C comes with natural algebraic operations (inher-C(X) of continuous functions f: ited from the usual ones on. up {|f (x)|}:$x \in X$. In fact, these operations make C) and a norm f  =C(X) into a C^*-algebra.
The multiplication in C(X) is commutative, because the multiplication of complex numbers is commutative. every C(X)A basic result of Gelfand and Naimark asserts that. Given a commutative commutative C*-algebra is isomorphic to some C*-algebra A, one con- struc tsp his ms Xξ: as the collection of all algebra homomor-A \to  C, and the Gelfand transform then associates withto C.a \in  A the function ξ \to  ξ(a) from X The Gelfand–Naimark theorem is a foundational result of operator theory. For example, a modern proof of the spectral theorem might proceed as follows.
Let$T$ be a self-adjoint or normal operator on a Hilbert space H, and let A be the commutative C*-algebra generated byto C(X)T. By the Gelfand–Naimark theorem, for some space X, which may in fact be identi-A is isomorphic fied with the spectrum ofthen the formula S → Sv, v T. If defines a statev is a unit vector inφ on HA,. The GNS space associated with this state is a hilbert space of functions on$X$, and elements of A = C(X) act as multiplication operators. In particular, a multiplication operator.
A small additional argument T acts as shows that tion operator, or at least to a direct sum of such opera-T is unitarily equivalent to this multiplica- tors (which is itself a multiplication operator on a larger space). Continuous functions can be composed: iff and g are continuous functions (with the range ofin the domain off ), then f ◦g is also a continuous func-g contained tion.
Since the Gelfand–Naimark theorem tells us that any self-adjoint element of a$C^{*} - algebra A \text{sits inside}$ an algebra isomorphic to the continuous functions onthe spectrum ofa, we conclude that if a \in  A is self- adjoint, and ifspectrum ofaf, then an operatoris a continuous function defined on thef (a) exists in A. This functional calculus is a key technical tool in C* - algebra theory. For example, suppose thatu \in  A is unitary andu - 1 < 2. Then the spectrum of u is a subset of the

519

unit circle in C that does not contain-1. One can define a continuous branch of the complex logarithm functionon such a subset, and it follows that there is an element a = . og u of the algebra such that a = −a^* and u = e^a . The patht \to  eta, 0 ⩽ t ⩽ 1, is then a continuous path of unitaries in unitary sufficiently close to the identity is connected to A connecting u to the identity. Thus every the identity by a unitary path.

3.2 Further Examples of$C^{*} - Algebras$

3.2.1 The Compact Operators

An operator on a Hilbert space has range is a finite-dimensional subspace. The operators finite rank if its of finite rank form an algebra, and its closure is a$C^{*}-$ algebra called the algebra of denoted K. One can also view compact Kas a “limit” of matrix operators and algebras $M^{1}(C) \to M^{2}(C) \to M^{3}(C) → · · ·$, where each matrix algebra is included in the next by

$A \to A0 00$.

Many natural operators are compact, including the inte-gral operators that arose in Fredholm’s theory. The identity operator on a Hilbert space is compact if and only if that Hilbert space is finite dimensional.

3.2.2 The CAR Algebra

The presentation of K as a limit of matrix algebras leads one to consider other “limits” of a similar sort.(We shall not attempt a formal definition of these limits here, but it is important to note that the limit of a sequence A \to  A \to  A → · · · depends on the homo- morphisms One particularly important example is obtained as the1 Ai \to2(Ai()+1)3 as well as on the algebras Ai.) limit $M1(C) \to M2(C) \to M4(C) → · · ·$, where each matrix algebra is included in the next by

$A \to A0 A0$.

This is called the ments that represent the CAR algebra canonical anticommutation, because it contains ele relations that arise in quantum theory.$C^{*}$-algebras find several applications to quantum field theory and quan-tum statistical mechanics which extend von Neumann’s formulation of quantum theory in terms of hilbert space.

520

3.2.3 Group$C^{*} - Algebras$

Ifof GGis a group andon a Hilbert spaceg \to  UHg, we can consider the small-is a unitary representation estthis is called the C*-algebra of operators on C*-algebra generated H containing all theby the repre-Ug; sentation. An important example is the sent at i on on the Hilbert space 2(G) generated by regular repre-G, which we defined in section 2.2. Theit generates is denoted$C^{*}(G)$. The subscript “r” refers$C^{*} - \text{algebra that}$ r to the regular representation. Considering other repre-sentations leads to other, potentially different, group

$C^{*} - algebras$.

a commutative group, its tive, and thus it is isomorphic to Consider, for example, the case C*-algebra is also commuta-C(X)G =for a suitable Z. Since this is X, by the Gelfand–Naimark theorem. In fact, circle$S^{1}$, and the isomorphism X is the unit C(S1) C^*(Z)

r

takes a function on the circle to its Fourier series. States defined on group$C^{*} - \text{algebras correspond}$ to positive-definite functions defined on groups, and hence to unitary group representations. In this way new representations may be constructed and studied. For example, using states of group C* - algebras it is possi- ble to give to the set of irreducible representations of G the structure of a topological space.

3.2.4 The Irrational Rotation Algebra

The algebra C^*(Z) is generated by a single unitary ele- ment universal example U (corresponding to 1 of such a C*\in -algebra, which is to say Z). More over, it is the that given anyone and only one homomorphism C*-algebra A and unitary C*(Zu) \to \in  AA, there is sending Ucal cul us homomorphism for the unitary to u. In fact, this is nothing other than the functionalu. If instead we consider the universal example of a C*- algebra generated by two unitaries U , V subject to the relation

UV = (e2()π){i}αV U,

whereα is irrational, we obtain a noncommutative C*- algebra called the irrational rotation algebras have been studied inten-irrational rotation algebra$A^{α}$. The sively from a number of points of view. Using(see below) it has been shown that A is isomorphic to K-theory AαIt can be shown that the irrational rotation algebra2 if and only if α1 ± α2 is an integer.α 1 is satisfying the commutation relation above will generate simple, which implies that any pair of unitaries U, V

IV. Branches of Mathematics

a copy of unitary: 1 is a unitary operator, but it does not generate A^α. (Note the contrast with the case of a single a copy of$C^{*}(Z)$.) This allows us to give a concrete rep- resentation ofis the rotation through 2 A^α on the Hilbert spaceπα and V is multiplication by L2(S1), where Uz:$S1 \to C$.

4 Fredholm Operators

Ato be a bounded operator Fredholm operator between Hilbert spaces is defined T for which the kernel and cokernel are finite dimensional. This means that the homogeneous equation T u =0 admits only finitely many linearly independent solutions, while the in homogeneous equation$T u = v \text{admits a solution if} v$ satisfies a finite number of linear conditions. The terminology arises from Fredholm’s original work on integral equations; he showed that if K is an integral operator, then I + K is a Fredholm operator.
dimensions of the kernel and cokernel must be equal, but in general this need not be so. The For the operators that Fredholm considered, the unilateral shift operator tor”(a , a , a S, . . . ), which maps the infinite “row vec-to$(0, a , a , . . . )$, is an example. The equation the equation1 2 Su^3 Su == 0 has only the zero solution, butv has a solution only if the first1 2 coordinate of the vectorv is zero. integer difference The index of a Fredholm operator is defined to be the index$(T ) = \dim (ker(T )) - \dim (coker(T ))$.
For example, every invertible operator is a fredholm operator of index 0, where as the unilateral shift is a Fredholm operator of index-1.

4.1 Atkinson’s Theorem

Consider the two systems of linear equations⎧ ⎫ ⎧ ⎫⎨ 2$.1x + y = 0\} and \{ 2x + y = 0\}$.\{ 4 x + 2 y = 0\} \{ 4 x + 2 y = 0\}

Although the coefficients of these equations are very close, the dimensions of their kernels are quite different: the left-hand system has only the zero solution, where as the right-hand system has the nontrivial solutions(t$, -2t)$. Thus the dimension of the kernel is an unstable il ar remark applies to the dimension of the cokernel.invariant of the system of equations. A sim By contrast, the index is stable, despite its definition asthe difference of two unstable quantities.

IV.15. Operator Algebras

precise expression to these stability properties. Atkin-son’s theorem asserts that an operator An important theorem of Frederick Atkinson gives T is Fredholm if and only if it is invertible modulo compact opera-tors. This implies that any operator that is sufficiently close to a Fredholm operator is itself a Fredholm operator with the same index, and that ifoperator and K is a compact operator, then T is a Fredholm T + K is a Fredholm operator with the same index asthat, since integral operators are compact operators, T . Notice this contains Fredholm’s original theorem as a special case.

4.2 The Toeplitz Index Theorem

topology mat ical systems that remain the same when the sys-[I.3 §6.4](/part-01/fundamental-definitions) studies those properties of ma the tem is (continuously) perturbed. Atkinson’s theorem tells us that the Fredholm index is a topological quantity. In many contexts it is possible to obtain a for-mula for the index of a Fredholm operator in terms of other, apparently quite different, topological quan-tities. Formulas of this sort often indicate deep connections between analysis and topology and often have powerful applications. The simplest example involves the Toeplitz operators.
A Toeplitz operator has a matrix with the special form⎛ ⎞⎜⎜⎜bb^0^-^1 bb^1^0 bb^2^1 bb^3^2 · · ·· · ·⎟⎟⎟T = ⎜⎜⎜⎜⎜bb^-^-^2^3 bb^-^-^1^2 bb^0^-^1 bb^1^0 · · ·· · ·⎟⎟⎟⎟⎟ .⎝ ... ... ... ... . .. ⎠

In other words, as you go down each diagonal ofthe matrix, the entries remain constant. The sequence of coefficients$\infty=−$. nfty bnz-n on the unit circle in the complex plane$,{bn}\infty\text{n}=−$. nfty defines a function$f$ (z) = called the shown that a Toeplitz operator whose symbol is a con-n symbol of the Toeplitz operator. It can be tinuous function which is never zero is Fredholm. Whatis its index? as a mapping from the unit circle to the nonzero com-plex numbers: in other words, as a closed path in the The answer is given by thinking about the symbol nonzero complex plane.
The fundamental topological invariant of such a path is its winding number: the number of times it “goes around” the origin in the counter clockwise direction. It can be proved that the index of a Toeplitz operator with nonzero symbol is minus the winding number off . For example, if ff is the function$f (z) = z (\text{with winding number} + 1)$,

521

then the associated Toeplitz operator is the unilateral shift S that we encountered earlier (with index -1). The Toeplitz index theorem is a very special case of the atiyah–singer index theorem topological formula for the indices of various Fredholm[V.2](/part-05/the-atiyahsinger-index-theorem), which gives a operators that arise in geometry.

4.3 Essentially Normal Operators

Atkinson’s theorem suggests that compact perturb a-tions of an operator are in some sense “small.” This leads to the study of properties of an operator that are preserved by compact perturbation. For instance, the complex numbers essential spectrum. ambda for which of an operator T - . ambda I fails to be Fred-T is the set of holm (that is, invertible modulo compact operators).Two operators T and T are essentially equivalent if there is a unitary operator differ by a compact operator.
A beautiful theorem orig - 1 2 U such that UT1 U* and T2 inally due toor normal operators are essentially equivalent if and weyl [VI.80](/part - 06/hermann - weyl - 18851955) asserts that two self-adjoint only if they have the same essential spectrum. tors in this theorem is in appropriate. Since we are con-cerned with properties that are preserved by compact One might argue that the restriction to normal opera perturbation, would it not be more appropriate to consider T for which essentially normal T*T - T T*operators—that is, operatorsis compact?
This apparently modest variation leads to an unexpected result. the unilateral shift S is an example of an essentially nor- mal operator. Its essential spectrum is the unit circle, as is the essential spectrum of its adjoint; however,$S$ and S* cannot be essentially equivalent, because S has index - 1 and S* has index + 1. Thus some new ing red i - ent, beyond the essential spectrum, is needed to clas-sify essentially normal operators.
In fact, it follows easily from Atkinson’s theorem that if essentially normal operators T and T are to be essentially equivalent, then not only must they have the same essential spec-trum but also, for every1 2. ambda not in the essential spectrum, the Fredholm index ofholm index of T - . ambda IT. The converse of this statement1-. ambda I must be equal to the Fred- was proved by Larry Brown, Ron Douglas, and Peter2 Fill more in the 1970 s, using entirely novel techniques that led to a new era of interaction between$C* - algebra$theory and topology.
4.4 K - Theory A remarkable feature of the Brown–Douglas–fill more work was the appearance within it of tools from 522 algebraic topology ber that, according to the Gelfand–Naimark theorem,[IV.6](/part - 04/algebraic - topology), notably K-theory. Remem- the study of (suitable) topological spaces and the study of commutative C*-algebras are one and the same; all the techniques of topology can be transferred, via the Gelfand–Naimark isomorphism, to commutative$C^{*}-$ algebras.
Having made this observation, it is natural to ask which of these techniques can be extended further, to provide information about all$C^{*} - algebras$, commutative or not. The first and best example is K-theory. Ch om om or phism of*In its most basic form,-algebra A an Abelian group C*-algebras a corresponding homo-K-theory associates with each K(A), and with each morphism of Abelian groups. The building blocks for K(A) can be thought of as generalized Fredholm oper- ators associated with operators act on “Hilbert spaces” in which the complex$A$;
the generalization is that these scalars are replaced by elements of the$C^{*} - algebra A$. The group connected components of the space of all such general-K(A)itself is defined to be the collection of ized Fredholm operators. Thus if$A = C$, for instance (so that we are dealing with classical Fredholm operators)$, then K(A) = Z$. This follows from the fact that two Fred- holm operators are connected by a path of fredholm operators if and only if they have the same index. can construct ent ingredients.
For example, every projection One of the great strengths of$K$-theory classes from a variety of differ-K-theory is that onep \in  A defines a class in“dimension” for the range of K(A) which can be thought of as ap. This connects K-theory to the classification of factors (section 2.2), and has become an important tool in the effort to classify various families of C*-algebras, such as the irrational rota- tion algebras. (It was at one time thought that the irra-tional rotation algebras might not contain any nontrivial projections at all:
the construction of such pro-jections by Marc Rieffel was an important step in the development of C* - algebra K - theory.) Another beauti- ful example is George Elliott’s classification theorem for locally finite - dimensional C* - algebras like the CAR algebra; they are completely determined by invariants. K - theoretic noncommutative algebras, has turned out to have important connections The problem of computing the C*-algebras, particularly group K-theory groups of C*- with topology.
In fact, some key advances in topol-ogy have come from C*-algebra theory in this way, there by allowing operator algebraists to repay some ofthe debt they owe to the topologists for K - theory. The IV. Branches of Mathematics principal organizing problem in this area is the Connes conjecture, which proposes a description of the Baum K-theory of group C*-algebras in terms of invariants familiar in algebraic topology.
Most of the progress onthe conjecture to date is the result of work of Gennadi Kasparov, who dramatically broadened the original discoveries of Brown, Douglas, and Fill more to cover not just single essentially normal operators but also noncommuting systems of operators, that is,$C* - alge-$ bras. Kasparov’s work is now a central component ofoperator algebra theory.
5 Noncommutative Geometry descartes’s [VI.11](/part - 06/ren - descartes - 15961650) invention of coordinates showed that one can do geometry by thinking about coordinate functions rather than directly thinking about points in space and their inter relationships: these coordinate functions are the familiarx, y, and z. The Gelfand Naimark theorem can be viewed as one expression ofthis idea of passing from the “point picture” of a space Xtions on it.
The success ofto the “field picture” of the algebra K-theory in operator algebras C(X) of func- invites us to ponder whether the field picture might bemore powerful than the point picture, since K-theory can be applied to noncommutative C* - algebras which may not have any “points” (homomorphisms to C) at all. One of the most exciting research frontiers in operator algebra theory is reached along a path which develops these thoughts.
The noncommutative geometry general program of Connes takes seriously the idea that a C*-algebra should be thought of as an algebra of functions on a “noncommutative space,” and goes onto develop “noncommutative” versions of many ideas from geometry and topology, as well as completely new constructions that have no commutative counterpart. Noncommutative geometry begins with the cre-ative reformulation of ideas from ordinary geometry in ways that involve only operators and functions, but not points. Consider, for instance, the circle S1.
The algebra C(S1)reflects all the topological properties of S1, but to incorporate its well we look not just at metric (distance - related) properties as C(S1) but at the pair consisting of the algebra Hilbert space C(SH = 1 L)2 and the operator(S1). Notice that if D = f i dis a function/dθ on the on the circle (considered as a multiplication operatoron H), then the commutator Df -f D is also a multipli- cation operator, this time by i dordinary measurements of angular distance between f /dθ. It follows that

IV.16. Mirror Symmetry

points on the circle can be recovered from C(S1) and D by the formul ad(p, q) = . ax {|f (p) - f (q)|}:$Df - f D ⩽ 1$. Connes argues that operator|D|-1 plays the role of the “unit of arc-length dc om pl i cated situations.$s$” in this and many other, more2 also of central importance in noncommutative geom-etry, is the fact that the operator Another feature of the examples Connes considers,$|D|^{-k} \text{is a trace}-$ class operator (see section 1.5) when In the case of the circle, k needs to be bigger thank is large enough.

1. Computations with traces connect noncommutative geometry to cohomology theory [IV.6 §4](/part-04/algebraic-topology). We now have two kinds of “noncommutative algebraic topol-ogy,” namely K-theory and a new variant of homology called two is provided by a very general index theorem.cyclic cohomology; the connection between the mutativebe applied) from classical geometric data. The irra-There are several procedures that produce noncom-$C^{*}$-algebras (to which Connes’s methods can tional rotation algebrascal picture to which they apply is the Aθare examples;
the classi-quotient space [I.3 §3.3](/part-01/fundamental-definitions) of the circle by the group of rotations through multiples ofθ. Classical methods of geometry and topology are unable to handle this quotient space, butthe noncommutative approach via$A^{θ} \text{is much more}$ successful. An exciting but speculative possibility is that the basic laws of physics should be addressed from the perspective of noncommutative geometry. The transition to noncommutative C* - algebras can be viewed as analogous to the transition from classical to quan-tum mechanics.
However, Connes has argued that noncommutative C*-algebras play a role in describing the physical world even before the transition is made to quantum physics.

Further Reading

Connes, A. 1995.Academic Press. Noncommutative Geometry. Boston, MA: Davidson, K. 1996.$C^{*} - \text{Algebras by Example}$. Providence, RI: Fill more, P. 1996.American Mathematical Society. Canadian Mathematical Society Series of Monographs and A User’s Guide to Operator Algebras. Halmos, P. R. 1963. What does the spectral theorem say?Advanced Texts. New York: John Wiley. American Mathematical Monthly 70:241–47. stant functions. A small modification must therefore be made before considering inverse operators. The operator2.
The operator D is not quite invertible since it vanishes on con-|D|is by definition the positive square root of D2.

523

IV.16 Mirror Symmetry

Eric Zaslow

1 What Is Mirror Symmetry?

Mirror symmetry is a phenomenon found in theoretical physics that has had profound mathematical applica-tions. It burst onto the mathematical scene after Can del as, de la Ossa, Green, and Parkes exploited the physical phenomenon to make precise predictions about certain sequences of numbers describing geometric spaces. The sequence predicted by those authors began 2875, 609 250, 317 206 375, of calculation at the time. The phenomenon of mirror. . . , and was far beyond the scope symmetry is that some physical theories have equiv-alent, “mirror” theories that lead to the same predictions.
If some prediction requires a hard calculation but is easy to perform in the mirror theory, then you can getthe answer for free! These physical theories do not have to be realistic models of physics. For instance, beginning students of physics often study point particleson frictionless planes. Although they are unrealistic, such toy models can bring the physical concepts into focus and their analysis can give rise to very interesting mathematics.

1.1 Exploiting Equivalences

Children at school in the 1950 s used log tables to exploit the equivalence of multiplication of positive numbers with addition of real numbers. Given the prob-lem of multiplying two large numbers a and b, they would use a table to look up the logarithms log(a) and log then add them by hand. They would then use the same(b)(to a certain number of significant figures), table to find which number had a logarithm equal to$\log (a) + \log (b)$. The answer is ab.
defined by College students some times exploit the equivalence fourier transforms [III.27](/part-03/the-fourier-transform) to solve differential equations. Basically, the Fourier transform isa rule that maps one functionf (x) to a new func- tion ˆderivativef (p). What is nice is that the transform of thef^ (x)relates in a very simple way to ˆf (p):
it is i If you want to solve a differential equation such aspf (p)ˆ , where i is the imaginary number. qrt{-1}$.f (x) + 2 f (x) = h(x)$, where h(x) is a given function and you are trying to findto its Fourier transform equation if , you can map the equationpf (p)ˆ$+$2 ˆ$f (p) =h(p)$ˆ . This is much easier: it is an algebraic equation

524

rather than a differential equation, and has the solu-tion ˆ$f (p) = h(p)/($ˆ 2$+ ip)$. The solution f (x) is then the function which has ˆh(p)/(2 + ip) as its Fourier transform. Mirror symmetry is like a fancy Fourier transform, mapping much more information than is contained ina single function. Every aspect of a physical theory is involved. This article will (eventually) focus on the mathematics of mirror symmetry, but it is crucial to understand its physical origins. We therefore begin with a brief guide to physics.
(For a further discussion of math-ematical physics, see vertex operator algebras [IV.17 §2](/part-04/vertex-operator-algebras).) This is in no way an adequate treatment—a separatewe hope to give enough of the flavor of the subject to Companion to Physics would be needed—but help the reader with the later sections.
(A reader famil-iar with physical theories may wish to skip the next section and refer back as needed.) 2 Theories of Physics 2.1 Formulations of Mechanics and Action Principles 2.1.1 Newtonian Physics Newton’s second law states that a particle moving through space accelerates1 in proportion to the force it experiences: F = mx ̈. The force is itself the (negative) gradient of a gravitational potential equation can be written$mx$ ̈$+ ∇V (x) = V (x)0$. Stationary, so this particles sit at minima of the potential:
examples area ball in equilibrium at the end of a spring, or a pea at the bottom of a bowl. In stable situations, there is arestoring force proportional to some displacement distance. This means that in some appropriate coordinate, F ∼ −x, so V (x) = kx2/2, for some k. The solutions are oscillatory, with angular frequencyω = k/m. This model is called the simple harmonic oscillator.

2.1.2 The Least Action Principle

Every major theory can also be formulated by means ofan idea known as the least action principle. Let us see how it works for the equations of Newtonian mechan-ics. Consider an arbitrary path of a particlex(t) and time. We denote position byp one nt position vector, and we denote time derivatives by dots, so1. Acceleration is the second derivative of position with respect tox, which is shorthand for a three-com- acceleration is denoted by  ̈x.

IV. Branches of Mathematics

form the quantity

$S(x) = [^{1}^{2}mx$ ̇2- V (x)] dt.

Here and below, the notation than one coordinate. Ifx is used as a point in space-x may represent more time, it will include the time coordinate, if that is not otherwise noted. Likewise, we omit component notation on most vectors. The notation should be clear from the context. The quantity S(x), which is known as the action energy. One then considers which paths minimize this, equals the kinetic energy minus the potential action.
That is, we ask which paths erty that, when they are perturbed by a small amountx(t) have the prop-δx(t)fact we require only that the action is unchanged to first, the action is unchanged, to leading order. (So in order, and not that it is actually minimized. Solutions of saddle-point type are allowed.) The answer turns out to be precisely those paths that satisfy$mx$ ̈$+∇V (x) = 0$.2 tor in two dimensions. We can model plex number and set For example, consider the simple harmonic oscil la-$V (x) = k|x|^{2}$. The action is thenx as a com-$12$[m|x ̇|2-k|x|2].
Note that a phase rotation x \to  (ei)θx leaves the action invariant, and is therefore a symmetryof the equations of motion. Lesson. Physical solutions extremize the action. physical situations, as we shall see below. First, though, we describe another formulation of mechanics. The principle of least action applies to many other

2.1.3 The Hamiltonian Formulation of Mechanics hamilton motion also deserves mention. It leads to first-order’s [VI.37](/part-06/william-rowan-hamilton-18051865) formulation of the equations of equations. Let Sbe the action and define L by S = L dt, and consider the (typical) case where coordinate sx and their time derivatives  ̇L is a function ofx. Then setpon  ̇=xd.
(In the example L/d  ̇x, a function that can depend both on L =1 mx ̇2- V (x) that we havex and already considered, we find that Now let us consider the function2$p H==mpx$ ̇$x$ ̇, or  ̇- Lx, which is= p/m.) called the from(x, x) ̇hamiltonian to(x, p)so as to remove all mention of  ̇[III.35](/part-03/hamiltonians), and change variablesx. In the example, H works out to bep2 - p2 - V (x) = p2 + V (x), m 2 m 2 m the linear terms inare2. To see this, replace(. abla V )δx. One then has to integrate by parts to remove the timeδx and its time derivative.
Forx by x + δx in the action and keep only V the linear terms derivative ofwill be zero for arbitrary variationsδx and isolate it as a factor in the integrand. The integralδx only when the term multiplying it vanishes. This gives the equation. Try it! IV.16. Mirror Symmetry which is the total energy. For the simple harmonic oscillator, H = p2/2 m + kx2/2. The equations  ̇$x = \partial H/\partial p$and  ̇ p = −. artial H/. artial x are the equations of motion in the Hamiltonian formulation; they can be shown to be equivalent to those obtained from the action principle.
In the example,  ̇$x = p/m andp$ ̇$= −∇V$. Using the first equation to replac ep by mx ̇ in the second, we recover the equation$mx$ ̈$+ ∇V (x) =$

0. More generally, one can consider the time derivative of some quan tit yf (x, p) constructed from p and x and prove—using the chain rule and the equations of motion—that $f$ ̇= . artial f. artial x . artial H. artial p - . artial f. artial p . artial H. artial x = \. \1}, f \\\\\\\\\\\\\\\\\\\\\}. The term in the middle is called the H and f , denoted \\\\\\\\\\\\\\\\\\\\. \1, f \\\\\\\\\\\\\\\\\\\\\}. Poisson bracket of Lesson. The Hamiltonian controls time dependence through the Poisson bracket.
themselves into the bracket, we derive the identity Notice that when we plug the coordinate sx and p\\\{x, p\\\} = −1. (1) It is also possible to begin with the Hamiltonian view - point. One considers a space endowed with a bracket operation on functions, such that there are coordinate functions (not uniquely determined) obeying\\\{x, p\\\} =-1. The mechanical model is defined by a function H(x, p), which determines the dynamics. 2.1.4 Symmetry A brief remark on symmetry is in order.
noether [VI.76](/part - 06/emmy - noether - 18821935) proved that in the action formulation of me - chanics, a symmetry of the action results in a conserved quantity. The prototypical example is transla-tional or rotational symmetry, where the potential of a particle is invariant under some direction of trans-lation or rotation: the corresponding conserved quantity is then momentum or angular momentum. In the example above, V (x) = k|x|2/2 is independent of θ, the phase ofvaryingθ is dx.
The equation of motion determined by(m|x|2θ)/ ̇ dt = 0, so in this case it is the angular momentum m|x|2θ̇ that is conserved. In the Hamiltonian formulation, since a conserved quantity zero Poisson bracket with the Hamiltonian: f (x, p) does not change with time, it must have\. \1, f \\ = 0. In particular, the Hamiltonian itself is conserved. 525 2.1.5 Action Functions for Other Theories Returning now to action principles, we shall see how different physical theories are described through different actions.
In electricity and magnetism, equations [IV.13 §1.1](/part - 04/general - relativity - and - the - einstein - equations) can be formulated in the form maxwell’s δS = 0, where now the action S takes the form of an integral over space and time of the electric net ic(B)fields. In the case where there are no sources,(E) and mag- the action is written S = 8πe12 [E2 - B2] dx dt, (2) where is one important difference from the previous exam - e is the electric charge of an electron.
There ple, which is that the variations of the action must be taken with respect to the fundamental fields, and E and Be le ct ro magnetic potential are not fundamental as they are derived from the A = (φ, A) by the equations E = ∇φ - A ̇, B = ∇ . imes A. If you rewrite S in terms of A, vary A by δA, and set δS = 0, then you recover Maxwell’s equations from the least action principle. It is clear that the electromagnetic action merely changes sign under the replacement and therefore any solutionδS = 0 remains a solu - E \to B, B → −E, tion under the transformation.
This is an example ofan equivalence of a classical theory of physics. In fact, this symmetry extends to the case where there are sources (such as electrons) if we also interchange electric and magnetic sources. (No magnetic sources have been observed in the universe, but a theory with such objects still makes sense.) Lesson.sources. Physical equivalences act on fields and their Electricity and magnetism is a “field theory,” which means that the degrees of freedom involve functions that depend on position in space.
Contrast this with Newtonian mechanics, where the spatial degrees of freedom are just the coordinates of the particle(s). However, there is not much conceptual distance between the two, as can be seen in the following toy model. φvalues. Now imagine that space has just one dimen-. That is, We will consider the simplest example: a scalar field,φ is just a function that takes numerical sion, not three, and further that that dimension is a circle, which we can describe with an angular coordinate,θ.
At any fixed point in time we can use[III.27](/part - 03/the - fourier - transform) to write the scalar field as$φ(θ)fourier = series$ cn . xp (inθ), where the c^nare the Fourier coefficients, and if we want the values ofbers then we must insist thatn c =φcto be real num-*. We can then-n n 526 think of dimensional vectorφ(θ)not as a function but as an infinite-(c , c , . . . ). The spatial dependence of If we now wish to consider time dependence, thenφis completely determined by the coefficients0 1 cn.
all we have to do is use time-dependent components $(cquantum - \text{mechanical particles}^{0}(t)$, c1(t), . . . ), which looks a lot like an infinite set of$cn$. Thus, the function φ has the Fourier expansion The simplest action for a scalar fieldφ(θ, t) =ncnφ(t)that allows. xp (inθ). wave-like solutions of the equations of motion serves as a natural analogue of equation (2): S = 21π [(φ) ̇ 2- (φ^ )2]dθ dt, (3) whereφ^ = . artialφ/. artialθ. When we plug the Fourier expan- sion into the action and perform theget. um θ integration, we S = n [|ċn|2 - n2|cn|2] dt.
(4) Note that the term in brackets is just the action for aparticlec in a quadratic potential, as in section 2.1.2. We simply have an infinite number of harmonic oscil- n lators (with the exception of the which corresponds to a free particle in no potential).$c^{0} \text{degree of freedom}$, Lesson.infinite number of particles. The particles correspond Field theory is like point particle theory with an to the degrees of freedom of the field. When the action is just quadratic in the derivatives, the particles have an interpretation as simple harmonic oscillators. work as a field theory.
For a space-time Even general relativity [IV.13](/part-04/general-relativity-and-the-einstein-equations) fits into this frame-$M$, the field is the metric is what determines the lengths of paths between riemannian metric [I.3 §6.10](/part-01/fundamental-definitions) on space-time. The points—so a stretching of space-time, for example, is represented by a rescaled metric. The action is then constructed as the integral of the Riemannian curvature scalar$R$over space-time:$S$ = R.3 M

2.2 Quantum Theory

Mirror symmetry is an equivalence of quantum theo-ries, so we must develop an understanding of what a quantum theory is and what an equivalence looks like. There are two formulations of quantum mechanics: the operator formulation and Feynman’s path-integral formulation. Both formulations are probabilistic, meaning that you cannot predict exactly what will be observed in at the origin.3. In 3-space, the paraboloidz =1 2 ax2 +1 2 by2 has curvature ab

IV. Branches of Mathematics

a single measurement, but you can make precise pre-dictions about what will be observed after multiple, repeated measurements in the same environment. For instance, your experimental apparatus may involve a beam of electrons hitting a screen and making a mark. The beam will contain millions of electrons, so the pattern of marks on the screen can be predicted with great accuracy.
However, we cannot say what will happen toa single, given electron—all we can do is assign probabilities to the out comes of various measurements. These probabilities are encoded in the so-called “wave function”Ψ of the particle.

2.2.1 Hamiltonian Formulation

In the operator formulation of quantum mechanics, the positions and moment a of classical mechanics (and any quantity formed from them) are converted intotors [III.50](/part-03/linear-operators-and-their-properties) acting on a hilbert space [III.37](/part-03/bayesian-analysis) accord-opera ing to the following rule:{· ,·} by i/ [· ,·], where [A, B]replace the Poisson bracket= AB -BA is the commu- tator bracket ple, we get from equation (1) the relation and is Planck’s constant.
Thus, for exam-[x$, p] = i .$ The state of a particle (or system) is now defined not as a set of values of Hilbert space. Once again, time evolution is determinedx and p but as a vector Ψ in the by the Hamiltonian, basic dynamical equation is H, but now H is an operator. The HΨ = i ddt Ψ . (5)

This is called the Schrödinger equation.

Lesson. To quantize a classical theory, replace ordinary degrees of freedom by operators on a vector space; replace Poisson brackets by commutator brackets. In the case where we have a particle on the real line R, the Hilbert space is the space of square-integrable func-tions L2(R), so we write Ψ as Ψ (x). The commutation relation is obeyed if we think ofx as the operator that sends the function the relation[x, p] =Ψ (x)i means that we should repre-to the function xΨ (x). Now sentp as the operator - i (d/dx).
The values of the classical quantity associated with an operator correspond to theso for example a state with momentum eigenvalues [I.3 §4.3](/part-01/fundamental-definitions) of that operator, p has the formΨ ∼ . xp (ipx/ ). Unfortunately, this is not square- integrable on the real line, but it would become so ifwe identifiedx and x +2πR, for some number (radius)R > 0. Topologically, this compactifies [III.9](/part-03/compactness-and-compactication) R to a circle, but note thatΨ will be single-valued only if IV.16. Mirror Symmetry p“quantized” in units of = n /R, where n is an integer.
Thus, momentum is/R.4 The integer label of thec momentum.n of equation (4) can therefore also be thought of as a In the above example, R is the degree of freedom of the classical coordinate copy of L2(R) for each real degree of freedom, whe the rx. In other examples, there is a or not it represents a geometric location. Another novelty is that position and momentum do not commute as operators in quantum mechanics, meaning they cannot be simultaneously diagonalized: you cannot specify the position and momentum simultaneously.
This is a form of Heisenberg’s uncertainty principle (see operator algebras [IV.15 §1.3](/part-04/operator-algebras)). 2.2.2 Symmetry As the rules of quantization would suggest, a symmetry of a quantum theory is an operator[H, A] = 0. That is, A commutes with the Hamiltonian, A such that and therefore respects the dynamics. 2.2.3 Example: The Simple Harmonic Oscillator We now discuss an example that will be useful later on for understanding quantum field theory and mirror symmetry: the simple harmonic oscillator in quantum mechanics.
Suppose that the constants are chosen sothat the Hamiltonian is given by H = x2 + p2. If one defines one can show thata = (x + iap)/† raises the energy of a state by one. qrt{2} and a† = (x - ip)/. qrt{2}, then unit5 anda lowers the energy by one unit. Invoking the physical argument that there is a ground state lowest energy, this state must obey$aΨ = 0$. One thenΨ0 of finds that all states can be written in terms of the basis vectorsΨ = (a†)nΨ with energy n + {}01. Note that Ψ has energy number basis, since the interpretation is that(n1)2.6 The basis0 {Ψn} is called the2 occupationΨ has n0 n

energy “quanta” above the ground state.

example, we could work in the fictitious time unit of “sqeconds,” one second equals4. We shall occasionally choose our units to make sqeconds. equal to 1. For [H, aing interpretation. Suppose5. Here is the calculation:†] = a^† and [H, a] = −Ψ[a, ais an eigenvector ofa. These equations have the follow-^†] = 1 and H = Ha^†with eigenvaluea +1 2. Further, (energy)H(a E. Then†Ψ ) =HΨ(Ha=†EΨ-. Consider a†H + a†H)Ψa†Ψ=. One quickly finds that([H$, a^{†}] + a^{†}H)Ψ= (a^{†} + a^{†}E)Ψ = (E + 1)(a^{†}Ψ )$.

We learn thatby one unit.a†Ψ has eigenvalue E + 1, so a†has “raised” the energy defined by6. It is instructive to write these equations in terms of the operatorsx and p.

527

2.2.4 Path-Integral Formulation

Feynman’s path integral formulation of quantum me-chanics builds on the idea of the least action principle. In this formulation, the probability of an experiment is calculated through an average over all paths of particles, and not just the ones which extremize the action. Each pathx(t) is weighted by the factor exp(i S(x)/ ), where Planck’s constant, which is very small compared with S(x) is the action of the path x(t) and is macroscopic action scales. This average can be an imag-inary number, but the probability of the process is the square of its absolute value.
Note that exp$(i S/ ) = \cos (S/ ) + \text{i sin}(S/ )$, so if S changes appreciably when we vary and imaginary parts will oscillate rapidly, sincex(t), then the realis small. Then, when we integrate over pathsx(t), the positive and negative oscillations will roughly cancel. As a result, the main contributions to the weighted sum over paths will come from those paths for which not vary when the path does: the classical paths! How-S does ever, if the variations are sufficiently small compared with , then nonclassical paths can contribute appreciably.
One typically separates the degrees of freedom into the classical trajectory piece and the quantum fluctuations near it. Then one can organize the path integralin a perturbation theory around the parameter . integral, and will not go into the details of this. The We have not yet discussed the integrand of the path main point is that the theory makes a prediction about the likelihood of measuring a physical process. Each process determines a possible integrand.
For example, from our discussion above we learn that the integrand for measuring the likelihood of a quantum-mechanical particle going from the pointx at time t to the pointx1 at time t1 gives nonzero weight—determined by the0 0 exponentiated action—to all paths that go fromx as t goes from t to t , and zero weight to all otherx0 to paths.1 0 1 integral on a “space-time” that consists of just a single It is illustrative to consider a toy model of a path point. Then the possible “paths” of a scalar field, say, are simply the values that the field can take at the point, so they are real numbers.
The action is then an ordinary function let us consider the case where i S(x) on R. For the purposes of this example, S/ = −1 x2 +. ambda x3. The possible integrands are (sums of) powers of basic path integrals to perform are(x2)k . xp x(-, so the1 x2 +. ambda x3)dx, which we denote by xk. The value at2λ = 0

528

is easily calculated.7 For small. ambda we expand e^. ambda x3 as 1 +. ambda x3+λ2 x6/2+· · · , and evaluate each term by the same methods as forλ = 0. This is how we construct a well- defined perturbation theory, even when the integral isnot calculable. iest when the action is only quadratic in the variables, just as we found in the operator formulation of quan-As we see from this example, path integrals are eastum mechanics.
The mathematical reason for this isthat Gaussian integrals (exponentials of squares) can be done explicitly, while integrals involving exponen-tials of cubics or higher are difficult or impossible. For quadratic actions, the path integral can be evaluated exactly, but when cubic or higher terms appear, the perturbation series is necessary.

2.2.5 Quantum Field Theory

The generalization to field theories follows our earlier pattern. We think of quantum field theories, then, as being like quantum mechanics with infinite numbers of particles. In fact, the quantum field theories in which the fieldsΦ and their derivatives do not have more than quadratic terms in the action are easily understood inthis way—we had a preview of this in equation (4). The Fourier components correspond to particles indexed by their moment a. Each one looks like a simple harmonic oscillator at some frequency, which will depend on the Fourier coefficient.
The quantum Hilbert space is then a (tensor) product of lots of different “occupation num-ber Hilbert spaces,” one for each Fourier component of each field. Since the occupation number basis is alsoan energy eigenbasis, these states have a simple time evolution under the hamiltonian on some state$Ψ (t = 0)$, then that state evolves like H. That is, if H = EΨ (t) = . xp (i Et/ )Ψ (0).

higher However, if the action includes terms that are, then things get interesting: particles can decay!cubic or This can be seen, for example, from the scalar field ofequation (3) if we include a termφ3 in the action, and therefore also the Hamiltonian. If we write this using Fourier components, we get terms involving three oscillators, such aswe quantize the real field(a†)3(a†)4 a7. To see this, recall that afterφ, the Fourier components$7$. Consider. xp (-1 x2 + Jx)dx = . xp (-1 (x + J)2)$. xp (1 J2) dx$2$= . qrt{2π}$. xp2(1 J2).
2 Now if we differentiate this answer with respect towe get$x$. Taking k derivatives gives xk, and the theory is solved. J, and set J = 0,

IV. Branches of Mathematics

cfor the associated creation and annihilation operators.n act as harmonic oscillators, and we have written an Since the Hamiltonian governs time evolution accord-ing to equation (5), this means that over time one particle (the 7 mode) can decay into two others (the 3 andthe 4). Such decay processes occur in real life, and it is a great triumph of quantum field theory that it can predict such events with astounding accuracy.
dimensional, the path integral in quantum field theory is not usually defined in a mathematically rigorous way. In fact, because the space of paths of fields is infinite However, the perturbation series for producing predictions can be defined just as for quantum mechan-ics, and this is how physicists make their predictions in practice. This perturbation series is organized in terms of Feynman diagrams (which are discussed in vertex operator algebras and the rules for computing them, completely solve the[IV.17](/part-04/vertex-operator-algebras)). These diagrams, perturbation problem.
integrands of the path integral correspond to different As in the example of quantum mechanics, different predictions. If quantum field theory, we writeΦis some function of the fields of someΦ for the path inte- gral withΦ as an integrand (as we did for xk in the previous section). We call such a term a “correlation function.” If$Φ = φ (x ) · · · φ (x )$, the answer will depend on the action of the theory, the fields1 1 nn φ , andi

the space-time point sx .i

always remains a symmetry of the same theory after quantization. The answer is some times no. Such a case One might wonder if a symmetry of a classical theory is known as an “anomaly.” Roughly speaking, this is because the measure of integration of the path integral is not preserved under the symmetry, but thisis a some what heuristic explanation because the path integral has no rigorous definition in general. Returning to our cubic example, if the interaction termφ3 has a coefficientλ, so that it is λφ3, then we organize the perturbation series as a power series in In terms of paths,
probabilities of decay processes canλ. be evaluated by considering paths that split into two— like the letter Y—with each leg carrying the label of the appropriate particle.

2.2.6 String Theory

Feynman’s perturbation theory has an important gener-al ization in string theory. String theory considers particles not as points but as loops. Instead of paths ofparticles through space-time, we get paths of loops,

IV.16. Mirror Symmetry

which look like two-dimensional surfaces. String theory amplitudes are computed by summing over all surfaces. These sums are organized in a perturbation series in powers of the so-calledstant,λ^g. The power of λ^g in the perturbation series string coupling con- depends on the number of holes in the surface. The surfaces are called worldsheets. At each point of the worldsheet, its location in space-time is deter-mined by coordinates$X^{i}$. These coordinates them- selves depend on the location on the worldsheet. In effect, we get an auxiliary theory:
a field theory of coordinates on the two-dimensional surface! In string theory, even this two-dimensional field theory mustbe considered as a quantum field theory. The fields of the two-dimensional theory are maps from the sur-face to actual space-time. However, from the point of view of the worldsheet, the worldsheet itself is a two dimensional space-time and the maps are fields on space-time with values in some other (target) space.this study of these quantum field theories on two-dimen-Mirror symmetry was discovered as a result of the sional surfaces.
Subsequently, the same phenomenon was discovered in the case where the strings were not closed loops but filaments with endpoints. Both cases play an important role below. 3 Equivalence in Physics Mirror symmetry is a particular type of equivalence of quantum field theories. As we have seen, quantum field theories are rules for producing probabilities of physi-cal processes. In the path-integral formulation, probabilities are computed from correlation functions of fields. According to Feynman, these correlation functions can be thought of as being averages over all paths of fields.
Each path is weighted by expthe action of the path and is Planck’s constant. Let us$(i S/ )$, where S is denote the correlation function of some integrand theory A as Φ . Recall that Φ can depend on variousΦ in fieldsφi and points of space-time A xi, and the corre la- tion function will depend on all these and the action of theory$A$.φBi Equivalence, then, is a map from all possible fields such thatin a theory$A$to corresponding fields  ̃$φ^{i} \text{in a theory}Φ^{A} = Φ$ ̃B.

(For the moment, we deliberately neglect to notate the dependence on the point sx .) One special correlation i

function is denote by$Z$. As the field 1 always gets mapped to 1, we1 , which we call the partition function and

529

derive the corollary that the partition functions mustbe equal: Z = Z . formulation of the quantum theory. Each state Of course, this all has a description in the operator A BΨ and each operator corresponding state  ̃a in one theory must get mapped to aΨand operator  ̃a in the mirror theory, in such a way that corresponding operators map corresponding states to states which themselves correspond. Here one sees the sharp analogy with the slide rule and the operations of multiplication and addition of numbers.
mathematical model, so an equivalence implies a hostof mathematical identities between quantities con-Each theory is typically described through some struc ted from corresponding models. The particular case of mirror symmetry refers to an equivalence of quantum field theories on a two-dimensional surface. The most typical example of mirror sym-metry is the physical theory whose fields are mapsφ from a two-dimensional some target space, M . Such a theory is called a riemann surface [III.79](/part-03/riemann-surfaces)sigmaΣ to model role of actual space-time, but for our purposes we can.
As we saw above, in string theory M plays the even consider the case where M is the real line R, so thatφ is an ordinary function. This case has already been studied in section 2.1.5. The action is given inequation (4). We can then write the partition function as

$Z = 1 = [Dφ](e^{i})S(φ)/$,

where all paths.[D8φ] represents the measure of integration over is through a process known as Euclideanizes the time coordinate by writing One approach to evaluating the partition function Wick rotation. One first$τ = Zit$ (this is the Wick rotation), which leads to an imaginary Euclidean action i$S^{E}$. One then tries to evaluate the path integral in this framework, hoping that the answer willbe holomorphic [I.3 §5.6](/part-01/fundamental-definitions). If it is, then one can use analytic continuation to work out the answer for ordi-nary time.
The advantage is that the Euclidean exponential weighting becomes exp$(-S / )$, so the minima E of might converge. The nonconstant minima of the Euclid-SE receive the greatest weighting and the integral ean action are called equation (4), the action becomes the “energy”instantons. After Euclideanizing S of the E a theory with “supersymmetry,” meaning, in particular, that there are“fermionic” terms that complete the theory. We omit the fermionic8. Warning: these expressions represent only the “bosonic” part of completions for ease of notation and exposition.

530

mapφ: S = |∇φ|2. E meaning that it is independent of local scale trans-formations on the Riemann surface, that is, trans for-The energy of a map has aΣ conformal symmetry, ma tions that can be locally approximated by a com-bination of rotations and dilations. Invariance under rescaling by a positive number each of the two derivatives in|∇φλ|2 can easily be seen: decreases by a factor oftional invariance is clear from the form ofλ, while the area element increases by|∇λφ2|. Rota - 2.
The combination of the two, along with the fact that this argument did not depend on the derivatives of the scaling parameterλ, leads to the statement of local scale invariance. The conformal symmetry of the action is an example of a classical symmetry of the action that is not nec-essarily maintained in the quantum theory. However, the quantum theory has no anomaly—meaning that the symmetry is preserved—if M is chosen to be a complex, calabi–yau manifold [III.6](/part - 03/calabiyau - manifolds). plex notion of orientation.
Recall that for an oriented manifold one can continuously choose, on each patch, The Calabi–Yau condition can be thought of as a coma basis for the tangent space such that, when we move from patch to patch, the determinant of the change of-basis matrix is equal to one. The same is true on a Calabi–Yau manifold, but now we consider complex bases for the complex tangent spaces. the instantons are complex analytic maps from the two-dimensional surface. Instantons are not “close” to the When the target manifold is a Calabi–Yau manifold, constant paths;
their effects are therefore not accessible by perturbative methods such as Feynman dia-grams. They are therefore “nonperturbative” phenomena. An example from quantum mechanics would bea particle in a double-well potential such as(x2 - 1)2. The zero-energy minima are the two constant (station-ary) paths atx = ±1. An instanton path could go fromx = −1 to x = +1, or vice versa.
Such trajectories occur and are known as “quantum tunneling.” Lesson.tonic effects are notoriously challenging to calculate. Inaccessible by perturbation theory, instan3.1 Mirror Pairs In the setting above, we considered maps from a two-dimensional surfaceΣto a target (Calabi–Yau) space. Let us denote this quantum field theory by Q(M), which

IV. Branches of Mathematics

is shorthand for the collection of all fields and all pos-sible correlation functions created from them. In this setup, we say that the Calabi–Yau manifolds M and Wth rough the magic of mirror symmetry, hard problems are “mirror pairs” if Q(M) is equivalent to Q(W ).$in$ Q(M) involving instantons can be answered in Q(W ) by considering only the much simpler constant paths. 4 Mathematical Distillation A physical theory contains a tremendous amount of information.
For example, correlation functions can involve any number of fields, each evaluated at differ-ent points on the two-dimensional surface. This is typically too unwieldy a situation to approach mathemat i-cally. Instead, equipped with a symmetry of the theory called “supersymmetry,” a mathematical distillation can be performed. The distillation procedure is called topological twisting theory” has correlation functions that are independent, and the resulting “topological field of the positions of points.
Because of this independence, the correlation functions are certain characteris-tic numbers associated with the underlying geometric setup. In fact, there are two types of twisting, typically called A and B, which capture different aspects of the manifold in question.

4.1 Complex and Symplectic Geometry

4.1.1 Complex Geometry

To get a feel for the geometric aspect captured by topo-logical twisting, recall that we can construct the circle Sθ1+from the real line2π, and therefore also R by identifying the pointsθ +2πn, where n is any inte-θ and ger. What we have done is identified points related by a lattice of integer translations. We could choose the lattice to consist of multiples of some other real number rall scaling of, but since any two such lattices differ only by an over-R, we would effectively get the same space.
In the complex plane C, we can do the same thing with a two-dimensional lattice of translations generated bytwo complex numbers$λ^{1} and λ^{2}$, as long as the quo- tie nth as the same topology as any two-dimensional surfaceλ2/λ1 is not real. This space is called a torus and with one hole. It has more structure, however, because it can be covered by regions described by a complex coordinate—with different regions related by complexanalytic maps. The pairs(λ , λ ) and (λ , λ + λ ) generate the same lattice of translations, as do the pairs(λ , λ ) and (λ , -λ ).
In fact, lattices related b(y1()2()1()2)1 1 2 2 1

IV.16. Mirror Symmetry

a complex rescaling of parametrization of the lattice is the ratio C are equivalent, so a better$τ = λ /λ$. assume that the imaginary part of takes values in the upper half of the complex plane. By By redefining the direction of one of theτ is positive, so. ambda s, we ca(n2)1 τ the reasoning above, we note thatas-1/τ, all come from the same lattice. The numberτ and τ + 1, as wellτ can also be thought of in the following way. The torus has two distinct loops, one generated by a straight path from from$\text{zz toto zz} ++λλ^{1}$.
Then, and one generated by a straight path. ambda and . ambda are both the result of the line integral of the complex differential dloop. In fact, the loop did not even need to be straight2 1 2 z over the to lead to this conclusion. The values of such integrals over subspaces with out boundaries (the loops, here) are more generally called periods. one can show that there is no between two complex tori described by genuinely dif-Although any two tori are topologically equivalent, complex analytic map ferent values of mines the complex geometry of the space. Roughlyτ.
The parameter τ therefore deter- speaking, we think of this parameter as describing the shape of the torus. (See moduli spaces [IV.8 §2.1](/part-04/moduli-spaces) for a further discussion of this.)The topological B-model depends only on the complex geometry of the target space depends, continuously, only on the parameter M . That is, the theoryτ.

4.1.2 Symplectic Geometry

Another aspect of geometry is the which is described simply by an area element. Let ussize of the torus, recall that, topologically, all tori look like R2 with points identified by the lattice of integer horizontal and verti-cal translations (but not necessarily in a way that would respect any complex geometry). The points of the torus can be thought of as the unit square with opposite sides glued together. An area element in R2 looks like ρsquare.
These notions of two-dimensional area gener-dx dy , which then determines the area ρ of the unit alize to two-dimensional subspaces in higher-dimen-sional spaces. The study of such structures is called symplectic geometry symplectic parameter. [III.88](/part-03/symplectic-manifolds), and so we callρ the plectic geometry of the target space theory depends, continuously, only on the parameter The topological A-model depends only on the sym-M. That is, theρ.

4.2 Cohomological Theories

As you might imagine, the passage from an ordi-nary theory to a topological theory involves identifying

531

many aspects of the physical theory that were previ-ously distinct, such as different point values of a single field. Mathematically, a well-established method of pro-ducing topological aspects of a structure—and one that involves making identifications—is through aology theory [IV.6 §4](/part-04/algebraic-topology). Cohomology theories follow co hom the pattern of having an operator tionδ ◦ δ = 0. We think of this equation as the state-δ obeying the equa- ment image is formed as the quotient(δ) ⊂ ker(δ).
The cohomology group H(δ) = ker(δ)/ image H(δ)(δ), which means that we identify any two vectors$v satisfying δu = δv =$0, so long as the differenceu andu - v can be written as δw for some w. Then H(δ) is just the space of all such vectors, up to identifications. The topological twisting of physical theories is similar. The operatorδ is a physical operator acting on a Hilbert space of states. The presence of super symme-try in our theories ensures thatδ exists and squares to zero. The vector states of the topological theory are just the elements of$Ψ obeying δΨ =H(δ)$0, up to identification.
In many cases,, i.e., states in the original theory these states can be identified with ground states. contains the complex translations of points on the two-dimensional surface. This means that the value of a It is crucial that supersymmetry is a symmetry that field operator valueφ(z^ ) at another. In other words, the physics ofφ(z)at one point is identified with its the topological theory is independent of the positions of the operators!
In the path-integral formulation, this means that the correlation functions are independent of the positions of the fields inserted into the integrand. What can they depend on, then? They depend on the particular field or combination of fields inserted, and they depend on the geometric parameter (such asρ orτ) of the space M.

4.2.1 The A-Model and the B-Model

Given a Calabi–Yau space, one can actually construct two zero. There are therefore two distinct corresponding operators,δ^A and δ^B, each of which squares to topological twistings and two distinct topological the-ories that can be constructed from a Calabi–Yau space. wonder if the topological models constructed from If M and Ware mirror Calabi–Yau pairs, you might them will still be equivalent theories. The answer is amost interesting form of yes:
the resulting A-model of one Calabi–Yau manifold M is equivalent to the B-model of the mirror ple ct ic aspects of the theories get interchanged under$W$, and vice versa! The complex and sym-

532

mirror symmetry! In particular, a hard symplectic ques-tion of M might get mapped to an easy computation involving the complex geometry of W. be completely topologically distinct. For example, the Euler characteristic of one is the negative of the other. We emphasize here that the two manifolds may 5 Basic Example: T-Duality Although the circle is not complex, it provides avery illustrative entry into mirror symmetry that can be studied quite easily. We will find an equivalence between two theories constructed from circles.
The equivalence will be very nontrivial, however, as states of very different kinds will be shown to correspond. Consider the case where the two-dimensional surface is a cylinder, with spatial dimension a unit circle, andone dimension of time, and let us look at the sigma model (these were introduced in section 3). Suppose also that the target space is a circle of radius R, which we denote bytwo points identified if they differ by a multiple of 2(SR)1. We think of (SR)1 as the real line, withπR.
Maps from one circle to another can be classified by their winding number, an integer that tells you how many (net) times the image of a point goes around the second circle when the point goes once around the first. The mapnumbermθ. This allows us to write the field\to  m Rθ from the circle to (SR)1 has windingφ(θ) as a winding piece, winding):φ(θ)m Rθ= m Rθ, plus an honest Fourier series (no+ x + c . xp (inθ). Here we have singled out the constant mode Fourier series.
We have expanded just the(n. eq()0){n} x =θcdepend-0 of the ence in a series, so every continuous parameter (x and the well.cn) should be thought of as a function of time, as puted as in section 2.1.3: The energy, or Hamiltonian, of such a map is com H = (m R)2 + x ̇2$+ n |c$ ̇$n|^{2} + n^{2}|c^{n}|^{2}$. Comparing this with the harmonic oscillator Hamilto-nian of section 2.1.3, we can see that each degree of freedom mechanical particle in a simple harmonic oscillator cn(t) plays the role of a (complex) quantum- potential.
There is an occupation-mode basis for de-scr ib ing the quantum mechanics of each mode.9 The full Hilbert space of the quantum theory is the (ten-sor) product of each of these, plus parts involving the similarly for the imaginary parts of the9. Eacha†n = [Re(c ̇n) - in Re(cn)]/. qrtc2 nn. is a raising operator, and

IV. Branches of Mathematics

constant mode and winding number, which we now dis-cuss. (Remember, each degree of freedom of the classical theory becomes a theory.) particle in the quantum field The constant mod ex has energy  ̇x2, and therefore has no associated potential (it can be any where on the circle). This mode represents a free quantum-me-chanical particle on the circle. Recall that the momentum of thetor-i(d/dx)x. This operator has eigenfunctions ep article is represented by the opera-i px.
The requirement that these eigenfunctions are invari-ant under the translationx \to x + 2πR means that the eigenvalues of momentum are “quantized,” and have the form p = n/R. ber (from a circle to a circle. Although integral, it is clearly In contrast to momentum, the integer winding num-m) is really a classical label for the possible maps on a different footing from the integer Still, it is also an important label on the Hilbert space.n of momentum. For each tions which gets quantized to become them, we have a space of m-winding configura-mth sector of the Hilbert space.
Roughly, this sector the functions of all the degrees of freedom of all the Hm comprises mb er as an operator by simply declaring that the states-winding maps. We can consider the winding num- with winding number Ignoring the oscillator modes for the moment, them have eigenvalue m R. state of momentum(n/R)2 +(m R)2. In particular, the energy is unchangedn/R with winding m has energy if we make the simultaneous switches and R ↔ 1/R.
Since the oscillator modes(m, n) ↔a (n, m)have energies that are independent of modes are noninteracting particles, this symmetry can R, and since then be extended to a full equivalence of the theories with targets$S1 and S1$, with momentum in one theory corresponding to winding number in the other. In this example, the target space(R1)/R S1 is neither com- plex nor symplectic. As a result, we cannot construct the topological A- and B-models. Nevertheless, we have demonstrated the stronger statement that the two sigma models with target space S1 and S1 are equiva- lent.
The theories are mirror pairs. In the special case of circles, mirror symmetry is referred to as T-duality. In(R1)/R fact, the entire phenomenon of mirror symmetry—even for noncircles—can be deduced from T-duality.

5.1 Tori

If we take the product of two circles torus. We can think of the torus as a circle family of cir-(SR()1)1 . imes (SR()1)2, we get a cles, since for each point in(SR)1 2 we have a circle (SR)1 1. As

IV.16. Mirror Symmetry

we have seen in section 4.1.1, this space is complex—specifically, it is the complex plane C quotiented by a lattice of translations. A particularly simple lattice isthe one generated by the translation sz \to  z + R andztice is determined by the complex number\to  z+i R2.
As discussed in section 4.1.1 above, the lat-τ = i R1 /R , equal to the ratio of integrals (“periods”) of the complex form dz over the two nontrivial loops of the torus.2 1 Recall that we can choose coordinates that the identifications look like unit translations in The symplectic data is captured by the area element.x and y such each direction. Then the (normalized) area element ofthe torus with radii R and R is R R dx dy , which integrates tothe symplectic parameter R1 R2 on the unit square. Let us define1$ρ =2i R R$.
We now perfor(m1)2 T-duality for the first circle under this substitution, the complex and symplectic$(R1)1 \to 21/R1$. We see that parameters get interchanged:10 τ ←→ ρ.

Lessons.symplectic parameters. Mirror symmetry is T-duality. Mirror symmetry interchanges complex and

5.2 The General Case

The torus is the only compact one-dimensional Calabi–Yau space and is therefore the simplest one, but the discussion above is part of a more general picture. The Calabi–Yau condition ensures a unique complex volume element, or orientation (dods” determine, and in turn vary with, the complexz, above), whose “per i parameters.
Though the A- and B-models both turn outto be rather simple in the case of the torus, what is important in general is that the B-model is completely determined by how the periods of the complex volume element (which were with the parameters of the theory (of which there wasλ1 and λ2 in section 4.1.1) change just one in section 4.1.1, namelyτ = λ /. ambda is quite simple for the torus, but more com-τ). Again, the relation plicated in general. In any case, this data gives all the information of the B-model.
The reason for all of this is2 1 that the instantons of the B-model turn out to be just the constant maps. Each point of the target space determines a constant map, and as a result the B-model is reduced to (classical) complex geometry of the target space. This is determined by the periods. This state of affairs is to be compared with the Amodel. The A-model depends on the symplectic param-etersρ, i.e., the areas of two-dimensional surfaces the details for simplicity.10. The parametersτ and ρ can also have real parts, but we neglect

533

inside the target space. In contrast to the B-model, however, the dependence onρ is very complicated, in general. The reason for this is that the instantons of the A-model are area-minimizing surfaces inside the target space, and their enumeration is a notori-ously challenging problem. (The problem is not terribly challenging for the torus, however.) Mathematically, the A-model instantons are described by the theory of Gromov–Witten invariants, the subject to which we now turn.
6 Mirror Symmetry and Gromov–Witten Theory As we mentioned above, the B-model onentirely by the classical complex geometry of W is explained W. The only relevant maps for B-model computations are the constant ones, so the space of such maps is equal tograls over W itself, and correlators reduce to (classical) inte-W . In fact, one of the integrands to be inte- grated is the complex volume element. Let us call the parameter for all possible complex volume elementsτ. B-model correlation functions are then determined byτ-dependent integrals over W .
In particular, the parti- tion functionso we write it as(ZB)(W )Z(W )of the B - model on(τ). W depends on τ, The main point about topological twisting is that B local variations of the fields are all identified, as they are related by the operatorδ. In particular, varying the point on the worldsheet is a trivial operation in the topological theory. It turns out that, for the B-model on W, only the constant maps contributed, but for the A-model the situation is a bit more subtle. To give a feel for the geometry, consider again the winding of a map from a circle to a circle.
Maps with different windings can never be deformed continuously into one another. The winding number is a measure of how the first circle “wraps” (or winds) around the target, according tothe map. Because it is a discrete parameter it cannot change under continuous variations. Likewise, whenis a higher-dimensional space, the two-dimensional sur-$M$ faceof MΣby different amounts. The parameters for wrap-can “wrap” around two-dimensional subspaces ping are again discrete. A mapφ can wrap Σ around the basic surfac esk .
We say that Cki in= Mkby different integer amounts, labels the “class” of the map φis compact, andi. (More precisely, klabels its homology class.) Differ-φ(Σ)i is a closed 2 - cycle when Σ ent classes actions Sk(ρ)k , which depend on the areas contribute through different (Euclidean)ρ and the$534 class$φ . The partition function can have contributions fromk but not on the continuous details of the map all classes. Different classes may contribute differently not only through the exponential weighting, but also$k$ in accordance with how many contain.
(A good example of a minimal surface in three-minimal surfaces they dimensional space is a soap film. If you fix the boundary with a wire, the soap film will seek to find the minimumarea surface with that boundary.) In our examples, the space Mis actually complex; the minimal surfaces we speak of in Gromov–Witten theory are complex analytic maps fromΣ. That is, if you have a complex coordinate forcan be written as complex analytic functions ofΣ, then the complex coordinates for the surfacesΣ.
M comes from the fact that the topological model is con-struc ted from an operator The difference between the A-model and the B-modelδ, which was guaranteed to exist by the presence of supersymmetry in our theo-ries. For the different models, the relevant supersymmetry operators saw above, the maps relevant to the A-model are theδA and δBare simply different. As we instantons, or complex analytic maps from Roughly, then, A-model correlation functions onΣMto, and M.
in particular the partition function class esk of surfaces in M and sums over instantons in (ZA)(M), are sums over each class, each one weighted by its instanton action$\exp (-S (ρ))$. We have explicitly written the depend- ence on the parameter for the symplectic structure For Calabi–Yau manifolds, such maps should be dis-k ρ. crete, and it is a conjecture, true in all known cases, that they are finite in number if we fix the class, this data is packaged in a function ofρ, and based onk. All what we have argued, the partition function must take the general form

(ZA)(M)(ρ) = nk . xp (-Sk(ρ)).

The coefficients ants.11 nk are call edk Gromov–Witten invariand if we can identify for each complex parameter for Putting things together, if W a corresponding symplectic parameter(M, A) is mirror toρ(τ)(W , B)forτ, M, then we have ZA^(M)(ρ) = ZA^(M)(ρ(τ)) = ZB^(W )(τ). (6) The first equality means we should rewriteofτ, and the second says that the answer should beρ in terms gers, in fact they are only rational numbers. They can be expressed in terms of more basic integers, however. These integers are the ones11.
Though our discussion makes it seem as though thenk are inte- referred to at the beginning of this article.

IV. Branches of Mathematics

given by the corresponding B-model onall of the information about complex analytic surfaces W . Therefore, in completely determined by the classical geometry of M, which is encapsulated in the coefficients$n^{k}$, is W! of an infinite number of difficult Gromov–Witten invari-ants through equations such as (6)—is what led to such This remarkable predictive power—the computation intense interest in mirror symmetry at its inception. 7 Orbifolds and Nongeometric Phases

7.1 Nongeometric Theories

Mirror symmetry is about an equivalence of quantum field theories, and not every such field theory has the geometric content of a target space as in the sigma model. The structure involved in mirror symmetry—or at least its topological version—begins with a quantum theory with a supersymmetry algebra that allows for the passage to a topological theory. That is, there isa Hilbert space of states, a Hamiltonian operator, and a particular algebra of symmetries, i.e., operators that commute with the Hamiltonian.
There are no dictates as to how one constructs such a setup, and the sigma model of maps to a target space is only one such way. Other methods abound. The geometric case is merely the one most suited for mathematicizati on (and exposition), which is why we have focused on the theory witha target space. bly not—we will discuss the so-called orbifold theories. As an intermediate case—possibly geometric, possi7.2 Orbifolds When space-time is a cylinder S1 as its spatial dimension, there is a fascinating con-S1 . imes  R, with a circle struc tion in quantum field theory known as an theory.
This is defined as follows. Suppose there is a orbifold finite groupmetry). That is, each group element acts as an opera-$G$of symmetries (such as a reflection symtor on the Hilbert space, so ifg \in G then it sends a state by identifying states related by the symmetry. To con-Ψ to a state gΨ. Then one defines a new theory struct the theory, let us first consider the ground stateΨ0 of the original theory. This is assumed to be invari- ant under the group:
that is, elements, g.12 One then constructs the spacegΨ0 = Ψ0 for all group H of all a free particle on a circle (no potential at all), the ground state maybe a superposition of classical values of the field. For the circle, the12. In the case where there are flat directions of a potential, as in constant wave function location. It is still invariant under any group of rotations, however.Ψ = 1 is not associated with a single, classical IV.16. Mirror Symmetry invariant states. This is known as theandΨ is the ground state of the untwisted sector.
Inuntwisted sector, the case where then constructed for every group element0 G is commutative, a twisted sectorg \in G.13 Tois construct the twisted sector, first think of the spatial dimension S1 as being an interval [0, 1] with endpoints 0 and 1 identified. Recall that the Hilbert space of states is constructed from (functions of) all the degrees of freedom of the possible configurations of fields. The twisted sector Hcor responds to additional field configurations action ofgΦ: sothat are related at the two ends by the$Φ(g 1) = gΦ(0)$.
Such field configurations represent configurations on the circle$S^{1} \text{since left}$ and right ends are related by the group, and therefore get identified. These additional configurations are thus part of the orbifold theory. One constructs a sector$H$ of the Hilbert space by taking all such states also obey the invariance condition$hΨ = Ψ Ψ\text{for all}^{g} that^{g}g^{g}$

group elements Orbifolds may be geometric, as they are in the caseh. of the sigma model to a manifoldcrete group G acts. For example, rotations act on the X on which a dis- plane, and we can consider the four-element group gen-erated by a right-angle rotation. The quotient of the plane by these rotations looks like a cone. As another example, the finite groups of symmetries of the platonic solids (tetrahedron, cube, etc.) act on the two-dimensional sphere by rotations.
When we take$X = S^{2}$ and In fact, if we simply take the space of orbits of the G a platonic group, we get an interesting orbifold. group G, it is topologically just a sphere again, but not a smooth one—it has cone points. These cone points would be trouble some in a quantum field theory, but the “stringy” orbifold is perfectly “smooth.”The orbifold theory itself carries a symmetry. For example, if ments, then there is an untwisted sector and a unique G is the commutative group with two ele- twisted sector.
There is a symmetry corresponding to multiplication by 1 in the untwisted sector and by-1 in the twisted sector. This symmetry is not geomet-ric. Orbifold theories with symmetries can often themselves be orbifolded in such a way as to recover the orig-inal theory. In fact, the theory and its orbifold are also often mirror pairs! Greene and Plesser used such a con-struc tion to create the first examples of mirror pairs. Further more, they used ways of ascribing geometric interpretations to some non geometrically constructed which are the same as group elements when13.
The twisted sectors are properly labeled by conjugacy classes, G is commutative.

535

theories so as to identify mirror Calabi–Yau spaces. Tobe precise, they took the space of all nonzero complex 5-vectors equation$X = (X1$, X2$, X3$, X4, X5) satisfying the(X1)5 + (X2)5 + (X3)5 + (X4)5 + (X5)5 + τX1 X2 X3 X4 X5 = 0, identifying berλ. (If X Xis a solution, then so iswith . ambda X for any nonzero complex num-. ambda X.) The equation actually defines a family of complex spaces, since$τ \in C$ is a parameter. The orbifold theory is defined from the finite group of phase transformations

(X1, X2, X3, X4, X5)\to (ωn 1 X1, ωn 2 X2, ωn 3 X3, ωn 4 X4, ωn 5 X5), where space and its orbifold are actually the mirror pair aboutω = (e2()π){i}/ 5 an(d5)i=1 ni is a multiple of 5. This which Can del as et al. made their famous predictions. 8 Boundaries and Categories The entire story of mirror symmetry becomes much richer when we allow the strings to have endpoints. Strings with ends are called “open strings,” while “closed strings” refers to loops. Mathematically, allow-ing ends corresponds to adding boundaries to the worldsheet surfaces.
With this addition, we would liketo perform the same topological twisting. To do so, we must first ensure that some supersymmetry con-dition persists when we put the boundary conditions on the fields. If we begin with a Calabi–Yau target man-ifold, we can ask to preserve the conditions that allow either the A-twisting or the B-twisting (but not both: the boundary condition will destroy some symmetry, much as pinning a rope will constrain its degrees of freedom). After the twist, the boundary topological theory will depend on symplectic or complex information, respectively.
lie on a Lagrangian subspace. The Lagrangian condition constrains half the coordinates; for linear spaces it is For the A-model, the endpoints or boundaries must like a restriction to the real part of a complex vector space. For the B-model the boundaries must lie on a complex space. Locally, a complex space looks like C$n$ and a complex subspace is described by complex analytic equations in the coordinates. A boundary condi-tion that preserves supersymmetry and allows a chosen topological twisting is called aogy mimics the word “membrane,” but applies to any brane.
(The terminol dimension.) In short, A-branes are Lagrangian; B-branes are complex.

536

boundary theory, one appeals to the mathematical notion of a To package all the information of the topological category [III.8](/part-03/categories). A category is a way of talking about structure: it consists ofany pair of objects there is a space of objects morphisms, and for from one object to the other. Often the objects are mathematical structures of some kind and the morphisms from one object to another are the functions that preserve the relevant structure.
For example, if the objects are (i)spaces [III.90](/part-03/topological-spaces), (iii) groups sets [I.3 §2.1](/part-01/fundamental-definitions), (iv)[I.3 §2.1](/part-01/fundamental-definitions), (ii)vector spaces topological [I.3 §2.3](/part-01/fundamental-definitions), or (v) chain complexes, then the morphisms are, respectively, (i) maps [I.2 §2.2](/part-01/language-and-grammar), (ii) continuous maps maps [III.90](/part-03/topological-spaces), (iii)[I.3 §4.2](/part-01/fundamental-definitions), or (v) chain maps.
The morphism spaces homomorphisms [I.3 §4.1](/part-01/fundamental-definitions), (iv) linear between objects should be thought of as some kindof relational data. Morphisms themselves interact with one another, as they can be composed when the end object of one morphism is the start object of another. The composition is associative, so whether you com-puteabc as (ab)c or a(bc) does not matter. A use- ful image is a directed graph, which is a category with vertices as objects and paths between two vertices as morphisms. Composition is defined in this category by concatenating paths.
boundary conditions, we construct a category whose objects are branes (i.e., boundary conditions). The mor-In the case of a two-dimensional field theory with phisms between two branes states Hof the boundary field theory defined on theα and β are the ground infinite stripditionα on the left boundaryαβ [0,1]. imes R, where we put the boundary con-{0}×R and the conditionβ on the right boundary {1} × R. Morphisms are com- posed by gluing boundaries together, and associativity is guaranteed by topological invariance.14 comes the following statement:
two manifolds Mirror symmetry with boundary conditions then be-M and Wtwisting ofare mirror pairs if the brane category of the A-M is equivalent to the brane category of the B-twisting ofcal translation of this statement is called the W (and vice versa). The mathemat i-homologi- cal mirror symmetry conjecture the A-model side, the brane category is the so-called, due to Kontsevich. On themselves cohomology classes. At the “chain” level, before the topo-logical twisting, there is no associativity. The notion of a category14.
We speak of associativity of the topological states, which are with morphisms that have a cohomology and compose only “up to cohomology” is called an A. nfty  category. One can also imagine a cate- gorical definition that captures the structure of surfaces with handles and holes. Indeed, the proper mathematical framework for a complete understanding of mirror symmetry is still under construction.

IV. Branches of Mathematics

Fukaya category maps from surfaces with boundaries, where the bound-, and is governed by complex analytic aries must be mapped to Lagrangian branes. On the B-model side, the branes form a category determined by complex subspaces, together with complex analytic vector bundlestor bundle associates a complex vector space to every[IV.6 §5](/part-04/algebraic-topology) on them. A complex vec point. For example, the complex circle{x2 + y2 = 1} in Cplex analytic” means that this subspace of2 has a complex tangent space at every point. “Com-C2 changes in a complex analytic way.
For the complex circle, the space of tangent vectors at tip les of the vector(-y, x)(x, y), an assignment which isconsists of all mul- clearly complex analytic. Physically, the bundles arise from allowing charges on the endpoints of strings. egories of branes are equivalent. That statement is natural from the physics point of view, but by iden - Kontsevich’s conjecture asserts that these two cattifying the precise categories that correspond to the physical picture, this conjecture is a major contribution to the translation of mirror symmetry from physics into rigorous mathematics.
The equivalence of cate-gories means that not only is there a corresponding Lagrangian A-brane of M for every complex B-brane of Wbranes are also in correspondence., but that the relationships, or morphisms, between 8.1 Example: Torus Kontsevich’s conjecture can be proven and easily illus-trated in the example of a 2 - torus. Think of the nowfamiliar symplectic two-torus as being the two - dimen-sional plane, with integer lattice translations identified. We take the torus to have area element A dx dy, so that the symplectic parameter is the imaginary num - berρ = i A, as in section 4.1.2.
Now consider straight lines on the plane. These will correspond to closed cir-cles on the torus as long as they have rational slope: m = d/r , with d and r relatively prime integers. They are Lagrangian branes of the A-model boundary theory. The minimal-energy open strings connecting one line of slopem = d/r to another of slope m^ = d^ /r^ are those that have zero length. They are therefore the points of intersection. It is an easy exercise to show that there are|dr - r d | such points.
a complex paramete rr or pairs, we should set On the mirror side, we again have a torus, but withτ, and for the two tori to be mir-τ = ρ. The objects of the B- model brane category are complex vector bundles. It isa theorem that the basic bundles are classified by their IV.16. Mirror Symmetry rankr and degree d, two integers.15 It is customary to organize these two numbers into what is known as a “slope,”m = d/r (the nomenclature preceded this application), and basic bundles must haver relatively prime. d and spondence we have We can now easily guess that under the mirror corre slope←→ slope.
This means that a Lagrangian brane of slope torus with symplectic parameterρ should correspondm on the to aror torus with complex parameter complex vector bundle with slopeρ. Now suppose wem in the mir- have the B-model version of our example above, so wetake two vector bundles of slope m and m. In fact, the minimum-energy open strings between two com-plex analytic bundles of slopem and m correspond to complex maps between the bundles, and the[V.31](/part-05/the-riemannroch-theorem) counts this number as riemann–$|dr -$ roch formul ar d^ |.
This is the same result as for our A-model calcu- lation above! Therefore, corresponding objects relate in a corresponding way. Beyond the morphism spaces, one checks finally that the compositions of correspond-ing morphisms correspond, just as for logarithms and slide rules. Doing so proves Kontsevich’s conjecture.

8.2 Definition and Conjecture

In fact, Kontsevich’s definition of mirror symmetry is really a conjecture stating that the boundary notion of mirror symmetry as an equivalence of categories is compatible with, and even implies, the traditional notion of mirror symmetry that relates Gromov–Witten theory and complex structures. One way to show this is to try to reconstruct the Gromov–Witten invariants from the boundary theory. A heuristic, geometric approach to doing so involves looking at the diagonal boundary condition in two copies of a space.
A disk mapping into two copies of a space is described by two maps of a disk into the space. Further, if the boundary condition is diagonal, this means that the maps have to agree on the boundary. What we have, then, is two disks inside a space which agree on the boundary. That is exactly what a sphere is: two disks (or cups) glued together! The disks are the two hemispheres, and they are glued torus. The rank is the dimension of that space. The degree is roughly a measure of the complexity of the bundle. For example, if we have a15.
A vector bundle assigns a vector space to each point of the two-dimensional surface and consider the bundle that assigns to each point the tangent space at that point, the degree is equal to 2$- 2g$, whereg is the number of holes on the surface.

537

along the equator. Now the minimal disks are instan-tons for the open string (with boundary), and by gluing them together along a common boundary, we have constructed a minimal sphere, or closed-string instanton. Thus the open string on this double theory should recover the closed string on the original theory. formations as deformations of the category of branes. A more algebraic approach sees the closed-string de That is, a change in bulk (nonboundary) theory induces a change in boundary theory.
But once equipped with a category, one can classify its deformations intrinsically. That is, if one views a category as a fancy algebra,16 then, as the deformations of an algebra are easily clas-sified through a notion called Hochschild cohomology, the deformations of a category can be treated similarly. One arrives at the maxim that the closed string is the Hochschild cohomology of the open string.
By comput-ing the Hochschild cohomology of a brane category, one can, in principle, check this maxim, establish Kontse-vich’s conjecture, and then prove the connection to traditional mirror symmetry and Gromov–Witten theory. 9 Unifying Themes How does one find mirror pairs construction? Although mirror symmetry has spawned(M, W )? What is the many results and proofs, these basic questions con-tinue to vex. proof of mirror symmetry, which constructs mirror pairs but not through an evident mathematical chan-On the one hand, Hori and Vafa have given a physics nel.
Of course, one can attempt to mathematicize the physical argument, but that does not seem to lead to insights into the construction—perhaps because path integrals and other methods of quantum field theory such as renormalization are not very well understood mathematically. Batyrev has devised a procedure for constructing mirror pairs within the context of toric geometry. This method is a generalization, to a wide class of examples, of the original construction of Greene and Plesser. The recipe has been extremely successful in producing examples of every stripe.
However, the underlying meaning behind the construction is unclear. is a physical argument that makes contact with math-ematics, but it has not yet been made rigorous. The As for a geometric construction of mirror pairs, there argument uses T-duality. Start with the B-model onand consider a point P of M as a zero-dimensional M

16. An algebra is a category with one object.

538

complex subspace. Then the choice of point P onis parametrized by M itself. By mirror symmetry, there M should be a corresponding Lagrangian brane mirror manifold W . Further more, the choices of TTon the must equal the choices of P, i.e., the manifoldif we can find the brane T on W, we can parametrize the M . Therefore, choices of M of W from T , and recover W itself. M. So we can find the mirror to say about the structure of the Calabi–Yau spaces involved in mirror symmetry.
Specifically, the choices This construction is geometric and has something of a Lagrangian brane always look like a family of tori. Therefore, M itself should look like a family of tori. Further, one can argue that by performing T-duality infamilies of tori (in a similar way to how one does it for a single torus), one arrives back at the mirror manifold, W. This is what we did for the torus, thought of as a cir- cle family (member of the family, we found the mirror torus. So(SR()1)2) of circles (SR()1)1.
When we T-dualized each mirror symmetry is T-duality, and Calabi–Yau spaces of mirror symmetry should look like families of tori. This approach also relates to the homological mirror symmetry construction. Though promising, it remains mathematically elusive. Various points of view on mirror symmetry are helpful for different applications. To date, no unified under-standing of the phenomenon has been achieved. To some extent, we are still “feeling the elephant.” 10 Applications to Physics and Mathematics As a computational tool in string theory, mirror sym-metry is unparalleled in its power.
When combined with other physical equivalences, its power is multiplied. For example, there are certain equivalences in physics that relate one type of string theory to another. With out going into the details of string theory, we can get a flavor of its complexity by returning to mir-ror symmetry. Recall that the B-model was able to compute the difficult instantons on the A-model, yielding a great simplification of the two-dimensional quantum field theory on the worldsheet.
But this whole quantum field theory was just an auxiliary tool for computing some Feynman diagram for the perturb a-tion theory of the full string theory! Unfortunately, a satisfactory description of the full string theory path integral is, at the time of writing, way out of reach. String theory instanton effects are mostly unknown to us, unless a string equivalence or other argument can relate them to a perturbative effect in aent string theory. The perturbative string calculation differ-

IV. Branches of Mathematics

in that other theory may then be performed by exploit-ing mirror symmetry. Tracing through chains of equivalences in such a manner, many different phenomena in string theory can ultimately be calculated via mirror symmetry. perturbative and perturbative aspects of a single theory by outsourcing the calculations to equivalent theories In principle, one should be able to calculate all nonand exploiting mirror symmetry.
The barriers to doing this at the time of writing are largely technological, not conceptual. Beyond physics, the rich texture of mirror symmetry means that there is interesting mathematics to be discovered in the proper formulation of the problem. For example, defining the precise categories of branes in full generality remains a challenge. Yet there are also direct applications to mathematical questions. We have already discussed how enumerative geometry has been revolutionized by mirror symmetry and the counting of instantons. Results in symplectic geometry have also been obtained.
Occasionally, two objects may be proven to be equivalent as B-model branes. If the A-model mirrors can then be found, one has the result that the corresponding Lagrangian sub-spaces of the mirror symplectic space are also equivalent. Of course, to make such an argument, one must first prove Kontsevich’s version of mirror symmetry for the mirror pair considered. As a final recent example, Kapustin and Witten have found a relation of mirror symmetry to the geometric Langlands program in representation theory.
This program, loosely stated, is a correspondence between objects associated with two dimensional surfaces and Lie groups. From a surfaceΣ and a gauge group G, one constructs the space M of solutions to Hitchin’s equations. Central to that pro-gram are complex analytic objects on M that behave H nicely under the action of an algebra of operations. The Langlands correspondence relates two sets of such H objects: one easy to calculate and the other more dif-ficult. In fact M is itself a family of tori, and the easy objects correspond to points.
Mirror symmetry states that the points should turn into the tori under H T-duality, so the hard objects should correspond to the tori themselves! It is an appealing proposition, and making it precise mathematics will be difficult—but the gauntlet has been thrown down. The discovery that mirror symmetry relates to the geometric Langlands program has elicited great excitement among researchers and reveals yet another facet of this fascinating phenomenon.

IV.17. Vertex Operator Algebras

Further Reading

The article “Physmatics” (which can be found onlineat www.claymath.org/library/senior_scholars/zaslow_ physmatics.pdf) is a general discussion of the relationship between mathematics and physics, and may serve as a complement to this article. Readers with a university-level mathematics background who want to learn about mirror symmetry in more detail could try consulting the book Mirror Symmetry (Clay Mathematics Monographs, volume 1, edited by K. Hori and others (American Mathematical Society, Providence, RI, 2003)). IV.17 Vertex Operator Algebras

Terry Gannon

1 Introduction

Algebra is the mathematics that places more emphasis on abstract structure than on intrinsic meaning. The conceptual simplifications that can result when context is stripped away from structure give algebra a special power and clarity compared with other areas: compare, for example, the difficulty of visualizing fourdimensional space with the triviality of manipulating quadruples this abstractness can also blind us. For instance, basic(x1, x2$, x3$, x4) of real numbers.
However, identities likeab = ba and a(bc) = (ab)c that are obeyed by numbers can be modified in count less directions, and each modification defines a new algebraic structure, but it is hard to guess from a purely abstract perspective which of these modifications will give rise to a rich, accessible, and interesting theory. For guidance, algebra has traditionally turned to geometry. For example, over a century agogested that the identities ab = −ba lie and[VI.53](/part - 06/sophus - lie - 18421899) sug - a(bc) =(ab)c + b(ac) were worth studying for geometrical rea - sons:
the resulting structures are now called lie algebras has joined geometry in this guiding role and has had[III.48 §2](/part - 03/lie - theory). More recently, as we shall see, physics spectacular success. The renowned physicist and mathematician Edward Witten believes that a major theme of twenty - first-century mathematics will be its reconciliation with the branch of physics known as quantum field theory. Conformal field theory (the quantum field theory that under lies string theory) is an especially symmetric and well-behaved class of quantum field theories.
When this notion is translated into algebra, the result is a struc-ture known as a vertex operator algebra (VOA). This

539

article sketches where VOAs come from, what they are, and what they are good for. as absurd as to aim to explain quantum field theory in a few pages, but, undaunted, I shall try to do both. To aim to explain a VOA in a few pages is almost Obviously it will be necessary to gloss over many impor-tant technicalities and to commit major simplifications; with out question this exposition will raise the ire of experts and the eyebrows of knowledgeable amateurs, but I hope that it will at least convey the essence of this important and beautiful area.
Vertex operator algebras are the algebra of string theory: they should be thought of as the same sort of gift to the twenty-first century that Lie algebras were to the twentieth. 2 Where VOAs Come From The two most revolutionary developments in physics inthe early twentieth century are usually held to be relativity and quantum mechanics. They are revolution-ary not just because they have consequences that are extremely counter intuitive, but also because they pro-vide very general frameworks that can potentially affect all physical theories:
one can take a theory from classi-cal physics, such as the theory of the harmonic oscillator or the theory of electrostatic force, for example, andone can try to make it “relativistic,” so that it becomes compatible with relativity, or to “quantize” it, so that it becomes compatible with quantum mechanics. fully compatible with quantum mechanics. To put this another way, the ultimate concern of relativity is grav-Unfortunately, nobody knows how to make relativity itation, and a direct application to gravity of the usual quantizing techniques fails.
This ought to mean that a fundamentally new physics arises at small distance scales that we are ignoring. Indeed, naive calculations suggest that the space-time “continuum” at distance scales of around 10-35 m should deteriorate into some sort of “quantum foam,” whatever that might mean.(10-35 m is extremely small: for instance, the order of magnitude of the size of an atom is 10$-10 m$.) proach to quantum gravity is string theory. The elec-Perhaps the most popular and controversial aptron is aa point.
In string theory, the fundamental object is a particle, i.e., in principle it can be localized to string, a finite curve of length approximately 10$-35 m$. In place of the dozens of kinds of fundamental particlesin the generally accepted quantum field theory, there is only one string, whose precise physical properties(mass, charge, etc.) depend on its current “vibrational mode.”

540

a worldsheet. For reasons that we will sketch below, much of string theory reduces to studying confor-As the string moves, it traces out a surface called mal field theory, which is the induced quantum theory on these surfaces. Probably no other structures have affected so many areas of “pure” mathematics in so short a time as string theory and, what is essentially the same thing, conformal field theory. Indeed, five of the twelve Fields Medals awarded in the 1990 s (namely, those to Drinfel’d, Jones, Witten, Borcherds, and Kontsevich) were for such work.
We shall focus in this arti-cle on their algebraic impact; see mirror symmetry [IV.16](/part-04/mirror-symmetry) for some geometrical implications.

2.1 Physics 101

A quick over view of physics will be useful for the discussion. Further details can be found in mirror symmetry [IV.16 §2](/part-04/mirror-symmetry).

2.1.1 States, Observables, and Symmetries

A physical theory is a set of laws that govern the behav-ior of some kind of physical system. A state of that system is a complete mathematical description of the system at a particular time: for instance, if the system consists of a single particle, then we could take its state to be its positionx and momentum p = m(d/dt)x (where measurable quantity such as position, momentum, orm is its mass). An observable is a physically energy. It is through observables that a theory is com-pared with experiment.
Of course, for this to be true we also need to know what an observable is from a theoretical point of view. ical function of the state. For example, our single particle has energy In classical physics, an observable is just a numer-E, which depends on the posi- tion and momentum via a formula of the form$(1/2m)p^{2} + V (x)$. (This gives us the kinetic energy E = plus the potential energy.) Classical states at different times are related by the equations of motion, which are usually expressed as differential equations.
However, string theory and conformal field theory (CFT) are quantum theories, which are significantly different from classical theories: one can think of them as “applied linear algebra.” Where as a classical state was given by acollection of a few numbers (two, in the case of the particle above), a quantum state is an element of a hilbert space can think of as a column vector with infinitely many[III.37](/part-03/bayesian-analysis), which for the purposes of discussion we complex entries.
As for a quantum observable, it is ahermitian operator [III.50 §3.2](/part-03/linear-operators-and-their-properties) on the Hilbert space,

IV. Branches of Mathematics

which we can think of as an. nfty × . nfty matrix ˆA that acts on the states by matrix multiplication. As in classi-cal physics, one of the most important observables is energy, which is given by the Hamiltonian operator Hˆ. states to states has anything to do with the notionof a physical observation, and indeed the relationship It is far from obvious how a linear operator that takes between observables and observation is a major differ-ence between classical and quantum theories.
If ˆA is an observable, then the tells us that the Hilbert space has anspectral theorem orthonormal[III.50 §3.4](/part-03/linear-operators-and-their-properties) basis the experiment that is modeled by the observable ˆ[III.37](/part-03/bayesian-analysis) of eigenvectors [I.3 §4.3](/part-01/fundamental-definitions). When we do A, the answer we obtain will be one of the eigenvalues of ˆA. However, this answer is usually not fully deter- mined by the state bility distribution: the probability of obtaining a par-v .
Instead, it is given by a proba- ticular eigenvalue is proportional to the square of the norm of the projection ofv into the corresponding eigenspace. Thus, the only circumstances under which the answer is determined in advance are if the state$v$ is an eigenvector of ˆThere are two independent ways in which a quan-A. tum state can evolve in time: a deterministic evolu-tion between measurements, governed by the famous schrödinger equation and discontinuous one that occurs at the instant when[III.83](/part-03/the-schrdinger-equation), and a probabilistic a measurement is made.
For our purposes, only the deterministic evolution will be relevant. see. Symmetries in physical theories are highly desir-The symmetries of CFT are extremely rich, as we shall able because of two consequences that they have. First, they lead by noether’s theorem [IV.12 §4.1](/part - 04/analysis) to conserved quantities For example, the equations of motion of our particles, i.e., quantities independent of time. are usually invariant under translation: for instance, the gravitational force between two particles depends only on the difference between their positions.
The cor-responding conservation law in this case is the conservation of momentum. A second consequence of symmetries in quantum theories is that infinitesimal generators of the symmetries act on the state space$H$(the Hilbert space to which the states belong), forming a representation of the Lie algebra. Both consequences are important to CFT. 2.1.2 The Lagrangian Formulation and Feynman Diagrams We will need two of the languages in which physics is written. One is the Lagrangian formalism, which is IV.17.
Vertex Operator Algebras responsible for the relationship between string theory and CFT, as well as for the appearance of modular functions in string theory. The other is the Hamiltonian bra arises. Vertex operator algebras try to explain theor Poisson bracket formalism, which is where alge“miracle” that these two formalisms cohere. The Lagrangian formalism can be expressed classically through Hamilton’s action principle. When there are no forces present, particles travel in straight lines, which are the curves of shortest length.
Hamilton’s principle explains how this idea generalizes to arbi-trary forces: instead of minimizing length, the particle minimizes a related quantity S called the action. to Feynman. He expresses the probability of measuring the system in some final (eigen)state The quantum version of Hamilton’s principle is due|out , given that it was originally in some initial state integral” of ei S/ over all possible histories that connect|in, using a “path |in and |out . The details are not important for us (and in any case are mathematically dubious in general).
the intuition behind the path integral formulation is that the particle simultaneously follows every one of those histories, and each of them contributes to the probability.as$\to \text{is called}$0, the contribution from the path that satisfies Planck’s constant ; in the “classical limit” Hamilton’s principle dominates everything else. The main use of Feynman’s path integral is in perturbation theory. Finding exact solutions in physics is typi-cally impossible and rarely useful. In practice, it suffices to find the first few terms in some Taylor expansion ofthe solution.
This so-called “perturbative” approach to quantum theories is particularly transparent in Feyn-man’s formalism, where each term of the expansion can be represented pictorially as a graph. See figure 1(a)for typical examples. The graphs contributing to the nnth-order term in this Taylor expansion will involve vertices. Feynman’s rules describe how to convert these graphs into integral expressions for computing the individual terms in the Taylor expansion. In this article we are interested in perturbative string theory.
The string Feynman diagrams (see figure 1(b)for three equivalent ones) are surfaces called worldsheets these surfaces are much less singular than the particle; the need for quantum foam is avoided because graphs (which have singularities at each vertex), and this is also largely why the mathematics of strings is so nice.
To cut a long story short, each term in the per-tur ba tive expression for probabilities in string theory can be calculated from a quantity called a “corre la-tion function” in a CFT that lives on the corresponding 541 (a) (b) Figure 1(a) particles and (b) strings. Some Feynman diagrams of worldsheet. Feynman’s path integral here amounts tothe integral of a quantity that CFT can compute, over some The vertices in a Feynman diagram represent places moduli space [IV.8](/part - 04/moduli - spaces) of surfaces. where one particle absorbs or emits another.
The corresponding rules of string theory tell us that we should dissect the worldsheet into “tubular Y - shapes,” or spheres with three legs, as in figure 2. Since these spheres with legs play the role of vertices in the Feyn-man diagram, the factor they contribute to the integrand of the path integral is called aand now it describes the absorption or emission of vertex operator, one“algebra” of these vertex operators.string by another. A vertex operator algebra is the 2.1.3 The Hamiltonian Formulation and Algebra The Poisson bracket\\.
\1, B\. of two classical observ - P ables A and Bis defined to be . artial A. artial x . artial B. artial p - . artial B. artial x . artial A. artial p . Note that son bracket is\. \1}, B\. anti - commutative P = −\\. \1, A\\. \1: in other words, the Pois-. It also satisfies the

Jacobi identity{A}, \\. \1, C \\. \1 P + . \1, \\. \1, A\\. \1. \1 + . \1, \\. \1, B\\. \1. \1 = 0, and therefore defines a Lie algebra. The hamiltonian formulation of classical physics expresses the evolution of an observable equation ̇$A = . 1$, H\\, where Aby means of the differential H is the hamiltonian P

542

Figure 2 Dissecting a surface.

[III.35](/part-03/hamiltonians): that is, the energy observable. The quantum version of this picture is due to Heisenberg and Dirac: the observables are now linear operators rather than smooth functions, and the Poisson bracket is replacedby the commutator[A,ˆB]ˆ= Aˆ◦ Bˆ- Bˆ◦ Aˆ of operators. This again has the anti-commuting property-[B,ˆA]ˆ and again satisfies the Jacobi identity, so the[A,ˆB]ˆ$=$ process of “quantization” gives rise to a homomor-phism of Lie algebras. The derivative with respect to time of a quantum observable ˆlogue of the classical case:
it is proportional to A is then the natural ana-[A,ˆH]ˆ , where ˆH is the Hamiltonian operator. Thus the Hamil- tonian has a dual role: as the energy observable and asthe controller of time evolution. All of physics is stored in the action of the observables on state space H , as well as the commutators of these observables with ˆLet us illustrate this picture with the quantum spring H., also known as the harmonic oscillator. The position and momentum observables ˆthe infinite-dimensional space$x$, ˆp are operators acting on H of possible spring- states.
It is more convenient to work with certain combi-nations of them called ˆ$a$and ˆa† (the dagger denotes the “Hermitian adjoint,” or complex-conjugate transpose), which obey the commutator relation[a,ˆ$a$ˆ$†] = I$, where Iobservables can be built from ˆis the identity operator. It turns out that all other$a$and ˆ$a^{†}$. For example, the Hamiltonian ˆstantl. The vacuum H is, which is denote dl(aˆ†aˆ+1 2 ) for some positive con-|0 , is the state of minimum energy. In other words, the state$|0 is$ an eigenvector of ˆ$H$ˆ|0 = E |0 for some Hwith smallest possible eigenvalue:
E \in  R and all other eigenvalue Eaˆ|$of ^{0}$=H0. To see why, consider the effect of ˆare greater than0 0$E0$. It follows from this that Hon ˆ$a|0$: $H$ˆ$a$ˆ$|0 = l(a$ˆ†aˆ$+1 2)a$ˆ$|0 = l(a$ˆ$a$ˆ$† -1 2)a$ˆ$|0 = al($ˆ$a$ˆ†aˆ$-1 2 )|0 = a($ˆ$H$ˆ$- l)|0 = (E0 - l)a$ˆ|0 . Here, we have used the fact that ˆobservables ˆ$a$and ˆa† are called creation and annihila-a†aˆ$= a$ˆ$a$ˆ† - I. (The

IV. Branches of Mathematics

tion operatorsbe interpreted as adding or removing a particle from a because, as we shall see later, they can certain they pro du cen-particle state. Showing this uses the fact that±I when you interchange their order.) This calculation shows that if ˆa|0 is not zero, then it is an eigenvector of ˆE , which is a contradiction. H with an eigenvalue smaller than$12$ l Since ˆ. We now define, for each positive integer$a|0 =$0, it follows that ˆH|0 =1 2 l|0 n, so, a state E0 =|n to be (aˆ†)n|0 ∈ H . Similar calculations to the one just given show that$|n \text{has energy} E^{n} = (2n + 1)E^{0}$.
For example, $H$ˆ$|1 = l(a$ˆ†aˆ$+1 2)a$ˆ$†|0 = l(a$ˆ†(aˆ†aˆ$+ I) +1 2a$ˆ$†)|0 = 3 2 la$ˆ$†|0 = E1|1$.

(Note that we used the fact that$a|0 = 0 \text{in the penul}-$ timate equality above.) We think of the vacuum as the ground state, and|n as being the state with n quantum particles. These states|n span all of the state space H . To see how some observable acts on some state, one writes the observable in terms of the basic observables$a$ˆ, ˆa† and the state in terms of the basic states |n . In this algebraic way we can recover all of the physics. This idea of building up the whole space H from the vacuum and the operators is a fruitful one in mathematics as well:
something similar happens for the most important modules of most of the important Lie algebras.

2.1.4 Fields

A classical ues can be numbers or vectors, which represent quan-field is a function of space and time. Its val ti ties such as air temperature or the current in a river. The values taken by at her more, a quantum field is not a quantum field are operators; fur-function of space and time, but a more general object called a[III.18](/part-03/distributions). The prototypical example of a distribution is the distribution Dirac delta functionδ(x - a). Despite its name, this is not a function: rather, it is defined by the property that

f (x) δ(x - a) dx = f (a) (1)

for any sufficiently well-behaved function thoughδ(x - a) is not a function, one can informallyf (x). Even interpret it as the derivative of a step function, andone can visualize it as equaling 0 every where except at x = a, where it is infinite, in such a way that the infinitely tall and infinitely thin rectangle under the graph has area 1. However, it really only makes sense inside an integral, as in (1). Similar remarks apply to

IV.17. Vertex Operator Algebras

distributions in general, so a quantum field can really only be evaluated inside an integral of space and time, applied to some “test function” likeof such an integral will be an operator on the statef above. The value space H. takes Poisson brackets of classical fields. Similarly, commutators of quantum fields involve delta functions Dirac deltas appear in classical mechanics when one too.
For example, in the simplest cases the quantum fieldsφ satisfy[φ(x, t), φ(x$, t)] = 0, \}|\}φ(x, t)$, . artial t. artial φ(x$, t) = i δ(x - x)$.⎪⎭ (2) This is a mathematical way of expressing, in the context of quantum field theory, the cherished physical principle called locality:1 the only way we can directly affect something is by nudging it. In order to influence some-thing not touching us, we must propagate a disturbance from us to it, such as a ripple in water. The main pur-pose of both classical and quantum fields is that they provide a natural vehicle for realizing locality.
Localityis also at the heart of vertex operator algebras. An important aspect of modern physics is that many of the central concepts of classical physics become less central, and are instead derived quantities. For example, the basic object ofa Lorentzian manifold, and familiar physical quantities general relativity [IV.13](/part - 04/general - relativity - and - the - einstein - equations) is such as mass and gravitational force are, from the point of view of this manifold, just names (that are not wholly precise) given to certain of its geometrical features. Particles are obviously essential
to classical physics, but we have not mentioned them in our brief sketch of quantum field theory. They arise through the so-called modes of quantum fieldsφ, which play the role of the operators ˆ$a$, ˆa† that we met in section 2.1.3. A mode is the operator that results from hitting the quantum field with an appropriate test function and integrating—just as one does when working out a Fourier coefficient, in which case the test functions are trigonometric functions [III.92](/part - 03/trigonometric - functions). In fact, when viewed appropriately, modes actually kind.
The commutators of these modes can be obtained are Fourier coefficients of a certain from the commutators of the fields. Now, recall that the vertex operators of string theory are related to the not even light can connect two given space-time points, then the quan-tum fields at those points must be causally independent. In particular,1. More precisely, for quantum fields, locality takes the form that if measurements at such points can be performed simultaneously with arbitrary precision. In quantum theories, this requires those operators to commute.
Equation (2) is a generous way to satisfy locality. 543 emission and absorption of strings. As we shall see shortly, these vertex operators are the quantum fields in a quantum field theory of point particles (namely, the associated conformal field theory); the modes of these vertex operators generate the “particles” (or in more conventional language, themal field theory. Equivalently, they generate the various states) in that con for vibrational states of a single string in that string theory.

2.2 Conformal Field Theory

Awith a two-dimensional space-time whose symmetries conformal field theory (CFT) is a quantum field theory include all what this means in the next paragraphs, but for now itconformal transformations. We shall explain is enough to know that a CFT is a particularly symmet-rical kind of quantum field theory. A CFT lives on the worldsheet some times colliding and separating, through time. InΣ traced by a set of strings as they evolve, this subsection we shall informally sketch their basic theory; in section 3.1 we shall be more precise. sions, has two almost independent halves.
This is eas-iest to see in the context of string theory: the ripples CFT, like any quantum field theory in two dimenon the string are responsible for the physical proper-ties (charge, mass, etc.) of the corresponding state, but they can move (at the speed of light) either clockwiseor counter clockwise around the string. When they do so, they just pass through each other with out inter-acting. These two alternatives, clockwise and counter clockwise, yield the two CFT, one first analyzes its chiral halves and then splices chiral halves of CFT.
To study a them together to form the “bichiral” physical quanti-ties. Almost all attention in CFT by mathematicians has focused on the chiral (as opposed to physical) data, and indeed that is where vertex operator algebras live. For ease of presentation, we will usually suppress one of the chiral halves. A conformal transformation is a transformation that preserves angles. The simplest reason one can give for why two dimensions are so special for CFT is that there are far more conformal transformations in two dimensions than there are in higher dimensions.
When n >bi nations of translations, rotations, and enlargements.2 the only examples are the obvious ones: com This means that the space of all local conformal trans-formations in R(nn)+2 nis far richer: it is= 2 the space of local conformal transformations isinfinite2 dimensional. However, when dimensional. Indeed, if you identify R2 with the complex plane C, then any morphic function [I.3 §5.6](/part-01/fundamental-definitions)f (z) that does not haveholo-

544

zero derivative at a pointa CFT is invariant under conformal transformationsz0 is conformal near z0. Since and there are many conformal transformations, a CFTis especially symmetrical: this is what makes CFTs so interesting mathematically. Lie algebras arise naturally whenever one has local symmetries, and indeed one can form an infinite-dimensional Lie algebra out of the infinitesimal conformal transformations. This algebra has a basis that obeys the Lie-bracket relationsln, n \in  Z,[lm, ln] = (m - n)lm+n. (3)

The algebraic interpretation of the conformal symmetry of CFT turns out to be that these basis elements act naturally on all the quantities in the theory, as we$l^{n}$ shall explain below. The basic example that under lies all the others is when space-time sponding to an in coming string. It is parametrized byΣis a semi-infinite cylinder corretimet < 0 and the angle 0 ⩽ θ < 2π around the string. We can conformally map the cylinder to the punctured disk in C byz = (et()-i)θ, so t = −$\infty$ corresponds toz = 0. This allows us to say what we mean by conformal symmetries of the cylinder.
ators of string theory. As always, these quantum fieldsφThe quantum fields are “operator-valued distributions” on space-timeφ(z) of CFT are the vertex oper-Σ, acting on the space H of states. Now it is possible for a field First, you calculate its modesφto be “holomorphic,” in the following sense.φ , one for each n \in Z, which are linear maps from the state space given by the formul an H to itself,φn = φ(z)(zn)-1 dz,

where the integral is around a small circle about the origin. Then you take these modes as the coefficients ofa formal power seriesφ zn. We call φ holomor- phic if this formal power series can be identified withφ, in a sense that we shall discuss more in section 3.1. An\in  Z)n typical field bin at i on of holomorphic and anti-holomorphic fields,φ(z)is not holomorphic: rather, it is a com which make up the two chiral halves of CFT. We will focus on the space of holomorphic fieldsφ(z), which we call V.
This turns out to form a vertex operator algebra (as do the anti-holomorphic fields).For example, the most important vertex operator comes directly from the conformal symmetry: the stress-energy tensor T (z) ∈ Vis the “conserved current” that Noether’s theorem associates with the conformal symmetry. Labeling its modes (Noether’s

IV. Branches of Mathematics

“conserved charges” here) bythat T (z) = L (z-n)-2, we find that they Ln = T (z)zalmos(t-n)-3 dzreal-, so ize the conformal algebra: instead of (3), however, they$n^{n}$ obey the slightly more complicated relations $[L^{m}$, Ln] = (m - n)(Lm)+n + δn$, {}^{-}m m(m122 - 1) c I$, (4) where and I form an extension of the conformal algebra by I is the identity. In other words, the operators LIn. The resulting infinite-dimensional Lie algebra is called the Virasoro algebra Vir. The numberc appearing in (4) is called the measure of its size.central charge of the CFT and is a rough formal algebra (3).
Instead, they form a so-called tive representation The operators$Ln$. Projective representations of sym-do not precisely represent the con-projec- me tries, such as (4), are common in quantum theories. The fact that they are not true representations is not a problem, since one can turn them into true re pre sen-tat i ons by extending the algebra. In our case, the state space Virasoro algebra H carries inside it a true representation of the Vir, which is useful as it means Vir can be used to organize H.
field correspondence its in coming state, which is the limit as the time Any quantum field theory has what is called a: with each fieldφ one associate st state–tends to−$\infty$ of φ|0 (as always, |0 is the vacuum state in H and field correspondence is a bijection. This means we canφacts on states). CFT is unusual in that the state identify We want to make H and Vand use states to label all fields. V into some sort of algebra, but the obvious direct approach of taking productsφ1(z)φ2(z) fails, since distributions, unlike true func- tions, cannot in general be multiplied.
For example, the Dirac deltaδ(x - a) cannot be squared with out causing problems in (1). However, even if the prod-uctφ (z)φ (z) does not make sense, one can make sense ofbution on1φΣ1 2(z2. It is then possible to recover most of1)φ2(z2) as an operator-valued distri- the physics of CFT by studying the singular terms asz \to  z . By the operator product expansion, we mean expanding products2(z -1 z )h O (z )φ. The set1(z1)φ2(z V2)is closed under thisas sums of the form product in the sense that each coefficient inh V .
A typical example i(s1)2 h 1 Oh(z) lies T (z1)T (z2) =1 2 c(z1 - z2)-4 I + 2(z1 - z2)-2 T (z1)+ (z1 - z2)ddz T (z1) + · · · .

Physicists call V a chiral algebra; for us it is the prototypical example of a vertex operator algebra. It is not an

IV.17. Vertex Operator Algebras

algebra in the conventional sense though, since, given vertex operatorsφ (z) and φ (z), we have not just a single product productsφ (z)φ* 1(z)1φ*(z)φ2=(z)Oin2(z)V, all belonging tobut infinitely many V . field theory; here it turns out to be proportional to the mode The Hamiltonian plays a crucial role in any quantum L discussed earlier. Being an observable,1 h 2 h L is diagonalizable on H can be written as a sum0 H, which means that any statev, where v \in H v0 has\in(hh)h energy There is a special class of CFT that is particularly h: that is,$L^{0}v^{h} = hv^{h}. well-behaved.
Le. art V denote the space of all anti-holo- morphic fields in the CFT—it is the other chiral half. Recall that the full CFT consists of Van. ard V spliced together. We call the CFT rational if V ⊕ . arV is so large that it has finite index, in an appropriate sense, in the full space of quantum fields in the CFT. The name “rational” arises because the central chargec and other parameters in a rational CFT have to be rational numbers. Let us briefly look at one example. (We will use several The mathematics of rational CFT is especially rich.
words that will be unfamiliar to most readers, but at least it will give some idea of which areas are touched by CFT.) As with everything else, the quantum prob-abilities arising in CFT are found by first computing chiral quantities and splicing them together. These chiral quantities are called are found using simple Feynman-like rules applied toconformal or chiral blocks, and dissections like figure 2. In rational CFT we get a finite-dimensional space F of chiral blocks for any world- sheet of punctures.
These spaces carry projective re pre sen-Σ, i.e., for any choice of genusg, n g and number n tat i ons of the mapping class group the fundamental groupπ of the moduli spaceΓg, n(defined to be M ). This Jones’s relation of theΓ^{g}$, n-representation is the source, for instance, of braid group1 [III.4](/part-03/braid-groups) (and henceg, n knots [III.44](/part-03/knot-polynomials)) to subfactors, Borcherds’s explanation of “Monstrous Moonshine,” the Drinfel’d–Kohno mon-odromy theorem, and the modularity of affine Kac Moody characters. Some of this we will touch on in section 4.
The most important example here is the torus, where the chiral blocks are functions of fundamental mathematical importance. Amodular functions, a class of modular function is a meromorphic function (that is, a function that is holomorphic except at a few “poles” where it can tend to infinity)the upper half-plane H= {τ \in  f (τ)C | Imthat is defined onτ > 0} and that is “symmetric” with respect to the group SL2(Z) of 2 . imes 2

545

matrices with integer entries and determinant 1, in the sense that for any such matrix(a b ) the function f (τ) is closely related (though not necessarily exactly equal)to the functionf ((aτ +b)/(cτ +c dd)). We shall discuss this further in section 3.2.The appearance of modularity can be understood by recalling from section 2.1.2 that Feynman’s path inte-gral in string theory is an integral over moduli spaces. The moduli space the quotient of the half-plane M1^,0 for the torus can be written as H by the action of SL (Z).
Therefore, if one lifts the integrand of Feynman’s inte-gral from M to H, one obtains a function Z(τ)2 that is invariant under Sl grand Z(τ)1 is a quadratic combination of the chira(l,()0){2}(Z) and hence modular. This inte- blocks for the torus. 3 What VOAs Are It is possible to give a fully axiomatic definition of ver-tex operator algebras. However, when one first encounters this definition (and not just the first time either)it can seem very complicated and arbitrary, and one is given no feel for the importance of VOAs. Our treatment below will be much more in formal:
this will clarify their importance even if it hides much of their complexity. Thanks to the previous section, it is possible to givea quick justification for VOAs: if you concede that CFT (or equivalently, perturbative string theory) is important, and if you have seen how closely related CFT is to VOAs, then you must concede that VOAs are important. However, this is not the whole story, as we shall see. 3.1 Their Definition Let us begin by defining them in terms of other con-cepts that must themselves be defined:
a vertex operator algebra is an algebra of vertex operators, or in other words the chiral algebra Vof a conformal field theory. The most important thing to understand in this definition is that a vertex operator is a quantum field, which, as we have seen, is an “operator-valued distribution of space - time.” So we can think of it informally as a matrix-valued function of space - time, where the matrix is. nfty . imes. nftyand its entries can be generalized functions like the Dirac delta (1). However, we shall give a much better description of these vertex operators shortly.
tured atretically this set corresponds to a semi-infinite cylin-By “space-time” we mean the unit disk inz = 0. Recall from section 2.2 that string-theo-C punc- der parametrized by the angle$-π < θ ⩽ π running$ around the string as well as the time−$\infty$ < t < 0

546

running along the axis: the map from this to the punc-tured disk was(θ, t) \to z = (et()-i)θ. We want to restrict our attention to quantum fields that depend holomor-ph ically on$z$. However, it is not obvious what “holomorphic” means for distributions. We touched on this question in section 2.2: now we shall look at it in more detail. To do this, we need a more concrete description of a vertex operator. The key idea is a very convenient algebraic interpretation of holomorphic distributions.

Consider the sum

$d(z) = n=−\infty\infty z^{n}$. (5)

Multiply it by$f (z) = 3z^{-2} - 5z^{3}$, say. This gives usf (z)d(z) = 3 n=−$\infty$. nfty zn-2 - 5 n=−$\infty$. nfty zn+3 = 3 n=−$\infty$. nfty zn - 5 n=−$\infty$. nfty zn = −2 d(z). A few more examples like this will convince you thatf (z)d(z) = f (1)d(z) for any polynomial function f ofz and z-1. Therefore, d(z) behaves exactly like the Dirac deltaδ(z - 1), at least for polynomial test func- tions positive powers have a convergent sum only forf . Note that d(z) cannot converge for any|zz|: the$< 1$, and the negative powers only for$|z| >$1.
The “function”seriesd(z). nfty  is an example of aanzn, where the coefficients formal power series$a^{n} \text{can be}$: any anything and we ignore all convergence issues. By inspection, these formal power series are “holo- n=−. nfty morphic” through out the punctured plane: after all, holomorphic just means that the complex derivative dmal power series clearly remains a formal power series./dz exists, and the derivativen nan(zn)-1 of a for- (By contrast, nonholomorphic series would involve the complex conjugat. arez.) mal power series a So that is what a vertex operator looks like:
a for-is now an operator (endomorphism) on the space. nftyn=−. nftyanzn, where each coefficient$V$ of states, which is an infinite-dimensional vector space.$n$ Since the vertex operators are in one-to-one correspon-dence with the states (we called this the “state–field correspondence” above), we can label these vertex opera-tors with states: the standard convention is to denote the vertex operator corresponding to state$v \in V byY (v$, z) =n=−$\infty$. nfty vn(z-n)-1.
(6) The symbol “three legs, which as we know is the vertex of string$Y$” should remind you of the sphere with

IV. Branches of Mathematics

theory. These coefficients quantum field theory, all observables and states in th evn are the modes: as in any theory are built up from them. The most important state in the theory is the vacuum$Y (|0 |$, z)0. It corresponds to the identity vertex operator:= I. From the physical point of view, the ver- tex operator$v \text{at time} t = −\infty Y (v$, z), i.e., is the field that created the state Y (v, 0)|0 exists and equals v .
(Recall that in our model Among other things, this means that z = 0 corresponds tov (|0 t )= −$\infty$= v.), so indeed the modes applied torequired in any quantum field theory.$|0 generate^{-1} V$, as is The most important observable in the theory is the Hamiltonian, or energy operator, which we denote by L . It is diagonalizable (so V can be written as a sum ofintegers. For example, the vacuum0 L^0-eigenspaces) and all of its eigenvalues must be|0$has 0 energy$: $Lthe^{0}|0 = L -\text{decomposition of}0$.
Since |0 should have the minimum energy, V is then V = . nfty  V , where finite dimensional, and we can think of0 V^0 = C|0 . Each space V^n turns out to be Las definingn=0^n a Z+-grading on state space V . the stress-energy tensor is called the The most important vertex operator in the theory isconformal vector T (z). The corresponding stateω:$Y$ (ω$, z) = T (z)$. This means that re sent at i on (4) of the Virasoro algebraω has modes ωn = (Ln)-1 that form a rep-Vir. (This is the algebraic expression for the requirement of con-formal symmetry.) The conformal vector has energy 2:

$ω \in V2$.

most important axiom to help us to pin it down fur-ther is locality. With a little work, one can show that So far our theory is seriously under determined. The this reduces to the condition that the commutator[Y (u, z), Y (v, w)] of two vertex operators should be a finite linear combination of the Dirac deltaz-1 . nfty  (w/z)n and its derivatives (. artial k/. artial wδ(zk-)δ(zw) =-w)this, look at the case. Now, n=−. nfty$(z - w()k)+1 k(\partial = k/\partial w1:$ k)δ(z - w) = 0.
To see(z - w)2 . artial w. artial δ(z - w)=n=−$\infty$. nfty (n(wn()-1 z()-n)+1 - 2 nwnz - n + n(wn()+1 z()-n)-1)=n=−$\infty$. nfty ((n + 1) - 2 n + (n - 1))wnz - n = 0. The proof for general can be recast in an equivalent form as follows: givenk is similar. Therefore, locality anyu, v ∈ V, there is a positive number N such that(z - w)^N [Y (u, z), Y (v, w)] = 0. (7)

IV.17. Vertex Operator Algebras

This equation may look strange. Why can we not sim-ply divide out the(z - n)N and get that all vertex operators commute? The reason is that when formal power series are involved, there can be zero divisors. For example, it is easy to check that0. Locality in the form (7) is at the heart of VOAs;(z - 1)n \in Z zn = for instance, one can express it as a triply infinite sequence of identities that the modes must obey, and this emphasizes just how restrictive a condition itis, and how correspondingly interesting it is to find examples of VOAs. This completes the definition of a VOA.
A consequence of these properties is that the modes the L0-grading that we mentioned earlier. This mean sun respect that ifhas energ yu has energyk + l - n - k1. The definition followed here isandv has energy l, then un(v) some times called a Voas ons. Some times in the literature some of these con-of CFT-type, for obvious readitions are weakened or dropped. For example, muchof the theory is independent of the existence of the conformal vector cial, for reasons that will be explained in the nextω, although to us it will be cru- subsection. ical object.
We have emphasized their physical origins A VOA is simultaneously a physical and a mathematin order to help explain the motivation for studying them. We know they should be valuable to mathematics, simply because CFT is, and indeed this is the case, as we shall see in section 4. But from a purely mathematical point of view, they might appear somewhatad hoc, as though we had a list of mathematical ingredients and said to ourselves, “Let’s consider this, and then have some of these, oh, and perhaps one of those too, but with the following extra assumption: . . .
.” For-tunately, there are more abstract formulations of VOAs that make them appear much less arbitrary as mathe-mat ical structures. For example, Huang has shown that they can be regarded as “two-dimensionalized” Lie alge-bras, in the following sense. If you want to keep track of the Lie brackets in an expression such as(which is important since the Lie bracket is not an asso-[a, [[b, c], d]] cia tive operation), you can do so with the help of a binary tree, and in fact it is easy to formulate Lie algebras in the language of such trees.
If one then replaces binary trees by diagrams made out of spheres with legs, as we did with Feynman diagrams earlier, one obtains a structure that is equivalent to a VOA. (Of course, this is very far from a full explanation of what Huang did: his proof is extremely long.) 547 3.2 Basic Properties We see from the definition sketched in the last subsec-tion that a VOA is an infinite - dimensional Z+-graded vector space with infinitely many products (namely$u* v = u (v))$, which obey infinitely many identities.
Need less to say, it is not an easy definition, and there are no easy examples.$n^{n}$ the conformal vector However, if we ignore the conformal symmetry (i.e.,ω), then there are some sim- ple, though uninteresting, examples. The easiest is theone-dimensional algebra$V = C|0$. More generally, a Voa tive associative algebra with a unit 1 V that obeys (7) with N = 0 is a commuta-= |0 . It also has auct u derivation* v = u-T(v)=: this means a linear map that$L^{-1}$, with respect to the prod- obeys the product rule satisfied by derivatives, namely T (u* v) = (T u()1)* v + u* (T v).
The converse of this statement is true too: any such algebra is a VOA that obeys (7) with N = 0. In these simple examples, the role of the derivation T is to recover the z-dependence of the vertex operator. want interesting examples. Likewise, the vertex oper-ators Therefore, we need Y (u, z) must be distributions (that is, they must N not to be zero in (7) if we involve doubly infinite sums) or again the VOA reduces to a commutative associative algebra.
existence of the conformal vector is not needed), the space It is also easy to show that in any VOA (again the V is a Lie algebra, with Lie bracket given by[uv]carry a representation of this Lie algebra, and= (u1)0(v). This is important because each V Vgener-^n will ates continuous symmetries of the VOA (at least when V = {0}). For a typical VOA V these Lie algebras1 are very familiar. For instance, for the VOAs associated with rational CFT, they are1 reductive, which means that they are a direct sum of copies of the trivial Lie algebra C with simple Lie algebras.
port ant when one starts to consider the representation theory of VOAs. AThe existence of the conformal vector becomes im - V -module is defined in a natural way. We shall not give full details here, but, roughly speaking, it is a space on which V acts in such a way that as much as possible of the VOA structure isrespected. For example, V will automatically be a mod- ule for itself, just as a group acts on itself in a sim-ple way.
(See representation theory [IV.9 §2](/part - 04/\text{representation} - theory) for an explanation of the latter.) A rational VOA is defined to be one that has the simplest representation theory: it has only finitely many irreducible V - modules, and548 any V -module is a direct sum of irreducible ones. They are called rational VOAs because they are the Voas that come from rational CFT. For these VOAs, V acts irreducibly on itself. Assume now that V is rational. Any irreducible V - module numbers,$\text{MMwill inherit from} = M$, into finite-dimensional spaces V an L0 - grading by rational Mh.
The characterχ (τ)h=χM h(τ). imis defined by M e2^πi^τ(h-c/24^), (8)(Mh)h

whereurally in CFT as well as in Lie theory (orcis the central charge. This definition arises nat-affine Kac Moody algebras for (9) below, is mysterious in Lie theory. (In CFT it has), although the curious “$c/$24,” needed a natural explanation as a certain topological effect.)These characters converge for anyτ in the upper half- plane group SLH. They carry a representation of the modular(Z):
χM aτcτ ++db =N\in Irr(V ) ρ ac bd MN χN (τ), (9) where Irr modules, and(V )denotes the (finite) set of irreducibleρ(a b ) is a matrix with complex entries, V- whose rows and columns are labeled by Equation (9) holds for anyc d (a b ) in SL (Z)M, N, i.e., for any\in  Irr(V ).integers proof of (9), by Zhu, is perhaps the high point of VOAa, b, c, d satisfyingc dad - bc2= 1. The lengthy theory, and owes much to the intuitions of rational CFT.In the next section, we shall get some idea of why it is so important. 4 What Are VOAs Good For?
This section describes what are probably the two most significant applications of VOAs. But let us begin by listing (with out any explanations) a few others. Inspired by the geometry of string theory, vertex operator (super)algebras have been assigned to manifolds, resulting in a powerful, though complicated, algebraic invariant of those manifolds that generalizes and enriches more classical data such as de Rham cohomology. VOAs associated with affine Kac–Moody algebrasat “degenerate” levelsk are deeply related to the geo- metric Langlands program.
The modularity of affine algebra characters, as well as that of, for example, lattice theta functions, are all special cases of Zhu’s theo-rem, which places these modularities in a much broader context.

4.1 The Mathematical Formulation of CFT

Since the 1970 s quantum field theory has had con-sider able success, especially in geometry, by studying

IV. Branches of Mathematics

classical structures using infinite-dimensional meth-ods; this is a theme in particular of Atiyah’s school. Conformal field theories are a class of exceptionally symmetric quantum field theories, and they are also among the simplest nontrivial quantum field theo-ries known. In the past two decades mathematics has feasted on this combination of symmetry and (relative)simplicity, often by “looping” or “complexifying” more classical structures, and the impact of CFT (or, equiva-lently, of string theory) has been especially significant and broad.
In hindsight the importance of CFT to mathematics is not surprising: it is a coherent and intri-cate structure that straddles several disparate areas of mathematics, sprawling across geometry, number theory, analysis, combinatorics, and indeed algebra. theory has been to CFT itself. Quantum field theories From this point of view, a crucial application of VOA are notoriously difficult to put on a rigorous mathe-mat ical footing.
But the successful applications suggest that these difficulties are a symptom of mathemat i-cal profundity and subtlety rather than of irreparable mathematical incoherence. In this sense the situation is highly reminiscent of the deep conceptual challenges to eighteenth-century mathematicians that were raised bycalculus. The definition of a VOA by Richard Borcherds makes the chiral algebra of a CFT completely rigorous, as well as concepts like the operator product expansion. Subsequent work (especially by Huang and Zhu) reconstructs from the VOA more and more of the CFT, in arbitrary genus.
The resulting clarity makes the whole subject more accessible to, and hence exploitable by, mathematicians. Quantum field theories are here to stay in mathematics, and thanks to VOAs mathemat i-cians are absorbing a large class of them completely and explicitly.

4.2 Monstrous Moonshine

In 1978 Mc Kay noticed that 196 884$\approx 196 883$. Why was this an interesting observation? Well, the number on the left is the first meaningful coefficient of the function [IV.1 §8](/part-04/number-theory)j - j(τ) = q - 1 + (744+)196 884 q + 21 493 760 q2 + 864 299 970 q3 + · · ·, (10)

the generator of all modular functions for SL2(Z). Recall that a modular function is a functionis meromorphic in the upper half-plane H and invari-f (τ) that ant under the usual action of SL2(Z). It should also be

IV.17. Vertex Operator Algebras

meromorphic at the boundary points Q∪ i. nfty, which are called lier. Thejcusps-function generates these functions in the; we did not mention this condition ear sense that any such modular function written as a rational function poly(j(τ))/f (τ)poly can be(j(τ)). In other words, identifies(H ∪ Qj(τ)∪ is a uniformizing function thati. nfty)/SL (Z) with the Riemann sphere C∪. nfty.
We bracketed the constant term 744 in2 (10) because although 744 was the traditional choice itcan be freely replaced with any other number, including 0.The number on the right in Mc Kay’s observation is the dimension of the smallest nontrivial representation of the Monster, the most exceptional of theple groups [V.7](/part - 05/the - classication - of - finite - simple - groups). This relation between modular func-finite sim tions and the Monster was completely unexpected, asthey seem to occupy completely independent spots in the mathematical universe.
Conway, Norton, and others fleshed out and expanded Mc Kay’s original obser-vation by making a number of conjectures, collectively called pair(g, h)Monstrous Moonshineof commuting elements in the Monster (a. For instance, with every group of size about 8$\times 1053)$, we expect there to be associated a function ular functions for some discrete sub gr oupj(g, h)(τ) that generates all mod-Γ(g, h) of$SL$ g =2(Zh)=. The identity.j-function would be assigned in the case The first major step toward proving these Moonshine conjectures was made by Frenkel, Lepowsky, and Meur-man in the mid 1980 s.
They constructed an infinite dimensional vector space V% out of formal power series. They were motivated on the one hand by the vertex operators of string theory, and on the other by the formally similar distributions used in constructing affine algebra representations. This seemed a promising direction since for both string theory and affine algebra representations modular functions arise naturally. Together with a rich algebraic structure that came from these “vertex operators,” V\\\% was also acted on in a natural way by the Monster group.
More over, although V%is infinite dimensional, it comes packaged into finite-dimensional pieces“graded dimension”. im (VV%)q% =n equals . nf tyn=−1 j V-n %, and the744. The action of the Monster sends each each space V% itself carries a representation of th(en)n (Vn)%to itself; that is, Monster. Frenkel, Lepowsky, and Meurman proposed that V% lies at the heart of the Monstrous Moonshinen conjectures. tween Borcherds was struck by the formal similarity be-V% and the chiral algebras of CFTs, and by

549

abstracting out their important algebraic properties he defined a new structure called a vertex (operator) algebra. His axioms clarified their relationship with (generalizations of) Kac–Moody algebras, and by 1992 he had proved the main Conway–Norton conjecture (which corresponds to the case wheretrary buth is the identity in the conjecture giveng is arbi- earlier).
Although his definition of VOAs required a deep understanding of the physics of CFT, his elab-orate proof of this Moonshine conjecture is purely algebraic. We would now call V% a rational VOA with only one irreducible module (namely itself); its symmetry group is the Monster and its character (8) is j(τ) - 744. The removal of the constant term 744 from (10) is signifi-cant as it says that the Lie algebra V%is trivial—this is necessary if the symmetry group is to be finite. It is con-jectured that V% is the unique VOA with central charge1 c = 24, trivial V1, and only one irreducible module.
This is meant to be reminiscent of the[I.4 §4](/part - 01/general - goals), which is known to be the unique twenty-four-leech lattice dimensional even self-dual lattice with no vectors of$\sqrt{}$ length in the construction of2. Indeed, the Leech lattice plays a crucial role$V^{\\\\%}$. Most of the Moonshine conjectures are still open and this deep connection between modular functions andthe Monster is still some what mysterious. At the time of writing, however, VOAs still provide the only serious approach to the Moonshine conjectures.
Borcherds defined VOAs to clarify the chiral algebra of CFT and to tackle Monstrous Moonshine. For this work, he was awarded a Fields Medal in 1998.

Further Reading

Borcherds, R. E. 1986. Vertex algebras, Kac–Moody algebras, and the Monster. Proceedings of the National Academy of Sciences of the USA. 1992. Monstrous Moonshine and monstrous Lie su-83:3068–71. Di Francesco, P., P. Mathieu, and D. Sénéchal. 1996.per algebras.mal Field Theory Inventiones Mathematicae. New York: Springer. 109:405–44.Confor Gannon, T. 2006.Connecting Algebra, Modular Forms and Physics Moonshine Beyond the Monster: The Bridge. Cam Kac, V. G. 1998.bridge: Cambridge University Press. Providence, RI: American Mathematical Society. Vertex Algebras for Beginners, 2 nd edn.
Lepowsky, J., and H. Li. 2004.ator Algebras and their Representations Introduction to Vertex Oper-. Boston, MA: Birkhäuser.

550

IV.18 Enumerative and Algebraic

Combinatorics

Doron Zeilberger

1 Introduction

enumeration est mathematical subject, while algebraic combinator-, otherwise known as counting, is the oldics is one of the youngest. Some cynics claim that alge-braic combinatorics is not really a new subject but just a newics in order to enhance its (former) poor image, but name given to enumerative combinator algebraic combinatorics is in fact the synthesis of two opposing trends: abstraction of the concrete and concretization of the abstract the first half of the twentieth century, starting with.
The former trend dominated Hilbert’s “theological” proof of the fundamental the-orem of invariants, in which he showed by abstract means that certain invariants existed, but not how tofind them. The latter trend is dominating contemporary mathematics, thanks to the omnipresence of The Mighty Computer.
conceptualizati on(in short, The abstraction trend consists of the“bourbakization”, structuralizati on[VI.96](/part-06/nicolas-bourbaki-1935)) of mathematics., and categorization fancification, Enumeration did not escape this trend, and in the hands of such giants as Gian-Carlo Rota and Richard Stanley in America and Marco Schützenberger and Dominique Foata in France, classical, enumerative combinatorics became more conceptual, structural, and algebraic. However, as algebraic combinatorics has established itself as a fully fledged and separate mathematical speciality, the more recent trend
toward the cre te, and constructive has left its mark as well. It has explicit, con revealed that many algebraic structures have hidden combinatorial underpinnings; the attempts to unearth these have led to many fascinating discoveries and unsolved problems.

1.1 Enumeration

The fundamental theorem of enumeration, indepen-dently discovered by several anonymous cave dwellers, states that

$|A| = a \in^{A} 1$.

In words: the number of elements in A is the sum over all elements of While this formula is still useful after all these years, A of the constant function 1. enumerating specific finite sets is no longer considered

IV. Branches of Mathematics

mathematics. A genuine mathematical fact has to incor-porate infinitely many facts, and the generic enumeration problem is to enumerate not just one set but all the sets in an infinite family. To be precise, given an infinite sequence of sets {An}. nftyn=0, where each set An consists of objects sat- i sfy ing some combinatorial specifications that depend on the parameter$n$, answer the question: How many elements does In a moment we shall look at some examples. But$A^{n}$have? before we can learn how totion, let us consider a meta-question: What is an answer this kind of quesanswer? Wilf.
To give some background to Wilf’s meta-answer, let us examine answers to some famous instances of This was posed, and beautifully answered, by Herbert enumeration questions. In the list below, when we are given a set A (which will change from example to example), we shall write instead of|A |. That is, a will stand for the numbern an of elements of$n A^{n}$.n (i) I Ching.then$a = If2An$.n is the set of all subsets of {1, . . . , n, (ii) Rabbi Levi Ben Gerson.tat i onsn [III.68](/part-03/permutation-groups) on \\{1, . . . , n If\. \1, thenn is the set ofa = n!.
permu(iii) Catalan.opening brackets and If An is the set of legal bracketings withn closing brackets, thenn a n=(n2 n)opening brackets and!$/(n + 1)$!$n$!. (A legal bracketingn closing brackets such thatis a sequence ofn at no point in the sequence has the number of closing brackets exceeded the number of opening brackets. For instance, whenn = 2 the legal bracketings are[ ][ ] and [ [ ] ].)

(iv)finite sequences that consist only of 1 s and 2 s and leonardo of pisa [VI.6](/part-06/leonardo-of-pisa-known-as-fibonacci-vi57-christian-felix-klein-18491925). Let An be the set of that sum ton. (For example, when n = 4 the pos- sible sequences are 1111, 112, 121, 211, and 22.) In this case, we have follows. three equivalent answers as (i) 1 1+. qrt{5}n + 1 1-. qrt{5}n + 1 an = . qrt{5} 2 - 2.

(ii)

$n/ {}^{2!}a^{n} = k = 0 n - k k$.

(iii)athe recurrencen = (Fn)+1, where F F=n Fis the sequence+ F , subject to the defined by initial conditionsn F0 =n^-0,1 F1 =n^-1.2

IV.18. Enumerative and Algebraic Combinatorics (v)nc a yley vertices, then[VI.46](/part-06/arthur-cayley-18211895).a If A=n nis the set of labeled trees o(nn)-2. (A tree is a connected graph vertices have distinct names.)[III.34] with out cycles, and it isn labeled if the (vi)vertices, then If An is the set of labeled simple graphs witha = 2 n(n-1^)/2. (A graph is simple if itn (vii)onhas neither loops nor multiple edges.)Ifn Avertices (that is, graphs for which every vertexn is the set of label edn connected simple graphs can be reached from every other by a path), then$a$ isexpansion of$n$!
times the coefficient ofxn in the power-seriesn. og k. nfty=0 2 k(kk-!1$)/ {}^{2} x^{k}$. (viii) If An is the set of Latin squares of size n (n . imes  n matrices each of whose rows and columns is a per-mutation of$\\{1}$, . . . , n\\\\\\\\\\\\\\\\\\\\\}), then not even a good approx- imation for$a^{n} \text{is known}$. In 1982, Wilf defined an answer as follows. Definition. An answer is a polynomial-time algorithm (in$n) \text{for computing a}^{n}$.
paper proposing a “formula” for the answer to ques-tion (viii), and realized that its “computational com-Wilf arrived at this definition after he refereed a plexity” exceeds that of the caveman’s formula of direct counting. What is a “formula”? It is really an algorithm that inputs shorthand for the recursive algorithm$n \text{and outputs a}^{n}$. For example$, an = 2n \text{is ifelse}$ n = a 0 = then2 · aan =$, 1, nn^{-}1$

which takes O(n) steps. However, using the algorithm$if$ n = 0 then an = 1, else ifelsea n=is odd, thena2 an = 2 an-1$, nn/2$

takes In other cases, like enumerating self-avoiding walks, O(. og n) steps, much faster than Wilf demands. the best algorithm known is exponential,$O(c^{n})$, and any lowering of the constantc is a major advance. (A self-avoiding walkin the two-dimensional integer lattice, where eachis a sequence of points$x^{0}$, x1, . . . , xxni

is one of the four neighbors ofthex are equal.) Notwithstanding these exceptions, (xi)-1 and no two ofi

Wilf’s meta-answer is a very useful general guideline for evaluating answers.

551

were probability and statistics. In fact, discrete prob-ability is almost synonymous with enumerative com-Traditionally, the main customers of enumeration binatorics, since the probability of an event ring is the ratio of the number of successful cases E occur- divided by the total number. Also, statistical physics is, by and large, weighted enumeration of lattice models (see phase transitions and universality [IV.25]). About fifty years ago, another important customer came along: computer science.
Here one is interested in the that is, in the number of steps it takes to execute them.computational complexity [IV.20](/part - 04/computational - complexity) of algorithms: 2 Methods The following tools are indispensable to the enum era-tive combinatorial ist$. 2.1 Decomposition$|A ∪ B| = |A| + |B| (if A ∩ B = ∅).

In words: the size of the union of two disjoint sets equals the sum of their sizes.

$|A \times B| = |A| · |B|$.

In words: the size of the Cartesian product of two sets(that is, the set of all pairs(a, b), where a \in  A andb \in  B) equals the product of their sizes.|AB| = |A(||()B){|}.

In words: the size of the set of functions from equals the size of A raised to the power the size of B to BA. For example, the number of 0–1 sequences of length which can be viewed as functions from\\{1}$, 2, . . . , n\\nto,\\\{0,1\\\}$, equals 2 n.$2$.2 Refinement If$A =$.B (disjoint union), (nk)nk

and ifeven if it is not), then bnk, the number of elements of Bnk, is “nice” (and

$a^{n} = k b^{n}k$.

The idea here is that it may be possible to take a set$A$ that is difficult to count, and split it up into disjoint sets B that are easier to count. For example, consider then set union of subsets nk An of example (iv). This can be split into a disjoint B^nk, where each B^nk consists of the

552

sequences in2 s, then there must be A^n that have exact lyn - 2 k 1 s, sokb2 s. If there are=^n^-^k . This knk^k

yields answer (ii).

2.3 Recursion

Suppose that that it is a combination of fundamental operations An can be decomposed in such a way applied to the setsa recurrence relation of the form(An)-1$, (An)-2,$. . . , A0. Then ansatisfies an = P (an - 1$, an - 2,$. . . , a0). sequence insequence must add up to For example, let An starts with a 1, then the rest of the An be the set of example (iv). If an - 1, and if it starts with a 2, then the rest must add up to n - 2.
Since when n ⩾ 2 exactly one of these possibilities occurs and both are possible, we can decompose A into 1 A- and 2 A-,$where 1$(An)-1 is shorthand for the set of all sequence(sn()n()1()n)2 that begin with a 1 and continue with a sequence in(An)-1, and 2(An)-2 is defined similarly.
Since the sizes of 1 that An^-a1 and 2= a A-n^-+2 aare clearly^- , which yields answer (iii).(an)-1 and (an)-2, it follows (example (iii)), then a typical legal bracketing can be written recursively as If(An)n is the set of legal bracketings wit(hn()1()n)2 [L ]L , where L andn L pairs are smaller (possibly empty) legal bracketings. For exam - ple, if the bracketing is 1[ [ ] [ ] ] [ [ ] ] [ [ ] [ [ ] ] (]2()1)2 then Lthen1 = L[ ] [ ]hasandn - L21 -= k[ [ ] ] [ [ ] [ [ ] ] ]pairs. It follows that.
If L1 has A kcan be pairs, identified with the union cardinalities,2$an = n=-1 a"k n ka=-n 0 1 -(A1()k)- \timesk$. This is a(An)-1 - k, and, taking non line a rn (in fact, quadratic) and nevertheless one that satisfies Wilf’s dictum.k0 nonlocal recurrence, but it is 2.4 generatingfunct ionology According to Wilf, who coined this neologism by mak-ing it the title of his classic book (a free download from his Web site, even though it is still in print!): A generating function is a clothesline on which we hangup a sequence of numbers for display. most useful tools of the trade of enumeration.
The gen-erating function of a sequence, some times called its The method of generating functions is one of thez - transform, is a discrete analogue of the laplace transform himself. If the sequence is[III.91](/part - 03/transforms), and indeed goes back to(a ). nfty , then its generat - laplace [VI.23](/part - 06/pierre - simon - laplace - 17491827)nn = 0 ing function words, the terms of the sequence are regarded as thef (x)is defined to be. nftyn = 0 anxn. In other coefficients of a power series inx. IV.
Branches of Mathematics tion about the sequence Generating functions are so useful because informa-(an) translates to information about some manipulations one often gets additional informa - f (x) that is often easier to process, and after tion aboutmation about the sequence. For example, iff (x) that can be translated back into infor - a = a = 1 and following manipulations onan = an - 1 + an - 2 whenf (x)n ⩾ 2, then we can do the:
0 1 f (x) =n. nfty = 0 anxn = a0 + a1 x + n. nfty = 2 anxn = 1 + x + n. nfty = 2(an - 1 + an - 2)xn = 1 + x + n. nfty = 2 an - 1 xn + n. nfty = 2 an - 2 xn = 1 + x + xn. nfty = 2 an - 1 xn - 1 + (x2)n. nfty = 2 an - 2 xn - 2 = 1 + x + x(f (x) - 1) + x2 f (x)= 1 + (x + x2)f (x).

It follows that

$f (x) = 1 - x1 - x^{2}$.

If one performs a partial-fraction decomposition, and expands the two resulting terms in a Taylor series, then one can obtain answer (i) to example (iv). 3 Weight Enumeration According to the modern approach, pioneered by Pólya, Tutte, and Schützenberger, generating functions are neither “generating,” nor are they functions. Rather, they areators of combinatorial sets. (Usually, but not always, formal power series that are weight enumerthese sets are infinite:
for a finite set the corresponding“power series” has only finitely many nonzero terms and is therefore a polynomial.)A power series. nfty  a xn is called formal when one sheds its analytical connotation as a Taylor series of a function, and there by obviates the need to worry about n = 0 n convergence. For example, the sum fect ly legal as a formal power series even though it$n = 0 n$!n!xn is per- converges only when$x = 0$. As for weight enumerators, consider the following situation. Suppose that we want to study the age distri-bution of a finite population.
One way of doing this is to ask 121 questions. For eachi between 0 and 120, we ask those whose age is count each of these age-groups one by one, compilingi to raise their hand. Then we

IV.18. Enumerative and Algebraic Combinatorics a table of$a (0 ⩽ i ⩽ 120)$, and finally computing the

$i$

generating function

$f (x) = {}^{1}20 a x^{i}$.i

But if the size of the population is much less than 120, itis much more efficient, because fewer questions would$i = 0$ be needed, to ask every person their age and then to declare the weight of a person of agei to be xi. Then the generating function is the sum of these weights. That is,

f (x) = xag(e()person),

persons

which is a natural extension of the caveman’s formula of naive counting. Once we knowf (x) we can eas- ily compute statistically interesting quantities, like the average and the variance, which work out to be$\mu = f (1)/f (1) and σ^{2} = f (1)/f (1)+\mu-\mu^{2}$, respectively. (finite or infinite) combinatorial set, let us call ita certain numerical The general scenario is that we have anattribute,α: A \to  N, which assigns interesting A, and to each element of A a natural number. (Here we allow 0 as a natural number.) Then the A with respect to αis defined by the formula weight enumerator of

f (x) = x^α(a).

We shall also use the notation this equals$a \in^{A}|A|^{x} for f (x)$. Obviously,. nftyanxn,

whereα equalsannis the number of members of. Hence if we have some kind of exp li citn=0 A whose expression for expression for the actual sequencef (x), we immediately have an “explicit”$a^{n} assuming$, that$is$, that one considers the operations needed to calcu-late thenth coefficient a of f (x) as constituting an explicit expression foris still often possible to get a “nice” formula for(an)n. Even if one does not, then itan, or, failing this, to extract the asymptotics. The fundamental operations for naive counting also hold for For example, weighted counting:
just replace| · | by | · |x$.|A ∪ B|x = |A|x + |B|x (if$ A ∩ B = ∅) and|A . imes B|x = |A|x · |B|x.

Let us quickly see why the second of these is true. If the members ofcal attributesα and A andβ, respectively, and one defines an B are endowed with numeri- 553 attributeγ on A . imes B by letting γ(a$, b) equal α(a)+β(b)$, then

|A . imes  B|x = xγ(a, b)=(a, b)\in A. imes B xα(a()+)β(b)(a, b)\in A. imes B= xα(a) · xβ(b)(a, b)\in A. imes B= xα(a) · xβ(b)a. um \in  A)b\in B . um= xα(a) · ·xβ(b)= |Aa|\in x)A· |B|x$.b \in B$

Let us see how these facts can be useful. First, consider theand 2 s, and let the attribute be “sum of entries.” then infinite set$A$, of all (finite) sequences of 1 s the weight of 1221 isa sequence(a · · · a x)6 is, and, in general, the weight ofxa^+···+a. The set A can benaturally decomposed as1(r1)k A = {φ} ∪ 1 A ∪ 2 A,

whereφ is the empty word, and 1 A is short for the set of all sequences obtained by prefixing a 1 to members of A, and analogously for 2 A. Applying | · | , we getx|A|x = 1 + x|A|x + x2|A|x,

which, in this simple case, can be solved yield, once again explicitly, to

$|A|^{x} = 1 - x1 - x^{2}$.

the weight is noted, it can be written as A legal bracketing$x^{0} = L1)$, or else, as we have already is either empty (in which case L = [L ]L , where L and LL2 are (shorter) legal bracketings. Conversely, whenever and L are legal bracketings, so is1 [L2 ]L . Let1 L be the (infinite) set of weight of a legal bracketing to be1 2 all legal bracketings, and define the$xn$, wher(e1)2 n is the number of bracket pairs[ ] is x and the weight of[ ][ [ ] [ [ ] [ ] ] ]. For example, the weight ofis x5. The set L decomposes naturally as follows:

$L = {φ} ∪ ([L] \times L)$,

whereφ denotes the empty word and [L] × L denotes the set of all words of the form L in L. This leads to the nonlinear[L(in fact, quadratic)1]L2 with L1 and$equation2$|L|x = 1 + x|L(|2)x,

554

which yields, thanks to the Babylonians, the explicit expression$\sqrt{}|L|x = 1 - 21x - 4x$.

This in turn gives us the answer to example (iii) above, via Newton’s binomial theorem. trees vertex has either no children or exactly two chil-Legal bracketings are equivalent to so-called, that is, unlabeled ordered trees where every binary dren. For instance, when we write the legal bracketing[ [ ] [ ] ] [ [ ] ] [ [ ] [ [ ] ] ] in the form [L1]L2 we can think$of$ L [ [ ] [ ] ] [ [ ] ] [ [ ] [ [ ] ] ]= [ ] [ ] and L = [ [ ] ] [ [ ] [ [ ] ] ]as the parent, with children. Then L’s children are1φ and [ ], while2 L2’s are[ ] and [ [ ] [ [ ] ] ]1.
This process continues until we have reached branch of the family.φ down every tex may only have exactly zero or five children, then the generating function, alias weight-enumerator, satisfies If we try to count penta-trees instead, where each verthe quintic equation

$f = x + f^{5}$,

which, according tonot solvable by radicals abel(see[VI.33](/part-06/niels-henrik-abel-18021829) andthe insolubility of the galois [VI.41](/part-06/variste-galois-18111832), is quintic [V.21](/part-05/the-insolubility-of-the-quintic)). However, solvability by radicals is not everything. More than 200 years ago, devised a beautiful and extremely useful formula for lagrange [VI.22](/part - 06/joseph - louis - lagrange - 17361813) extracting the coefficients of the generating function from the equation it satisfies, now called the Lagrange in version formula number of complete.
Using it one can easily show that thek - ary trees with (k - 1)m + 1 leaves is (km)!$.((k - 1)m + 1)!$ m!

sion formula, discovered by the great Bayesian proba-bilist I. J. Good, enables one to enumerate A multivariate generalization of the Lagrange inver-colored trees and many other extensions.

3.1 Enumeration Ansatzes

If one wants to turn enumerative combinatorics intoa theory rather than a collection of solved problems, one needs to introduce classification, and enumeration paradigms“paradigm” is such a pretentious word, let us use thefor counting sequences. But since much humbler German word “ansatz,” which roughly means “form of solution.” Let(an). nftyn=0 be a sequence, and letf (x) =n. nfty=0 anxn

IV. Branches of Mathematics

be its generating function. If we know the “form” ofwe can often deduce the form off (x) (and vice versa)$.a^{n}$, (i) Ifan is a polynomial in n, then f (x) has the formf (x) = (1 -P (x)x()d)+1,

where degree of the polynomial that describes P is a polynomial function andadn.is the (ii) Ifintegeran is a Nquasi-polynomial such that for eachin nr (i.e., there exists an= 0, . . . , N - 1, the functionm \to am N+r is a polynomial in m), then, and some polynomial function for some (finite) sequence of integers$P$, d1$, d2$, $. . .f (x) = (1 - x()d)1 (1 - x P (x)2()d)2(1 - x3()d)3 · · · .$ (iii) if recurrence equation with constant coefficients$a^{n} is C - recursive$, that is, if it satisfies a linear an = c1(an)-1 + c2(an)-2 + · · · + cd(an)-d (a good example is the Fibonacci sequence),
thenf (x) is a rational function of x: that is,$f (x) =$ (iv) If$P$ (x)/Q(x)form an satisfies a linear recurrence equation of the, where P and Q are polynomials.c0(n)an = c1(n)(an)-1 + c2(n)(an)-2+ · · · + cd(n)(an)-d,

where the coefficient sc (n) are polynomial in n, i

then it is said to ben! is P-recursive since we have the recurrence P-recursive. (For example, aan ==na which means that it satisfies a linear different i a ln-1.) If this is the case, then f (x) is D-fin i ten , equation with polynomial coefficients (inx). In the case of$a^{n} = n$! the recurrencean = n(an)-1 is first order satisfying a higher-order linear recurrence with polyno-. A natural example of a P-recursive sequence mial coefficients is the sequence that counts the num-ber of involutions on$\\{1}$, . . . , n\\\\\\\\\\\\\\\\\\\\\}.
(An involution is a permutation that equals its inverse.) Let us call thisnumberw . The sequence (w )satisfies the recurrence

nn

relation

wn = (wn)-1 + (n - 1)(wn)-2.

This recurrence follows from the fact that in the per-mutationn belongs either to a 1-cycle or to a 2-cycle. The former case accounts forand the latter for(n-1)w of them. (There arewn-1 of the involutions, n - 1 ways of choosing the cycle-mate, ing the resulting cycle leaves an involution of then-2 i, say, of n, and delet - n - 2 elements$\\{1}$, . . . , i - 1, i + 1, . . . , n - 1\\\\\\\\\\\\\\\\\\\\\}.) IV.18.
Enumerative and Algebraic Combinatorics 4 Bijective Methods This last argument was a simple example of aproof, in this case, of a recurrence for the number ofbijective involutions on proof.n objects. Contrast it with the following The number of involutions of\\\{1, . . . , n\\\} with exact lyk 2 - cycles isn (2 k)! ,$2$ k k!2 kbe cause we must first choose the 2 participate in thek 2-cycles, and then match them upk elements that will into (unordered) pairs, which can be done in(2 k)!

$(2k - 1)(2k - 3)· · · 1 = k$!2$k$

ways. Hence

$wn = k 2nk (k2$!2 k)k!.

Nowadays such sums can be handled completely matically, and if one inputs this sum to the Maple au to package EKHAD (downloadable from my Web site), one would get the recurrence$w = w + (n - 1)w$ as the output, together with a (completely rigorous!)(nn()-1()n)-2 proof. While the so-called Wilf–Zeilberger (WZ) method is able to handle many such problems, there are many other cases where one still needs a human proof. In either case such proofs involve (algebraic, and some times analytic)rialist Adriano Garsia derogatorily calls such proofs manipulations.
The great combinato“manipulatorics,” and real enumerators do not manipulate preferred method of proof is by, or at least try to avoid it whenever possible. the bijection [I.2 §2.2](/part-01/language-and-grammar). n, where Suppose one has to prove that An and Bn are combinatorial families.
The|An| = |Bn| for every “ugly way” is to get, by some means or other, algebraicor analytic expressions for a = |A | and b = |B |.Then onea, which in turn leads to yet another expression manipulates an, getting another expressio(nn)n n an^  , and if one is patient enough, and clever enough, and inluck, or if the problem is not too deep, one eventually$nn$ arrives at$bn$, and the result follows.|AOn the other hand, then| = |Bn| is by constructing a (preferably nice)nice way of proving that bi jec- tion corollary, that$T^{n}$:$A^{n} \to |AB| = |^{n}$, which immediately implies, as a B |.
bijective proof is also In addition to being morenn philosophically aesthetically more sat is fac-pleasing, a tory. In fact, the notion of (cardinal)sophisticated derived notion based on the much more number is a highly

555

basic notion ofto frege [VI.56](/part-06/gottlob-frege-18481925), the cardinal numbers are being in bijection. Indeed, according equivalence classes, where the equivalence relation [I.2 §2.3](/part - 01/language - and - grammar) is “is in bijective correspondence with.” Saharon Shelah said that people have been exchanging objects, in a one - to-one way, since long before they started to count. Also, a bijective proof explains why the two sets are equinumerous, as opposed to just certifying the formal correctness of this fact.
For example, suppose that Noah had wanted to prove that there were as many male as female creatures in his Ark. One way of proving this would have been to count the males and count the females, and check that the two resulting numbers were indeed the same. But a much better, conceptual, proof would have been to note that there is an obvious one - to - one correspondence between the set M of males and the set Fof females: the function bijection, with inverse w:$M \to \text{Fdefined byh}$: F \to w(x)Mdefined by= Wife Of(x)h(y)is a= Husband Of(y).
proof of A classic example of a bijective proof is Glaisher’seuler’s [VI.19](/part - 06/leonhard - euler - 17071783) “odd equals distinct” partition theorem. Ait as a sum of positive integers, where order does not partition of an integern is a way of writing matter. For example, 6 has eleven partitions: 6, 51, 42, 411, 33, 321, 3111, 222, 2211, 21111, 111111. (Here3111 is shorthand for the sum 3$+ 1 + 1 + 1$, and so on. Since order does not matter, we count 3111 as the same partition of 6 as 1311, 1131, and 1113.
It is convenient to write the partitions with their numbers in decreasing order, as we have done.) A partition is called odd if all its parts are odd, and it is called Odd(n) and Dis distinct(n) be the sets of odd and distinctif all its parts are distinct. Let partitions of\\{51, 33,3111, n111111, respectively. For example$, Odd\\ \text{and Dis}(6) = \\\{6,51, 42,(3216) =\\\}$. Euler proved that|Odd(n)| = |Dis(n)| for all n. His “manipulatorics” proof goes as follows.
Letd(n) be the number of odd and distinct partitionso(n) and offunctions$n$, respectively, and let us define the generating  f (q) =n . nf ty = 0 o(n)qn and g(q) =n . nf ty = 0 d(n)qn. With the help of the “multiplication principle” for weighted counting, Euler showed that  f (q) =i . nf ty = 0 1 - q(12)i+1 and g(q) =i . nf ty = 0(1 + qi). 556 Using the algebraic identity 1$+ y = (1 - y2)/(1 - y)$, we have. nf ty . nf ty -2 i 1 q(1 + qi) =

1- qii = 0 i = 0= . nftyi = 0(1 - q . nftyi=2 0 i)(1 -. nftyi = q0(2 i1)- (q2()i)+1). nfty = 1 - q(12()i)+1.i=0

hence follows by extracting the coefficient of$g(q) = f (q)$, and the identityqo(n)n. = d(n) For a very long time, these kinds of manipulation were considered to belong to the realm ofand in order to justify the manipulations of the infi-analysis, nite series and products, one talked about the “region of convergence,” usually|q| < 1, and every step had to be justified by the appropriate analytical theorem. Only relatively recently did people come to realize that no analysis need be involved:
everything makes sense in the completely elementary and much more rigorous (from the philosophical viewpoint) algebra of formal power series gence, so as to exclude, for example, an infinite product. One still needs to worry about conver like$\infty^{i} = 0(1 + x)$, but the notion of convergence in the ring of formal power series is much more user-friendly than its analytical namesake. Euler’s proof, while purely algebraic and elementary, Even though invoking analysis was a red herring, is nevertheless still manipulatorics.
It would be much nicer to find a direct bijection between the sets Dis(n) and Odd(n). Such a bijection was given by Glaisher. Given a distinct partition, write each of its parts as2 r · s, where s is odd, and replace it by 2^r copies of s.(For example, 123 + 3 + 3 + 3.) The output is obviously a partition of the = 4 · 3, so we would replace 12 by same integer the partition(n10, but now into odd parts. For example,, 5, 4) is transformed to the new par - tition(5, 5, 5, 1, 1, 1, 1). To define the inverse transformation, take an odd partit shows up.
If it shows upa and count how many timesm times, then write m in binary notation, copies of$\text{a by themk} = parts: 22$ s1 + · · · +s 1 a, . . . ,(2 s)k, and replace the(2 s)k a. It is not hardm to check that if you do the first transformation to a par-tition in Dis(n) and then do the second transformation, you get back to the partition you started with. analytical) manipulations, we are really rearranging and When we perform algebraic (and logical, and even combining symbols, and hence we are doing combina-torics in disguise. In fact, everything is combinatorics.

IV. Branches of Mathematics

All we need to do is to take the combinatorics out ofthe closet, and make it explicit. The plus sign turns into (disjoint) union, the multiplication sign becomes Cartesian product, and induction turns into recursion. But what about the combinatorial counterpart of the minus sign? In 1982, Garsia and Steven Milne filled this gap by producing an ingenious “involution principle”that enables one to translate the implication

$a = b and c = d ⇒ a - c = b - d$

into a bijective argument, in the sense that if D ⊂ B, and there are natural bijections f: AC \to ⊂ AB andandg: C \to D establishing that |A| = |B|, and |C| = |D|, then it is possible to construct an explicit bijection between A \C and B \D. Let us define it in terms of people. Suppose that in a certain village all the adults are married, with the result that there is a natural bijection from the set of married men to the set of mar-ried women,$m \to \text{Wife Of}(m)$, with its inverse w \to Husband of extramarital affairs, but only one per person, and all(w).
In addition, some of the people have within the village. There is a natural bijection from theset of cheating men to the set of cheating women, called $m \to \text{Mistress Of}(m)$, with its inverse w \to  Lover Of(w). It follows that there are as many faithful men as there are faithful women. But how do we match them up?(One might imagine, for example, that each faithful man wants a faithful woman to go to church with him.) wife to come with him. If she is faithful, she agrees. Ifshe is not, she has a lover, and that lover has a wife. So Here is how it is done.
A faithful man first asks his she tells her husband: “Sorry, hubby, I am going to thepub with my lover, but my lover’s wife may be free.” If this happens, then the man asks the wife of the lover of his wife to go with him, and if she is faithful, she agrees. If she is not he keeps asking the wife of the lover of the woman who has just rejected his proposal. Since the village is finite, he will eventually get to a faithful woman. The reaction of the combinatorial enumeration community to the involution principle was mixed.
On theone hand it had the universal appeal of a general principle, one that should be useful in many attempts tofind bijective proofs of combinatorial identities. On the other hand, its universality is also a major drawback, since involution-principle proofs usually do not give any insight into theone feels a bit cheated. Such a proof answers the specific structures involved, and letter proof of this kind, one still hopes for aof the question, but it misses its spirit really. Given a natural,

IV.18. Enumerative and Algebraic Combinatorics “involution-principle-free proof.” This is the case, for instance, with the celebrated Rogers–Ramanujan identity, which states that the number of partitions of an integer into parts that leave remainder 1 or 4 when divided by 5 equals the number of partitions of that integer with the property that the difference between any two parts is at least 2. For example, if dinal it i es of{61,4111, 1111111} and {7,61 n ,=527 the car-} are the same.
Garsia and Milne invented their notorious prin-ciple in order to give a Rogers–Ramanujan bijection, there by winning a 50 prize from George Andrews. However, finding a really nice bijective proof is still an open problem. A quintessential example of a bijective proof is Prüfer’s proof of there are(nn)-2 labeled trees on cayley’s [VI.46](/part-06/arthur-cayley-18211895) celebrated result thatn vertices (example (v) earlier). Recall that a labeled tree is a labeled connected simple graph with out cycles.
Every tree has at least two vertices with only one neighbor (these are called leaves associates with every labeled tree). A certain mapping called the T a vector of integers Prüfer bijection (ator is called its1,. . . , an-2), with 1 Prüfer code⩽ ai. Since there are⩽ n for each i. This vec-(nn)-2 such vectors, Cayley’s formula follows once we have defined the mapping f: Trees\to  Codes and proved that it is indeed a bijection. This really needs four steps:
defining fg, defining its alleged inverse map◦f and f ◦g are the identity maps on their respectiveg, and proving that domains. The mappingfis defined recursively as follows. If the tree has 2 vertices, then its code is the empty sequence. Otherwise, leta be the (sole) neighbor of the smallest leaf and letthe smaller tree obtained by deleting that leaf.((a1)2, . . .
, (an)-2) be the code of 5 Exponential Generating Functions So far, when we have discussed generating functions, we have been talking about ordinary generating functions ing ordered structures like integer partitions, ordered(or OGFs). These are ideally suited for count trees, and words. But many combinatorial families are really natural concept is that of ansets, where the order is immaterial. For these the exponential generating function The EGF of a sequence(or EGF)$.{a(n)}$. nftyis defined to be

n=0. nftya(n)xn.n!

irreducible Labeled objects can be often viewed as sets of smaller objects. For example, a permutation is the$n = 0$

557

disjoint union of union of nonempty sets cycles, a (labeled) forest is the disjoint, a set partition is the disjoint union of labeled trees, and so on. andof size Suppose that we have two combinatorial families B, and suppose that there aren in the A family, and b(n)a(n)in the labeled objects B family. We A can construct a new set of labeled objects$C = A \times B$, where the labels are disjoint and distinct, and define the size of a pair to be the sum of the sizes of the components. We have

$c(n) =k n = 0 \text{nk a}(k)b(n - k)$,

since we must

(i) decide the size of the first component, ger between 0 andn), which forces the size of thek (an inte- second component to ben - k, (ii) decide which of the nent (n ways), andnlabels go to the first compo(iii) pick the objects for each component from theand Bkfamilies, respectively, using the available A labels (a(k)b(n - k) ways). Multiplying both sides by$x^{n}/n$! and summing from

n = 0 to n = $\infty$ yields . nfty c(n) xn = . nfty n a(k) xk b(n - k) (xn)-kn = 0 n!$n = 0 \infty^{k} = 0 k$!$(n \infty - k)$!$-= a(k)k$!$x^{k} b(n(n - k)k)$!(xn)-k. Hence EGF(C) = EGFk = 0 (A) EGF(B)n. Iterating$, \text{we get} - k = 0$ EGF(A1 . imes  A2 × · · · × Ak) = EGF(A1)· · · EGF(Ak). In particular, if all the A are the same, we have thati

the EGF of orderedk - tuples, Ak, equals [EGF(A)]k. But if “order does not matter,” then the EGF of objects is$[EGF(A)]^{k}/k$!, since there are exact lyk-sets ofk! ways A- of arranging ak-set into an ordered array (since all labels are distinct, all these objects are different). Sum-ming fromk = 0 to k = . nftywe get the “fundamental theorem of exponential generating functions.” Ifas sets of “connected components” that belong to a B is a labeled combinatorial family that can be viewed combinatorial family A, then EGF(B) = . xp [EGF(A)].
This useful theorem was part of the physics folklore for many years, and was also implicit in many older combinatorial proofs. However, it was explicated only 558 in the early 1970 s. It was fully “categorized” by means of Joyal’s theory of species, which grew to be a beautiful theory of enumeration in the hands of the école Québecoise and others).(the Labelle and Bergeron frères, Leroux, the EGF of set partitions. That is, let us try to figure outan expression for Here are some venerable examples. Let us try to find

$\infty\text{b}(n)xn$, n!

where ber of set partitions of anb(n) (so-called Bell numbers) denotes the num-n=0 n-element set. disjoint the union of all the Recall that a nonempty set partition subsets of A equals of a set A, A\\{. For example, the set AA1\\}, . . . , Ais a set of pairwise-r , such thati

partitions of the 2-element set{\\{1}}$, 2\\$. \\{1}$,2\\are {{1}}, {2} and (We think of a set itself into just one set.) Let The atomic objects in this example are Aas being the “trivial” partition ofa(n) be the number of ways nonempty sets. of partitioning a set of size Clearly, whenn = 0 this cannot be done, son into one nonempty set.a(0) = 0. Whenn ⩾ 1 there is exactly one way of doing it, so the EGF of the sequence a(n). nfty is A(x) = 0 +n=1 n1! xn = ex - 1.

It follows immediately from the fundamental theorem that

. nftyb(n)xn = (ee()x)-1, (1)n!

an identity of Bell. Nowadays, with computer algebra systems, this can be used immediately to crank out the$n = 0$ first 100 terms of the se que nceb(n). For example, in Maple one simply types taylor(exp(exp(x)-1), x = 0,101); so this is definitely an answer in the Wilfian sense. Wecan also easily derive recurrences (albeit ones that need at least(1) and comparing coefficients. O(n)memory), by differentiating both sides of thing much deeper.
How about an EGF-style proof of Levi Ben Gerson’s celebrated formula for the number That was really easy, so let us go on and prove someof permutations onlier)? Every permutation can be decomposed into an objects, n! (example (ii) ear disjoint union of cycles, so the atomic objects are nowis of course cycles. How many$(n - 1)$!, since$n$-cycles are there? The answer(a , a , . . . , a ) is the 1 2 n

IV. Branches of Mathematics

same as(a , . . . , a (a, a2, a$, a3, . . . , a)$, etc., which means that we can pickn$, a^{1})$, which is the same as the first entry arbitrarily, after which we have choices for placing the remaining entries. The EGF for3(n1)2 (n - 1)! cycles is therefore

$\infty (n - 1)$!$x^{n} = \infty 1 x^{n}n = {}^{1} n$!= −n=. og1 n(1 - x) = . og (1 - x)-1. Using the fundamental theorem, we get that the EGF of permutations is

. nfty  . nfty. xp (. og (1 - x)-1) = (1 - x)-1 =n=0 xn =n=0 nn!!xn, and voilà we have a beautiful new proof that the number of permutations onn objects is n!. slight modification leads immediately to the (ordinary)generating function for the number of permutations on This argument may not look very impressive. But a \\{1, . . . , n\\} with exactly k cycles, which we shall denote bythe generating function isc(n, k). Here we are fixing C (α)n and letting=n c(n, k)αk vary, sok.
All we have to do to calculate this is go from nk = 0 naive count- ing totation the weight weighted counting, and assign to each permu-α#cycles. The fundamental theorem of exponential generating functions carries over word-for word to weighted counting. The weighted EGF for cyclesisα . og (1 - x)-1, so the weighted EGF for permutations$is$. nfty. xp (α · . og (1 - x)-1) = (1 - x)^-^α =n=0 (α)n!$n x^{n}$, where

(α)n = α(α + 1) · · · (α + n - 1)

is the so-called derived the far less trivial result that the number of rising factorial. We have therefore permutations ofthe coefficient of{α1, . . . , nk in (α)} with exactly. k cycles equals I used this technique to give a combinatorial proof of About ten years ago (Ehrenpreis and Zeilberger 1994)$n$ the Pythagorean theorem in the form

. in2 z + . os2 z = 1.

The functions sin increasing sequencesz and cosof odd and even lengths, respec-z are the weighted EGFs for tively, with weight(-1()[)lengt(h/()2)]. Hence the left-hand side is the weighted EGF for ordered pairs of increasing sequences

a1 < · · · < ak, b1 < · · · < br,

IV.18. Enumerative and Algebraic Combinatorics such that{a , . . . , a }kandand{br, . . . , bhave the same parity, the sets} are disjoint, and the union of the two sets is1 k1\\\\\\\\\\\\\\\\\{1, 2, . . . , kr + r \\\\\\\\\\\\\\\\\}. There is a killer involution on these sets of pairs defined as follows. Ifa < b then map the pair tokra1 < · · · < ak < br , b1 < · · · < (br)-1.
and otherwise map it to$a1 < · · · < (ak)-1$, b1 < · · · < br < ak. For example, the pair 1,3,5,6 2, 4, 7, 8, 9,10, 11,12, whose sign is(-1)2 · (-1)4 = 1, goes to the pair$1$, 3,5,6,12 2, 4, 7, 8, 9, 10, 11, whose sign is(-1)2 · (-1)3 = −1 (and vice versa). Since this mapping changes the sign, and is an involution, all such pairs can be paired up into mutually can-celing pairs. But this mapping is undefined for one special pair, namely the pairis 1. Therefore, the EGF for the sum of the weights of(empty, empty), whose weight all pairs is 1, which explains the right-hand side.
of André’s generating function for the number ofdown Yet another application of this method is a proof permutations. A permutation ofa · · · aup–is called up–down (or some times$a < a > a < · · ·$. Let abe the number of up–down zigzag) if(a1)1 < (an)2 > permutations$. Then3 4 5$ n . nftya(n)xn = sec x + . an x.n!

This is equivalent to saying that$n = 0 \infty \cos x ·^{n} = 0 a(n)n$!xn = 1 + . in x.

Can you find the appropriate set and the killer involution? 6 Pólya–Redfield Enumeration Often in enumeration it is easy enough to count objects, but what about unlabeled ones? For example, labeled the number of labeled (simple) graphs on(example (vi)) is trivially 2 n((n-1))/ 2, but how many un-n vertices labeled graphs are there on harder, and in general there are no “nice” answers,
butn vertices? This is much the best known way is via a powerful technique initi-ated by Pólya, which was largely anticipated by Redfield. Pólya enumeration lends itself very efficiently tocounting chemical isomers, since, for example, all the

559

carbon atoms “look the same.” Indeed, counting iso-mers was Pólya’s initial motivation (see mathematics and chemistry [VII.1 §2.3](/part-07/mathematics-and-chemistry)). alence classes of easy - to-count count these equivalence classes. But what is the equiv-The main idea is to view unlabeled labeled objects as equiv - objects, and to alence? The answer is that there is always atry group [I.3 §2.1](/part - 01/fundamental - definitions) involved, and it leads to a natural symme equivalence relation. Let the symmetry group belet the set of labeled objects be A.
Then two objects G, anda andb of A are regarded as equivalent if b = g(a) for some member is some symme tryg of the groupg in the group G. This means that there G that transforms a toand the equivalence classes are the setsb. This is easily seen to be an equivalence relation Orbit(a) = {g(a) | g \in G}, a \in  A, which are known aswe have the task of counting the number of families.orbits. Calling each orbit a “family,” Note thatof the finite set G is a subgroup of the group of permutations A.
families and we want to count the number of families. One way would be to define some “canonical head” of Suppose that there is a picnic consisting of many each family, say “mother,” and count the number of mothers. But some daughters look like mothers, so this is not so easy. On the other hand, you cannot just count everybody, since then you would count each family several times. The problem is that “naive” counting of people (or objects) is giving a credit of 1 to each person, and this is in appropriate if we are trying to count families.
If instead we were to ask each person “How bigis your family?” and add to our count the reciprocal of that number, then the calculation would come out just right, since a family of sizek would get a credit of 1 have been counted exactly once by the end. Going back/k for each of its members, and would therefore to counting orbits, we see by the same reasoning that their number is

.|Orbit(a)|

The conceptual opposite of “orbit ofa \in A a” is the subgroup of members of Gthat fixa: Fix(a) = {g \in G | g(a) = a}. (This is some times known as the each ele men tb = ga in the orbit of stabilizer a, we can asso-of a.) To ciate the left cosetg Fix(a) of Fix(a). This association turns out to be a well-defined one-to-one correspon-dence between the orbit ofa and the cosets of Fix(a)

560

inis|GG/, from which it follows that the size of Orbit Fix(a)|. We can therefore substitute |Fix(a)|/(a)|G|$for 1$/|Orbit(a)| in the previous formula, which implies that the number of orbits is1

|Fix(a)|.|G|

Let us use the notationthe statement is true and 0 if it is false. Thena\in χ(Astatement) to stand for 1 if|G1 |a\in A |Fix(a)| = |G1|a\in  A)g\in G χ(g(a) = a)= |G1 |g\in  G)a\in A χ(g(a) = a)= |G1 |g\in G$fix$(g),

where fixis viewed as a permutation of(g)is the number of fixed points of A). We have just prove dg (when g what used to be called back to cauchy [VI.29](/part-06/augustin-louis-cauchy-17891857) and Burnside’s lemma frobenius [VI.58](/part-06/ferdinand-georg-frobenius-18491917). It states, but it goes that the total number of orbits equals the average num-ber of fixed points ofg, over all transformations g in Gperm ut at i ons of. If the group GAis the full symmetric group of all the, then the average number of fixed points equals 1 (since in this trivial case there is only one orbit!).
counting (e.g., chemical isomers, or colorings of the Enter Pólya. The objects that he was interested in faces of the cube) were all naturally underlying set to a set of colors (or atoms). Let us call functions from an the underlying settry of U gives rise in a natural way to a transformation U and the set of colors C. A symme- of the set of functions one defines a new function$f$: Ugf\to by C. Given a functiong(f )(u) = f (g(u))f.
(If we think ofing that assigns tof as a coloring, thenu the color that fgf assigned tois the new color-g(u).) Now let us think about the number of fixed points ofin the set of C-colorings of U. Such a fixed point is a col-$g$ oringu. But thenf that equa lsf (u) =gff (gu): that is,$=f (u)f (g^{2} = u)f (gu)= · · ·\text{for every}$, which means that, given any cycle ofsame color to all members of that cycle. It follows thatg, f must assign the the number of fixed colorings of$g is c^{#}cycles^{(}g)$, wherec = |C| is the number of colors.

number of different colorings oflence) is Applying Burnside’s lemma, we may deduce that the U (up to G - equiva - c#cycles(g),|G|

since an equivalence class of colorings is simply an orbit of one of the colorings in that class.$g \in^{G}$

IV. Branches of Mathematics

(with out a clasp) are there that consist of Here is a simple application. How many necklacesp beads (where The underlying set isp is a prime) and that use\\{0, . . . , p - 1\\}a, and the symme-different colors? try group is Zp , the cyclic group of order p. As usual, regard the elements of the symmetry group as permu-tat i ons of the set of beads. Sincep is a prime, there a rep one element (the identity permutation) with- 1 elements of Zp with one cycle (of length pp cycles), and(all of length 1). It follows that the number of necklaces is $p1 ((p - 1) · a + 1 · a^{p}) = a + a^{p}p - a$.
In particular, since this number is necessarily an integer, we get as a bonus a combinatorial proof of[III.58](/part-03/modular-arithmetic): that$a^{p} - \text{a is always afer}-$ mat’s little theorem multiple ofp. Perhaps one day there will be an equally nice combinatorial proof of Fermat’sone has to do is to prove that there is no bijection from last theorem. All the union of the set of straight necklaces of sizex colors, and the set of such necklaces using yncolors, using to the set of necklaces using$z colors (with n > 2$, of course).
If one wants to keep track of how many beads there are of each color, one simply replaces straight countingby weighted counting, andc#cycles(g) is replaced by(x1 + · · · + xc()α)1 · ((x1)2 + · · · + (xc)2()α)2 · · · (assuming that g has α1 1 - cycles, α2 2 - cycles, etc.). The resulting expression is the celebrated polynomial. cycle-index

6.1 The Principle of Inclusion–Exclusion and

Möbius In version

Another pillar of enumeration is the principle of inclusion–exclusion (nicknamed PIE). Suppose that there aren sins, s , . . . , s , that a person may succumb to, and suppose that for each set of sins people who have all the sins in1 n S (and possibly others).S, AS is the set of Then the number of good people (with out sins) is

(-1()|()S){|}|A |.SS

For example, if the setπ of \\{1, . . . , n\\} and the A is the set of all permutations ith sin is having π[i] = i, then$|A | = (n − |S|)$!, and we get that the number of

$S$

derangements (permutations with out fixed points) is n (-1)k n (n - k)!$= n$!n (-1)k 1, k = 0 kk = 0 k!

IV.18. Enumerative and Algebraic Combinatorics which yields theis some times called the “umbrella problem”: if on a answer: “closest integer to$n$!$/$ e.” This rainy day leave an umbrella by the door, and if on their depar-n absent-minded people go to a party and ture they each take a random umbrella, then the probability that nobody ends up with the right umbrella is about 1$/e$. eral partially ordered sets (posets) where the poset hap-pens to be the Boolean lattice.
This realization was pub-The PIE is a special case of Möbius in version on gen li shed in a seminal paper by Rota (1964) and reprintedin his collected works. It is considered by many to be the big bang that started modern algebraic combinatorics. Möbius’s original in version formula is recovered when the partially ordered set is N and the partial order is divisibility. A contemporary account of enumeration from the “algebraic” point of view can be found in a marvelous two-volume set by Stanley (2000), which I strongly recommend.
7 Algebraic Combinatorics So far I have described one of the routes to algebraic combinatorics: abstraction and conceptualizati on of classical enumeration. The other route, “concretization of the abstract,” is almost every where dense in mathematics, and cannot be described in a few pages. Letme quote from the preface of the excellent New Perspectives in Algebraic Combinatorics(1999). by Billera et al.
Algebraic combinatorics involves the use of techniques from algebra, topology, and geometry in the solution of combinatorial problems, or the use of combinato-rial methods to attack problems in these areas. Problems amenable to the methods of algebraic combina-torics arise in these or other areas of mathematics or from diverse parts of applied mathematics. Because ofthis interplay with many fields of mathematics, algebraic combinatorics is an area in which a wide variety of ideas and methods come together.

7.1 Tableaux

An interesting class of objects that initially came upin group representation theory, but that turned out to be useful in many other areas—such as, for exam-ple, the theory of algorithms—are Young tableaux. They were first used by Reverend Alfred Young to construct explicit bases for the irreducible representations [IV.9 §2](/part-04/representation-theory) of thetitionλ = λ · · ·symmetric group. ambda of n, a Young tableau of shape[III.68](/part-03/permutation-groups).
For any par-. ambda is 1$k$561 an array of first row,. ambda ken tries in the second row, and so on, such left-justified rows with$λ^{1} \text{entries in the}$ that every row and every column is increasing, and theset of entries is2$\\{1}$,2, . . . , n\\\\\\\\\\\\\\\\\\\\\}. For example, there are two standard Young tableaux whose shape is 22, 1 2 1 3 , 3 4 2 4 and three of shape 31, 1 2 3 1 2 4 1 3 4 .4 3 2 Letshapef^λ . ambda be the number of standard Young tableaux of. For example$, for n = 4:$ f = 1$, f = 3, f =$2, these numbers is 1 f211 = 3, and f11112 + =32 1.
The sum of the squares of + 22 + (32)4 + 12 = 3124 = 4!. 22 representation parametrized byin The number representation theoryf. ambda is the dimension of the irreducible[IV.9](/part - 04/\text{representation} - theory) known asλ. It follows by a result Frobenius reciprocity words, that the same is true for all$n$. In other(fλ)2 = n!, a result known as the. ambda Young–Frobenius identity*n.
A gor- ge ous beautiful properties, was given by Gilbert robinson bijective proof of this identity, which has many and Craige Schensted and later extended by Donald Knuth, and is now known as the Robinson–Schensted Knuth correspondence. It inputs a permutationπ π · · · π , and outputs a pair of Young tableaux ofπ = the same shape, there by proving the identity.1 Algebraic combinatorics is currently a very active2 n field, and as mathematics is becoming more and more concrete, constructive, and algorithmic, there are going to be many more combinatorial structures discovered in all areas of
mathematics (and science!) and this will guarantee that algebraic combinatorial ists will stay very busy for a long time to come. Further Reading Billera, L. J., A. Bjorner, C. Greene, R. E. Simion, and R P.Stanley, eds. 1999. New Perspectives in Algebraic Combi Ehrenpreis, L., and D. Zeilberger. 1994. Two EZ proofs ofnatorics$\sin2 z +$. Cambridge: Cambridge University Press.. os2 z = 1. American Mathematical Monthly101: Rota, G.-C. 1964. On the foundations of combinatorial691.theory. I. Theory of Möbius functions. Zeitschrift für wahrscheinlichk eitstheorie und Verwandte Gebiete68.
2:340 Stanley, R. P. 2000.and 2. Cambridge: Cambridge University Press. Enumerative Combinatorics, volumes 1 562 IV.19 Extremal and Probabilistic Combinatorics Noga Alon and Michael Krivelevich 1 Combinatorics: An Introduction 1.1 Examples It is hard to give a rigorous definition of combinatorics. Instead, let us start with a few examples to illustrate what the area is about.(i) In the course of an examination of friendship between children some fifty years ago, the Hungar-ian sociologist Sandor Szalai observed that among any group of about twenty children he checked he could always find four
children any two of whom were friends, or else four children no two of whom were friends. Despite the temptation to try to draw socio-logical conclusions, Szalai realized that this might well be a mathematical phenomenon rather than a socio-logical one. Indeed, a brief discussion with the mathematicians Erd ̋os, Turán, and Sós convinced him this was the case. Ifis some symmetric X is any set of size 18 or more, and relation[I.2 §2.3](/part - 01/language - and - grammar) on X, then there R is always a subset property:
eitherx Ry S offor any two distinct elements X of size 4 with the followingx, y ofthis case, S, or x Ry X is a set of children andfor no two distinct elements Ris the relation “isx, y of S. In friends with.” This mathematical fact is a special case of Ramsey’s theorem, which was proved by the economist and mathematician Frank Plumpton Ramsey in 1930.Ramsey’s theorem led to the development of Ramsey theory, a branch of extremal combinatorics, which will be discussed in the next section.(ii) In 1916, Schur was studying fermat’s last theorem Diophantine equation has no solutions by showing
that[V.10](/part - 05/fermats - last - theorem). It is some times possible to prove that a it has no solutions mod Schur proved that for every integerp for some primek and every suf - p. However, fic ient ly large primeandc, none of them congruent to 0 modp, there are three integer sp, such thata, b, ak + bk is congruent to ck. Although this is a result in number theory, it has a relatively simple and purely combinatorial proof, which is another example of the many applications of Ramsey theory.
random polynomials,(iii) When studying the number of real zeros of littlewood [VI.79](/part - 06/john - edensor - littlewood - 18851977) and Offord investigated in 1943 the following problem. Let. . . , zn be n not - necessarily-distinct complex numbers, z1, z2, IV. Branches of Mathematics each of modulus at least 1. One can form 2 n sums by taking some subset of these numbers and adding them together (with the convention that if one takes the empty set, then the sum is 0).
Littlewood and Offord wanted to know how many of these sums there could conceivably be such that the difference between anytwo of them had modulus less than 1. When$n = 2$ the answer is easily seen to be at most 2. There are four sums: 0, z , z , and z + z . You cannot choose both of the first two or both of the last two or you will have a difference of1 2$(z1)1$, which has modulus at2 least 1. Kleitman and Katona proved that in general the maximum isn . Notice that a simple construction proves that this maximum can be achieved.
Indeed, letz = z = · · · =n/2!z and choose all sums of precise lyn/1 2! of them. There ar(e2)n n/n 2! such sums and they are all equal. The proof that one cannot do better than this uses tools from another area of extremal combinatorics, where the basic objects studied are systems of finite sets. TT1(iv) Consider a school in which there are, Thas to teach the class2, . . . , Tm and n classes Cfor a specified number C1$, C2$, . . . , Cn. The teach erm teacher sp of lessons. What is the minimum possible number of periods in a complete timetable?
Letij di denote the total ij number of lessons the teacher T has to teach, and leticto be taught. Clearly, the number of periods require dj denote the total number of lessons the class Cj has for a complete schedule is at least as big as any cj, and thus at least as big as the maximum of all these di or numbers, which we denote by obvious lower bound ofdis also an upper bound: itd. It turns out that this is always possible to fit all the lessons that need to be taught into theorem, which is a basic result in graph theory. Sup-d periods.
This is a consequence of König’s pose now that the situation is not so simple: for every teacher T and every class Cthere is some specified set ofd periods in which the teaching has to take place.i j Can we always find a feasible timetable with these more complicated constraints? Recent breakthroughs from a subject known as always possible. list coloring of graphs imply that it is how many colors do you need if you want to color the countries with out giving any two adjacent coun-(v) Given a map with several countries represented, tries the same color?
Here we assume that each coun-try forms a connected region in the plane. Of course, at least four colors may be necessary: think of Belgium, France, Germany, and Luxembourg, out of which anytwo have a common border. The four-color theorem

IV.19. Extremal and Probabilistic Combinatorics [V.12](/part-05/the-four-color-theorem), proved by Appel and Haken in 1976, asserts that you never need more than four colors. The study of this problem led to numerous interesting questions and results about graph coloring.(vi) Let S be an arbitrary subset of the two-dimen- sional lattice Z2.
For any two finite subsets A, B ⊂ Z we can think of the Cartesian product of “combinatorial rectangle.” This set has size A . imes B as a sort|A| |B| (where|X| denotes the size of a set X), and we can define an obvious notion of the A . imes  B by the formula d (A, B) = |density S ∩ (Ad S. imes (A, B)B)|/|of A| |SBin|, S

which measures what proportion of the elements of A . imes  B belong to S. For each k, let d(S, k) be the largest possible value of d(A, B) if |A| = |B| = k. What can S we say about guess that almost any behavior is possible, but, remark - d(S, k) as ktends to infinity? One might ably, basic results in extremal graph theory (about theso-called Turán numbers of complete bipartite graphs) imply that(vii) Suppose thatd(S, k) must always tend to 0 or 1.n basketball teams compete in a tournament and any two teams play each other exactly once.
The organizers wish to awardk prizes at the end of the tournament. It would be embarrassing if there ended up being a team that had not won a prize despite be at ing all the teams that had won a prize. However, unlikely though it might sound, it is quite possible that this will be the case what eve rk teams they choose, at least ifn is large enough. To demonstrate this is easy if one uses theof the most powerful techniques in combinatorics.
for probabilistic method, which is one any fixed of all the games are chosen randomly (and uniform lyk, and all sufficiently largen, if the results and independently), then there is a very high probability that for any beats all of them. Probabilistic combinatorics, which isk teams there is another team that one of the most active areas in modern combinatorics, started with the realization that probabilistic reasoning often provides simple solutions to problems of this type, problems that are often very hard to solve in any other way.
subgroup of size and(viii) Ifn/k right cosets of Gis a finite group ofk in G, then there are H. Is there always a set ofn elements, andn/k left cosets H n/kis a elements ofeach right coset and a single representative of each left G that contains a single representative of coset? Hall’s theorem, a basic result in graph theory, implies that there is. In fact, if H is another subgroup of sizeof G that contains a single representative of each rightk in G, then there is always a set of n/k elements coset of H and a single representative of each left coset

563

of H^ . This may sound like a result in group theory, but it is really a (simple) result in combinatorics.

1.2 Topics

The examples described above illustrate some of the main themes of combinatorics. The subject, some times also called discrete mathematics, is a branch of mathematics that focuses on the study of discrete objects(as opposed to continuous ones) and their properties. Although combinatorics is probably as old as the human ability to count, the field has experienced tremendous growth during the last fifty years and has matured into a thriving area with its own set of problems, approaches, and methodology.
basic mathematical discipline that plays a crucial role The examples above suggest that combinatorics is a in the development of many other mathematical areas. In this essay we discuss some of the main aspects of this modern field, focusing on extremal and probabilistic combinatorics. (An account of combinatorial prob-lems with a rather different flavor can be found in algebraic and enumerative combinatorics of course, impossible to cover the area fully in such[IV.18](/part-04/enumerative-and-algebraic-combinatorics).) It is, a short article.
A detailed account of the subject can be found in Graham, Grötschel, and Lovász (1995).Our main intention is to give a glimpse of the topics, methods, and applications illustrated by representative examples. The topics we discuss include extremal graph theory, Ramsey theory, the extremal theory of set systems, combinatorial number theory, combinatorial geometry, random graphs, and probabilistic com-binatorics. The methods applied in the area include combinatorial techniques, probabilistic methods, tools from linear algebra, spectral techniques, and topological methods.
We also discuss the algorithmic aspects and some of the many fascinating open problems inthe area. 2 Extremal Combinatorics Extremal combinatorics deals with the problem of determining or estimating the maximum or minimum possible size of a collection of finite objects that sat-isfies certain requirements. Such problems are often related to other areas, including computer science, information theory, number theory, and geometry. This branch of combinatorics has developed spectacularly over the last few decades (see, for example, Bollobás(1978)$, Jukna (2001)$, and their many references).
564 2.1 Extremal Graph Theory Astructures. It consists of a set of points, called graph [III.34] is one of the very basic combinatorial vertices, some of which are linked by edges. One can represent a graph visually by drawing the vertices as points in the plane and the edges as lines (or curves). However, formally a graph is more abstract: it is just a set together with a collection of pairs taken from the set. More precisely, it consists of a setset E, called the edge set;
the elements of V, called the vertex set E (the edges), and a are sets of the form$\\{u}$, v\\\\\\\\\\\\\\\\\\\\\}, where u and v are distinct elements of V . If \\{u, v\\} is an edge, we say that u andvnumber of vertices adjacent to it.are adjacent. The degree d(v) of a vertex v is the Here are a number of simple definitions associated with graphs that have emerged as important. Aof len gthk from u to v in G is a sequence of distinct path vertices adjacent for all u = v0, vi < k1, . . . , v.
If vk == vv, where(but all verticesvi and vi + v1 are for i < kis usually denoted byare distinct), this is called a C . A grap(h0)k cycle G is of length connected kif for, andi any two ver tice su, v ofk G there is a path from u to v. A complete graph any two of them are adjacent. AKr is a graph with sub gr a phr vertices such thatof a graph G is a graph that contains some of the vertices ofsome of its edges. A clique in G is a set of vertices in G and G such that any two of them are adjacent. The maximum size of a clique in G is called the clique number of G.
Similarly, an G with no two of them adjacent, and the independent set in G is a set of vertices in independence number set in it. of G is the maximum size of an independent nections between various parameters of a graph, such Extremal graph theory deals with quantitative conas its numbers of vertices and edges, its clique num - ber, or its independence number.
In many cases a certain optimization problem involving these parameters has to be solved (for example, determining how big one parameter can be if another one is at most some given size), and its optimal solutions are the graphs for this problem. Many important optimization extremal problems that do not explicitly mention graphs can be reformulated, using the definitions above, as problems about extremal graphs.

2.1.1 Graph Coloring

Let us return to the map-coloring example discussed inthe introduction. To translate the problem into mathematics, we can describe the map-coloring problem in

IV. Branches of Mathematics

terms of a graph respond to the countries on the map, and two vertices G, as follows. The vertices of G cor- are connected by an edge in G if and only if the cor- responding countries share a common border. It is not hard to show that one can draw such a graph in such a way that no two edges cross each other: such graphs are called planar. Conversely, any planar graph arises in this way. Therefore, our problem is equivalent to the following: if you want to color the vertices of a planar graph so that no two adjacent vertices receive the same color, then how many colors do you need?
(One can make the problem yet more mathematical by removing the nonmathematical notion of color. For example, one can assign to each vertex a positive integer instead.)Such a coloring is called proper. In this language, the four-color theorem states that every planar graph canbe properly colored with four colors. Here is another example of a graph-coloring problem. Suppose we must schedule meetings of several parlia-ment committees. We do not wish to have two committees meeting at the same time if some parliament member belongs to both, so how many sessions do we need?
Gvertices adjacent if and only if the corresponding com-. The vertices of Again we can model this situation by using a graph G represent the committees, with two mittees share a member. Aassigns to each committee one ofschedule is a functionk time slots. Moref that mathematically, we can think of it as just a function from$V \text{to the set} \\{1}$,2, . . . , k\\\\\\\\\\\\\\\\\\\\\}. Let us call a schedule valid number. This corresponds to no two committees being if no two adjacent vertices are assigned the same assigned the same time slot if they share a member.
The question then becomes, “What is the minimal value of$k$for which a valid schedule exists?” graph colors in any proper coloring of The answer is called the G, denoted χ(G): it is the smallest number ofchromatic number G. Notice that a color-of the ing of a graph the set of vertices of that color is independent. There-G is proper if and only if for each color fore, of independent sets into which it is possible to par-χ(G)can also be defined as the smallest number tition the vertices of G.
A graph is called k-colorable if it admits a partitioned intok-coloring, or, equivalently, if it can bek independent sets. Thus, χ(G) is the minimum Two simple examples are in order. Ifk for which G is k-colorable. G is a complete graph Kn on n vertices, then obviously in any coloring ofare necessary. Of course, G all vertices get distinct colors, and thusncolors are also sufficient, n colors

IV.19. Extremal and Probabilistic Combinatorics sotices, then easy parity arguments show that at leastχ(Kn) = n. If G is a cycle (C2()n)+1 on 2 n + 1 ver- three colors are needed, and three colors are enough: color the vertices along the cycle alternately by colors1 and 2, and then color the last vertex by color 3. Thus, χ(CIt is not hard to prove tha(t2()n)+1) = 3. G is 2-colorable if and only if it does not contain a cycle of odd length. Graphs that are 2-colorable are usually called split into two parts, with all the edges going from one bipartite, since they part to the other.
The easy character ization ends here, and no simple criterion equivalent tok-colorability is available fork ⩾ 3. This is related to the fact that for each fixedk ⩾ 3 the computational problem of decid- ing whether a given graph isa notion discussed in computational complexityk-colorable is NP-hard, [IV.20](/part-04/computational-complexity).Coloring is one of the most fundamental notions of graph theory, as a huge array of problems in this field and in related areas like computer science and operations research can be formulated in terms of graph coloring.
Finding an optimal coloring of a graph is known to be a very hard task, both theoretically and practically. There are two simple yet fundamental lower bounds on the chromatic number. First, as every color class ina proper coloring of a graph G forms an independent set, it cannot be bigger than the independence number of|V (G)|G/α(G), which is denoted by colors are necessary. Secondly, ifα(G). Therefore, at least G con- tains a clique of size that clique alone, and thusk, then χ(G)k colors are needed to color⩾ k. This implies thatχ(G) ⩾ ω(G), where ω(G) is the clique number of G.
One of the simplest approaches to coloring a graph is todo it What about upper bounds on the chromatic number?greedily: put the vertices in some order and color them one by one, assigning to each one the smallest positive integer that has not already been assigned to one of its neighbors. While the greedy algorithm can some times be very inefficient (for example, it can color bipartite graphs in an unbounded number of colors, even though two colors are sufficient), it often works quite well.
Observe that when applying the greedy algorithm, a color given to a vertex than the number of the neighbors ofv is at most one morev preceding it in the chosen order, and is thus at mostd(v) is the degree of v in G. It follows that ifd(v). elta+(G)1, where is the maximum degree ofat most. elta(G) + 1 colors. Therefore G, then the greedy algorithm usesχ(G) ⩽ . elta(G) + 1. This bound is tight for complete graphs and odd cycles, 565 and, as shown by Brooks in 1941, those are the only cases:
if G is a graph of maximum degree . elta, thenχ(G) ⩽ . elta unless G contains a clique (K. elta)+1, or . elta = 2 and G contains an odd cycle. rather than the vertices. In this case a proper coloringis defined to be one where no two edges that meet at It is also possible to color the edges of a graph, a vertex are given the same color. Theof$G$, denoted by χ^ (G), is the minimum chromatic indexk for which G admits a proper edge-coloring with ple, if G is the complete graph K , thenk colors. For exam-χ^ (G) = 2 n-1.
This turns out to be equivalent to the fact that it is2 npossible to organize a round-robin tournament with 2 teams and fit it into 2 n -1 rounds: just ask the man- nager of a soccer league. It is also not hard to show thatχ^ (K ) = 2 n - 1. Since in any proper edge-coloring ofdistinct colors, the chromatic index is obviously at least G2 all edges o(fn)-1 G that are incident to a vertex v get as big as the maximum degree.
Equality holds for bipartite graphs, as proved by König in 1931, which implies the existence of a complete timetable usingd periods in the problem of teachers and classes discussed in the introduction. Remarkably, this trivial lower bound ofχ^ (G) ⩾ . elta(G) is very close to the true behavior oftal theorem of Vizing from 1964 states thatχ (G). A fund a men-χ^ (G) is always equal either to the maximum degree. elta(G) +1. Thus, the chromatic index of G is much easier. elta(G) or to to approximate than its chromatic number.
2.1.2 Excluded Subgraphs If a graph(that is, three vertices all joined to each other) then G has n vertices and contains no triangle how many edges can it contain? Ifn is even, then you can split the vertex set into two equal partssizen/2 and join every vertex in A to every vertex in A and B of Bn. The resulting graph2/4 edges. More over, adding another edge will auto - G contains no triangles and has matically create a triangle (in fact, several triangles).But is this the densest possible triangle-free graph? A hundred years ago the answer was shown to be yes by Mantel.
(A similar theorem holds when now A and B must have nearly equal sizesn is odd, but(n + 1)/2$and$(n - 1)/2.) of the triangle is played by an arbitrary graph. more precisely, let Let us look at a more general problem, where the role H be any graph, with m vertices, say, and whenn ⩾ mlet us define ex(n, H) to be the maximum possible number of edges in a graph withn vertices

566

that does not contain“ex” stands for “exclude.”) The function ex H as a subgraph. (The notation(n, H) is usu- ally called the Turán number of H, for reasons that will become clear, and finding good approximations for ithas been a central problem in extremal graph theory. His that if What kind of examples of graphs that do not contain can we think of? One observation that gets us started H has chromatic number r , then it cannot be a subgraph of a graph than$r$. (Why not?
Because a proper G with chromatic number less(r - 1)-coloring of G provides us with a proper (r - 1)-coloring of any sub- graph of graph G with G.) So a promising approach is to look for an vertices, chromatic number r - 1, and as many edges as possible. This is easy to find. Our con-str a int is that the vertices can be partitioned into$r - 1$ independent sets. Once we have done that, we may aswell include all edges between those sets. The result is a complete(r - 1)-partite graph.
A routine calculation shows that in order to maximize the number of edges, one should partition into sets that have sizes as nearly equal as possible. (For example, if$n = 10 and r = 4$, then we would partition into three sets of sizes 3, 3, and 4.) Turán graphtains is denoted by The graph that satisfies this condition is called the(Tr)-1(n)(tr)-and the number of edges it con-1(n). We have just argued that exas big as(n, H) ⩾(1 t-r -11/(r(n)-, which can be shown to be at least1))n.
exact solution, in 1941, for the most important case, when Turán’s contribution to this area was to give an H is the complete graph2 K on r vertices. Her

proved that exis actually equal to(n, Ktr)- is not just at least(n). More over, the only(tr)-1(n)K , but-free graph with graph(Tr)-1(n)n vertices and ex. Turán’s paper is generally considered$r^{1} (n$, Kr )edges is the Turán$r$ the starting point of extremal graph theory. Later, Erd ̋os, Stone, and Simonovits extended Turán’s theorem by proving that the above simple lower bound for exwith chromatic number at least 3.
That is, if(n, H) is asymptotically tight for any fixedr is the H chromatic number oft- (n) tends to 1 as n Htends to infinity., then the ratio of ex(n, H) tor Thus, the function ex1 (n, H) is well-understood for all nonbipartite graphs. Bipartite graphs are rather differ-ent, because their Turán numbers are much smaller: if H is bipartite, then ex(n, H)/n2 tends to zero. Deter- mining the asymptotics of exa challenging open problem with many unsettled ques-(n, H) in this case remains tions. Indeed, the full story is unknown even for the very simple case when H is a cycle. Partial results

IV. Branches of Mathematics

obtained so far use a variety of techniques from differ-ent fields, including probability theory, number theory, and algebraic geometry.

2.1.3 Matchings and Cycles

Let edges in G be a graph. AG of which no two share a vertex. A matching matching in G is a collection of Mof the edges inin G is called Mp erf ect. (The idea is that the edges determineif every vertex belongs to one a “match” for each vertex: the match fory for which xy is an edge of M.) Of course, forx is the vertex G to have a perfect matching it must have an even number of vertices. Hall’s theorem, which provides a necessary and suffi-cient condition for the existence of a perfect matching One of the best-known theorems in graph theory is in a bipartite graph.
What kind of condition can this be?It is very easy to write down a trivial necessary condition, as follows. Let sets A and B of equal size. (If they do not have equal G be a bipartite graph with vertex size, then clearly there is no perfect matching.) Given any subset S of A, let N(S) denote the set of all vertices in B that are joined to at least one vertex in S. If there is to be a matching, then it must be possible to assign toeach vertex in$S$a distinct “match,” so obviously N(S) must have at least as many elements asorem, proved in 1935, asserts that, remarkably, this$S$.
Hall’s the obvious necessary condition is also sufficient. That is, if N(S) is always at least as big as S, then there will be a perfect matching. More generally, ifthen the same condition guarantees that one can find A is smaller than B, a matching that includes every vertex insome vertices in B unmatched). A (but leaves in terms of set systems. Let tion of sets, and suppose that we would like to find a There is a useful reformulation of Hall’s theorem$S^{1}$, S2, . . . , Sn be a collec- system ofx , x , . . . , xdistinct representatives such that x is an element of:
that is, a sequence S and no two of the1 2 x^n are the same. Obviously this cannot be^i^ii

done if the union of somek of the sets S has size lessi

th ancient. It is not hard to show that this assertion is equiv- k. Again, this obvious necessary condition is suffialent to Hall’s theorem: let define a bipartite graph with vertex sets S be the union of the1, 2, . . . , n Si andand S, joining i to x if and only if x \in  S . Then a match-i

ing that includes all of the set$\\{1}$,2, . . . , n\\\\\\\\\\\\\\\\\\\\\} picks out a system of distinct representatives: S that is matched with i. xi is the element of of finding a system of representatives for the right and Hall’s theorem can be applied to solve the problem

IV.19. Extremal and Probabilistic Combinatorics left cosets of a subgroup Define a bipartite graph F, whose two sides (of size H, mentioned in section 1.1.n/k each) are the left and right cosets ofis connected by an edge of F to a right coset H. A left coset Hg if theyg1 H share a common element. It is not difficult to show that Fsatisfies the Hall condition, and hence it has a per-2 fect matching M.
Choosing for each edge (gi H, Hgj) ofthe required family of representatives. M a common element of gi H and Hgj, we obtain for the existence of a perfect matching in a general(not-necessarily-bipartite) graph There is also a necessary and sufficient condition G. This is a theorem of Tutte, which we shall not state here. Recall that C denotes a cycle of length k. A cycle is a very basic graph structure, and, as one might expect, there are many extremal results concerning cycles.$k$ Suppose that G is a connected graph with no cycles.
If you pick a vertex and look at its neighbors and then the neighbors of its neighbors, and so on, you will see that it has a tree-like structure. Indeed, such graphs are called trees. An easy exercise shows that any tree withn vertices has exactly n - 1 edges. It follows that every graph cycle. If you want to guarantee that this cycle has cer-G on n vertices with at least n edges has a tain extra properties, then you may need more edges. For example, the theorem of Mantel mentioned earlier implies that a graphn2/4 edges contains a triangle G with n vertices and more than C = K .
One can also prove that a graph has a cycle of length longer than G = (V , E) withk3 (and this is in fact a|E3| >1 2 k(|V | − 1) sharp result).A Hamilton cycle in a graph G is a cycle that vis- its every vertex ofinvented by hamilton G. This term originated in a game,[VI.37](/part - 06/william - rowan - hamilton - 18051865) in 1857, the objective of which was to complete a Hamilton cycle in the graph of the dodecahedron. A graph containing a Hamilton cycle is called related to the well-known hamiltonian traveling salesman prob-.
This concept is strongly lem [VII.5 §2](/part - 07/the - mathematics - of - algorithm - design): you are given a graph with positive weights assigned to the edges, and you must find a Hamilton cycle for which the sum of the weights of its edges is minimized. There are many sufficient criteria for a graph to be Hamiltonian, quite a few of which are based on the sequence of degrees. For example, Dirac proved in 1952 that a graph on n ⩾ 3 vertices all of whose degrees are at leastn/2 is Hamiltonian.

2.2 Ramsey Theory

Ramsey theory is a systematic study of the following general phenomenon. Surprisingly often, a large struc-

567

ture of a certain kind has to contain a fairly large highly organized substructure, even if the structure itself is completely arbitrary and apparently chaotic. As succinctly put by the mathematician T. S. Motzkin, “Com-plete disorder is impossible.” One might expect that the simple and very general form of this paradigm ensures that it has many diverse manifestations in different mathematical areas, and this is indeed the case.
(One should, however, bear in mind that some natu-ral statements of this kind are false for nonobvious reasons.)A very simple statement, which can be regarded as a basic prototype for what follows, is the pigeonhole principle with. This states that if a sets colors, then there must be a subset of X of n objects is colored X of size at least called monochromaticn/s that uses just one color. Such a subset is. The situation becomes more interesting if the set X has some additional structure.
It then becomes natural to ask for a monochromatic subset that keeps some of the structure of obvious whether such a subset exists. Ramsey theory X . However, it also becomes much less consists of problems and theorems of this general kind. Although several Ramsey-type theorems had appeared before, Ramsey theory is traditionally regarded as having started with Ramsey took as his set Ramsey’s theorem X the set of all the edges in, proved in 1930. a complete graph, and the monochromatic subset he obtained consisted of all the edges of some complete subgraph.
A precise statement of his theorem is as follows. Let exists an integerk and l be integers greater than 1. Then theren such that, however you color the edges of the complete graph withn vertices, using the two colors red and blue, there will either besuch that all edges between them are red orkl vertices vertices such that all edges between them are blue. That is, a suf-fic ient ly large complete graph colored with two colors contains a largish complete subgraph that is monochro-matic. Let R(k, l) denote the minimum number n with this property.
In this language, the observation of Sza-lai, mentioned in the introduction, is that$R(4$, 4) ⩽ 20 (in fact,$R(4$, 4) =18). Actually, Ramsey’s theorem was more general, in that he allowed any number of colors, and the objects colored could be rather than just pairs, as one has when coloring graphs.r -tuples of elements The exact computation of small Ramsey numbers turns out to be a notoriously difficult task: even the value of

R(5, 5) is unknown at present. by Erd ̋The second cornerstone of Ramsey theory was laidos and Szekeres, who in 1935 wrote a paper 568 containing several important Ramsey-type results. In particular, they proved the recursion R(k, l) ⩽R(kary conditions - 1, l)+R(k, l R(2-, l)1). Combined with the easy bound-= l, R(k, 2) = k, the recursion leads to the estimate the so-called diagonal case R(k, l)k⩽= lkwe obtai(n+k()-l()-1)2. In particular, for R(k, k) < 4 k. Remarkably, no improvement in the exponent of the latter estimate has been found so far.
That is, nobody has found an upper bound of the form Ck for some C <cuss in section 3.2, is roughly4. The best lower bound known, which we shall dis-R(k, k) ⩾ 2 k/2, so there is a rather substantial gap. and Szekeres, is of a geometric nature. They showed that for every Another Ramsey-type statement, proved by Erd ̋n ⩾ 3 there exists a positive integer os N such that, given any configuration of N points in the plane in general position (i.e., no three of them are on aline), there aren that form a convex n - gon.
(It is in struc- tive to prove that ifn = 4 then N can be taken to be 5.) There are several proofs of this theorem, some using the general Ramsey theorem. It is conjectured that the smallest value ofconvexn-gon is 2 n N - 2 that will do in order to ensure a + 1. following Ramsey-type result: any sequence of The classic Erd ̋os–Szekeres paper also contains the n2 + 1 distinct numbers contains a monotone (increasing or decreasing) subsequence of length$n + 1$.
This provides a quick lower bound of$\sqrt{n} \text{for a}$ well-known problem of Ulam, asking for the typical length of a longest increasing subsequence of a random sequence of len gthn. A detailed description of the distribution of this length has recently been given by Baik, Deift, and Johansson. In 1927 van der Waerden proved what became known as van der Waerden’s theorem: for all positive integersk and r there exists an integer W such that for every coloring of the set of integers$\\{1}$,2, . . .
, W\\\\\\\\\\\\\\\\\\\} using r col-$ors$, one of the colors contains an arithmetic progres-sion of len gthk. The minimum W for which this is true is denoted by W (k, r )are enormous: they grow like an Ackermann-W (k, r ). Van der Waerden’s bounds for type function. A new proof of his theorem was found by Shelah in 1987, and yet another proof was given by Gowers in 2000, while he was studying the (much deeper) “density version” of the theorem, which will be described in section 2.4.
These recent proofs pro-vided improved upper bounds for W (k, r ), but the best- known lower bound for this number, which is only exponential inkfor each fixedr , is much smaller. IV. Branches of Mathematics that for any positive integer ger Even before van der Waerden, Schur proved in 1916 S(r ) such that for every r -coloring ofr there exists an inte-\{1, . . . , S(r )\} one of the colors contains a solution of the equationx + y = z. The proof can be derived rather easily from the general Ramsey theorem. Schur applied this state-ment to prove the following result, mentioned in section 1.1:
for everyp, the equation ak + k band all sufficiently large primesk = ck has a nontrivial solution in the integers modulothatp ⩾ S(k) and consider thep. To prove this result, assume field [I.3 §2.2](/part - 01/fundamental - definitions) Z of integers mod group [I.3 §2.1](/part - 01/fundamental - definitions) under multiplication. Letp. The nonzero elements of H be the sub - Zp form ap group of this group consisting of all H = {xk}:$x \in Z*$. It is not hard to show that the index kth powers: that is, rin particular is at mostof H is the highest common factor ofp k.
The partition ofk and Zp* -into the1, and cosets of Schur’s theorem there exist H can be thought of as anx, y, z \in {r -coloring of1, . . . , pp - 1 Z}* pthat. By all have the same color—that is, they all belong to the same coset ofd \in Z* such that H. In other words, there exists a residuex = dak$, y = dbk$, z = dck, anddaif we multiply both sides byk + pdbk = dck modulo p. The desired result fol lo wsd - 1. Graham, Rothschild, and Spencer (1990) or in Graham, Grötschel, and Lovász (1995, chapter 25).Many additional Ramsey-type results can be found in

2.3 Extremal Theory of Set Systems

Graphs are one of the fundamental structures stud-ied by combinatorial ists, but there are others too. An important branch of the subject is the study of set systems sets of some. Most often, these are simply collections of sub-n-element set. For example, the collection of all subsets of the set\\{1, 2, . . . , n\\} of size at mostn/problem in this area is any problem where the aim is to3 is a good example of a set system. An extremal determine, or estimate, the maximum number of sets there can be in a set system that satisfies certain con-ditions.
For example, one of the first results in the area was proved by Sperner in 1928. He looked at the following question: how large a collection of subsets can one choose from ann-element set in such a way that no set from the collection is a subset of any other? A simple example of a set system satisfying this condition is the collection of all sets of sizer , for some r . From this it immediately follows that we can obtain a collection as large as the largest binomial coefficient, which is$nn/ {}^{2}$

ifn is even and((n+n()1))/2 if n is odd.

IV.19. Extremal and Probabilistic Combinatorics sible size of such a collection. This result supplies aquick solution to the real analogue of the problem of Sperner showed that this is indeed the maximum pos Littlewood and Offord described in section 1.1. Sup-pose that$x^{1}$, x2, . . . , xn are n not-necessarily-distinct real numbers, each of modulus at least 1. A first obser-vation is that we may assume that all thex are posi-i

tive, since if we replace a negativexi by -xi (which is positive), then we end up with exactly the same set ofsums, but shifted by-x . (To see this, compare a sumi

that used to in vol vex with the corresponding sum thati

does not involve-x , and vice versa.) But now, if A is ai

proper subset ofto A, so B, then some xi belongs to B and not Therefore, the total number of subset sums you can find with any two differing by less than 1 is at mosti\in B xi -i\in A xi ⩾ xi ⩾ 1.n/A set system is called a(nn()2)!, by Sperner’s theorem.intersecting family if any two sets in the system intersect. Since a set and its comple-ment cannot both belong to an intersecting family of subsets of family can have size at most 2\\{1}$, 2, . . . , n\\$, we see immediately that such a^n^-^1.
More over, this bound is achieved by, for example, the collection of all sets that contain the element 1.
 But what happens if we fixak and assume in addition that all our sets have size k? We may assume thatn ⩾ 2 k, as otherwise the solution is trivial. Erd ̋isn-1 os, Ko, and Rado proved that the maximum . Here is a beautiful proof discovered later by Katona. Suppose you arrange the elements randomly around a circle. Then there are$k^{-1} n \text{ways of choosing} k$ elements that are consecutive in this arrangement, andit is quite easy to convince your self that at mostk of these can intersect (if$n ⩾ 2k)$. So out of these n sets of size ing family.
Now it is also easy to show that every set hask, only k of them can belong to any given intersect- an equal chance of being one of these proves (by a simple double-counting argument) that then sets, and this largest possible proportion of sets in the family is Therefore, the family itself has size at most$(k/n)k/n^{n}., which equals and Rado is more complicated than this, but it is impor-(nk()-){ - 1}1. The original proof of Erd ̋os, Ko, k tant because it introduced a technique known aspression, which was used to solve many other extremal com problems. Letn > 2 k be two positive integers.
Suppose that you wish to color all subsets of the set\\{1, 2, . . . , n\\} of siz ek intersect each other. What is the smallest number ofin such a way that any two sets with the same color

569

colors you can use? It is not difficult to see that$n - 2k + 2$ colors suffice. Indeed, one color class can be the family of all subsets of$\\{1}$, 2, . . . , 2 k - 1\\\\\\\\\\\\\\\\\\\\\}, which is clearly an intersecting family. And then, for eachi such that 2 k ⩽i largest element is⩽ n, you can take the family of all subsets whosei. There are n - 2 k + 1 such families, and any set of size the first family. Therefore, k belongs either to one of them or ton - 2 k + 2 colors are enough.
in other words, that if you have fewer than colors then you will have to give the same color to Kneser conjectured in 1955 that this bound was tight:$n - 2 k + 2$some pair of disjoint sets. This conjecture was proved by Lovász in 1978. His proof is topological, and uses the Borsuk–Ulam theorem. Several simpler proofs have been found since, but they are all based on the topolog-ical idea in the first proof. Since Lovász’s breakthrough, topological arguments have become an important partof the armory of researchers in combinatorics.
2.4 Combinatorial Number Theory Number theory is one of the oldest branches of math - ematics. At its core are problems about integers, but a sophisticated array of techniques has been devel-oped to deal with those problems, and these techniques have often themselves been the basis for further study(see, for example, algebraic numbers [IV.1](/part - 04/number - theory), analytic number theory[IV.5](/part - 04/arithmetic - geometry)). However, some problems in number theory have[IV.2](/part - 04/number - theory), and arithmetic geometry yielded to the methods of combinatorics.
Some of these problems are extremal problems with a combinatorial flavor, while others are classical problems in number theory where the existence of a combinatorial solution has been quite surprising. We describe below a few examples. Many more can be found in chapter 20 of Graham, Grötschel, and Lovász (1995), in Nathanson (1996), and in Tao and Vu (2006).A simple but important notion in the area is that of a sumset eral ly are two subsets of an. If A and B are two sets of integers, or more gen-abelian group[I.3 §2.1](/part-01/fundamental-definitions), then the sumset$A$, b \in B.
For instance, if A + Bis defined to be A = {1,3} and B{a= {+5 b,6}}:$,12a \in$, then relating the size and structure of$A + B = \\{6}$, 7, 8, 9, 13,15\\\\\\\\\\\\\\\\\\\\\}. There are many results A + B to those of A and which has numerous applications in additive number B. For example, the Cauchy–Davenport theorem, theory, is the statement that ifare two nonempty subsets of Zp, then the size ofis a prime, and AA+, BB is at least the minimum of occurs if A and B are arithmetic progressions with thep andp |A| + |B| −1.
(Equality same common difference.) cauchy [VI.29](/part - 06/augustin - louis - cauchy - 17891857) proved this 570 theorem in 1813, and applied it to give a new proof of alemma that lagrange [VI.22](/part - 06/joseph - louis - lagrange - 17361813) had proved as part of his well - known 1770 paper that shows that every positive integer is a sum of four squares. Davenport formulated the theorem as a discrete analogue of a related conjec-ture of Khinchin about densities of sums of sequences of integers.
The proofs given by Cauchy and by Daven-port are combinatorial, but there is also a more recent algebraic proof, based on some properties of roots of polynomials. The advantage of the latter is that it provides many variants that do not seem to follow from the combinatorial approach. For example, let us define Aa⊕=Bbto be the set of all. Then the smallest possible size ofa + b such that a \in AA⊕, Bb, given the\in B, and sizes of A and B, is the minimum of p and |A| + |B| − 2. Further extensions can be found in Nathanson (1996)and in Tao and Vu (2006).
tion 2.2 implies that, however you color the positive integers with some finite number The theorem of van der Waerden mentioned in sec - r of colors, there must be some color that contains arithmetic progres-sions of every length. Erd ̋os and Turán conjectured in 1936 that this always holds for the “most popular”color class. More precisely, they conjectured that for any positive integer there is a positive integerk and for any real numbern such that if n > n > 0,, any set of at leastn contains a k-term arithmetic progression.
(Set ti ngn positive integers between 1 an(d0)0 = r - 1 one can easily deduce van der Waerden’s theorem from this.) After several partial results, this con-jecture was proved by Szemerédi in 1975. His deep proof is combinatorial, and applies techniques from Ramsey theory and extremal graph theory. Furstenberg gave another proof in 1977, based on techniques of ergodic theory [V.9](/part - 05/ergodic - theorems). In 2000 Gowers gave a new proof, combining combinatorial arguments with tools from analytic number theory. This proof supplied a much better quantitative estimate.
A related very recent spectacular result of Green and Tao asserts that there are arbitrarily long arithmetic progressions of prime numbers. Their proof combines number-theoretic techniques with the ergodic theory approach. Erd ̋tured that any infinite sequenceni for which the sumos conjec - progressions. This conjecture would imply the theorem of Green and Tao.i(1/ni) diverges contains arbitrarily long arithmetic 2.5 Discrete Geometry Letthe plane. Let us define an P be a set of points and let incidence L be a set of lines into be a pair (p, ),

IV. Branches of Mathematics

where lies on the linep is a point in. Suppose that P, is a line in P contains L, and the pointm distinctp points and L contains n distinct lines. How many inci- dences can there be? This is a geometrical problem, but again it has a strong flavor of extremal combinatorics. As such, it is typical of the area known as combinatorial) geometry. discrete (or dences there can be betweenmerédi and Trotter determined the asymptotic behav-Let us write I(m, n) for the maximum number of inci-m points and n lines. Sze- ior of this quantity, up to a constant factor, for all possible values ofm and n.
There are two absolute positive constantsc1, c2 such that, for all m$, n, c1(m2/3n2/3 + m + n) ⩽ I(m, n)⩽ c2(m2/3n2/3 + m + n)$. If m > n2 or n > m2 then one can establish the lower bound by taking all lines through a single point, respectively. In the hard erm points on a single line, or all n cases when prove it by lettingm and Pn contain all the points of aare closer to each other, one can . qrtm! by. qrtm! grid, and by taking the nmost “popular” lines: that is, the P. Establishing the upper bound is more difficult.
Then lines that contain the most points of most elegant proof of it is due to Székely, and is based on the fact that, however you draw a graph withm ver- tices and more than 4 pairs of edges that cross each other. (This is a rat herm edges, you must have many simple consequence of the famous Euler formula connecting the numbers of vertices, edges, and regions inany drawing of a planar graph.) To bound the number of incidences between a set of points in the plane, one considers the graph whose vertices are P and a set of lines L the points P , and whose edges are all segments between
consecutive
points along a line inis obtained by observing that the number of crossings L. The desired bound in this graph does not exceed the number of pairs of lines in L, and yet should be large if there are many incidences. the following question: if you take how many pairs Similar ideas can be used to give a partial answer to(x, y) of these points can there be withn points in the plane, the distance fromx to yequal to 1? It is not surprising that the two problems are related: the number of such pairs is the number of incidences between the given$n$ points and the points.
Here, however, there is a large gap between then unit circles that are centered at these best known upper bound, which isc(n4()/){3} for some abso- lute constantis only(n1()+c)/clog log, and the best known lower bound, whichn for some constant c^  > 0.

IV.19. Extremal and Probabilistic Combinatorics have a finite family Rd A fundamental theorem of Helly asserts that if you, and if any d + 1 of them have a point in common, F of at least d + 1 convex sets in then all sets in the family have a common point. Nowlet us start with a weaker assumption: given anyp of the sets, somed+1 of those p sets have a point in com- mon. (Herep is some integer greater than d + 1.) Can one then find a setset in F contains a point in X of at most X, with C points such that each C a constant that depends onthe family?
This question was raised by Hadwiger andp but not on the number of convex sets in Debrunner in 1957 and solved by Kleitman and Alonin 1992. The proof combines a “fractional version” of Helly’s theorem with the duality of linear programming Unfortunately, it gives a very poor estimate for[III.84](/part-03/the-simplex-algorithm) and various additional geometric results. C: even in two dimensions and withp = 4 it is not known what the best possible value of C is. in discrete geometry.
Such results have been applied extensively in computational geometry and in com-This is just a small sample of problems and results binatorial optimization in recent decades. Two good books on the subject are Pach and Agarwal (1995) and Matoušek (2002).

2.6 Tools

Many of the basic results in extremal combinatorics were obtained mainly by ingenuity and detailed rea-soning. However, the subject has grown out of this early stage: several deep tools have been developed that have been essential to much of the recent progressin the area. In this subsection, we include a very brief description of some of these tools. Szemerédi’s regularity lemma is a result in graph theory that has numerous applications in various areas, including combinatorial number theory, computational complexity, and, mainly, extremal graph theory.
The precise statement of the lemma, which can be found, for example, in Bollobás (1978), is some what technical. The rough statement is that the vertex set of any large graph can be partitioned into a constant number of pieces of nearly equal size, so that the bipartite graphs between most pairs of pieces behave like random bipartite graphs. The strength of this lemma is that it applies to any graph, providing a rough approximation of its structure that enables one to extract a lot of information about it.
A typical application is that a graph with“few” triangles can be “well-approximated” by a graph with no triangles. More precisely, for any> 0 there

571

exists at mostδ >δn0 such that if3 triangles, then one can remove at most G is a graph with n vertices andn2 edges from looking statement turns out to imply the case G and make it triangle free. This innocent-k = 3 of Szemerédi’s theorem that was mentioned earlier. Tools from linear and multilinear algebra play an essential role in extremal combinatorics. The most fruitful technique of this kind, which is possibly also the simplest, is the so-called simplest form, the method can be described as follows.dimension argument.
In its In order to bound the cardinality of a discrete structure A, one maps its elements to distinct vectors in a vec- tor space [I.3 §2.3](/part-01/fundamental-definitions), and proves that those vectors are linearly independent. It then follows that the size ofis at most the dimension of the vector space in ques-$A$ tion. An early application of this argument was found by Larman, Rogers, and Seidel in 1977. They wanted to know how many points it was possible to find in Rn that determine at most two distinct differences.
An example of such a system is the set of all points whose coordinates consist ofn-2 0 s and two 1 s. Notice, however, that these points all lie in the hyperplane of points whose coordinates add up to 2. So this actually provides us with an example in R$n - 1$. Therefore, we have a simple lower bound of matched this with an upper bound ofn(n + 1)/2. Larman, Rogers, and Seidel(n + 1)(n + 4)/2. They did this by associating with each point of such aset a polynomial inn variables, and by showing that these polynomials are linearly independent and all liein a space of dimension$(n + 1)(n + 4)/2$.
This has been improved by Blokhuis tofindingn + 1 further polynomials that lie in the same(n+1)(n+2)/2. He did this by space in such a way that the augmented set of polynomials is still linearly independent. More applications of the dimension argument can be found in Graham, Grötschel, and Lovász (1995, chapter 31).Spectral techniques, that is, an analysis of eigenvectors and eigenvalues [I.3 §4.3](/part-01/fundamental-definitions), have been used extensively in graph theory. The link comes through the notion of an adjacency matrix of a graph G.
This is defined to be the matrix each pair of (not-necessarily-distinct) vertices$A \text{with entries a}^{u}$, vu andforvand, wherea =au, v0 otherwise. This matrix is symmetric, and= 1 if u and v are joined by an edge, therefore, by standard results in linear algebra, it has real eigenvalues and anu, v orthonormal basis [III.37](/part-03/bayesian-analysis) of eigenvectors. It turns out that there is a tight relationship between the eigenvalues of the adjacency matrix A and several structural properties of the graph G, and these properties can often be useful in the study of

572

various extremal problems. Of particular interest is the second largest eigenvalue of a regular graph. Suppose that every vertex of a graph vector for which every entry is 1 is easily seen to be an G has degree d. Then the eigenvector with eigenvalue eigenvalue. If all other eigenvalues have modulus muchd, and this is the largest smaller than ways like a randomd, then it turns out thatd-regular graph. In particular, the G behaves in many number of edges inside any set ofk of the vertices is roughly the same (provided would expect with a random graph.
It follows easily thatk is not too small) as one any set of vertices that is not too big has many neigh-bors among the vertices out side that set. Graphs with the latter property are called have numerous applications in theoretical computer expanders [III.24](/part-03/expanders) and science. Constructing such graphs explicitly is not aneasy matter and was at one time a major open problem. Now, however, several constructions are known, based on algebraic tools. See chapter 9 of Alon and Spencer (2000), and its references, for more details.
of combinatorial objects such as partially ordered sets, The application of topological methods in the study graphs, and set systems has already become part of the mathematical machinery commonly used in combinatorics. An early example is Lovász’s proof of Kneser’sconjecture, mentioned in section 2.3. Another example is a result of which the following is a representative special case. Suppose you have a piece of string with 10 red beads, 15 blue beads, and 20 yellow beads on it.
Then, no matter what order the beads come in, youcan cut the string in at most 12 places and place the resulting segments of beaded string into five piles, eachof which contains two red beads, three blue beads, and four yellow beads. The number 12 is obtained by multi-plying 4, the number of piles minus 1, by 3, the number of colors. The general case of this result was proved by Alon using a generalization of Borsuk’s theorem. Many additional examples of topological proofs appear in Graham, Grötschel, and Lovász (1995, chapter 34).
3 Probabilistic Combinatorics A wonderful development took place in twentieth-cen-tury mathematics when it was realized that it is some times possible to use probabilistic reasoning to prove mathematical statements that do not have an obvious probabilistic nature. For example, in the first half of the century, Paley, Zygmund, Erd ̋os, Turán, Shannon, and others used probabilistic reasoning to obtain strik-ing results in analysis, number theory, combinatorics,

IV. Branches of Mathematics

and information theory. It soon became clear that theso-called probabilistic method is a very powerful tool for proving results in discrete mathematics. The early results combined combinatorial arguments with fairly elementary probabilistic techniques, but in recent years the method has been greatly developed, and now it often requires one to apply much more sophisticated techniques. A recent text dealing with the subject is Alon and Spencer (2000).
The applications of probabilistic techniques in discrete mathematics were initiated by Paul Erd ̋contributed to the development of the method moreos, who than anyone else. One can classify them into three groups. The first deals with the study of certain classes of random combinatorial objects, like random graphs or ran-dom matrices. The results here are essentially results in probability theory, although most of them are motivated by problems in combinatorics. A typical problem is the following: if we pick a graph “at random,” what is the probability that it contains a Hamilton cycle?
lowing idea. Suppose you want to prove that a combi-The second group consists of applications of the folnatorial structure exists with certain properties. Then one possible method is to choose a structure randomly (from a probability distribution that you are free to specify) and estimate the probability that it has the properties you want. If you can show that this probability is greater than 0, then such a structure exists. Surprisingly often it is much easier to prove this thanit is to give an example of a structure that works.
For instance, is there a graph with large girth (meaning ithas no short cycles) and large chromatic number? Even if “large” means “at least 7,” it is very hard to come upwith an example of such a graph. But their existence is a fairly easy consequence of the probabilistic method. The third group of applications is perhaps the most striking of all. There are many examples of statements that appear to be completely deterministic (even when one is used to the idea of using probability to give existence proofs) but that nevertheless yield to probabilis-tic reasoning.
In the remainder of this section we shall briefly describe some typical examples of each of these three kinds of application.

3.1 Random Structures

The systematic study of random graphs was initiatedby Erd ̋os and Rényi in 1960. The most common way of defining a random graph is to fix a probabilityp and

IV.19. Extremal and Probabilistic Combinatorics then to join each pair of vertices with an edge with prob-abilityp, with all the choices made independently. The resulting graph is denoted G(n, p). (Formally speaking, G(n, p)but one often talks about it as though it is a graph thatis not a graph but a probability distribution, has been produced in a random way.) Given any prop-erty, such as “contains no triangles,” we can study the probability that G(n, p) has that property.
many properties of graphs “emerge very suddenly.”Some examples are “contains a Hamilton cycle,” “is A striking discovery of Erd ̋os and Rényi was that not planar,” and “is connected.” These properties areall monotone, which means that if a graph G has the property and you add an edge to graph still has the property. Let us take one of these G, then the resulting properties and define the random graph G(n, p)f (p) has it. Because the prop-to be the probability that erty is monotone, f (p) increases as p increases. What Erd ̋increase happens in a very short time.
That is, os and Rényi discovered was that almost all of thisf (p) is almost 0 for small rapidly and becomes almost 1.p and then suddenly changes very Perhaps the most famous and illustrative example of this swift change is the sudden appearance of the so-called giant component. Let us look at G(n, p) when pa bility all the connected components ofhas the form c/n. If c < 1, then with high prob-G(n, p) have size at most logarithmic inn. However, if c > 1, then G(n, p)ear in nal most certainly has one component of size lin-(the giant component), while all the rest have logarithmic size.
This is related to the phenomenon of phase transitions in mathematical physics, which are discussed in probabilistic models of critical phenomena phase transition for a graph property that is “global,”[IV.25]. A result of Friedgut shows that the in a sense that can be made precise, is sharper than theone for a “local” property.
Another interesting early discovery in the study of random graphs was that many of the basic parameters of graphs are highly “concentrated.” A striking example that illustrates what this means is the fact that, forany fixed value ofp and for most values of n, almost all graphs G(n, p) have the same clique number. That is, there exists some that with high probability, whenr (depending onn is large, the cliquep and n) such number ofhold for all G(n, p)n, for continuity reasons, but in the excep-is equal to r .
Such a result cannot tional cases there is still some number is almost certainly equal either tor such that the cliquer or to r + 1. In both cases, r is roughly 2 log n/ . og (1/p). The proof

573

of this result is based on the so-called method: one estimates the expectation and the variance second moment of the number of cliques of a given size contained in G(n, p), and applies well-known inequalities of Markov and chebyshev [VI.45](/part-06/pafnuty-chebyshev-18211894). is also highly concentrated. Its typical behavior for val-ues of The chromatic number of the random graphp that are bounded away from 0 was deter-G(n, p) mined by Bollobás. A more general result, in which allowed to tend to 0 asn →. nfty, was proved by Shamir, p is Spencer, Łuczak, Alon, and Krivelevich.
In particular, itcan be shown that for every$α <^{1} \text{and every integer}-$ valued function$r (n) < n^{α}$, there exists a function2 p(n)precisely such that the chromatic number ofr (n) almost surely. However, determining the G(n, p(n)) is precise degree of concentration of the chromatic num-ber of G(n, p), even in the most basic and important case occur with equal probability), remains an intriguingp =1 2 (in which all labeled graphs on n vertices open problem. Many additional results on random graphs can be found in Janson, Łuczak, and Ruci ́nski (2000).

3.2 Probabilistic Constructions

One of the first applications of the probabilistic method in combinatorics was a lower bound given by Erd ̋os for the Ramsey number section 2.2. He proved that if R(k, k), which was defined in

n (21)-( k) < 1, k

thenof the edges of the complete graph on R(k, k) > n. That is, there is a red/blue color i ngn vertices such that no clique of size blue. Notice that the numberk is completely red or complete lyn =  2 k/2!satisfies the above inequality for allk ⩾3, so Erd ̋os’s result gives an exponential lower bound forple: if you color the edges randomly and independently, R(k, k). The proof is sim- then the probability that any fixed set ofall its edges of the same color is twice 2-k(k 2 vertices has). Thus, the expected number of cliques with this property is

n (21)-( k).k

If this is less than 1, then there must be at leastoring for which there are no cliques with this property, one coland the result is proved. in the sense that it merely proves the existence ofsuch a coloring, but gives no efficient way of actually Note that this proof is completely nonconstructive, constructing one.

574

nament problem mentioned in section 1.1. If the results of the tournament are random, then the probability, for A similar computation yields a solution for the tour any particular all is(1 - (1/2 kk))teams, that no other team beats the(mn)-k. From this it follows that ifnk 1 - 2(1 k)n -k < 1,

then there is a nonzero probability that for every choice of In particular, it is possible for this to happen. Ifk teams, there is another team that beats them all.n is larger than aboutk22 k log 2, then the above inequality holds. ful in supplying lower bounds for Ramsey numbers. Be sides the bound for Probabilistic constructions have been very power-R(k, k) mentioned above, there is a subtle probabilistic proof, due to Kim, thatck2/ . og k, for some c > 0.
This is known to be tight up R(3, k) ⩾ to a constant factor, as proved by Ajtai, Komlós, and Szemerédi, who also used probabilistic methods.

3.3 Proving Deterministic Theorems

Suppose that you color the integers with call a set S multicolored if all k colors appear ink colors. Let us S. Straus conjectured that for everyk there is an m with the fol- lowing property: given any setis a coloring of the integers with S withk colors such that allm elements, there translates of proved by Erd ̋$S$os and Lovász. The proof is probabilistic, are multicolored.
This conjecture was and applies a tool called the Lovász local lemma, which, unlike many probabilistic techniques, allows one toshow that certain events hold with nonzero probability even when this probability is extremely small. the assertion of this lemma, which has numerous additional applications, is, roughly, that for any finite collection of “nearly independent” low-probability events, there is a positive probability that none of the events holds.
Note that the statement of Straus’s conjecture has nothing to do with probability, and yet its proof relies on probabilistic arguments. A graph G is k-colorable, as we have said, if you can properly color its vertices with that instead of trying to usek colors in total, you havek colors. Suppose now a separate list ofk colors for each vertex, and this time you want to find a proper coloring ofeach vertex gets a color from its own list.
If you can G where always do so, no matter what the lists are, then call edk-choosable, and the smallest k for which GG isiskthe lists are the same, then one obtains a-choosable is called the choice number chk(G)-coloring,. If all

IV. Branches of Mathematics

so ch expect ch(G) (G)must be at least as big asto be equal to χ(G), since it seems asχ(G). One might though using different lists ofk colors for different vertices would make it easier to find a proper coloring than using the samek colors for all vertices. However, this turns out to be far from true. It can be proved that for any constantc there is a constant C such that any graph with average degree at least ber at leastc. Such a graph might easily be bipartite C has choice num- (and therefore have chromatic number 2), so it follows that ch(G) can be much bigger than χ(G).
Some what surprisingly, the proof of this result is probabilistic. graph that arises in Ramsey theory. Its vertices areall the points in the plane, with two vertices joined An interesting application of this fact concerns a by an edge if and only if the distance between themis 1. The choice number of this graph is infinite, by the above result, but the chromatic number is known to be between 4 and 7.A typical problem in Ramsey theory asks for a substructure of some kind that is entirely colored with one color.
Its cousin, discrepancy theory, merely asks that the numbers of times the colors are used are nottoo close to each other. Probabilistic arguments have proved extremely useful in numerous problems of this general kind. For example, Erd ̋os and Spencer proved that in any red/blue coloring of the edges of the com-plete graph K there is a subset V of vertices such that the difference between the number of red edges inside V^0 and the number of blue edges inside^n^0 V^0 is at least cn^3^/^2, for some absolute constant c > 0.
This problem is a convincing manifestation of the power of proba-bilistic methods, since they can be used in the other direction as well, to prove that the result is tight up toa constant factor. Additional examples of such results can be found in Alon and Spencer (2000). 4 Algorithmic Aspects and Future Challenges As we have seen, it is one matter to prove that a cer-tain combinatorial structure exists, and quite another to construct an example.
A related question is whether an example can be generated by means of an efficient algorithm [IV.20 §2.3](/part-04/computational-complexity), in which case we call it explicit ta nt because of the rapid development of theoret-. This question has become increasingly impor ical computer science, which has close connections with discrete mathematics. It is particularly interesting when the structures in question have been proved to exist by means of probabilistic arguments. Efficient

IV.20. Computational Complexity

algorithms for producing them are not just interesting on their own, but also have important applications in other areas. For example, explicit constructions of error-correcting codes that are as good as random ones are of major interest inmation theory [VII.6](/part-07/reliable-transmission-of-information), and explicit constructions of coding and in for certain Ramsey-type colorings may have applications in derandomization [IV.20 §7.1.1](/part-04/computational-complexity) (the process of converting randomized algorithms into deterministic ones).
good explicit construction is often very difficult. Even the simple proof of Erd ̋It turns out, however, that the problem of finding aos, described in section 3.2, that there are red/blue colorings of graphs with2 k/2! vertices containing no monochromatic clique of size leads to an open problem that seems very difficult. Cank we construct, explicitly, such a graph withn ⩾ (1 + )k vertices in time that is polynomial into be any constant, as long as it is positive. This prob-n? Here we allow lem is still wide open, despite considerable efforts from many mathematicians.
braic and analytic techniques, spectral methods, and The application of other advanced tools, such as alge topological proofs, also tends to lead in many cases to nonconstructive proofs. The conversion of these to algorithmic arguments may well be one of the main future challenges of the area. creased appearance of computer-aided proofs in com-Another interesting recent development is the inb in at or i cs, starting with the proof of the theorem [V.12](/part-05/the-four-color-theorem).
To incorporate such proofs into the four-color area, with out threatening its special beauty and appeal, is a further challenge. its tight connection to other disciplines, and its many These challenges, the fundamental nature of the area, fascinating open problems ensure that combinatorics will continue to play an essential role in the general development of mathematics and science in the future. Further Reading Alon, N., and J. H. Spencer. 2000.2 nd edn. New York: John Wiley. The Probabilistic Method, Bollobás, B. 1978.demic Press. Extremal Graph Theory. New York: Aca Graham, R. L., M.
Grötschel, and L. Lovász, eds. 1995.Handbook of Combinatorics. Amsterdam: North - Holland. Graham, R. L., B. L. Rothschild, and J. H. Spencer. 1990.Ramsey Theory, 2 nd edn. New York: John Wiley. Janson, S., T. Łuczak, and A. Ruci ́Graphs. New York: John Wiley. nski. 2000. Random Jukna, S. 2001. Extremal Combinatorics. New York: Springer. 575 Matoušek, J. 2002.Springer. Lectures on Discrete Geometry. New York: Nathanson, M. 1996.orems and the Geometry of Sumsets Additive Number Theory: Inverse The-. New York: Springer. Pach, J., and P. Agarwal. 1995.York: John Wiley. Combinatorial Geometry.
New Tao, T., and V. H. Vu. 2006.bridge: Cambridge University Press. Additive Combinatorics. Cam IV.20 Computational Complexity Oded Goldreich and Avi Wigderson 1 Algorithms and Computation This article is concerned with what can be computed efficiently, and what cannot. We will introduce several important concepts and research areas, such as formal models of computation, measures of efficiency, the P versus NP question, NP - completeness, circuit complexity, proof complexity, randomized com put a - tion, pseudo randomness, probabilistic proof systems, cryptography, and more.
Underlying them all are the related notions of algorithms and computation, and we begin by discussing these. 1.1 What Is an Algorithm? Suppose that you are presented with a large positive integer What should you do? One possibility would be to apply N and asked to determine whether it is prime. the method ofis even, then whether it is a multiple of 3, then whether trial division. That is, first see whether N it is a multiple of 4, and so on through all the numbers up to. qrt N.
If N is composite, then it has a factor between 2 and these questions is no.. qrtN, so it is prime if and only if the answer to all cient. qrt NThe trouble with this method is that it is highly is at least 10. Suppose, for instance, that50, so in order to carry the method N has 101 digits. The nine ff i out one would have to answer 1050 questions of the form, “Isthan a human lifetime, even if all the world’s computers K a factor of N?” This would take far longer devoted themselves to the task. What, then, is an “effi-cient procedure”? This question divides into two parts:
what is a procedure, and what counts as efficient? We shall look at these two questions in turn. satisfy if it is to count as a procedure for solving this problem are Two very obvious conditions that a method should finiteness —that the procedure should have a finite description (so, for example, one cannot simply look up the answer in an infinite list of integers and

576

their factorizations)—and N, it correctly tells you whether correctness N is prime.—that, for every There is also a third, more subtle, condition, which goes to the heart of what is meant by the word “algo-rithm.” It is that it should consist of simple steps. This is needed in order to rule out ridiculous “procedures”such as, “See whether Nhas any nontrivial factors; declare Nto be prime if and only if it does not.” The problem with this is that we cannot see, just like that, whether N has nontrivial factors.
By contrast, all that the method of trial division asks of us is that we should do basic arithmetic, such as increasing integers by 1, comparing them, and doing long division. More over, the procedures of basic arithmetic can be broken down into yet simpler steps: for instance, it is possible to do long division by a succession of elementary operations applied to single digits at a time. In order to understand this simplicity condition better, and to prepare ourselves for a formal definition ofthe notion of algorithms, let us look at long division in slightly more detail.
Suppose that you have a piece of paper in front of you and you want to divide 5 959 578 by 857. You will write the two numbers down, and then, as the calculation proceeds, you will write other num-bers as well. For instance, you may wish to start by writing out all the multiples of 857 up to 9. imes 857. At some point early on you will probably find your self compar-ing 5999= 7 \times857 with 5959: this you do by scanning the numbers from left to right and comparing individ-ual digits. In this case, a difference is first detected in the third digit.
You then write 5142 (which is 6. imes 857) underneath the 5959, subtract (again by scanning num-bers from left to right and performing single-digit operations), write down the difference 817, “bring down”the next digit, 5, of 5 959 578, and repeat the process with the number 8175.At each stage in this calculation you are modifying the piece of paper in front of you.
As you do so you need to keep track of which stage of the procedure youare at (whether you are writing out the initial table of multiples of 857, or seeing which one is the largest that does not exceed another number, or subtracting one number from another, or bringing down a digit, etc.), and which symbols on the page you are currently deal-ing with. What is remarkable is that this information has aas the size of the input (that is, the two numbers to be fixed size, in the sense that it does not increase divided) increases.
local changes Therefore, the procedure can be regarded as making to some “environment,” using repeated

IV. Branches of Mathematics

applications of a fixed rule that does not depend onthe input. (This rule will typically have some internal structure, such as a list of simpler rules together with specifications of the circumstances under which they should be applied.) In general, this is what we mean bya computation: it modifies an environment by means of repeated applications of a fixed rule. The rule is usually referred to as an algorithm. Notice that this description applies to many scientific theories of dynamic evolution in nature (of weather, chemical reactions, or biological processes, for example).
Thus, these can beregarded as computational processes, of sorts. Some of these dynamical systems also demonstrate well the fact that simple, local rules can result in a very complex modification of the environment if they are iter-ated many times. (See dynamics [IV.14](/part - 04/dynamics) for further discussion of this phenomenon.) Thoughts such as these lie behind the idea of a Turing machine notion of an algorithm.
It is interesting that he came, turing’s [VI.94](/part - 06/alan - turing - 19121954) famous formalization of the up with his formalization Indeed, this abstraction and central features of it, most before computers existed. notably the existence of a “universal” machine, greatly influenced the actual construction of computers. It is very important to know that the idea of an algorithm can be formalized, so that one can talk precisely about whether there are algorithms that will perform particular tasks, how many steps they need for a given size of input, and so on.
However, there are many ways of doing this, which all turn out to be equivalent, and for the purposes of understanding this article it is not necessary to go into the details of any particular method. (You can, if you like, think of an algo-rithm as any procedure that can be programmed on a real computer—slightly idealized so that it has unlim-ited storage space—and a step of an algorithm as any change of one of the bits of that computer from a 0 toa 1 or vice versa.) Nevertheless, just to show roughly how it is done, here is a brief description of the basic features of the Turing machine
model. To begin with, one makes the observation that all computational problems can be encoded as operations on sequences of 0 s and 1 s. (This observation is not just theoretically useful but also very important for the actual building of computers.) For example, all numbers that occur in the course of a computation can be converted into their binary representations; one can also use 1 to stand for “true” and 0 to stand for “false” and there by perform the basic logical operations; and IV.20. Computational Complexity so on.
For this reason we can define a very simple “envi - ron ment” for a Turing machine: it is a “tape,” infinitely long in both directions, that consists of a row of “cells,”each of which contains either a 0 or a 1. Before the computation starts, a certain prespecified portion of this tape is filled with theof 0 s and 1 s. The algorithm is a little control mecha - input, which is a sequence nism. At any one time, this mechanism can be in one of a finite set of states, and it is located at one of the cells of the tape.
According to the state it is in and the value, 0 or 1, that it sees at the cell it has reached, it makes three decisions: whether to change the value inthe cell, whether to move left or right by one cell, and which state it should next be in. One of the states of this control mechanism is “halt.” If this state is reached, then the mechanism stops doing anything and is said to have halted. At that point, a certain prespecified portion of the tape will be regarded as the output of the machine. An algorithm can be thought of as any Turing machine that halts for every possible input.
And the number of steps of the algorithm is the number of steps taken by that Turing machine. Remark - ably, this very simple computational model is enough to capture the full power of computation: in theory one could build a Turing machine, out of clockwork, say, that would be able to do whatever a modern supercomputer can do. (However, it would take too long over each step to be practical for anything but the very simplestof computations.) 1.2 What Does an Algorithm Compute? A Turing machine converts a sequence of 0 s and 1 sinto another sequence of 0 s and 1 s.
If we wish to use mathematical language to discuss this, then we needto give a name to the set of$\\{0}$, 1\\ - sequences. To be precise, we consider the set of all finite sequences of 0 s and 1 s, and we call this set write I for the set of all\{0,1\}-sequences of length I. It is also useful ton. Iffor instance, ifx is a sequence inn x is the string 0100101, then I, then we write |x|for its length:|x| = 7. To say that a Turing machine converts a sequence of0 s and 1 s into another such sequence (if it halts) is to say that it naturally defines a function from I to I.
If Mfunction, then we say thatis the Turing machine and M com put esf M is the correspond in gf M. Thus, every function f: I \to I gives rise to a com- putational task, namely that of computingf . We say that exists a Turing machinef is computable if this is possible: that is, if there M such that the corresponding 577 functionf M is equal to f . A central early result (due to Turing and independently tosome natural functions are not church computable.
(For more[VI.89](/part - 06/alonzo - church - 19031995)) is that details, seelem [V.20](/part - 05/the - insolubility - of - the - halting - problem).) However, complexity theory deals only with the insolubility of the halting prob computable functions, and studies which of these canbe computed efficiently. Using the notation we have just introduced, we can formally describe various different kinds of com put a-tional tasks, of which two major examples are search problems problem is, informally speaking, to find a mathematical and decision problems.
The aim of a search object with certain properties: for instance, one might wish to find a solution to a system of equations, and this solution might not be unique. We can model this by means of a binary relation [I.2 §2.3](/part-01/language-and-grammar)R on the set I: for a pair tion of problem instance(x, y) of strings inx Iif, we say thatx Ry. (This notation meansy is a valid solu- that common notation for the same thing isx is related to yin the way specified by(x, y)R;
another$\in R$.) For example, we might let positive integers N andx and K, respectively, and say thaty be binary expansions ofx Ry nontrivial factor ofif and only if NNis a composite number and. Informally, this search problem K is a would be, “Find a nontrivial factor ofrithm that computes a certain function$N$.” Iff M: Iis an algo-$\to I$, then we say that M solves the search problem MR if f M (x) is a valid solution ofhas a solution.
For example, it solves the search prob-x for every problem instance x that lem just defined if, for every composite number binary expansionx, f (x) is the binary expansion of a N with nontrivial factor$K of^{M}N$. in positive integers, but formally speaking an algorithm Notice that in the above example we were interested is a function of binary strings. This was not a problem, because there is a convenient and natural way to encode integers as binary strings—via their usual binary expan-sions.
For the rest of this article, we shall feel free to blur the distinction between the mathematical objects we wish to investigate and the strings we use to represent them in a computation. For instance, it is sim-pler to think of the algorithm M in the previous para- graph as computing a function the search problem if, for every composite number f M: N\to  N, and solving N, fre presentation of objects by strings is a rather succinct M (N) is a nontrivial factor of N. We stress that the one:
it takes only N, so the number,. og N2 is exponentially larger than the N- bits to represent the number length of its representation.

578

Now let us turn to decision problems. These are simply problems where one is looking for a yes/no answer. The problem with which we opened this article—Is$N$ a prime number?—is a classic example of a decision problem. Notice that here and in the paragraph before last we are using the word “problem” in a slightly unusual way, to mean a general class of questions rather than just one. In this example, the question, “Is443 a prime number?” would be called an instance of the problem, “Is$N$a prime number?” Modeling decision problems is very simple: they are subsets of I.
The idea is that a subset S of I consists of all the strings where the answer is yes. So if the prob-lem is to determine primality, then S would consist of all binary expansions of prime numbers, at least if we chose the obvious encoding of the problem. When dowe say that a machine M solves the decision problem S? We would like it to compute a functionf that says yes when the input That is, we say thatx belongs to M solves the problem S and says no otherwise. S if the asso- ciated function such thatf (x)f M=is a function from1 whenever x \in  SI to the setand f (x)\\{0=, 10\. . \1

otherwise.

lems, but the reader should bear in mind that com-Most of this article will be focused on decision prob put at i on al tasks that seem more complicated, including search problems, can in fact usually be reduced tosequences of decision problems. For example, if you can solve all decision problems and you want to factorize a large composite number as follows. First, determine whether the smallest prime N, then you can proceed factor of the number ends in a 1 (in its binary expansion). If the answer is yes, you can look at the next digit by asking if this factor ends in 11;
if it is no, then you can ask if it ends in 10. You can continue this process, extending your knowledge of the smallest prime factorby one bit at a time. The number of queries you will need to make will be at most the number of digits of N. 2 Efficiency and Complexity Near the beginning of this article we asked what was meant by the phrase “efficient procedure.” We have now discussed the word “procedure” in some depth, but we have yet to say what we mean by “efficient,” beyond pointing out that trial division takes too long to be practical if we have a very large integer and want to determine
whether it is prime. IV. Branches of Mathematics 2.1 Complexity of Algorithms How can we describe mathematically what it means for a procedure to “take too long to be practical”? The Turing-machine formalization is particularly useful for answering questions like this, because we can say pre-cisely what a step of a Turing-machine computation is and this allows us to give a precise definition:
an algorithm is a Turing machine, and itsto be the number of steps the machine takes before complexity is defined halting. If we look at this definition carefully, we see that what it defines is not just one number but a function. The time taken by a Turing machine depends on the input, so, given a Turing machine M and a string x, we can define halting whent M (x) to be the number of stepsx is the input. The function M ttakes before: I\to N is Mthe Most of the time, we are interested not so much in the complexity function of the machine M.
full detail of this complexity function, but in the case complexity of the machine M . This is a function worst - Tn M, T: MN(n)\to  Nis the maximum value of defined as follows. Given a positive integert M (x) over all input strings the longest possible time that our machine might takex of length n. In other words, we want to know when faced with an input of len gthn. And usually we do not look for an exact formula for purposes it is enough to have a good upper bound. TM(n):
for most time complexity how long The function M takes given of the algorithmt M (x) is more accurately called thex as its input. But time is M , since it measures not the only resource that matters in computer sci-ence. Another is how much memory an algorithm uses, beyond that needed to store the input, and this toocan be captured in our formal model. Given a Turing machine the number of cells, other than input cells, that are vis-M and an input x, we can define s M (x) to beited before the machine halts, under the extra condition that the input cells must be left unchanged.

2.2 Intrinsic Complexity of Problems

Much of this article will be concerned with a very gen-eral analysis of the power of computation. In particular, we shall discuss a central subfield of theoretical computer science known as computational complexity understand the(or complexity theory intrinsic complexity). The aim of this area is toof computational tasks. than “algorithms.” This is an important distinction and Notice that we said “computational tasks” rather

IV.20. Computational Complexity

it involves a change of focus. Returning to our exam-ple of primality testing, it is not too hard to estimate how long various algorithms take, and indeed we hadno trouble in seeing that trial division would take a very long time indeed. But does that mean that the task of primality testing is since there may be other algorithms that do the job intrinsically hard? Not necessarily, much more quickly. would be a good definition of the complexity of a com-This idea fits neatly into our formal scheme. What putational task?
Roughly speaking, the complexity ofsuch a task should be the smallest complexity of any algorithm this is as follows. If M that solves it. A convenient way of saying T: N\to  N is some integer function, we say that the task hasan algorithm M that solves the task such that complexity at most T if there is T ⩽ TM

(i.e.,$T^{M} (n) ⩽ T (n) \text{for every} n)$.

intrinsically hard, then all you have to do is devise analgorithm with low complexity that solves this task. If you want to show that a computational task is not But what if you want to show that this tasks ically hard? Then you have to prove, for every possibleis intrinlow-complexity algorithm M, that M does not solve this task. This is much harder: even after half a century ofintensive work, the best results that are known are very weak. Notice a big difference between the two kinds of research:
one can find algorithms with out knowing howthe concept of “algorithm” is formalized, but to analyzetial to have a precise definition of what an algorithm is.all algorithms with a certain property, it is essen Fortunately, with Turing’s formalization, we have one.

2.3 Efficient Computation and$P$

Now we have ways of measuring the complexity of algo-rithms and computational tasks. But we have not yet addressed the question of when we should regard an algorithm asciently solvable. We shall propose a definition of effi-efficient, or a computational task as efficiency that seems some what arbitrary and then explain why it is in fact a surprisingly good one. If Mis an algorithm, then we regard it as efficient if and only if it This means that there are constants terminates in polynomial timec and k such. that the worst-case complexity inequality$T (n) ⩽ cn^{k}$.
In other words, the time taken Tmal ways satisfies the by the algorithm is bounded above by a polynomial function of the length of the input string. It is not$M$ hard to convince your self that the familiar methods for adding or multiplying twon-digit numbers termi-

579

nate in polynomial time, where as trial division for pri-mality testing does not. Other familiar examples of tasks with efficient algorithms are putting a set of num-bers in increasing order, computing the determinant [III.15](/part-03/determinants) of a matrix (provided one uses row operations rather than substituting the entries directly into the formula), solving linear equations by Gaussian elimination, finding the shortest path in a given network, and more.
Since we are interested in the intrinsic complexity of computational tasks, we now define such a task tobe efficiently computable if there is an efficient algorithm Mthat solves it. In our discussion of efficient computability, we shall focus on decision problems and consider the class of all decision problems that have efficient algorithms. Understanding it isof computational complexity theory. Here is a formal the major goal definition. We shall use the following convenient piece of notation: ifthen M(x) is the output of M is a Turing machine andx.
(Earlier we wrotex is an input, f (x) for this function.) Since we are considering decision problems, M(x) will be 0 or 1.M Definition. A decision problem S ⊆ I is solvable in polynomial timenating in polynomial time, such thatif there is a Turing machine$M(x) =M1 \text{if and}$, termi- only if$x \in S$. polynomial time is our first example of aclass The class of decision problems that are solvable in. It is denoted P.
complexity ing the running time as a function of the input length, The asymptotic analysis of running time, i.e., est im at turns out to be crucial for revealing structure in the theory of efficient computation. The choice of polynomial time as the standard for efficiency may seem arbitrary, and theories could be developed with other choices, but it has amply justified itself. The main reason for this is that the class of polynomials (or func-tions bounded above by a polynomial) is closed under various operations that arise naturally in computation.
In particular, the sum, product, or composition of two polynomials is again a polynomial. This allows us, for example, to think of long division as a basic, one-step operation when we are investigating the efficiency of algorithms for primality testing. In fact, long division takes more than one step, but it is in P so the time it takes does not affect whether an algorithm that uses itis itself in P. In general, if we use the basic program- ming technique of subroutines, and if our subroutines

580

are in$P$, then we will preserve the efficiency of the algorithm as a whole. Almost all computer programs that are used in practice turn out to be efficient in this theoretical sense. Of course, the converse is not true: an algorithm that runs in timen100 is a polynomial. However, this seems not to mat-n100 is completely use less despite the fact that ter.
It is unusual to discover even an$n^{1}0 - \text{time algorithm}$ for a natural problem, and on the rare occasions when this happens, improvements to n3 - or n2 - time, which border on the practical, almost always follow. It is important to contrast P with the class EXP. A problem belongs to EXP if there is an algorithm that solves it in at most exp len gthn, where p is some polynomial. (Roughly speak-(p(n)) steps for any input of ing, EXP consists of problems that can be solved in exponential time:
the polynomial tion more robust and less dependent on the precisepmakes the de fin i nature of encodings, etc.)If you use trial division to test the primality of a number have to do N with . qrtn Ndig its in its binary expansion, then you long-division calculations. Since . qrt N is about 2 n/2, this is an exponential-time procedure. Expo- nential running time is considered blatantly and if the problem has no faster algorithm, then it is inefficient, deemed intractable. It is known (via a basic technique called diagonalization) that P ≠ EXP;
further more, some problems in EXP really do require exponential time. Almost all problems and classes considered inthis paper can easily be shown to belong to EXP via trivial, “brute-force” algorithms such as the trial divi-sion just discussed: the main question will be whether much faster algorithms can be devised for them. 3 The P versus NP Question In this section we discuss the famous P versus NP question, which is usually formulated in terms of decision problems, but which also has an interpretation in terms of search problems. We shall start with the latter.

3.1 Finding versus Checking

Can you rearrange the letters CHAIRMITTE to form an English word? To solve a puzzle like this, one has to search among many possibilities (all permutations of those letters), perhaps building up fragments of words and hoping that inspiration will strike. Now consider the following question: can the letters of CHAIRMITTE be rearranged to form the word “arithmetic”? It is very easy (if slightly boring) to check that the answer is yes.

IV. Branches of Mathematics

ture of many search problems: that once you find a This in formal example illustrates an important fea solution, it is easy to recognize that ithard part is to find the solution in the first place. Oris a solution. The at least, so it seems. But actually proving that search problems of this kind are hard is a famous unsolved problem, the P versus NP question. fact quite general and has a natural appeal to mathe-maticians, is the task of finding proofs for valid math-Another search problem with this quality, which is in ematical statements.
Again it seems to be far easier to check that an argument is a valid proof than it is to find the argument in the first place. Since finding a proof is a process that requires considerable creativity (as, in amuch smaller way, is finding an anagram), the P ver- sus NP question is, in a sense, asking whether this kind of creativity can be automated. In section 3.2 we shall define the class NP formally. Informally, it corresponds to the set of all search prob-lems for which it is easy to check whether you have found what you are searching for.
Another example ofsuch a problem is that of finding a factor of a large composite integer it is an easy task for you (or your computer) to verify N. If you are told that K is a factor, then that this is true: all you have to do is a single instanceof long division. ating theories to explain various natural phenomena)A vast number of problems in science (such as creand engineering (such as creating designs under vari-ous physical and economic constraints) have the same property that success is much easier to recognize than to achieve in the first place.
This gives some indication of the importance of this class of problems.

3.2 Deciding versus Verifying

For the purposes of theoretical analysis, it is actually more convenient to define NP as a class of decision problems. For instance, consider the decision problem,“Is N composite?” What makes this a problem in$NP$ is that, wheneverof this fact. Such a proof consists of a factor of N is composite, there is a short proof N, and is easy to check that this proof is correct. That is, itis easy to devise a polynomial-time algorithm M that takes as input a pair(N, K) of positive integers and$outputs 1 ifwise$.
If N is prime, then K is a nontrivial factor of M(N, K) = 0 for every N and 0 other-K, while ifsuch that N is composite there will always exist an integer M(N, K) = 1. More over, in this case the string K that encodes K will be at most as long as the string

IV.20. Computational Complexity

that encodes it should not be too much longer. These properties we N, though all we really care about is that now encapsulate in a formal definition. Definition (the complexity class$NP^{1})$. A decision problem R ⊂ I . imes  ISwith the following three properties.⊂ I belongs to NP if there is a subset (i) There is a polynomial functionp such that |y| ⩽p(|x|) whenever (x, y) \in R.

(ii)xt hat belongs to(x, y) belongs to S if and only if there is some R. y such (iii) The problem of determining whether a pair belongs to R is in P. (x, y) nesstime algorithm for determining whether a pair When such a) of the fact thaty exists, it is called ax belongs to S. The polynomial-proof (or(x, y)wit- belongs to determining whether R is called ax belongs to verification procedure S. for in Notice that every problem NP, since we can simply forget about the candi-S in the class P is also date proof belongs to Sy.
On the other hand, every problem inand use the efficient test for whether NPx is trivially in EXP, because we can enumerate all pos- si ble whether it works. (This is more or less what we do withys (in exponential time) and check for each one trial division.) Can this trivial algorithm be improved?Some times it can, even in very nonobvious cases. In fact, recently it was proved that the problem of deter-mining whether a number N is composite belongs to P.
(Further details can be found inber theory [IV.3 §2](/part-04/computational-number-theory).) However, we would like to know computational num whether for every problem in NP one can do much better than the trivial algorithm.

3.3 The Big Conjecture

The equals P Np versus. In terms of decision problems, this ques-NP problem asks whether or not P tion is asking whether the existence of an efficient verification procedure for some set implies the existence ofan efficient decision procedure for it. In other words, if there is a polynomial-time algorithm for checking whether proofs thatx \in  S are correct (as in the def- inition of polynomial-time algorithm for deciding whether NP just given), does it follow that there is ax \in  S? where ain an alternative definition of the class1.
The acronym NP stands for non deterministic polynomial-time, non deterministic machine is a fictitious NP. The non deterministic computing device used moves of such a machine correspond to guessing a “proof” in this definition.

581

be formulated as a question about search problems. Suppose we have a set As our earlier examples suggest, the problem can also R ⊂ I. imes I satisfying properties (i) and (iii) of the definition of NP. For instance, R might correspond to all pairs of integers a nontrivial factor of N. Then the corresponding search(N, K) such that K is problem, “Given a composite number Nfind a nontrivial factortion problem.
In general, any such relation K,” is closely related to the integer factoriza-R gives rise to a search problem, “Given a string such that(x, y) belongs to R (if such ax, find a string$y$exists).” Now$y$ the P versus Np problem asks the following:
“Are all such search problems solvable in polynomial time?”If the answer is yes, then the mere fact that it can be checked in polynomial time whether factor of N would imply that such a factor could actu-K is a nontrivial ally be found in polynomial time.2 Similarly, the mere fact that a short proof of a mathematical statement existed would be enough to guarantee that it could be found in a short time by a purely mechanical process. The apparent difference between the difficulty of dis-covering solutions and the ease of checking them once discovered would be entirely illusory.
believe that it is not the case. However, nobody has managed to prove it. So the big conjecture is that This would be very strange, and almost all experts P does not equalNP. That is, finding is harder than checking, and efficient verification procedures do not ne ces sar-ily lead to efficient algorithms for decision problems. This conjecture is strongly supported by our intuition, which has been developed over many centuries of dealing with search and decision problems in a wide variety of human activities.
Further empirical evidence in favor of the conjecture is given by the fact that there are literally thousands of NP problems, from many math- ematical and scientific disciplines, that are not known to be solvable in polynomial time, despite the fact that researchers have tried very hard to discover efficient procedures for solving them. The P ≠ NP conjecture is certainly the most impor- tant open problem in computer science, and one ofthe most significant in all of mathematics. Our later section on circuit complexity (section 5.1) is devoted to attempts to prove it.
There we shall discuss some partial results and limits of the techniques used so far. determining whether a number is composite, no such algorithm is known for actually finding its factors, and it is widely believed that no2. Despite the fact that there is a polynomial-time algorithm for efficient algorithm exists for this.

582

3.4 NP versus co NP

Another important class, known as co NP, is the class of complements of sets (or decision problems) in NP. For example, the problem “Isco Np because there is an efficient verification pro- Nprime?” belongs to cedure for showing that a given positive integer not prime, namely, exhibiting some factors. Equiva-N is lently, the set of primes belongs to co NP because its complement belongs to Does NP equal co NPNP? That is, if you have an effi-. cient verification procedure for determining member-ship of a set S, do you also have one for determining nonmembership at least not necessarily.
For instance, if a jumble of let-? Again, intuition would suggest not, or ters can be rearranged to form a word, then that word serves as a short demonstration. But suppose a jumble of letters cannot be rearranged to form a word. One could demonstrate this by looking at all possible rear-range ments and noting that none of them is a word, but this is a very long demonstration and there does not seem to be a systematic way of finding a truly short one. relevant:
to verify that a set of logical constraints is Here again intuition from mathematics is extremely mutually tions has in consistent no common root, or that a set of regions in, that a family of polynomial equa space hasto verify the opposite (exhibiting a consistent valua-empty intersection seems far harder than tion, a common root, or a point that belongs to allthe regions).
Indeed, only when rare extra mathematical structure is available, such as duality [III.19](/part - 03/duality) theorems or complete systems of invariants, are we able toshow that a set and its complement are computationally equivalent. So another big conjecture is thatis not equal to co NP. The section on proof complex-NP ity (section 5.3) looks further at this conjecture and atattempts to resolve it. lem, “Isnp surprisingly, it is not hard to show that the prob-, actually belongs to co Ncomposite?” which obviously belongs to NP as well.
To prove this, one uses the following fact from elementary number theory: p is prime if and only if there is an integer a < p such that(ap)-1 ≡ 1 (mod p) and ar ≡ 1 whenever r is a factor ofp - 1. Thus, to verify that p is prime it is enough to exhibit such an integer a. However, to check that tion ofa works, one needs to know the prime factoriza - p - 1, and one must give a short proof that it really is a factorization into primes. This takes us back to the problem we started with, but the numbers are smaller so one can give a recursive argument. (We men - IV.
Branches of Mathematics tion again that the set of primes is actually in P, but this is harder to prove.) 4 Reducibility and NP-Completeness One sign that a mathematical problem is fundamental is that it has many equivalent formulations. This is true to a quite extraordinary extent for the P versus NP problem, as we shall see in this section. Fund a men-tal to our discussion will be the notion of polynomialtime reducibility.
Roughly speaking, one computational problem is polynomially reducible to another if any polynomial-time algorithm for the second can be converted into a polynomial-time algorithm for the first. Let us see an example of this, and then we will define the notion formally. First, here is a famous problem in NP, called SAT. Consider the logical formula (p ∨ q ∨ r ) ̄∧ (. arp∨ q) ∧ (p ∨. arq∨ r ) ∧ (. arp∨ r ). ̄ Here, be true or false.
The symbols “p, q, and r are propositions∨” and “, each of which can∧” stand for OR and AND, respectively, an. ardp(\text{read as} "NOT-$ p”) is the proposition that is true if and only ifp is false. Then the first subformula Suppose now thatp is true, p ∨qqis true, and∨ $\bar{r} is true becauser is false. at least one of check that all the other subformulas are true, whichp, q, an. ar{d}r is true. Similarly, one can means that the entire formula is true. We call our choice of truth values forfor the formula, and we say that the formula isp, q, and r a satisfying assignment satisfiable.
A natural computation problem that arises is the following. SAT: given a propositional formula, is it satisfiable? In the example above, the formula was a conjunction of subformulas, called clauses. In their turn, these subformulas were disjunctions of propositions or their negations, which are called formulasφ , . . . , φ is the formula literals. (The conjunctionφ ∧ · · · ∧of someφ and their disjunction1 is kφ^1 ∨ · · · ∨ φ^k.)^1^k 3 SAT: given a propositional formula that consists of a conjunction of clauses that contain at most three literals each, is the formula satisfiable?
Notice that SAT and 3 SAT are in NP, since it is an easy matter to check whether a given truth assignment to the variables is a satisfying assignment for the formula. Let us now turn to a second problem in NP.

IV.20. Computational Complexity

3-colorability might find in an atlas), can its regions be colored with: given a planar map (such as one three colors, adjacent countries have the same color?Red, Blue, and Green, such that no two3 is, show how an algorithm that solves to solve We shall now “reduce”3 - colorability3-colorability as well. Suppose, then, that3 Sat to can be used3 SAT: that we have a map withsitions, which we shall calln regions. We shall need 3 R , . . . , R , B , . . . , Bn propo-, and Gmula in such a way that a satisfying assignment of the1, . . .
, Gn, and we would like to define a logical for - 1(n1)nformula will correspond to a 3-coloring of the graph. In the back of our minds, we shall think of Ri as the statement, “region similarly for B andi Gof the map is colored. We then take as our clauses Red,” and some statements that tell us that every region receives a single color and no two adjacent regions receive the ii same color. This is easy to do:
to guarantee that region i receives a color, we take the clause i and j are adjacent, then to guarantee that they do Ri ∨ Bi ∨ Gi, and if regions not receive the same color we take the three clauses R ∨R , B ∨B , and G ∨G . (To ensure that no region is assigned more than one color, we can also add clauses of the form(ij)i Rj ∨ B, Bi ∨ Gj, and G ∨ R .
Alternatively, we can allow multiple colors and finish by picking oneof the assigned colors for each region.)(ii)i i i i clauses is satisfiable if and only if there is a 3-coloring It is not hard to see that the conjunction of all these of the map.
Further more, the conversion process is a simple one that can be carried out in a time that is polynomial in the number of regions in the map. Thus, wehave our hoped-for polynomial-time reduction. just done. Now let us give a formal description of what we have Definition (polynomial-time reducibility).T be subsets of I. We say that S is polynomial-time Let S and reducible put able functionto T if there exists a polynomial-time com-h: I\to  I such that x \in  S if and only ifh(x) \in  T. lowing algorithm can be used to decide membership of If S:
given S is polynomial-time reducible tox, compute h(x) (in polynomial time), then T, then the fol- decide whe the rh(x) \in T. Therefore, if membership of Tship ofcan be decided in polynomial time, so can member - S. An equivalent, and important, way of saying that this can always be done with four colors.3. Recall that the celebrated four-color theorem [V.12](/part - 05/the - four - color - theorem) asserts 583 this is that if membership of polynomial time, then neither can membership of S cannot be decided in T. In short, if S is hard, then T is hard.
the notion of polynomial-time reducibility. Now let us give a very important definition based on Definition (NP - completeness).NP-complete if S is in NP and every decision problem A decision problem S is in NP is polynomial-time reducible to S. do(decision) problem is in a certain sense “universal”That is, ifall other Sproblems inhas a polynomial-time algorithm, then so NP. Thus, an NP-complete among all problems in NP. it is far from obvious that there are any NP-complete problems!
However, in 1971, it was proved that At first this may seem a peculiar definition, because SAT is NP - complete, and since then thousands of problems have been proved to be NP-complete as well. (Hundreds of them are listed in Garey and Johnson (1979).)Other examples are 3 SAT and 3 - colorability. The significance of 3 SAT is that it is one of the most basic of all NP-complete problems.
(It is not too hard toshow that, by contrast, 2 SAT and 2-colorability have polynomial-time algorithms.) In order to prove that a decision problem with a known NP-complete problem S is NP - complete, one starts Sand finds a polynomial-time reduction from S^ to S. It now follows that if S^ and hence so do all other problems in S has a polynomial-time algorithm, then so does NP. Some- times these reductions are quite simple, like our reduc-tion of 3-colorability to 3 SAT. But some times they need a great deal of ingenuity. Here are two further NP-complete problems. Subset sumand another integer:
given a sequence of integersb, does there exist a set Jasuch that1, . . . , ani \in J ai = b? Traveling salesman problem[III.34]G, does there exist a Hamilton cycle: given a finite? That is, graph can one find a cycle of edges that visits each vertex of the graph exactly once? Interestingly, almost all natural problems in NP that are not obviously in P turn out to be NP - complete. However, there are two important examples that have not been shown to be NP-complete and are strongly believed not to be. The first is a problem we have already discussed: integer factorization.
More precisely, consider the following decision problem. 584 Factor in interval prime factory such that: givena ⩽ yx⩽, ab,?b, does x have a A polynomial-time algorithm for this can be combined with a simple binary search to find a prime factor if it exists. The reason this problem is unlikely to be NPcomplete is that it also belongs to co NP.
(Roughly speaking, this is true because one can exhibit the prime factorization ofx and demonstrate in polynomial time that it really is a prime factorization.) If it were NP - complete, then it would follow that NP ⊂ co NP, and hence, by symmetry, that NP = co NP. The second example is the following. Graph is om or ph is mn vertices, is there a function: given two graphsφ from the vertex set of G and H with G to the vertex set of H when, and only when, H such thatxy is an edge ofφ(x)φ(y) Gis an edge of?
Notice with these two examples how surprising it is that they can be reduced in polynomial time to problems such as 3 SAT or 3-colorability. This is particularly true of the first, which has nothing to do with graphs or satisfiability of logical formulas. If P ≠ NP, then no NP-complete problem has a polynomial-time decision procedure. Consequently, the corresponding search problems cannot be solved in polynomial time. Thus, a proof that a problem is NP-complete is often taken as problem is hard:
if we could solve it, then we could evidence that this also efficiently solve a multitude of other problems. But thousands of researchers (and tens of thousands ofengineers) have, over several decades, tried and failed to find such procedures. Some times it is possible to prove a fact about all sets in NPNP-completeness has more positive aspects as well.by establishing it only for some NP-complete set (and noting that polynomial-time reductions preserve the claimed property).
Famous examples include the existence of “zero-knowledge proofs,” established first for 3-coloring (see section 6.3.2), and the so-called PCP theorem, established first for 3 SAT (see section 6.3.3). 5 Lower Bounds As we mentioned earlier, it is very much harder to prove that certain problemsit is to find efficient algorithms (when they exist). In this can not be solved efficiently than section, we shall survey some of the basic methods that have been developed for finding lower bounds for the complexity of natural computational problems. That is,

IV. Branches of Mathematics

we shall discuss results that say that no algorithm canrun in fewer than a given number of steps. In particular, we shall introduce the theories of circuit complexity with the long-term goal of proving that and proof complexity. The first is defined P ≠ NP, and the second is a program that is aimed at proving that NP ≠ co NP. Both of these theories use the notion of amation in a computation or a proof, and the sequence directed a cyclic graph, which models the flow of inforof derivations of each new piece of information from previous ones. given a direction.
One can visualize it as a graph with arrows along the edges. AA directed graph is a graph for which each edge isdirected cycle is a sequence of vertices an dt -1 there is an edge pointing fromv1, . . . , vt such that for everyv i toward between 1 v and there is also an edge pointing from(vi)t back toiv+1 1. If a directed graph called a cyclic. We shall abbreviate the phrase “directed G has no directed cycle, then it is a cyclic graph” by writing DAG. It is not hard to see that in every DAG there will be some vertices with no in coming edges and some withno out going edges.
These are called inputs and outputs, respectively. Ifis an edge fromuuandto vv, then we say that are vertices of a DAG and thereu is a prede- cessoryou place information at each input, and at each ver - ofv . The basic idea of the DAG model is that texv you have a very simple rule that derives some information atdecessors ofv. Starting at the inputs, you gradual lyv from the information at all the pre- move through the graph, working out the information at a vertex once you have worked out the information for all its predecessors, until you have reached all the outputs.
5.1 Boolean Circuit Complexity A Boolean circuit is a DAG in which all the values at the inputs, outputs, and intermediate vertices are bits. That is, each vertex may take the value 0 or 1. We have to specify simple rules for determining the value at a vertex from the values of its predecessors, and the usual choice is to allow three logical operations: AND, OR, and NOT. We call a vertexv an AND gate if the following rule applies: the value atv is 1 if all its predecessors have value 1 and is otherwise 0. At ana similar rule:
the value atv is 1 if and only if at least OR gate we have one of its predecessors has value 1. Finally, v is a NOT gate the value 1 if and only ifif it has exactly one pre de ces soru takes the value 0.u, and v takes IV.20. Computational Complexity andit a function Given any Boolean circuit with m out pu tsf fromv1, . . . , v Imto one can associate with I as follows. Given an inputs u1,. . . , un\\\{0, 1\\\} - string x = (x1, . . . , (xn)n) of len gthm n, let each ui take the value find the values at the outputsxi. Then use the gates of the circuit tov1, . . . , vm.
If these arey1 It is not hard to prove that, . . . , ym, then f (x1, . . . , xn)any= (yfunction from1, . . . , ym). I to IOR, and NOT gates, or more briefly “m can be computed in this way. Thus, we say that AND,∧”, “∨”, and “n¬”, form a restrict attention to DAGs where every vertex has atcomplete basis. More over, this is true even if we most two predecessors. In fact, we shall now assume that our DAGs have this property unless we say otherwise.
There are other choices of gates that are complete bases, but we shall stick with “∧”, “∨”, and “¬” since this does not affect our discussion in an essential way. It may be easy to show that every Boolean function$f$ can be computed by means of a circuit, but as soonas one asks how large the circuit needs to be, one comes up against fascinating and very difficult ques-tions. Thus, the following definition is central to the subject of circuit complexity. Definition. S(f ) is the size of the smallest Boolean circuit that Let f be a function from In to Im.
Then computes vertices in the corresponding DAG.f , where this is measured by the number of To see what this has to do with the P versus NP question, consider an NP-complete decision problem such as 3 SAT. This can be coded as a functionf from I to$\\{0}$,1\\\\\\\\\\\\\\\\\\\}, with f (x) taking the value 1 if and only if the formula corresponding tonot find a circuit to computexis satisfiable. Now we can-f for the simple reason thatto formulas that can be encoded as strings of length I is an infinite set. However, if we restrict attentionn, then we obtain a function try to estimate S(f ). fn:
 I$n → \\{0}$, 1\\\\\\\\\\\\\\\\\\\\\}, and we can mate for the growth rate ofity. Writing If we do this for everyffor the infinite sequence of functionsn n, then we obtain an esti-S(fn) as ntends to infin(ftakes1, f2 n, . . . )to S, let us define(f ). S(f ) to be the function that lowing fact: if there is a polynomial-time algorithm for computing This is an important definition because of the fol-f , then the functionn S(f ) is bounded above by a polynomial. More generally, given any function$f$: I\to  I, let f stand for the restriction of f to I .
If f has Turing complexity S(f ) is bounded above by a polynomial function ofn T(as defined in section 2.1), thennn

585

T (n)putes the function. That is, there is a sequence of circuits that com-f, and takes a time not significantly different from the time taken by the Turing machine. This provides us with a potential method of proving lower bounds on computational complexity, since if wecan prove that S(f ) grows very rapidly with n, then we have proved that the Turing complexity of large. Iff is a problem inn NP, then this proves thatf is very P ≠ NP.

The circuit model of computation is finite rather than infinite, which raises an issue called we build a family of circuits from a Turing machine, uniformity. When the circuits are all in a certain sense “the same.” more precisely, there is an algorithm that can generate these circuits, and the time it takes to generate each one is polynomial in its size. A uniform family of circuits is one that can be generated in this way. form.
Indeed, there are functions However, by no means all families of circuits are uni-f that cannot be com- puted by Turing machines at all (let alone in a reason-able amount of time), despite having circuits of linear size. This extra power comes from the fact that these families of circuits do not have a succinct (“effective”) description; that is, there is no single algorithm that can generate them. Such families are called nonuniform.
from Turing machines, then it would seem that prov-If there are many families of circuits that do not arise ing good lower bounds for circuit complexity should be much harder than proving lower bounds for Turing complexity, since now one must rule out many more potential ways of computing a function. However, there is a strong sentiment that the extra power provided by nonuniformity is irrelevant to the P versus NP ques- tion: it is believed that for a natural problem such as 3 Sat another big conjecture of theoretical computer science:, nonuniformity does not help.
Therefore, we have that NP-complete sets do not have polynomial-size circuits. Why do we believe this conjecture? It would benice to be able to say that its falsehood implied that P = NP. We do not quite know that, but we do know that if it is false then “the polynomial-time hierarchy collapses.”Roughly speaking, this means that a whole system of complexity classes, which appear to be distinct, would in fact all be the same, which would be very unexpected.
In any case, it is hard to imagine that there might be a sequence of polynomial-sized circuits computing an NP-complete problem with out its being possible to generate such a sequence by an efficient algorithm. 586 solve NP-complete problems, what is the point of Even if we grant that nonuniformity does not help replacing the Turing machine model by the more pow-erful model of circuit families? The main reason is that circuits are simpler mathematical objects than turing machines, and have the great advantage of being finite.
The hope is that, while abstracting away the unifor-mity condition, which ought to be irrelevant, circuits provide us with a model that can be analyzed using combinatorial techniques. It is also worth mentioning that Boolean circuits are a natural computational model of “hardware complex - ity,” so their study is of independent interest. More over, some of the techniques for analyzing Boolean func-tions have found applications elsewhere: for example, in computational learning theory, combinatorics, and game theory.
5.1.1 Basic Results and Questions We have already mentioned several basic facts about Boolean circuits, in particular the fact that they can effi-ciently simulate Turing machines. Another basic fact is that circuits most Boolean functions require exponential - size. This can be proved by a simple counting argument: the number of small circuits is far smaller than the number of functions. More precisely, let the number of inputs be defined on the set of alln. The number of possible functionsn-bit sequences is precisely (22)n.
On the other hand, it is not hard to show that the num-ber of circuits of sizem is bounded above by around(mm)2. It follows easily that we cannot compute all func- tions unless m > 2 n/2/n. Further more, the proportion of functions that can be computed by a circuit of sizeat mostm is tiny. for Turing machines) abound. However, this hardnessis proved via a counting argument, which does not give Thus, hard functions (for circuits and consequently us a way of actually exhibiting a hard function.
That is, we cannot prove such hardness for any explicit function fmic restriction on, where “explicit” means that we place some alg or ith-f , such as belonging to NP or EXP. In fact, the situation is even worse: no bound is known for any explicit function. For any func-nontrivial lower tion inputs), we trivially must havef on n bits (assuming that it depends on all its S(f ) ⩾ n, just to read the inputs. A major open problem of circuit complex-ity is beating this trivial bound by more than a constant factor.

IV. Branches of Mathematics

Open problem.even a length-preserving function Find an explicit Boolean functionf ) for which S(f )f (oris superlinear: that is, not bounded above byconstantc. cn for any question of whether addition is easier than multiplica-tion. Let A particularly basic special case of this problem is the ADD and MULT denote, respectively, the addition and multiplication functions defined on pairs ofintegers (presented in binary). For addition, the usual procedure one learns at school gives rise to a linear time algorithm, which implies a linear upper bound for S(ADD) as well.
For multiplication, the standard school algorithm runs inber of steps is proportional toquadratic time: that is, the num-$n^{2}$. This can be greatly improved (viaan algorithm that yields fast fourier transforms S(MULT) < n(. og n)[III.26](/part-03/the-fast-fourier-transform)) to2. Since. og superlinear. And now the question is whether thisn grows very slowly with n, this is only slightly can be improved further. In particular, do there exist linear-size circuits for multiplication?
nontrivial bounds are known for any explicit functions?How can circuit complexity be a thriving subject if no The answer is that there have been some remarkable successes in proving lower bounds under natural extra assumptions on the circuits. We shall now describe the most important of these extra assumptions.

5.1.2 Monotone Circuits

As we have seen, general Boolean circuits can compute every Boolean function, and can do it at least as efficiently as general algorithms. Now some functions have additional properties that might lead one to expect that they could be computed with Boolean circuits of a particular kind. For example, consider the function Clique is a graph with, defined on the set of all graphs as follows. Ifn vertices, then a clique in Gis defined G to be a set of vertices such that any two are joined by an edge.
Let us define a clique of size at least CLIQUE. qrt{n} and 0 otherwise.(G) to be 1 if G contains Notice that if we add an edge to G, then either Clique what it will(G) changes from 0 to 1 or it stays the same.notdo is change from 1 to 0: adding an edge obviously cannot We can encode G as a string destroy xa clique.ofn bits, one for each pair of vertices, assigning 1 to a bit if the correspond-ing pair of vertices is joined by an edge and 0 other-2 wise. If we then set find that changing any bit of CLIQUE(x)xto equal from a 0 to a 1 cannot CLIQUE(G), we

IV.20. Computational Complexity

change this property are called CLIQUE(x) from 1 to 0. Boolean functions with monotone. tions, it is extremely natural to restrict the circuits by When considering the complexity of monotone func allowing only AND and OR gates, and disallowing Not gates. Notice that “∧” and “∨” are monotone operations, in the sense that changing an input bit from 0 to 1 will not change the output of the gate from 1 to 0, where as “¬” is certainly not monotone in this sense. A circuit that uses just “∧” and “∨” is called a monotone circuit functionf . It is not hard to show that every monotone:
I\to  I can be computed by a monotone circuit, and that almost all monotone functions need exponential-sized circuits.nm ier to prove lower bounds? For over forty years the answer seemed to be not much: nobody could prove a Does the extra restriction on the circuits make it eas super-polynomial lower bound for the monotone com-plexity of any explicit monotone function. But then, in 1985, a new technique called the approximation method was invented to prove the remarkable theorem that CLIQUE has super-polynomial monotone complexity.
This technique eventually led to the following even stronger result. Theorem.nential size. CLIQUE requires monotone circuits of expo works as follows. Assume that Very roughly speaking, the approximation method CLIQUE can be computed with a small monotone circuit. Then replace the occurrences of “∧” and “∨” in this circuit with other gates that are cleverly chosen (and complex todescribe), denoting these by “ ̃∧” and “ ̃∨,” respectively. The new gates are chosen to satisfy two key properties.
(i) Replacing one particular gate has only a “small”effect on the output of the circuit (where “small” is defined in terms of a certain natural but nontrivial measure of distance). Consequently, if a circuit has few gates, then replacing all of them yields a new circuit that approximates the original circuit for (ii) On the other hand,“most” choices of inputs.size) containing only the approximating gates “ ̃every circuit (regard less of its∧” and “ ̃∨” computes a function that can be shown to be “far” from with CLIQUE on many inputs.
CLIQUE, in the sense that it disagrees CLIQUE is a well-known
NP-complete problem, so the above theorem provides us with an explicit monotone 587 function, conjectured not to be in P, that cannot be computed by small monotone circuits. It is natural atthis point to wonder whether every monotone function thatcuit. If so, we would be able to deduce thatis in P can be computed by a small monotone cir - P . eq NP. However, the same method yields alower bound for the size of monotone circuits that com - super-polynomial pute the tone and is in PERFECT Match i ngp.
Given a graph function, which is mono - G, this function out - puts 1 if one can pair up the vertices in such a way that every pair is connected by an edge and 0 otherwise. Further more, exponential-size lower bounds are known for other monotone functions in P, so general circuits are known to be substantially more powerful than monotone circuits, even for computing monotone functions. 5.1.3 Bounded-Depth Circuits To understand the motivation for our next model, con-sider the following basic question:
“Can one speed up computation by using several computers in parallel?”For instance, suppose that a certain task can be performed by one computer inbyt (or even t2) cooperating computers in constantt steps. Can it be performed time (or just inthe answer depends on the task in question: if a single$\sqrt{t}$ time)? The common wisdom is that person can dig at a rate of one cubic meter per hour, then in one hour a hundred people can dig a ditch that is 100 m long, but not a hole 100 m deep.
determining which computational tasks can be “parallelized” when many processors are available and which are “inher-ently sequential” is a basic question for both practical and theoretical reasons. A very good feature of the circuit model is that it can easily be used to study questions of this kind. Let us define the depth of a DAG to be the length of the longest directed path in it: that is, the longest sequence of ver-tices where there is an edge from each one to the next. This notion of depth models theto compute the function:
if you put a separate proces-parallel time needed sor at each gate of a circuit of depth phase you evaluate all gates for which the inputs haved, and at each already been evaluated, then the number of phases you need istional resource. Here again our knowledge is scarce—d. Parallel time is another important com put a- we do not know how to disprove the statement that every explicit function can be computed by a circuit of polynomial size Thus, we will restrict and logarithmic depth.d to be a constant.
It then be- comes necessary to allow our gates to have unbounded 588 fan-into have any number of in coming edges. (If we do not, meaning that the AND and OR gates are allowed allow this, then each output bit can depend only on a constant number of input bits.) With this very strin-gent restriction on circuit depth, it is possible to prove lower bounds for the complexity of explicit functions. For example, let PAR(x)(for “parity”) equal 1 if and only if the binary string has an odd number of 1 s, and let MAJ(x)(for “majority”) equal 1 if and only if there are more 1 s than 0 s inx.
Theorem. MAJ cannot be computed by a polynomial-sized family For any constantd, the functions PAR and of circuits of depthd. This result is due to another fundamental proof technique: theat random (with judiciously chosen parameters) most random restriction method. The idea is to fix of the input variables, by assigning them random val - ues. Note that this simultaneously restricts the function as well as the circuit. This “restriction” should satisfy the following two properties. (i) The restricted circuit becomes very simple:
for instance, it may depend on only a small subset of (ii) The restricted function remains complex: for in-the remaining, unfixed input variables.stance, it may depend on all remaining input variables. Forof course the heart of the matter is analyzing the effect PAR the second property is easily seen to hold, and of random restrictions on shallow circuits. Interestingly, MAJ remains hard for constant-depth polynomial-size circuits even if the circuits are also allowed (unbounded fan - in)“converse” does not hold; that is, PAR - gates.
However the PAR has constantdepth polynomial-size circuits with (unbounded fan - in) MAJ - gates. Indeed, the latter class seems to be quite powerful: nobody has managed to prove that there are functions in NP that cannot be computed by such circuits, even if the depth is restricted to 3. 5.1.4 Formula Size Formulas are perhaps the most standard way in which mathematicians express functions.
For example, given a quadratic polynomial at2 + bt + c with b2 > 4 ac, the larger of its two roots is represented in terms of its (input) coefficients a, b, and c by the formula(Boolean formulas the logical operations “-b + . qrt{b}2 - 4 ac)/2 a. This is an arithmetic formula. In¬”, “∧”, “∨” IV. Branches of Mathematics replace the arithmetic operations above. For example, ifx = (x , x ) is a Boolean string of length 2, then PAR(x) is given by the formula1 2(¬x1 ∧ x2) ∨ (x1 ∧ ¬x2).
circuit has the additional property that its underlying Any formula can be represented by a circuit, but this DAG is atation is not allowed to reuse a previously computed tree. Intuitively, this means that the com pu partial result (unless it recomputes it). A natural size measure for formulas is the number of occurrences ofvariables in them, which is the same as the number of gates, to within a factor of 2.
lence in mathematics, but also because their size canbe related to the depth of circuits and to the Formulas are natural not only because of their preva-memory complexity).requirements of Turing machines (i.e., their space By recursively using the above formula for PAR, that is, by using the fact that PAR$(PAR(x1$, . . . , xn), PAR(x PA(Rn)+1(x, . . . , x1, . . . , (x2)n)()2)n, we obtain a) is equal to formula for the parity ofn variables that has size n2. Given the fact that size, one might wonder if there are smaller formulas PAR has a simple circuit of linear as well.
One of the oldest results in circuit complexity gives a negative answer. Theorem.have at least quadratic size. Boolean formulas for PAR and MAJ must mation-theoretic) argument. By contrast, there are lin-The proof follows a simple combinatorial (or in for ear-size circuits for both functions. This is very easy toshow for PAR, but not for MAJ. mula size? One of the cleanest methods suggested so Can we give super-polynomial lower bounds on forfar is the vi des an information-theoretic setting for studying this communication complexity method, which pro computational problem.
The power of this approach has been demonstrated mainly in the context of mono-tone formulas, where it yields an exponential lower bound for the section 5.1.2). PERFECT MATCHING problem (defined in One player is given a graph Suppose that two players play the following game. G with n vertices that con- tains no perfect matching, and the other is given agraph H, with the same vertices, that does contain a perfect matching. Then there must be some pair of vertices that are joined by an edge inin$G$.
The aim of the two players is to find such a pair H but not joined by sending each other bit strings, which each thinks ofas encoding messages according to some prearranged

IV.20. Computational Complexity

scheme. Of course, the player with graphply send enough messages to specify the entire graph, G could sim- but the question is whether there is some protocol that would enable them to find a pair of the desired kind with far fewer bits being exchanged. The smallest number of bits needed (in the worst case) is called the monotone communication complexity It has been shown that the monotone communication of the problem. complexity must be at least linear inthe exponential lower bound just mentioned. More gen-n, and this leads to erally, if$f$:
I$n → \\{0}$, 1\\\\\\\\\\\\\\\\\\\\\} is a monotone function, then the monotone communication complexity ofsmallest number of bits that must be exchanged, in thef is the worst case, to find a placef (x) = 0 and f (y) = 1. If fi where is not monotone, then onexi = 0 and yi = 1, if simply asks to find smallest number of exchanges needed is thei such that xi and yi differ, and the communication complexity off .
It can be shown that the mono- tone formula size ofconstantc if and only if the monotone co mm un ic at io nf is at least exp(cm) for a positive complexity off is at least c^ m for a positive constantc^ . The corresponding statement also holds for general formula size and general communication complexity. 5.1.5 Why Is It so Difficult to Prove Lower Bounds? As we have seen, complexity theory has developed quite a few powerful techniques, which have been useful for proving strong lower bounds, at least in restricted models of computation.
But they all fall well short of providing nontrivial lower bounds for circuits. Is there a fundamental reason for this failure?general The same may be asked about any long-standing math-ematical problem, such as the riemann hypothesis [V.26](/part - 05/the - prime - number - theorem - and - the - vi34 - jnos - bolyai - 18021860), for example, and the typical answer would be rather vague: that it seems that the current tools and ideas do not suffice. ing has been made into a precise theorem. Thus, there is a “formal excuse” for our failure so far.
Roughly Remarkably, for circuit complexity this vague feel speaking, a very general class of arguments, called natural proofs known proofs of lower bounds for restricted circuits. In, has been defined and shown to include all fact, so broad is the class of arguments that it is very hard to envisage what an “unnatural” proof might belike. On the other hand, it has also been shown that if there is a natural proof that P . eq NP, then there are fairly efficient (not quite polynomial - time, but significantly faster than known) algorithms for various prob - lems, including integer factorization.
So if, like most 589 complexity theorists, you believe that these problemsdo not have efficient algorithms, then you also believe that there is no natural proof that P . eq NP. The connection between natural proofs that P . eq NP and some notoriously hard problems is through thenotion of pseudo randomness, which is discussed in section 7.1. One interpretation of this result is that it shows that general circuit lower bounds are “independent” of a certain natural fragment of peano arithmetic [III.67](/part - 03/the - peano - axioms).
This gives a hint that the P versus NP question may be independent of all of Peano arithmetic, or even ofthe axioms of zfc [IV.22 §3.1](/part - 04/set - theory), although few believe the latter to be the case. 5.2 Arithmetic Circuits As mentioned earlier, directed a cyclic graphs can beused in various different contexts. We shall now leave Boolean functions and operations and look instead at arithmetical operations and functions that take numer-ical values, by which we mean values in Q or R or indeed in any field [I.3 §2.2](/part - 01/fundamental - definitions).
If Fis a field, then we can consider a DAG in which the inputs are now elements of$F$and the gates are the field operations “$+$” and “$\times$” (including multiplication by fixed field elements suchas-1). Then, just as with Boolean circuits, once we know the inputs we can assign values to all verticesof the DAG: at each vertex one just applies the corresponding arithmetical operation to the values assignedto its predecessors, once these have been calculated.
An arithmetic circuit computes a polynomial function$p$:$F^{n} \to F^{m}$, and every homogeneous polynomial func- tion is computed by some circuit. To allow the compu-tation of in homogeneous polynomials, we augment the model by allowing a special input vertex whose value is the constant “1” of the field. mialtions and one addition, can be computed by the circuit Let us consider a couple of examples. The polyno-x2 -y2, which as written requires two multiplica-(xcation and two additions.
The polynomial+ y)(x - y) which requires instead one multipli-xd, which is defined usingd-1 multiplications, may in fact be com- puted with only 2 log$x$, x2, x4, . . . (each term in the sequence squaring th ed multiplications: first compute previous one), and then multiply together the appro-priate subset of these powers to get the exp one ntd. We denote by S (p) the smallest possible size of a F

circuit that computes shall assume that F =p Q. When we give no subscript, we, the field of rational numbers.

590

We do not count multiplication by a fixed field element as contributing to the size of a circuit: for example, when we said that(x + y)(x - y) involves one mul- tiplication, we were not counting the multiplication ofy by -1. The reader may wonder about division. How- ever, we will be mainly interested in computing poly-nomials, and for computing polynomials (over infinite fields) division can be efficiently emulated by the other operations. As usual, we will be interested in sequences of polynomials, one for every input size, and will study size asymptotically.
metic circuits over Boolean inputs) with only a constant factor increase in It is easy to see that, for any F can simulate Boolean circuits (on fixed finite field F, arith- size. Thus, lower bounds for such arithmetic circuits yield corresponding lower bounds for Boolean circuits. Therefore, if we want to avoid the extreme difficulty with which we are already familiar, it makes sense to focus more on infinite fields, where lower bounds may perhaps be easier to obtain.
polynomials is easy to establish.will be interested in As in the Boolean case, the mere existence of hard explicit (families of) polynomials.4 But, as before, we The notion of explicitness is more delicate here, butit can be formally defined (and, for example, polynomials with algebraically independent coefficients arenot considered explicit). Boolean model, is the computed.
For example, a polynomial of degree An important parameter, which is absent in the degree of the polynomial(s) beingd, even in one variable, requires size at least log consider the one-variable, or univariate$d$, case first, in. Let us briefly which the degree is the main parameter of interest, since this case already contains striking and important problems. Then we shall move to the generalate case, in whichn, the number of inputs, will be the multi var i- main parameter.

5.2.1 Univariate Polynomials

How tight is the log arithmetic circuit computing a polynomial of deg reed lower bound for the size of and degree-? A simple dimension argument shows that for mostd polynomials p, S(p) is proportional to d. However, we know of no explicit polynomial with this every many circuits of size 2). Instead, a “dimension” argument is used,4.
A counting argument over infinite fields is inadequate (e.g., fora, b \in F the circuit ax + bhas size two, and so there are infinitely showing that the set of polynomials that are computable by small circuits forms a vector space of lower dimension than the set of all polynomials of adequate degree.

IV. Branches of Mathematics

property. (Of course, this is shorthand for “explicit fam-ily of polynomials, one for each deg reed.”) In fact, considerably less is known even than this. Open problem.d, such that S(p)Find an explicit polynomial is not bounded above bypcof degree. og d for some constantc.xal ready seen thatd Two concrete examples are illuminating. Let, and qd(x) = (x S(p+ )1)(x⩽ 2 log+ 2)d· · ·, so the trivial lower(x + d). We havepd(x) = bound is relatively tight.
On the other hand, it is a major open problem to determined S(q ), and the conjecture is that This question is particularly important because of the S(qd) grows more quickly than any power of logd d. following result.of. og d, then integer factorization has polynomial-size If S(qd ) is bounded above by a power circuits.

5.2.2 Multivariate Polynomials

Now let us return to polynomials with convenient to maken our only input size parameter, n variables. It is so we shall restrict ourselves to polynomials of total degree at mostn, even when we do not mention this restriction. For almost every polynomialp in n variables, S(p) is at least exp(n/2). Again, this follows from an easy dimension argument, but again we would like to find explicit (families of) polynomials that are hard to compute. Unlike in the Boolean world, here there are lower bounds that slightly exceed the trivial ones.
The fol-lowing theorem is proved using elementary tools from algebraic geometry. Theorem. S(xn + xn + · · · +There is a positive constantxn) ⩾ cn . og n. c such that 1 2 nof similar strength for other natural polynomials suchas the symmetric polynomials and the The same techniques extend to prove lower bounds determinant [III.15](/part - 03/determinants) (which can be regarded as a polynomial in the entries of the matrix). Establishing a stronger lower bound for some explicit polynomial is a major open problem.
Another is obtaining a superlinear lower bound for any polynomial map of constant total degree. Outstanding candidates for the latter are the linear maps that compute the discrete Fourier transform over the complex numbers or the Walsh transform over the rationals. For both these transformations algorithms oftime complexity$O(n \log n) \text{are known}$.

IV.20. Computational Complexity

importance. The most natural and well-studied candi-date for the last open problem is Now let us focus on specific polynomials of central matrix multiplication [I.3 §4.2](/part-01/fundamental-definitions): given two$m \times m matrices A$, B, how many operations are needed to compute their product?The obvious algorithm, which follows from the definition of matrix product, requires about$m^{3} operations$. Can this be beaten? It turns out that what really mat-ters here is the number of multiplications.
The first hint that one can improve on the obvious algorithm comes from the first nontrivial case (i.e.,$m = 2)$. While the usual algorithm uses eight multiplications, one canin fact reorganize the calculation and get away with only seven. This leads to a recursive argument: givena 2 m . imes  2 m matrix, think of it as a 2 . imes  2 matrix, each entry of which is itself anm . imes m matrix. It follows that doubling the size of the matrix increases the num-ber of multiplications needed by a factor of at most 7.
This argument leads to an algorithm with onlym \lo(g2)7 multiplications (and roughly as many additions). yield the following strong, but not quite linear, upper bound, where we denote by These ideas have been developed and extended to$n = m^{2} \text{the natural input}$ size, and by MM the matrix multiplication function. Theorem.that S (MM)For every field⩽ c(n1().)19. F there is a constant c such F

only multiplication gates)? Is it linear, or almost linear(something like So what is the complexity ofn . og n, say), or is MMS(even if one counts(MM) at least n^α for some We next consider two polynomials in theα >1? This is a famous open problem. n = m2 variables representing anm . imes  m matrix. We have al- ready mentioned the determinant, but we shall also look at the permanent, which is defined by the determinant formula, except that now all the signs are pos-itive. (In other words, one simply adds up m!
products instead of adding some and subtracting others.)We shall denote these by DET and PER, respectively. matics, in statistical mechanics and quantum mechanics). In While Per det is some what esoteric (though it appears plays a major role in classical ma the the context of complexity theory both polynomials are of great importance, because they are representative of natural complexity classes.low complexity (and is related to the class of poly-DET has relatively nomials having polynomial-sized arithmetic formulas), while PER seems to have high complexity (indeed, it is complete for a
complexity
class of counting problems denoted #P, which extends NP). Thus, it is natural

591

to conjecture thatto DET. PER is not polynomial-time reducible this algebraic context is called wish to find an algorithm for computing the permanent One restricted type of reduction that makes sense in projection. Suppose we of anm . imes  m matrix A. One approach might be to con- struct an M . imes  M matrix B such that each of its entries is either a (variable) entry of Aor a fixed element of the field, and to do so in such a way that the determinant of B equals the permanent of A.
Then, as long as M is not too much larger than ri thm for DET to give us an efficient algorithm for m, we can use the efficient algo-PER. A projection of this kind is known to exist with$M = 3^{m}$, but this is nothing like good enough. Therefore we askthe following question. Open problem.matrix be expressed as the determinant of an Can the permanent of an$m M \times \times m M$ matrix, with M bounded above by a polynomial in m? If so, then$P = NP$: therefore, the answer is likely to be no.
Conversely, if the answer could be shown to be no, then this would provide a significant step toward proving that P ≠ NP, though it would probably not imply it.

5.3 Proof Complexity

The concept ofall other fields of human inquiry. Mathematicians have proof distinguishes mathematics from gathered millennia of experience to attribute such adjectives to proofs as “insightful,” “original,” “deep,” and, most notably, “difficult.” Can one quantify math-ematically the difficulty of proving various theorems? This is exactly the task under taken in proof complexity. It seeks to classify theorems according to the difficulty of proving them, much as circuit complexity seeks toclassify functions according to the difficulty of computing them.
In proofs, just as in computation, there will bea number of models, called proof systems, that capture the power of reasoning that is allowed to the prover. shall deal with are best illustrated by the following The types of statements, theorems, and proofs we example. We warn the reader in advance that the the-orem we are about to discuss may seem too trivial to give us any insight into the nature of proofs: however, it turns out to be highly relevant.
hole principle The theorem in question is the well-known, which states that if you have more pigeon pigeons than holes then at least two pigeons will haveto share a hole. More formally, there is no injection

592

[I.2 §2.2](/part-01/language-and-grammar)Y . Let us reformulate this theorem and then discussffrom a finite set Xto a smaller finite set the complexity of proving it. First, we turn it into a sequence of finite statements. For each$m > n \text{let PHP}^{m}$ stand for the statement, “You cannot fitm pigeons into nnn ient way of formulating this mathematically is to use holes if each pigeon needs a hole to itself.” A conveanused to describe a hypothetical mapping if we inter-m . imes  n matrix of Boolean variables xij. This can be pretin the xij jth hole.
The pigeonhole principle states that= 1 to mean that the ith pigeon is placed either some pigeon is not mapped any where or two pigeons are mapped to the same hole. In terms of the matrix, this says that either there is some$x = 0 \text{for every} j$, or we can findi ≠ i^  and ij such that such thatxas aijij =propositional formula(xi)j = 1.5 These conditions are easily expressible in the variables xij (that is, an expression built out of the“¬”), and the pigeonhole principle is the statement that$x^{i}j$using “∧”, “∨”, and this formula is aassignment of true or false values (or equivalently 1
ortautology: that is, it is satisfied by every 0) to the variables. How can we prove this tautology to some one who can read our proof and perform simple, efficient compu-tat i ons? Here are a few possibilities which differ from each other in a number of ways. • The standard proof uses symmetry and induction. It reduces PHPm to PH(Pm)-1 by saying that once the first pigeon has been assigned a hole, the task thatis left is to place the remaining(nn)-1 n - 1 pigeons in tom the- first1 holes.
Notice that these holes may not ben - 1 holes, so for such an argument to become a formal proof one must argue by sym-metry. Our proof system must be strong enough to capture this symmetry (which amounts to a renaming of the variables), and it must also allow • us to use induction. At the other extreme, one can obtain a trivial proof, which requires only “mechanical reasoning,” by simply presenting an evaluation of the formula for every possible input.
As there arethe proof length is 2 mn, which is exponential inmn variables, the size of the formula describing the assertion PHPm.•A more sophisticated (“mechanical”) proof uses n counting. Assume for a contradiction that there is mapped to more than one hole—we could do so, but the principle remains valid even if we do not.5. Note that we have not ruled out the possibility that some pigeon IV. Branches of Mathematics exists an assignment of truth values to the vari-ables that falsifies the formula. Since each pigeon is mapped to some hole, the assignment must have at leastm 1 s.
But since each hole contains at most one pigeon, the assignment must contain at mostn 1 s. Therefore, m ⩽ n, which contra- be admissible, our system has to allow inferences powerful enough to do counting of this kind.dicts the assumption thatm > n. For this proof to and their length depend on the underlying proof sys - tem. But what exactly is a proof system, and how do we The lesson from the above example is that proofs measure the complexity of a proof? It is to this ques-tion that we now turn. Here are the salient features that we expect from any such system. Completeness: Soundness:
no false statement has a proof.every true statement has a proof. Verification efficiency: ment T and a purported proof for it given a mathematical state-π, it can be eas- ily checked whether system.6π does indeed prove T in the much to expect from strong proof systems, as Actually, even the first two requirements are toogödel [VI.92](/part-06/kurt-gdel-19061978) famously proved in hisrem [V.15](/part-05/gdels-theorem). However, we are considering just pro posi-incompleteness theotional formulas with finite proofs, and for these there are proof systems.
In this context, the above conditions are concisely captured by the following definition. Definition.nomial-time Turing machine A (propositional)Mproof system with the property thatis a poly-Tsuch thatis a tautology if and only if there exists a (“M(π$, T ) = 1.^{7} proof$”)π table” proof system trivial proof in the foregoing example. Basically, this As a simple example, consider the following “truth-MTT, which corresponds to the machine will declare a formula evaluating T on each possible input makes T to be a theorem if T true.
A bit more formally, for any formula M (π, T ) = 1 if and only if π is a list of all binary T in n variables, strings of length T (σ )TT = 1. n, and for each such string σ we have time measured in terms of theproof6. Here, efficiency of the verification procedure refers to its running. In contrast, in sections 3.2 and 6.3, we consider the running time total length of the alleged theorem and as a function of the allow only proofs of a priori bounded length).length of the alleged theorem (or, alternatively, seen as coming before the theorem.7.
In agreement with standard formalisms (see below), the proof is

IV.20. Computational Complexity

length. The point, of course, is that for typical interest-ing formulas such as the pigeonhole principle, whose Notice that MTT runs in polynomial time in its input size depends polynomially on the number of variables, the input length is extremely long, since the proof has length exponential in the length of the formula.π This leads us to the definition of the efficiency (or com-plexity) of a general propositional proof system M:
it is the length of the shortest proof of each tautology. That is, if Tis a tautology, we define its complexity Lthat M (T )M(π, T )to be the length of the shortest string=1. We then measure the efficiency of theπ such proof system itself (i.e., maximum of L (T ) over all tautologies M) by defining LMT(n)of length to be then. polynomial-size proofs for all tautologies? The follow-ing theorem provides a basic connection between this Is there a propositional proof system which has$M$ question and computational complexity, and in partic-ular with the major question of section 3.4.
It follows quite easily from the NP-completeness oflem of satisfying propositional formulas (and the fact SAT, the prob that a formula is satisfiable if and only if its negation is not a tautology). Theorem. There exists a proof system M such that LM

is polynomial if and only if$NP = coNP$.

good sense to begin by considering simpler (and thus weaker) proof systems before moving on to more and To start attacking this formidable problem it makes more complex ones. More over, there are tautologies and proof systems that naturally suggest themselves as good ones to study, systems in which certain basic forms of reasoning are allowed while others are not.
In the rest of this section we shall focus on some of these restricted proof systems. If a typical proof in a branch of mathematics such as algebra, geometry, or logic is written out in full, then it starts with some axioms and proceeds to a conclusion using a set of very simple and transparent rules. Each line of the proof consists of a mathemat-deduction ical statement, or formula, which follows from earlier statements by means of one of these rules.8 This deductive approach goes right back to euclid [VI.2](/part-06/euclid-ca) and perfectly fits our DAG model:
the inputs can be labeled by the axioms, every other vertex is assigned a deduction rule, and the statement associated with each vertex this formalism, by considering a deduction rule that corresponds to a single step of the machine8. General proof systems as we defined them can also be adapted to M. However, the deduction rules considered below are even simpler, and more importantly they are natural.

593

is the statement that follows from its predecessors by means of the specified rule. nient view of (simple) proof systems, namely as (sim-ple)There is an equivalent and some what more conve-refutation systems. These encapsulate the idea of a proof by contradiction. We assume the negation ofthe tautology T we wish to prove, and use the rules of the system to derive a contradiction—that is, a state-ment that is identically FALSE.
It is often easy to write the negation of a tautology ally contradicting formulas (e.g., a set of clauses with T as a conjunction of mutu- no common truth assignment, a system of polynomials with no common root, a collection of half-spaces with empty intersection, etc).
Assuming, for a contradiction, that all these are simultaneously satisfiable by someσ (which could be an assignment, root, or point, respec-tively), we derive more and more formulas that must also be satisfied by derivation rules, until eventually we reach a blatant con-σ because of the soundness of the tradiction (such as¬x ∧ x$, 1 = 0, or 1 < 0, respec-$ tively).
We will use the refutation viewpoint through-out, and often exchange “tautology” and its negation, “contradiction.”So we turn to studying the proof length L (T ) of tau- to log i es which reveals a major difference between proof com-T in proof systems Π. The first observation,Π plexity and circuit complexity, is that the trivial count-ing argument fails. The reason is that, while the number of functions onn bits is (22)n, there are at most 2 n tau- tologies of length the existence of a hard tautology, let alone an exp li citn. Thus, in proof complexity, even one, would be of interest.
As we shall see, however, most known lower bounds (in restricted proof systems) apply to very natural tautologies.

5.3.1 Logical Proof Systems

The proof systems in this section will all have lines that are Boolean formulas. The differences between the systems will be in the structural limits that are imposed on these formulas. puts no restriction on the formulas manipulated by the The most basic proof system, called the Frege system, proof. It has just one derivation rule, called the from the two formulas(A ∨C), (B ∨ ¬C) we can derive cut rule: A ∨ B. Different basic books in logic have slightly different ways of describing this system.
However, froma computational perspective they are all equivalent, in the sense that (up to polynomial factors) the length of the shortest proofs is independent of which variant you pick.

594

ciple can be carried out efficiently in the Frege sys-tem (but this is not a trivial fact), which tells us that The counting-based proof of the pigeonhole prin LFrege(PH(Pn()n)+1) is polynomial in n. The major open problem in proof complexity is to find any tautology(as usual we mean a family of tautologies) that has no polynomial-size proof in the Frege system. Open problem.bound for the Frege system. Establish a super-polynomial lower for Frege systems, we turn to natural and interesting subsystems.
The most widely studied system is called As it seems to be very hard to find lower bounds resolution propositional (as well as first-order). Its importance stems from its use by most automated theorem provers.9 The formulas allowed in resolution refutations are simply clauses (disjunctions), so the cut rule defined earlier simplifies to the resolution rule: from two clauses(A ∨ x), (B ∨ ¬x) we can derive A ∨ B, where A major result of proof complexity is that proving the A, B are clauses and x is a variable. pigeonhole principle is hard in the resolution system.
Theorem. Lre solution(PH(Pn()n)+1) = 2Ω(n) ing way to the circuit lower bounds for the parity and majority functions discussed in section 5.1.3.The proof of this result is related in an interest5.3.2 Algebraic Proof Systems Just as a natural contradiction in the Boolean set-ting is an unsatisfiable collection of clauses, a natural contradiction in the algebraic setting is a system of polynomials with out a common root.10 1 has no common root (over any field)?
A quick way is to, f How would you prove that the system2 = 2 yz - 1, f3 = xz + 1, f4 = x + {fy1 +=zxy - 1+} observe thatmon root of the system would be a root of this linearzf1 - xf2 + yf3 - f4 ≡ 1. Clearly, a com - combination, which is a contradiction because the con - stant 1 function has no root. Can we always use such proofs? tautologies. These tautologies may be boring mathematically but of great practical importance, such as the statement that a computer9. These are algorithms that attempt to generate proofs for given chip or communication protocol functions correctly.
Interestingly, popular applications also include a variety of theorems that are mathematically interesting, such as results in basic number theory.10. More over, polynomials can easily encode propositional formulas. First, one puts such a formula into CNF: that is, one expresses it as the conjunction of a collection of conjunctive normal form, or clauses. CNF formulas can easily be converted to a system of polyno - mials, one per clause, over any field.
One often adds the polynomials(x2)i - xi, which ensure Boolean values. IV. Branches of Mathematics satzif A famous theorem known asf , f[V.17](/part - 05/hilberts-nullstellensatz) tells us that the answer is yes. It states that, . . . , f are polynomials (with any number of hilbert’s nullstellen variables) that have no common root, then there exist polynomials1 2 gn, . . . , g such that g f ≡1. How efficient are such proofs? Can we always have proofs (i.e., g s) of length polynomial in the description of th(e1()n()i()i)i fs? Unfortunately not:
the shortest explicit description ofthei g s may be of exponential length, though provingii

this fact is highly nontrivial.

to Hilbert’s Nullstellensatz and to computations of Gröbner bases in symbolic algebra programs, is Another natural proof system, which is related both polynomial calculus nom i a ls, represented explicitly by all their coefficients,(PC). The lines in this system are poly and it has two deduction rules: for any two polyno-mialsg, h, we can derive their sum, g + h, and for any polynomialg and any variable x , we can derive thei

prod uctx g. PC is known to be exponentially stronger i

than the proof system underlying Hilbert’s Nullstel-lens atz. However, strong size lower bounds (obtained from degree lower bounds) are known for this system as well. For example, encoding the pigeonhole principle as a contradicting set of constant degree polynomials, we have the following theorem. Theorem.2 n/2, over every field. For everyn and every m > n, LPC (PH(Pm)n ) ⩾

5.3.3 Geometric Proof Systems

Yet another natural way to represent contradictions isby sets of regions in space that have empty intersection. For instance, many important problems inrial optimization concern systems of linear inequalities combinatoin Rn and their relationship to the Boolean cube \\{0, 1\\}n. Each inequality defines a half-space, and the problem is to decide whether the intersection of all these half-spaces contains a point with coordinates all equal to 0 or 1.The most basic proof system is called Cutting planes integer coefficients. The deduction rules are that you(CP).
A line of a proof is a linear inequality with can add two inequalities, and, less obviously, that youcan divide the coefficients by a constant and do some rounding, taking advantage of the fact that the points of the solution space have integer coordinates. bounds are known for other tautologies. They are While PHPmn is easy in this system, exponential lower obtained from the monotone circuit lower bounds of section 5.1.2.

IV.20. Computational Complexity

6 Randomized Computation

Up to now, the computations we have considered have all been deterministic: that is, the output is completely determined by the inputs and the rules governing the computations. In this section we shall continue to focus on polynomial-time computations, but now we shall allow our computing devices to make probabilistic, or randomized, choices.

6.1 Randomized Algorithms

A famous example of such an algorithm is one that tests for primality. If N is the positive integer to be tested, then the algorithm randomly chooses than N, and repeatedly performs a simple test usingk numbers less each of the chosen numbers in turn. If N is composite, then the probability that the test detects this is at least3. Therefore, the probability that the algorithm fails to detect it for any of the4 k numbers is at most (1 4)k, which is very small indeed for even modestly large val-ues ofk.
Details of how the test works can be found in computational number theory [IV.3 §2](/part-04/computational-number-theory). It is not hard to give a rigorous definition of a randomized Turing machine, but we shall not need the precise details here. The main point is that if M is a randomized Turing machine andx is an input string, then dom variable M(x)is not a fixed output string, but rather a[III.71 §4](/part-03/probability-distributions).
If, for example, the output israna single bit, then we shall make statements such as,“The probability that M(x) = 1 is p.” The actual value ofmade by the machine M(x) will depend on the particular random choices M when it runs. If we are using a randomized algorithm to solve a decision problem correct answer with high probability S, then we would like whatever the input M(x) to give thex This leads to the definition of the complexity class. (The correct answer is 1 if x \in S and 0 otherwise.)BPP (for bounded error, probabilistic polynomial time). Definition (BPP).
A Boolean function f is in BPP if there exists a probabilistic polynomial-time machine such that Pr[M(x) . eq f (x)] ⩽1 for every x \in I. M much smaller if one runs the algorithm several times and takes a majority vote of the answers. (We stress The error bound 13 is arbitrary, and can be made that the random moves in the various runs are inde - pendent.) Standard probabilistic estimates show that, for anyk, the error probability can be reduced to 2 - k if one runs the algorithm O(k) times.
595 an exponentially small chance of failure is of no prac-tical importance, the class Because randomness is believed to be “available” and BPP is in many ways a better model for efficient computation than P, which it trivially contains. Let us mention some relations ofthis class BPP to other complexity classes we have seen already. It is easy to see that BPP ⊆ EXP; if the machine tosses2 m possible out comes of these coin tosses and take am coins, we could enumerate all majority vote. The relation ofbut it is known that if P = NPBPP tothen NPP = BPPis not known, as well.
Finally, nonuniformity can replace randomness: every function in BPP has polynomial-size circuits. But the fundamental question is whether or not ran-domized algorithms are genuinely more powerful than deterministic ones (for decision problems). Open problem. Does$P = BPP$? time algorithm was recently discovered for primality As we mentioned earlier, a deterministic polynomial testing, though in practice the randomized algorithmis much more efficient. However, there are quite a few problems11 that are known to be in BPP but not known to be in P.
Indeed, for most of these problems random- ness gives an exponential improvement over the best deterministic algorithms that are known. Is this evi-dence that randomness increases our power to solve decision problems? Surprisingly, a completely different kind of evidence (discussed in section 7.1) suggests the opposite, namely that$P$ = BPP.

6.2 Counting at Random

One important general question regarding NP search problems is that of determining particular instance has. This includes a host of inter-how many solutions a esting problems from various disciplines: for example, counting the number of solutions to a system of multivariate polynomials, counting the number of perfect matchings of a graph (or, equivalently, computing the permanent of a$\\{0}$,1\\\\\\\\\\\\\\\\\\\} matrix), computing the volume of a polytope (defined by linear inequalities) in high dimension (see [I.4 §9](/part-01/general-goals) for more about this problem), computing various
parameters of physical systems, etc. For most of these problems, even approximate counting is good enough. Clearly, an approximate count ofthe number of solutions will in particular allow one to circuit over11. A central example is Q, decide if it computes the identically zero polynomial. Identity Testing: given an arithmetic

596

determine whether a solution exists at all. For exam-ple, if one knows the approximate number of satisfying assignments for a given propositional formula, then one certainly knows whether this number is at least

1. This tells us whether the formula is satisfiable and solves an instance ofalso true: if one can solve SAT. Interestingly, the converse is SAT, then one can use this ability to produce a randomized algorithm for approximating the st ant factor greater than 1. More precisely, there is an number of solutions, to within any con efficient probabilistic algorithm that can produce such an approximate count if it is allowed to make free useof a subroutine that solves SAT instances. It turns out that analogous statements holds for all NP-complete problems.
done nomial-time probabilistic algorithms for approximat-For some problems, approximate counting can be with out the SAT subroutine. There are poly ing the permanent of positive matrices, approximating the volume of polytopes, and more. These algorithms use a connection between approximate counting and another natural algorithmic problem: that of randomly generating a solution in such a way that all correct solutions are equally likely to occur.
The basic technique is to construct a Markov chain on the space of solutions with uniform stationary distribution and to analyze the rate of convergence of the chain to this distribution (see Hochbaum 1996, chapter 12). can not even if it can make free use of a What about be done by an efficient probabilistic algorithm, exact counting? It is believed that this SAT subroutine. A remarkable “complete” problem for this class of count-ing problems is counting the number of perfect matchings in a graph.
What is surprising about it is that there is an efficient algorithm for finding a perfect matchingin a graph, if one exists, and yet counting such matchings is complete in the sense that an efficient algorithm for doing this can be turned into an efficient algorithm for the counting version of any other problem in NP.

6.3 Probabilistic Proof Systems

As we saw earlier, proof systems are defined in terms of their verification procedure. In section 5.3, we considered verification procedures that run in time thatis polynomial in the combined length of the assertion and its alleged proof. Here (as in section 3.2), we restrict our attention to verification procedures that run in time that is polynomial in the length of the assertion. Such proof systems are related to the class NP, since sets S

IV. Branches of Mathematics

in NPare those with the following property: there is a polynomial-time algorithm S if and only if there exists a string M such thaty of length poly-x belongs to nomial inx with M(x, y) = 1. In other words, we can regard belongs to yas a concise proof (verifiable by S. M) that x rithm? Then we obtain a systems are not put forward as a substitute for the What if we now allow probabilistic proof system M to be a randomized .
Suchalgo- notion of mathematical proof, but rather as an inter-esting extension of the notion of efficient verifiability in situations where a tiny amount of error can be tol - erated. As we shall see, various types of probabilistic proof systems yield enormous advantages in computer science. We shall exhibit three remarkable manifestations of this.
The first shows that we can use it to prove many more theorems, the second that we can do so with out revealing that alleged proofs can be written in such a way that anything in our proof, and the third verifiers need only look at a tiny handful of bits in order to decide whether they are correct. 6.3.1 Interactive Proof Systems Recall the graph isomorphism problem from section 4.Given two graphs G and H, it asks whether H is obtained from problem is clearly in G by simply permuting the vertices.
This NP, since one can just exhibit a permutation that transforms We can look at this as a protocol involving a ver - G into H. ifier, who can do polynomial-time computations, anda prover, who has unlimited computational resources. The verifier wishes to be convinced that isomorphic, so the prover sends a permutation and the G and H are verifier checks (in polynomial time) that it is valid. Suppose that we now look at the graph nonisomorphism problem. Is there any way for a prover to con-vince a verifier that two graphs G and H are not iso - morphic?
Obviously there will be for some pairs of graphs(G, H), but there does not seem to be a system- atic method of demonstration that works for som or ph ic pairs. Yet, remarkably, if we allow random-all non in ess verifier to be convinced.and interaction, then there is a simple way for the12 one of the two graphs vertices, and sends it to the prover. The prover then Here is how it works. The verifier chooses at random G and H, randomly permutes its not yield any gain; that is, such interactive (but deterministic) proof systems are exactly as powerful as12.
We note that allowing interaction with out randomness does NP. IV.20. Computational Complexity sends back a message saying whether this permuted graph is G or H. If G and H are not isomorphic, then the permuted graph is isomorphic to exactly one of prover can determine which and there by get the right G and H, so the answer. But ifhas no way of knowing which graph has been permuted, G and H are isomorphic, then the prover and therefore has a 50% chance of getting the right answer. So now, to become convinced, the verifier repeats the procedure the prover will always get the right answer.
If they arek times. If the graphs are not isomorphic, isomorphic, then with probability 1 - 2-k the prover will make at least one mistake. Ifnear - certainty, so if the prover never makes a mistake, k is large, this becomes a then the verifier will be convinced that the graphs arenot isomorphic. That was an example of an interactive proof system.
Given a decision problem for Sis a protocol involving an interacting verifier and S, an interactive proof system prover, with the property that iffier will eventually output 1, while ifx \in x S∉then the veri - S then there is a probability of at least 12 that the verifier will output 0. As in the example, the verifier can then repeat the protocol several times, there by replacing 1 by a probability very close to 1. Also as in the example, the verifier is allowed polynomial-time randomized com - 2 putations and the prover has unlimited computational power.
Finally, the number of rounds of the interaction must be at most polynomial in the size of the input x The class of decision problems for which an interactive, so that the entire verification procedure is efficient. proof system exists is denoted IP. persistent student, who asks the teacher “tough” ques-tions in order to be convinced of correctness. Inter-One can view the protocol as an “interrogation” by a est ing ly, it turns out that asking “tough” questions isno better than asking random questions!
That is, every set that has an interactive proof system also has onein which the verifier only asks random questions that are uniformly and independently distributed in some predetermined set. belongs tothat can be used to demonstrate that It turns out that for NP there is an interactive proof system every decision problemx \in S. It works S that by demonstrating thex is in S. The proof of this result, which tells us nonexistence of an NP-proof that that co NP ⊂ IP, involves an arithmetization of Boolean formulas.
Further more, a complete character-ization of the power of interactive proofs is known. 597 Let PSPACE be the class of all problems solvable in polynomial lems in Pspace space may require(or memory). Although solving prob-exponential time, they all have interactive proofs. Theorem.$IP = PSPACE$. While it is not known if NP ≠ PSPACE, it is widely believed to be the case, and so it seems that interactive proofs are much more powerful than standard noninteractive and deterministic proofs (that is, NP-proofs).

6.3.2 Zero-Knowledge Proof Systems

A typical mathematical proof not only guarantees the truth of a statement, but also about it. In this section we shall discuss a kind of proof teaches you something that teaches you absolutely nothing, beyond the fact that the statement is true. Since this seems impossible, let us give an example. Suppose a prover wants to convince you that a certain map (in the geography sense) can be colored with three colors in such a way that no two adjacent regions have the same color.
The most obvious approach isactually to show you a coloring, but this teaches you something—a particular coloring—which you would not otherwise be able to find easily, even knowing that it existed (since this search problem is NP-complete).Is there any way the prover can convince you with out giving you this extra knowledge?Here is a way of doing it. Given any coloring of the map, with red, blue, and green, say, one can produce other colorings by permuting the colors: for instance, one might change all the red regions into blue and all the blue ones into red.
Let the prover take six copies ofthe map and color them in six different ways, one for each permutation of the three colors. Now we have a sequence of rounds. In each round the prover randomly chooses one of the six colored maps, you randomly choose a pair of adjacent regions, and the prover allows you to check that they have different colors, not allow you to look at the rest of the map.
If the graph but does cannot be properly colored with three colors and the prover tries to cheat, then after enough rounds (a polynomial number suffices) you will discover the deceptionby hitting upon two adjacent regions that have been given the same color (or perhaps one of them has not been colored at all). However, at each stage, all you learn about the two regions you look at is that they have dif-ferent colors—you have no idea what those colors are

598

in the coloring the prover started with. So you end upwith no knowledge beyond the fact that the map can (almost certainly) be properly colored. mula is satisfiable should not reveal a satisfying assign-Similarly, a “zero-knowledge proof” that a certain for ment, or even any partial information (such as the truth value of one of the variables), or irrelevant information that is hard to compute (such as how to factorize an integer that happens to be encoded by the formula).
In general, a zero-knowledge proof is an interactive proof that does not help you (the verifier) to make put at i ons that you were not able to make efficiently any com already. ously, if the verifier can determine the answer with nohelp, then the theorem has a trivial zero-knowledge Which theorems have zero-knowledge proofs? Obvi proof, in which the prover does nothing at all. Thus, any set in BPP has a zero-knowledge proof.
The zero-knowledge proof outlined for depended on non computational procedures, such as3-colorability the prover watching carefully to make sure that you just look at two regions. Implementing the protocolin full on a computer takes some care, but a method of doing it has been devised, which depends on the hardness of integer factorization. The result is a zeroknowledge proof system completeness of 3-colorability. Combining this with the NP-, one can prove that zero-knowledge proof systems exist for NP.
More generally, we have the following theorem.every set in Theorem.in section 7), then every set in If one-way functions exist (these are defined NP has a zero-knowl- edge proof system. More over, this proof system can be efficiently derived from the standard NP proof. This theorem has a dramatic effect on the design of cryptographic protocols (see section 7.2). Further more, under the same assumption, an even stronger result holds: any set that has an interactive proof system also has a zero-knowledge interactive proof system.

6.3.3 probabilistic ally Checkable Proofs

In this section we turn to one of the deepest and most surprising discoveries about the power of probabilistic proofs. Here, as in the case of standard (noninteractive) proofs, the verifier receives a complete written proof. The catch is that the verifier may read only a very small, randomly selected, part of this proof. eeing a paper and trying to decide the correctness A good analogy is to imagine that you are refer-

IV. Branches of Mathematics

of a long proof by reading just a few random lines. If the proof has a single (but crucial) mistake, then you will probably not read the relevant line so you will not notice the mistake. But this is true only for the “natural” way of writing down proofs. It turns out that there are ways of writing proofs “robustly” (with a certain amount of redundancy) so that any mis-take will manifest itself in many different places. (This may remind you of There is indeed an important analogy here, and cross-error-correcting codes [VII.6](/part-07/reliable-transmission-of-information).
fer til ization between the two areas has been very sig-nif i cant.) Such a robust proof system is called a PCP, which stands for “probabilistic ally checkable proof.”Loosely speaking, a PCP system for a set S con- sists of a probabilistic polynomial-time verifier who has access to individual bits in a string that represents the(alleged) proof. The verifier tosses coins and, depending on the out come, accesses only athe bits in the alleged proof.
It should output 1 when-constant number of ever vi ded), while ifx belongs tox does not belong to S (and an adequate proof is pro-S, then (no matter which false proof is provided) it should output 0 with probability at least 1. Theorem (the PCP theorem).PCP system. Further more, there exists a polynomial-2 Every set in NP has a time procedure for converting any NP-proof to the corresponding PCP. length that is polynomial in the length of the input.
Infact, this PCP is itself an NP-proof. In particular, it follows that the (robust) PCP has13 rem (and its variants) has a major application to com-On top of its direct conceptual appeal, the PCP theoplexity theory: it allows us to prove that several nat-ural approximation problems are hard (assuming that

P ≠ NP). over the two-element field ues for the variables, then any given equation will be For example, suppose we are given F2. If we choose random val - n linear equations satisfied with probability satisfy at least half the equations. Also, by linear alge - 12, so it is clearly possible to bra one can quickly determine whether it is possibleto satisfy all the equations simultaneously.
However, it turns out that if P . eq NP then there is no polynomial- time algorithm that will output 1 if 99% of the equations can be satisfied simultaneously and 0 if it is impossible to be error free when theorem uses only a logarithmic number of coin tosses, so one can13. Here we take advantage of the fact that PCP systems are defined x\in Sand the fact that the verifier in the PCP efficiently check all possible out comes.

IV.20. Computational Complexity

to satisfy more than 51% of them. That is, even imately determining the number of equations that canapproxbe satisfied simultaneously is hard. problems and PCP, note that a PCP system for any set gives rise to an optimization problem as follows. Sup-To see the connection between such approximation Spose we are given an input proof thatx \in  S, which is presented as a stringx. Then for any allegedy, there is a certain probability that the verifier accept sy. What is the maximum of this probability over all alleged proofs to within a factor of 2, then we would be able to tell y?
If we could answer this question whe the rx belongs to S. Hence, if S is an NP-complete decision problem, the PCP theorem implies that this optimization problem is NP - hard (that is, at least as hard as any problem in NP). One can now use reduc - tions, capitalizing on the fact that the verifier reads only a constant number of bits in the alleged proof, to obtain similar results for many natural optimization problems. This is of great theoretical interest, but some practical disappointment:
in many cases, approximate solu-tions would have been just as useful as exact ones, but they turn out to be just as hard to obtain. 6.4 Weak Random Sources We now turn to the question of how to obtain the randomness for all the probabilistic computations discussed in this section. Although randomness seems to be present in the world (e.g., the perceived randomness in the weather, Geiger counters, Zener diodes, real coin flips, etc.), it does not seem to be in the perfect form of the unbiased and independent coin tosses we have postulated.
If we actually want to use randomized procedures, then we need to convert weak sources of randomness into almost perfect ones, because this is what probabilistic computations were defined to work with. a stream of almost completely independent and unbi-ased bits are called Algorithms that convert imperfect randomness into randomness extractors, and near optimal ones have been constructed. This large bodyof work is surveyed in Shaltiel (2002), for example.
The questions that arise turn out to be related to certain types of pseudorandom generators (see section 7.1) aswell as to combinatorics and coding theory. ness extraction, we consider three relatively simple models of weak random sources. Imagine first that you To illustrate the nature of the problem of random are in possession of a biased coin that has probability

599

pnot know the bias. Can you produce a uniformly dis-of coming up Heads, wher(e1)3 < p <2 3, but you do tributed binary value using such a coin? A simple solu-tion consists of tossing the coin twice, out putting 1 if the result isis Tails followed by Heads followed by Heads, and otherwise continuing Tails and 0 if the result to the next attempt. This way we can generate a per-fect coin toss by tossing the biased coin an expected number((1 - p)p)-1 of times.
different biased coins, with unknown biases each in the interval A more challenging setting arises if you are given(1$, {}^{2})$, and you are asked to gen-p^1, . . . , p^nn, erate an almost uniformly distributed binary value by tossing each of these coins3 3 exactly once. Here a good solution consists of tossing all coins and out putting the parity of the number of Heads. It can be shown that the out come will be 1 with a probability that is exponentially (in$n) \text{close to}^{1}$. signs the coins in the latter example, but does so after seeing the out come of previous coin tosses.
That is, you Finally, consider a situation in which the devil de-2 are tossing coin (i.e., p n) may depend on the out come of the pre-different coins, but the bias of the ith i

vious2). It can be shown that in this case you cannot doi - 1 coin tosses (but still lies betwee(n1)3 and better than simply out putting the out come of the first coin. However, if you are allowed to use just a few3 genuinely random bits, then you can do much better: given just O(. og (n/)) perfectly random coin tosses, together with thea string of length proportional ton biased coin tosses, you can outputnthat is “ -close” to being uniformly distributed.
7 The Bright Side of Hardness If P . eq NP, as almost everybody believes, then there are computational problems of great interest that are inherently intractable. This is bad news, but there is a bright side to the matter: computational hardness has many fascinating conceptual consequences as well asimportant practical applications. tence ofeasy to compute but hard to invert. For example, the The hardness assumption we shall make is the exis - one-way functions;
namely, functions that are product of two integers is of course easy to compute, but its “inverse”—factoring the resulting product—is the integer factorization problem, widely believed to be intractable. For our purposes, we shall need the inverse to be hard not just in the worst case, but hardage. For example, for factoring it is believed that theon aver - 600 product of two random primes of length factored in polynomial time, even with some small con - n cannot be stant probability of success. In general, we shall say that a functionf:
I \to I is a one-way function if it is easy to evaluate (i.e., there exists a polynomial-time algorithm that returns nnf (x) when you input x)but hard to invert in the following average-case sense: any polynomial-time algorithm M will fail to invert f correctly for at least half the input strings is, for at least half the string sx, if you inputx \in y I = n. Thatf (x) intof (x^ M) =, then the output will not be a stringy. x^ such that P = NPDo one-way functions exist? It is easy to see that ifthen the answer is no. The converse is an important open problem:
If P . eq NP, does it follow that one-way functions exist?Below, we discuss the connections between computational difficulty (in the form of one-way functions), and two important computational complexity theories: the theory of cryptography. pseudo randomness and the theory of

7.1 Pseudo randomness

What is randomness? When should we say that a mathe-mat ical or physical object behaves randomly? These are fundamental questions that have been thought about for centuries. When the objects are probability distributions, onone point at least: then-bit sequences, say, there is consensus about uniform distribution (in which eachn-bit string appears with probability 2-n) is “the most random” one.
More generally, it seems reasonable to say that any distribution that is statistically close to the uniform distribution should also be regarded as having “good randomness” properties.14 plexity theory is that there are distributions that are extremely far from the uniform distribution, but which One of the great insights of computational comare nevertheless “effectively random.” The reason isthat they are computationally in distinguishable from the uniform distribution. domly sample ability distribution Let us try to formalize this idea.
Suppose we can ran-n-bit strings chosen according to a prob-P , and suppose that we want to know whether One way to try to tell is to fix an efficiently computable Pn is in fact the uniform distribution.n function$f$: I$n → \\{0}$, 1\\\\\\\\\\\\\\\\\\\\. and consider two experiments: they assign roughly the same probabilities: that is, iffor every event14. Two probability distributions E. p1 and p2 are statistically closep1(E). pprox  p2(E)if

IV. Branches of Mathematics

one of the probability thatf (x) = 1 when x is chosen with probability thatf (x) = 1 when Pn(x)x is chosen with the uniform prob-, and the other of the probability$ability 2$-n. If there is a noticeable discrepancy between these two probabilities, then certainly form. However, the converse is not true: it may be that Pn is not uni-Pfunctionn is far from uniform, butf can help us detect this. In that case, we say no efficiently computable that Pn is pseudorandom. refers to any efficient procedure that may be employedin an attempt to tell two distributions apart.
And it is This definition is both general and pragmatic. It pragmatic because for any practical purpose a pseudo-random distribution is as good as a random one, for reasons we shall now explain. listic algorithm will be virtually unaffected if we replace its random source with a pseudorandom one.
Why?Notice first that the behavior of any efficient probabi Because if its behavior changed, then the algorithm itself would have efficiently distinguished between the random and pseudorandom sources, contradicting the definition of pseudo randomness!Replacing uniform distributions by pseudorandom distributions is beneficial provided we can generate the latter using fewer resources. In this context, there source we are trying hardest to save on is randomness. Suppose we have an efficiently computable func-tionφ: I\to  I and suppose that n > m.
Then we can define a probability distribution onby choosing a random mn m-bit string x and computingn-bit stringsφ(x). If this distribution is pseudorandom, then φ is called ais called the pseudorandom generator seed, and if the generator stretches. The random stringm-bitx long seeds into strings of length$n = (m)$, then we call the function the stretch measure of the generator. The larger the stretch measure, the better the generator is considered to be. pseudorandom generators exist? It is to this question that we now turn. Of course, all this raises an important question: Do

7.1.1 Hardness versus Randomness

There is an obvious connection between pseudo ran-dom generators and computational difficulty, since the main property of a pseudorandom generator is that its output should be computationally hard to distinguish from a purely random string, even though the two distributions are significantly different. However, there isa much less obvious connection as well.

IV.20. Computational Complexity

Theorem.if one-way functions exist. Further more, if pseudo-Pseudorandom generators exist if and only random generators exist then they exist for any stretch measure that is a polynomial.15 hardness th er more, its proof links computational in distinguish a-This theorem converts computational difficulty, or, into pseudo randomness, and vice versa.
Fur bility to computational un predict ability, hinting that the computational difficulty is linked to randomness, or at least to the appearance of randomness. The existence of pseudorandom generators has the remarkable consequence that probabilistic algorithms can be partially or even wholly derandomized. The basic idea is this. Suppose you have a probabilistic algorithm that computes a functionf and requires nc random bits (where that this algorithm out pu tsn denotes the length of the input). Sup pos ef (x) with probability at leastrandom23.
If you replace the random bits with bits, generated from a seed of sizemn, then thec pseudo- behavior of the algorithm will hardly be affected. There-fore, ifm is small, then you can do the same com put a- tion with only a small amount of randomness. Ifas small as O(. og n), then it becomes feasible to checkm is through these, the algorithm outputs all possible seeds. For close to two thirds off (x). But this means we can compute taking a majority vote!f (x)deterministical ly and efficiently by to achieve the ultimate derandomization result, that$BPP = P$Can this actually be done?
Can we use hardness? The theory has developed to give essentially optimal answers to this question. Notice that ifwe wish to achieve an exponential stretch measure, we do not mind if the algorithm that performs the stretch takes exponential time (in the length of the seed). Such pseudorandom generators exist under very plau-sible hardness assumptions, such as the assumption that NP-complete problems require exponential-size Boolean circuits. More generally, we have the following theorem. Theorem. If, for some constant$> 0$, S(SAT) > 2 n, then problem computable in BPP = P.
More over,2 O(n)SAT-time.can be replaced by any

7.1.2 Pseudorandom Functions

Pseudorandom generators allow you to generate long pseudorandom sequences efficiently from short ranmany15. In other words, if you can achieve a stretch measure+c >1, then you can also achieve a stretch measure of1. (m) =(m)mc for= 601

dom seeds. pseudorandom powerful: if you are given a random seed offunctions are even moren bits, they provide you with an efficient way of computinga function$f$: I→ \\\\\\\\\\\\\{0, 1\\\\\\\\\\\\\} that is computationally in distinguishable from a random function. Thus, with$n$ just2 nbits that appear random.
(Note that it is in efficient nbi ts of randomness, one has efficient access to to scan through all these bits—what we are given isthe ability to look at any one of them in polynomial time.) constructed given any pseudorandom generator that they have many applications (most notably in It turns out that pseudorandom functions can be, and cryptography).

7.2 Cryptography

Cryptography has existed for millennia, but where as in the past it was focused on one basic problem—that of providing secret communications—the modern computational theory of cryptography is interested inall tasks that involve several agents who each wish to obtain some information while preserving the secrecy of other information. An important priority be sides privacy (that is, keeping secrets) is resilience: one would like guaranteed privacy even if one is not certain that the other participants are be having honestly. ing a game of poker over the telephone or e-mail.
Youare encouraged to ponder seriously how this might A good example to illustrate these difficulties is playbe done, and realize to what extent standard poker relies on human vision, physical implements like cards with opaque backs, etc., to protect privacy and prevent cheating. schemes, called functionality (rules, privacy requirements, etc.), even in The general goal of cryptography is to construct protocols, that maintain any desired the face of malicious attempts to make them deviate from this functionality.
As with pseudo randomness, there are two key assumptions underlying the new theory.
First, it is assumed that all parties, including the malicious adversaries, are computationally limited. Second, it is assumed that there are hard functions. Some times these are one-way functions, and some times they are yet stronger functions called “trapdoor permutations,” which also exist if integer factorization is hard. achieved. There is a result that says, roughly speaking, This goal is an ambitious one, but it has been that every functionality can be securely implemented.

602

This includes highly complex tasks such as playing poker over the phone, but also very basic ones such as secure communication, digital signatures (a digital analogue of handwritten signatures), collective coin flip-ping, auctions, elections, and the famous millionaires’ problem who is richer, with out either of them learning anything: how can two people interact to determine further about the other’s wealth? tography and matters that we have already discussed. First of all, consider the very definition of the central Let us very briefly hint at connections between crypnotion of cryptography:
that of an-bit string, then when should we say that it is com-secret. If you have an pletely secret? A natural definition would be that it is secret if nobody else has any information about it: that is, from any body else’s point of view it is equally likely to be any of the 2 n-bit strings. However, in the new com- putational complexity theory, this is not the definition taken, since apractical purposes, be just as secret.pseudo ran do mn-bit string will, for all is huge.
The point of cryptography is not just to have secrets (that is easy, just select a string at random) but The difference between the two definitions of a secret actually to At first this seems impossible, since any nontrivial useuse them with out giving away information. of a secretsible strings that it might be, and therefore give awayn-bit string will cut down the set of pos- genuine information.
However, if the new probability distribution over the possible strings (after the infor-mation has been given away) is pseudorandom, then this information cient algorithm can tell the difference between a string cannot feasibly be used, since no eff i that gives rise to the information you have revealed and a truly random string. A famous example of this idea is given by the so called which are described in detail in public-key encryption schemes mathematics and, such as RSA, cryptography [VII.7](/part-07/mathematics-and-cryptography) and in Goldreich (2004, chapter 5).
In the RSA scheme, if a user, say Alice, wants to receive messages, she publishes a number N, called a If you know public key, which is a product of two primes N then you can encrypt any message, but P and Q. to decrypt it you need to know P and Q. Thus, if inte- ger factorization is hard, then only Alice can feasibly decrypt messages, even though P and Q are completely determined by The generic problem about using secrets is one in N. which there arek parties, and each party has a string of bits.
They are interested in the value of some efficiently computable functionf that depends on all the strings

IV. Branches of Mathematics

of bits, but they would like to as certain this with out giving away any information about their own strings beyond what follows from the value off . For example, in the case of the millionaires’ problem, there are two parties, each with a string that encodes their wealth. They would like a protocol that provides them with a single bit that tells them who is richer, but gives themno information beyond this. The precise formulation of this condition is an extension of the formulation ofzero-knowledge proofs (presented in section 6.3.2).
As hinted at earlier in this section, assuming the existenceof trapdoor permutations, every such multiparty computation can be performed with out yielding anything beyond the designated outputs Finally, we come to the issue of cheating. In the fore-. going discussion, we did not worry about malicious behavior and focused on what participants may learn from the transcript of their interaction. But how can a player, Bob, say, be forced to act “as specified,” when his actions may depend partly on his secrets, which hedoes not want to reveal? The answer is closely related to zero-knowledge proofs.
Essentially, each player whose turn it is to perform some computation is asked to prove to the others that he has acted as specified. Thisis a (mathematically boring) theorem and the standard proof is obvious (i.e., revealing all his secrets). But as we saw in our discussion of zero-knowledge proof systems in section 6.3.2, if a proof exists, then a zero-knowledge proof can be efficiently derived from it. Thus, can convince the others of his proper behavior with out Bob revealing anything about his secrets.
8 The Tip of an Iceberg Even within the topics reviewed above, many important notions and results have not been discussed, for space reasons. Further more, other important topics and even wide areas have not been mentioned at all. The P versus NP question, as well as most of the discussion so far, focuses on a simplified view of the goals of (efficient) computations. Specifically, we have insisted on efficient procedures that exact answer. However, in practice one may be con-always give the tent with less.
For example, one may be happy with an efficient procedure that gives the correct answer for a large fraction of the instances. This will be useful if all instances are equally interesting, but that istypically not the case. On the other hand, demanding success under all input distributions gives back worst-case complexity. Between these two extremes is

IV.20. Computational Complexity

a useful and appealing theory ofity (see Goldreich 1997): one demands that algorithms average-case complex succeed with high probability on every possible input distribution that can be Another possible relaxation is settling for approx i-efficiently sampled. mate answers. This can mean many things, and the bestnotion of approximation varies from context to context.
For search problems, we may be satisfied with a solution that is close in some(see Hochbaum (1996) and metric the mathematics of algo-[III.56](/part-03/metric-spaces) to being valid rithm design ask how close the input is (again in some natural met-[VII.5](/part-07/the-mathematics-of-algorithm-design)). For decision problems, we might ric) to an instance in the set (see Ron 2001). And there is also approximate counting, which was discussed in section 6.2. procedures. This is arguably the most important com-plexity measure, but it is not the only one.
Another is In this article we have focused on the running time of the amount oftation (see Sipser 1997). Another important issue is the work space consumed during the compuextent to which a computation can be performed in par-allel; that is, speeding up the computation by splitting the work among several computing devices, which are viewed as components of the same (parallel) machine and are provided with direct access to the same memory module.
In addition to the parallel mentally important complexity measure in such a case time, a fundais the number of parallel computing devices used (see Karp and Ramachandran 1990).Finally, there are several computational models that we have not discussed here. Models of put ing refer to distant computing devices, each given distributed coma local input, which may be viewed as a part of a global input. In typical studies one wishes to min-imize the amount of communication between these devices (and certainly avoid the communication of the entire input).
In addition to measures of communication complexity, a central issue is asynchrony (see Attiya and Welch 1998). Theity of two-argument (and many-argument) functions is communication complex a measure of their “complexity” (see Kushilevitz and Nisan 1996), but in these studies communication proportional to the length of the input is not ruled out (but rather appears frequently). While being “informa-tion theoretic” in nature, this model has many connections to complexity theory.
Altogether different types of computational problems are investigated in the context of computational learning theory (see Kearns and Vazirani 1994) and ofand El-Yaniv 1998). Finally, online quantum computation algorithms (see Borodin

603

[III.74](/part-03/quantum-computation) investigates the possibility of using quantum mechanics to speed up computation (see Kitaev et al. 2002). 9 Concluding Remarks We hope that this ultra-brief survey conveys the fasci-nating flavor of the concepts, results, and open problems that dominate the field of computational complex-ity.
One important feature of the field we did not do justice to is the remarkable web of (often surprising)connections between different subareas, and its impact on progress. For further details on sections 1–4 the reader is referred to standard textbooks such as Garey and John-son (1979) and Sipser (1997). For further details on sections 5.1–5.3 the reader is referred to Boppana and Sipser (1990)$, Strassen (1990)$, and Beame and Pitassi (1998), respectively. For further details on sections 6 and 7 the reader is referred to Goldreich (1999) (and also to Goldreich (2001, 2004)).
Further Reading Attiya, H., and J. Welch. 1998.damentals, Simulations and Advanced Topics Distributed Computing: Fun-. Columbus, Beame, P., and T. Pitassi. 1998. Propositional proof com - OH: Mc Graw - Hill.plexity: past, present, and future. Bulletin of the European Boppana, R., and M. Sipser. 1990. The complexity of finite Association for Theoretical Computer science functions. In Handbook of Theoretical Computer Sci - 65:66–89. encevan Leeuwen. Cambridge, MA: MIT Press/Elsevier., volume A, Algorithms and Complexity, edited by J. Borodin, A., and R. El - Yaniv. 1998.Competitive Analysis.
Cambridge: Cambridge University On-line Computation and Garey, M. R., and D. S. Johnson. 1979.Press. Intractability: A Guide to the Theory of NP-Completeness Computers and. Goldreich, O. 1997. Notes on Levin’s theory of average-New York: W. H. Freeman.case complexity. Electronic Colloquium on Computational Complexity. 1999. Modern Cryptography, Probabilistic Proofs and, TR97 - 058. pseudorandomnes sries, volume 17. New York: Springer.. Algorithms and Combinatorics Se Tools. 2001.. 2004.. Cambridge:
Cambridge University Press. Foundation of Cryptography Foundation of Cryptography, volume 1:, volume 2: Basic Basic Applications. 2008. Computational Complexity: A Conceptual Per-. Cambridge: Cambridge University Press. Hochbaum, D., ed. 1996.spec tive Hard Problems. Cambridge: Cambridge University Press.. Boston, MA: PWS.Approximation Algorithms for NP - 604 Karp, R. M., and V. Ramachandran. 1990. Parallel algorithms for shared-memory machines. In Handbook of Theoretical Computer Science plex i ty, edited by J. van Leeuwen. Cambridge, MA: MIT, volume A, Algorithms and Com Kearns, M.
J., and U.
V. Vazirani. 1994.Press/Elsevier.to Computational Learning Theory. Cambridge, MA: MITAn Introduction Kitaev, A., A. Shen, and M. Vyalyi. 2002.Press.tum Computation. Providence, RI: American Mathematical Classical and Quan Kushilevitz, E., and N. Nisan. 1996.Society.plexity. Cambridge: Cambridge University Press. Communication Com Ron, D. 2001. Property testing (a tutorial). In Randomized Computing, volume II. Dordrecht: Kluwer. Handbook on Shaltiel, R. 2002. Recent developments in explicit con struc-tions of extractors. Bulletin of the European Association Sipser, M.
1997.for Theoretical Computer Science Boston, MA: PWS.Introduction to the Theory of Computation77:67–95. . Strassen, V. 1990: Algebraic complexity theory. Inbook of Theoretical Computer Science, volume A, Hand-Algorithms and complexity bridge, MA: MIT Press/Elsevier., edited by J. van Leeuwen. Cam IV.21 Numerical Analysis Lloyd N. Trefethen 1 The Need for Numerical Computation Every one knows that when scientists and engineers need numerical answers to mathematical problems, they turn to computers.
Nevertheless, there is a widespread misconception about this process. The power of numbers has been extraordinary. It is often noted that the scientific revolution was set in motion when Galileo and others made it a principle that everything must be measured. Numerical measure-ments led to physical laws expressed mathematically, and, in the remarkable cycle whose fruits are all around us, finer measurements led to refined laws, which inturn led to better technology and still finer measurements.
The day has long since passed when an advance in the physical sciences could be achieved, or a significant engineering product developed, with out numerical mathematics. Computers certainly play a part in this story, yet there is a mis understanding about what their role is. Many people imagine that scientists and mathematicians generate formulas, and then, by inserting num-bers into these formulas, computers grind out the necessary results. The reality is nothing like this. What

IV. Branches of Mathematics

really goes on is a far more interesting process of exe-cution of algorithms. In most cases the job could not be done even in principle by formulas, for most mathe-mat ical problems cannot be solved by a finite sequence of elementary operations. What happens instead isthat fast algorithms quickly converge to “approximate” answers that are accurate to three or ten digits of pre-cision, or a hundred. For a scientific or engineering application, such an answer may be as good as exact. approximate solutions by an elementary example.
Sup-pose we have one polynomial of degree 4, We can illustrate the complexities of exact versus $p(z) = c0 + c1z + c2z2 + c3z3 + c4z4$, and another of degree 5, q(z) = d0 + d1 z + d2 z2 + d3 z3 + d4 z4 + d5 z5. It is well-known that there is an explicit formula that expresses the roots ofered by Ferrari around 1540), but no such formula forp in terms of radicals (discov- the roots of$q$(as shown by Ruffini and abel [VI.33](/part-06/niels-henrik-abel-18021829) more than 250 years later; seethe quintic [V.21](/part-05/the-insolubility-of-the-quintic) for more details).
Thus, in a cer-the insolubility of tain philosophical sense the root-finding problems forp and qare utterly different. Yet in practice they hardly differ at all. If a scientist or a mathematician wants toknow the roots of one of these polynomials, he or she will turn to a computer and get an answer to sixteen digits of precision in less than a millisecond. Did the computer use an explicit formula? In the case ofthe answer is certainly no, but what about$p$? Maybe, q, maybe not.
Most of the time, the user neither knows nor cares, and probably not one mathematician in a hundred could write down formulas for the roots ofp from memory. be solved in principle by a finite sequence of elementary operations, like finding the roots of Here are three more examples of problems that canp. (i) Linear equations: solve a system of tions inn unknowns. n linear equa- (ii) Linear programming: minimize a linear function ofn variables subject to m linear constraints. (iii) Traveling salesman problem: find the shortest tour betwee nn cities.
And here are five that, like finding the roots ofgenerally be solved in this manner.q, cannot (iv) Find an eigenvalue [I.3 §4.3](/part-01/fundamental-definitions) of an$n \times n matrix$. (v) Minimize a function of several variables.

IV.21. Numerical Analysis

(viii) Solve a partial differential equation (PDE).(vii) Solve an ordinary differential equation (ODE).(vi) Evaluate an integral. Can we conclude that (i)–(iii) will be easier than (iv)–(viii)in practice? Absolutely not. Problem (iii) is usually very hard indeed if Problems (vi) and (vii) are usually rather easy, at leastn is, say, in the hundreds or thousands. if the integral is in one dimension. Problems (i) and (iv) are of almost exactly the same difficulty: easy whenis small, like 100, and often very hard whenn is large, n like 1 000 000.
In fact, in these matters philosophy issuch a poor guide to practice that, for each of the three problems (i)–(iii), when ignores the exact solution and uses approximate (butn and m are large one often fast!) methods instead. Numerical analysis is the study of algorithms for solving the problems of continuous mathematics, by which we mean problems involving real or complex variables.
(This definition includes problems like lin-ear programming and the traveling salesman problem posed over the real numbers, but not their discrete ana-logues.) In the remainder of this article we shall review some of its main branches, past accomplishments, and possible future trends. 2 A Brief History Through out history, leading mathematicians have been involved with scientific applications, and in many cases this has led to the discovery of numerical algorithms still in use today. gauss [VI.26](/part-06/carl-friedrich-gauss-17771855), as usual, is an outstanding example.
Among many other contributions, he made crucial advances in least-squares data fitting (1795), systems of linear equations (1809), and numer-ical quadrature (1814), as well as inventing the fast fourier transform did not become widely known until its rediscovery by[III.26](/part-03/the-fast-fourier-transform) (1805), though the last Cooley and Tukey in 1965.Around 1900, the numerical side of mathematics started to become less conspicuous in the activities of research mathematicians.
This was a consequence of the growth of mathematics generally and of great advances in fields in which, for technical reasons, mathematical rigor had to be the heart of the matter. For example, many advances of the early twentieth century sprang from mathematicians’ new ability to reason rigorously about infinity, a subject relatively far from numerical calculation. was invented. From this moment numerical mathemat-A generation passed, and in the 1940 s the computer

605

ics began to explode, but now mainly in the hands of specialists. New journals were founded such as Mathematics of computation matik (1959). The revolution was sparked by hardware,(1943) and Numerische Ma the but it included mathematical and algorithmic develop-ments that had nothing to do with hardware.
In the halfcentury from the 1950 s, machines sped up by a factorof around 109, but so did the best algorithms known for some problems, generating a combined increase in speed of almost in com pre he ns i ble scale. Half a century on, numerical analysis has grown into one of the largest branches of mathematics, the specialty of thousands of researchers who publish in dozens of mathematical journals as well as applica-tions journals across the sciences and engineering.
Thanks to the efforts of these people going back many decades, and thanks to ever more powerful computers, we have reached a point where most of the classical mathematical problems of the physical sciences can be solved numerically to high accuracy. Most of the algorithms that make this possible were invented since 1950. the mathematical subject of Numerical analysis is built on a strong foundation: approximation theory.
This field encompasses classical questions of inter-polation, series expansions, and harmonic analysis[VI.25](/part-06/jean-baptiste-joseph-fourier-17681830), Gauss, and others; semiclassical problems of[IV.11](/part-04/harmonic-analysis) associated with newton [VI.14](/part-06/isaac-newton-16421727), fourier polynomial and rational minimax approximation asso-ciated with names such as chebyshev [VI.45](/part-06/pafnuty-chebyshev-18211894) and Bernstein;
and major newer topics, including splines, radial basis functions, and have space to address these subjects, but in almost wavelets [VII.3](/part-07/wavelets-and-applications). We shall not every area of numerical analysis it is a fact that, sooner or later, the discussion comes down to approximation theory. 3 Machine Arithmetic and Rounding Errors It is well-known that computers cannot represent realor complex numbers exactly. A quotient like 1/7 eval-uated on a computer, for example, will normally yield an in exact result.
(It would be different if we designed machines to work in base 7!) Computers approximate real numbers by a system ofin which each number is represented in a digital equiv - floating-point arithmetic, alent of scientific notation, so that the scale does not matter unless the number is so huge or tiny as to cause over flow or under flow. Floating-point arithmetic was invented by Konrad Zuse in Berlin in the 1930 s, and 606 by the end of the 1950 s it was standard across the computer industry. ferent arithmetic properties.
Then, in 1985, after years of discussion, the IEEE (Institute of Electrical and Elec-Until the 1980 s, different computers had widely diftronics Engineers) standard for binary floating-point arithmetic was adopted, or IEEE arithmetic for short. This standard has subsequently become nearly univer-sal on processors of many kinds. An IEEE (double precision) real number consists of a 64-bit word divided into 53 bits for a signed fraction in base 2 and 11 bits for a signed exponent.
Since 2 - 53 . pprox 1.1 . imes 10 - 16, IEEE numbers represent the numbers of the real line to a rel-ative accuracy of about 16 digits$. Since 2$±2 10 . pprox 10±308, this system works for numbers up to about 10 down to about 10-308.308 and course; they perform operations on them such asaddition, subtraction, multiplication, and division, and Computers do not merely represent numbers, of more complicated results are obtained from sequencesof these elementary operations.
In floating-point arithmetic, the computed result of each elementary opera-tion is almost exactly correct in the following sense: if “*” is one of these four operations in its ideal form and “.* ” is the same operation as realized on the computer, then for any floating-point numbers that there is no under flow or over flow, x and y , assumingx .*$y = (x^{*} y)(1 + ε)$.

Hereε is a very small quantity, no greater in abso- lute value than a number known as denoted byεmach, that measures the accuracy of the machine epsilon, computer. In the IEEE system,10-16. εmach = 2-53 . pprox 1.1 . imes is approximated by about 10 Thus, on a computer, the interval16 numbers. It is interest-[1,2], for example, ing to compare the fineness of this discretization with that of the discretizations of physics.
In a handful of solid or liquid or a balloonful of gas, the number of atoms or molecules in a line from one point to another is on the order of 108 (the cube root of Avogadro’s number). Such a system behaves enough like a continuumto justify our definitions of physical quantities such as density, pressure, stress, strain, and temperature. Computer arithmetic, however, is more than a million times finer than this.
Another comparison with physics concerns the precision to which fundamental constants are known, such as (roughly) 4 digits for the gravitational constant ment ary charge G, 7 digits for Planck’s constante, and 12 digits for the ratioh and the ele-\mu e/\mu B of IV. Branches of Mathematics the magnetic moment of the electron to the Bohr mag - neton. At present, almost nothing in physics is known to more than 12 or 13 digits of accuracy. Thus IEEE numbers are orders of magnitude more precise than any number in science.
(Of course, purely mathematical quantities likeπ are another matter.) closer to its ideal than is physics. It is a curious In two senses, then, floating-point arithmetic is far phenomenon that, nevertheless, it is floating-point arithmetic rather than the laws of physics that is widely regarded as an ugly and dangerous compromise. Numerical analysts themselves are partly to blame for this perception. In the 1950 s and 1960 s, the founding fathers of the field discovered that in exact arithmetic can be a source of danger, causing errors in results that “ought” to be right.
The source of such prob-lems is numerical instability: that is, the amplification of rounding errors from microscopic to macroscopic scale by certain modes of computation. These men, including and Henrici, took great pains to publicize the risks ofvon neumann [VI.91](/part - 06/john - von - neumann - 19031957), Wilkinson, Forsythe, care less reliance on machine arithmetic. These risks are very real, but the message was communicated all too successfully, leading to the current widespread impression that the main business of numerical analysis is coping with rounding errors.
In fact, the main business of numerical analysis is designing algorithms that converge quickly; rounding-error analysis, while often a part of the discussion, is rarely the central issue. If rounding errors vanished, 90% of numerical analysis would remain. 4 Numerical Linear Algebra Linear algebra became a standard topic in undergraduate mathematics curriculums in the 1950 s and 1960 s, and has remained there ever since. There are several reasons for this, but I think one is at the bottom of it:
the importance of linear algebra has exploded since the arrival of computers. The starting point of this subject is Gaussian elimination inn unknowns using on the order of, a procedure that can solve n linear equationsn3 arithmetic operations. Equivalently, it solves equations of the form Ax = b, where A is an n . imes n matrix and x and b are col- umn vectors of sizeon computers around the world almost every time an. Gaussian elimination is invoked system of linear equations is solved. Even ifn is as large as 1000, the time required is well under a sec-ond on a typical 2008 desktop machine.
The idea of IV.21. Numerical Analysis elimination was first discovered by Chinese scholars about 2000 years ago, and more recent contributors include lagrange [VI.22](/part - 06/joseph - louis - lagrange - 17361813), Gauss, and jacobi [VI.35](/part - 06/carl - gustav - jacob - jacobi - 18041851). The modern way of describing such algorithms, how-ever, was apparently introduced as late as the 1930 s. Suppose that, say, tr acted from the second row.
This operation can beαtimes the first row of A is sub- interpreted as the multiplication of A on the left by the lower-triangular matrix with the additional nonzero entry M1 consisting of the identitym = −α. Further analogous row operations correspond to further multi-plications on the left by lower-triangular matrices21 M .j

Ifthen we havek steps convert MA =AUto an upper-triangular matrix with M = M · · · M M , or, upon U,(k2)1

setting$L = M^{-1}$, A = LU.

Here with all its diagonal entries equal to 1. Since L is unit lower-triangular, that is, lower-triangular U rep- resents the target structure and tions carried out to get there, we can say that Gaussian L encodes the opera- elimination is a process of lower-triangular uppertriangular ization Many other algorithms of numerical linear algebra. are also based on writing a matrix as a product of matri-ces that have special properties. To borrow a phrase from biology, we may say that this field has a central dogma: algorithms←→ matrix factorizations.
In this framework we can quickly describe the next algorithm that needs to be considered. Not every matrix has an LU factorization; a 2. imes 2 counterexample is the matrix

$A = 01 10$.

Soon after computers came into use it was observed that even for matrices that do have LU factorizations, the pure form of Gaussian elimination is unstable, amplifying rounding errors by potentially large amounts. Stability can be achieved by interchanging rows during the elimination in order to bring maxi-mal entries to the diagonal, a process known as pivoting. Since pivoting acts on rows, it again corresponds to a multiplication of The matrix factorization corresponding to Gaussian A by other matrices on the left. elimination with pivoting is

$P A = LU$,

where and P Uis a permutation matrix, i.e., the identity matrix is upper-triangular, L is unit lower-triangular,

607

with permuted rows. If the permutations are chosen to bring the largest entry below the diagonal in column$k$ to the then L(k, k)has the additional property position before the kth elimination step,| | ⩽ 1 for all iij$and$ j.

The discovery of pivoting came quickly, but its theoretical analysis has proved astonishingly hard. Inpractice, pivoting makes Gaussian elimination almost perfectly stable, and it is routinely done by almost all computer programs that need to solve linear systems of equations. Yet it was realized in around 1960 by Wilkinson and others that for certain exceptional matrices, Gaussian elimination is still unstable, even with pivoting. The lack of an explanation of this discrepancy represents an embarrassing gap at the heart of numerical analysis.
Experiments suggest that the frac-tion of matrices (for example, among random matrices with independent normally distributed entries) for which Gaussian elimination amplifies rounding errors by a factor greater thanρn1^/2 is in a certain sense expo- nent i ally small as a function ofρ as ρ → $\infty$, where n is the dimension, but a theorem to this effect has never been proved. Meanwhile, beginning in the late 1950 s, the field of numerical linear algebra expanded in another direction:
the use of algorithms based on orthogonal [III.50 §3](/part-03/linear-operators-and-their-properties) or with unitary$Q^{-}1 = Q$[III.50 §3](/part-03/linear-operators-and-their-properties) matrices, that is, real matrices T or complex ones with Q^-1 = Q^*, where Q^* denotes the conjugate transpose. The starting point of such developments is the idea of A is an m . imes  n matrix with m ⩾ n, a QR factorization QR factorization. If$of$ A is a product A = QR,

where angular. One can interpret this formula as a matrix ex-Q has orthonormal columns and R is upper-tri- pression of the familiar idea of on al ization, in which the columns Gram–Schmidt orthog-$q1$, q2, . . . of Q are determined one after another. These column opera-tions correspond to multiplication of A on the right by elementary upper-triangular matrices. One could say that the Gram–Schmidt algorithm aims for Q and gets R as a by-product, and is thus a process of triangular orthogonalizati on showed in 1958 that a dual strategy of.
A big event was when householder orthogonal triangularizati on is more effective for many purposes. In this approach, by applying a succession of elementary matrix operations each of which reflects Rm across a hyperplane, one reducesvia orthogonal operations: one aims at A to upper-triangular form R and gets Q

608

as a by-product. The Householder method turns out tobe more stable numerically, because orthogonal operations preserve norms and thus do not amplify the rounding errors introduced at each step. From the QR factorization sprang a rich collection of linear algebra algorithms in the 1960 s. The QR factorization can be used by itself to solve leastsquares problems and construct orthonormal bases. More remarkable is its use as a step in other algorithms.
In particular, one of the central problems of numerical linear algebra is the determination of the eigenvalues and eigenvectors of a square matrixplete set of eigenvectors, then by forming a matrix A. If A has a com-X whose columns are these eigenvectors and a diagonal matrix eigenvalues, we obtain D whose diagonal entries are the corresponding AX = XD,

and hence, since X is nonsingular, A = XDX-1,

the which eigenvalue decomposition A is hermitian[III.50 §3](/part-03/linear-operators-and-their-properties), a complete set of. In the special case in orthonormal eigenvectors always exists, giving

$A = QDQ^{*}$,

where put ing these factorizations was developed in the early Q is unitary. The standard algorithm for com- 1960 s by Francis, Kublanovskaya, and Wilkinson: the QR algorithm. Because polynomials of degree 5 or more cannot be solved by a formula, we know that eigen-values cannot generally be computed in closed form. The QR algorithm is therefore necessarily an iterative one, involving a sequence of QR factorizations that is in principle infinite. Nevertheless, its convergence is extraordinarily rapid.
In the symmetric case, for a typical matrix A, the QR algorithm converges cubically, in the sense that at each step the number of cor-rect digits in one of the eigenvalue–eigenvector pairs approximately triples. The QR algorithm is one of the great triumphs of numerical analysis, and its impact through widely used software products has been enormous. Algorithms and analysis based on it led in the 1960 s to computer codes in Algol and Fortran and later to the software library EISPACK (“Eigensystem Package”) and its descendant LAPACK.
The same methods have also been incorporated in general-purpose numerical libraries such as the NAG, IMSL, andand in problem-solving environments such as MAT-Numerical Recipes collections, LAB, Maple, and Mathematica. These developments

IV. Branches of Mathematics

have been so successful that the computation of matrix eigenvalues long ago became a “black box” operation for virtually every scientist, with nobody but a few spe-cia lists knowing the details of how it is done. A curious related story is that EISPACK’s relative LINPACK for solving linear systems of equations took on an unex-pected function: it became the original basis for the benchmarks that all computer manufacturers run totest the speed of their computers.
If a supercomputer is lucky enough to make the TOP500 list, updated twicea year since 1993, it is because of its prowess in solving certain matrix problems Ax = b of dimensions ranging from 100 into the millions. ematicians, but the development of numerical linear algebra has also brought its younger cousin onto the The eigenvalue decomposition is familiar to all math scene: the singular value decomposition (SVD).
The SVD was discovered by Beltrami, sylvester [VI.42](/part-06/james-joseph-sylvester-18141897) in the late nineteenth century, and jordan [VI.52](/part-06/camille-jordan-18381922), and made famous by Golub and other numerical analysts beginning in around 1965. If A is an m . imes n matrix withm ⩾ n, an SVD of A is a factorization A = UΣV*, where U is m . imes n with orthonormal columns, V is n . imes n and unitary, andσ ⩾ σ ⩾ · · · ⩾Σ is diagonal with diagonal entriesσ ⩾ 0. One could compute the SVD by relating it to the eigenvalue problems forand1 A*A2, but this proves numerically unstable;
a bet- n AA*ter approach is to use a variant of the QR algorithm that does not squaredard route to determining the A. Computing the SVD is the stan - norm [III.62](/part - 03/normed - spaces - and - banach - spaces) A = σ (here norm of the inverse· is the hilbert space A - 1 = 1/σ[III.37](/part - 03/bayesian - analysis) or “2” norm), thein the case where$A^{1}$ is square and nonsingular, or their product, known asthe condition number,$nκ(A) = A \sum A^{-1} = σ^{1}/σ^{n}$.

It is also a step in an extraordinary variety of fur-ther computational problems including rank-deficient least-squares, computation of ranges and nullspaces, determination of ranks, “total least-squares,” low-rank approximation, and determination of angles between subspaces. All the discussion above concerns “classical” numerical linear algebra, born in the period 1950–75. The ensuing quarter-century brought in a whole new set of tools: methods for large-scale problems based on Krylov subspace iterations is as follows. Suppose a linear algebra problem is given. The idea of these iterations

IV.21. Numerical Analysis

that involves a matrix of large dimension, say$n /$

1000. The solution may be characterized as the vectorx \in Rnthat satisfies a certain variational property such as minimizing symmetric positive definite) or being a stationary point12 x TAx -x Tb (for solving Ax = b if A is ofric). Now if(x TAx)/(x KTx)is a(for so lvingk-dimensional subspace of Ax = . ambda x if A is symmet-Rn with ka tion al problem much more quickly in that subspace.0 n, then it may be possible to solve the same vari - k The magical choice of Kk is a Krylov subspace Kk(A, q) = span(q, Aq, . . .
, (Ak)-1 q) for an initial vector ing connections with approximation theory, solutio nsq. For reasons that have fascinat- in these subspaces often converge very rapidly to the exact solution in Rn as k increases, if the eigenvalues of Asible to solve a matrix problem involving 10 are favorably distributed. For example, it is often pos - 5 unknowns to ten-digit precision in just a few hundred iterations. The speedup compared with the classical algorithms may be a factor of thousands.
gate gradient and Lanczos iterations published in 1952, but in those years computers were not powerful enough Krylov subspace iterations originated with the conju to solve problems of a large enough scale for the meth-ods to be competitive. They took off in the 1970 s with the work of Reid and Paige and especially van der Vorst and Meijerink, who made famous the idea of preconditioning. In preconditioning a system Ax = b, one replaces it by a mathematically equivalent system suchas

$MAx = Mb$

for some nonsingular matrix the new problem involving MAMmay have favorably dis-. If M is well chosen, tributed eigenvalues and a Krylov subspace iteration may solve it quickly. Since the 1970 s, preconditioned matrix iterations have emerged as an indispensable tool of com put a-tional science.
As one indication of their prominence we may note that in 2001, Thomson ISI announced that the most heavily cited article in all of mathematics in the 1990 s was the 1989 paper by van der Vorst introducing Bi-CGStab, a generalization of conjugate gradients for nonsymmetric matrices. Finally, we must mention the biggest unsolved problem in numerical analysis. Can an arbitrary A be inverted in O(n^α) operations for everyn. imes nα >matrix2?
(The problems of solving a system$Ax = b \text{or com}-$ puting a matrix product elimination hasα = 3, and the exponent shrinks as AB are equivalent.) Gaussian

609

far as 2 algorithms published by Coppersmith and Winograd in.376 for certain recursive (though impractical)

1990. Is there a “fast matrix inverse” in store for us? 5 Numerical Solution of Differential Equations Long before much attention was paid to linear alge-bra, mathematicians developed numerical methods to solve problems of analysis. The problem of numeri-cal integration or quadrature goes back to Gauss and newton [VI.14](/part-06/isaac-newton-16421727), and even to archimedes [VI.3](/part-06/archimedes-ca).
The classic quadrature formulas are derived from the ideaof interpolating data atn + 1 points by a polynomial of degree Equally spaced interpolation points give then, then integrating the polynomial exactly. Newton Cotes formulas diverge at a rate as high as 2, which are useful for small degrees butn as n → . nfty: the Runge phenomenon. If the points are chosen optimally, then the result isand is numerically stable. It turns out that these opti-Gauss quadrature, which converges rapidly mal points are roots of Legendre polynomials, which are clustered near the endpoints.
(A proof is sketched in special functions poses is Clenshaw–Curtis quadrature[III.85](/part-03/special-functions).) Equally good for most pur-, where the interpolation points become cos$(jπ/n)$, 0 ⩽ j ⩽ n. This quadrature method is also stable and rapidly conver-gent, and unlike Gauss quadrature can be executed in O(n The explanation of why clustered points are necessary. og n) operations by the fast Fourier transform. for effective quadrature rules is related to the subject of potential theory. get attention: the solution of ODEs.
Thelas Around 1850 another problem of analysis began toare based on polynomial interpolation in equally Adams formuspaced points, which in practice typically number fewer than ten. These were the first of what are now called multistep methods The idea here is that for an initial value problem for the numerical solution of ODEs.u^ =f (t, u)time step with independent variableΔt >0 and consider a finite set of time values$t > 0$, we pick a smal ltn = nΔt, n ⩾ 0.

We then replace the ODE by an algebraic approx i-mation that enables us to calculate a succession of approximate values

$v^{n} \approx u(t^{n})$, n ⩾ 0.

(The superscript here is just a superscript, not a power.)The simplest such approximate formula, going back to euler [VI.19](/part-06/leonhard-euler-17071783), is

(vn)+1 = vn + . eltatf (tn, vn)$, 610 or$, using the abbreviation$f^{n} = f (t^{n}$, vn), (vn)+1 = vn + . elta tfn.

Both the ODE itself and its numerical approximation may involve one equation or many, in which case u(t, x) and vn become vectors of an appropriate dimension. The Adams formulas are higher-order gen-eral iz at i ons of Euler’s formula that are much more efficient at generating accurate solutions. For example, the fourth-order Adams–Bashforth formula is (vn)+1 = vn + {}241 . elta t(55 fn - 59(fn)-1 + 37(fn)-2 - 9(fn)-3). The term “fourth-order” reflects a new element inthe numerical treatment of problems of analysis: the appearance of questions of convergence as$\Delta t \to 0$.
The formula above is of fourth order in the sense that itwill normally converge at the rate O((. elta t)4). The orders employed in practice are most often in the range 3–6, enabling excellent accuracy for all kinds of com put a-tions, typically in the range of 3–10 digits, and higherorder formulas are occasionally used when still more accuracy is needed.
sis literature is to speak not of the Most unfortunately, the habit in the numerical analy-convergence of these magnificently efficient methods, but of their more precisely their discretization or truncation error error, or as distinct from rounding error. This ubiquitous lan-guage of error analysis is dismal in tone, but seems ineradicable. At the turn of the twentieth century, the second great class of ODE algorithms, known asone-step methods, was developed by Runge, Heun, and Runge–Kutta or Kutta.
For example, here are the formulas of the famous fourth-order Runge–Kutta method, which advance a numerical solution (again scalar or system) from timesteptn to (tn)+1 with the aid of four evaluations of the function$f$:

a = Δtf (tn, vn), b = . elta tf (tn + 1 2. elta t$, vn + 1 2 a)$, c = . elta tf (tn + 1 2. elta t$, vn + 1 2 b)$, d = . elta tf (tn + . elta t$, vn + c)$, (vn)+1 = vn + 1 6(a + 2 b + 2 c + d).

Runge–Kutta methods tend to be easier to implement but some times harder to analyze than multistep for-mulas. For example, for anys, it is a trivial matter to derive the coefficients of the formula, which has order of accuracy$s$-step Adams–Bashforth$p = s$. For Runge Kutta methods, by contrast, there is no simple relation-

IV. Branches of Mathematics

ship between the number of “stages” (i.e., function eval-ua tions per step) and the attainable order of accuracy. The classical methods with Kutta in 1901 and have orders =p 1=,2 s, but it was not until,3,4 were known to 1963 that it was proved thatto achieve orderp = 5. The analysis of such prob le mss = 6 stages are required involves beautiful mathematics from graph theory and other areas, and a key figure in this area since the 1960 s has been John But cher. For order smal numbers of stages ares = 7, 9, p11, while for = 6, 7, 8 the mini - p > 8 exact minima are not known.
Fortunately, these higher orders are rarely needed for practical purposes. When computers began to be used to solve differential equations after World War II, a phenomenon ofthe greatest practical importance appeared: once again, numerical instability to the unbounded amplification of local errors by a. As before, this phrase refers computational process, but now the dominant local errors are usually those of discretization rather than rounding.
Instability typically manifests itself as an oscillatory error in the computed solution that blows up exponentially as more numerical steps are taken. One mathematician concerned with this effect was Germund Dahlquist. Dahlquist saw that the phenomenon could be analyzed with great power and generality, and some people regard the appearance of his 1956 paper as one of the events marking the birth of modern numerical analysis. This landmark paper intro-duced what might be called the fundamental theorem of numerical analysis: consistency$+ stability = convergence$.
The theory is based on precise definitions of these three notions along the following lines.property that the discrete formula has locally positive Consistency is the order of accuracy and thus models the right ODE.bility is the property that errors introduced at one time Stastep cannot grow unboundedly at later times.gence is the property that asΔt \to  0, in the absence Conver- of rounding errors, the numerical solution convergesto the correct result.
Before Dahlquist’s paper, the idea of an equivalence of stability and convergence was per-haps in the air in the sense that practitioners realized that if a numerical scheme was not unstable, then it would probably give a good approximation to the right answer. His theory gave rigorous form to that idea fora wide class of numerical methods. As computer methods for ODEs were being developed, the same was happening for the much bigger

IV.21. Numerical Analysis

subject of PDEs. Discrete numerical methods for solv-ing PDEs had been invented around 1910 by Richardson for applications in stress analysis and meteo-rology, and further developed by Southwell; in 1928 there was also a theoretical paper on finite-difference methods by courant [VI.83](/part-06/richard-courant-18881972), Friedrichs, and Lewy. But although the Courant–Friedrichs–Lewy work later became famous, the impact of these ideas before com-puters came along was limited. After that point the subject developed quickly.
Particularly influential inthe early years was the group of researchers around von Neumann at the Los Alamos laboratory, including the young Peter Lax. discovered that some numerical methods for PDEs were Just as for ODEs, von Neumann and his colleagues subject to catastrophic instabilities. For example, to solve the linear wave equation$u = u \text{numerically we}$ may pick space and time steps grid,. elta tx andx . elta t for a regularxj = j. elta x, tn = nΔt, j, n ⩾ 0,

and replace the PDE by algebraic formulas that com-pute a succession of approximate values:

(vj)n . pprox u(tn, xj), j$, n ⩾ 0.$

A well-known discretization for this purpose is the Wendroff formula: Lax(vj()n)+1 = (vj)n +1 2λ((vj()n)+1 -(vj()n)-1)+1 2λ2((vj()n)+1 - 2(vj)n +(vj()n)-1)$, whereλ = \Delta t/\Delta x$, which can be generalized to non- linear systems of hyperbolic conservation laws in one dimension. For$u = u$, if . ambda is held fixed at a value less than or equal to 1, the method will converge to the cor-rect solution asΔtx,Δtx \to 0 (ignoring rounding errors). If Von Neumann and others realized that the presence or. ambda is greater than 1, on the other hand, it will explode.
absence of such instabilities could be tested, at least for linear constant-coefficient problems, by discrete fourier analysis sis.” Experience indicated that, as a practical matter, a[III.27](/part - 03/the - fourier - transform) in$x$: “von Neumann analymethod would succeed if it was not unstable. A theory soon appeared that gave rigor to this observation: the Lax equivalence theorem, published by Lax and Richtmyer in 1956, the same year as Dahlquist’s paper.
Many details were different—this theory was restricted to linear equations where as Dahlquist’s theory for ODEs also applied to nonlinear ones—but broadly speaking thenew result followed the same pattern of equating convergence to consistency plus stability. Mathematically, the key point was the uniform boundedness principle. 611 Lax–Wendroff formula and its relatives have grown into a breathtakingly powerful subject known as In the half-century since von Neumann died, the computational fluid dynamics and nonlinear equations in one space dimension soon.
Early treatments of linear moved to two dimensions and eventually to three. Itis now a routine matter to solve problems involving millions of variables on computational grids with hundreds of points in each of three directions. The equa-tions are linear or nonlinear; the grids are uniform or nonuniform, often adaptively refined to give special attention to boundary layers and other fast-changing features; the applications are every where. Numerical methods were used first to model airfoils, then whole wings, then whole aircraft.
Engineers still use wind tunnels, but they rely more on computations. Many of these successes have been facilitated by another numerical technology for solving PDEs that emerged in the 1960 s from diverse roots in engineering and mathematics: finite elements. Instead of approximating a differential operator by a difference quo - tient, finite-element methods approximate the solution itself by functionsf that can be broken up into simple pieces.
For instance, one might partition the domain off into elementary sets such as triangles or tetrahedra and insist that the restriction ofeach piece is a polynomial of small degree. The solu - f to tion is obtained by solving a variational form of the PDE within the corresponding finite-dimensional sub - space, and there is often a guarantee that the computed solution is optimal within that subspace. Finite-element methods have taken advantage of tools of functional analysis to develop to a very mature state.
These meth-ods are known for their flexibility in handling complicated geometries, and in particular they are entirely dominant in applications in structural mechanics and civil engineering. The number of books and articles that have been published about finite-element methods is in excess of 10 000. PDEs, what aspect of the current state of the art would most surprise Richardson or Courant, Friedrichs, and In the vast and mature field of numerical solution of Lewy? I think it is the universal dependence on exotic algorithms of linear algebra.
The solution of a large-scale PDE problem in three dimensions may require a system of a million equations to be solved at each time step. This may be achieved by a GMRES matrix iteration that utilizes a finite - difference preconditioner imple-mented by a Bi-CGStab iteration relying on another multigrid preconditioner.
Such stacking of tools was 612 surely not imagined by the early computer pioneers. The need for it ultimately traces to numerical instability, for as Crank and Nicolson first noted in 1947, the crucial tool for combating instability is the use of implicit formulas the new time step, which couple together unknowns att+, and it is in implementing this coupling that solutions of systems of equations are required. n1 Here are some examples that illustrate the successful reliance of today’s science and engineering on the numerical solution of PDEs:
chemistry (the schrödinger equationics (the equations of elasticity); weather prediction (the[III.83](/part - 03/the - schrdinger - equation)); structural me ch an geostrophic equations); turbine design (the navierstokes equations equation); telecommunicati ons ([III.23](/part - 03/the - euler - and - navierstokes - equations)); acoustics (the helmholtz maxwell’s equations [IV.13 §1.1](/part - 04/general - relativity - and - the - einstein - equations)); cosmology (the Einstein equations); oil dis - covery (the migration equations); groundwater remediation (Darcy’s law);
integrated circuit design (the drift diffusion equations); tsunami modeling (the shallowwater equations); optical fibers (the equations [III.49](/part - 03/linear - and - nonlinear - waves - and - solitons)); image enhancement (the Perona–nonlinear wave Malik equation); metallurgy (the Cahn–Hilliard equa - tion); pricing financial options (the black–scholes equation [VII.9 §2](/part - 07/the - mathematics - of - money)).
6 Numerical Optimization The third great branch of numerical analysis is opti-mization, that is, the minimization of functions of several variables and the closely related problem ofsolution of nonlinear systems of equations. The development of optimization has been some what indepen-dent of that of the rest of numerical analysis, carried forward in part by a community of scholars with close links to operations research and economics. achieve an extremum at a point of zero derivative, or at Calculus students learn that a smooth function may a boundary.
The same two possibilities characterize thetwo big strands of the field of optimization. At one end there are problems of finding interior zeros and min-ima of unconstrained nonlinear functions by methods related to multivariate calculus. At the other are prob-lems of linear programming, where the function to be minimized is linear and therefore easy to understand, and all the challenge is in the boundary constraints. ject. Newton introduced the idea of approximating Unconstrained nonlinear optimization is an old sub functions by the first few terms of what we now call

IV. Branches of Mathematics

their Taylor series; indeed, Arnol’d has argued that Tay-lor series were Newton’s “main mathematical discovery.” To find a zerox, every one knows the idea ofx* of a function Newton’s method F of a real variable: at the k Fth step, given an estimate^ (x(k))to define a linear approximation from which tox(k) . pprox  x*, use the derivative derive a better estimatex((k+1)): x((k+1)) = x(k) - F(x(k))/F (x(k)).
Newton (1669) and Raphson (1690) applied this ideato polynomials, and Simpson (1740) generalized it to other functions In today’s language, for a system of F and to systems of two equations.n equations in n unknowns, we regard at a pointx(k) \in  Rn is the F as annn. imes -vector whose derivativen Jacobi an matrix with entries $J^{i}j (x^{(}k)) = \partial x\partial F^{i} (x^{(}k))$, 1 ⩽ i, j ⩽ n.j

This matrix defines a linear approximation tois accurate for$x \approx x^{(}k)$. Newton’s method then takes F(x) that the matrix form x((k+1)) = x(k) - (J(x(k)))-1 F(x(k)), which in practice means that to getx((k+1)) from x(k), we solve a linear system of equations: J(x(k))(x((k+1)) - x(k)) = −F(x(k)). As long aslar atx* and the initial guess is good enough, the J is Lipschitz continuous and non sin gu- convergence of this iteration is quadratic: x((k+1)) - x* = O( x(k) - (x*)2).
(1) Students often think it might be a good idea to develop formulas to enhance the exponent in this estimate to 3 or 4. However, this is an illusion. Taking two steps ata time of a quadratically convergent algorithm yields a quartically convergent one, so the difference in effi-ciency between quadratic and quartic is at best a constant factor. The same goes if the exponent 2, 3, or4 is replaced by any other number greater than 1.
The true distinction is between all of these algorithms that converge superlinearly, of which Newton’s method is the prototype, and those that converge geometrically, where the exponent is just 1.linearly or small step from solving a system of equations to min-imizing a scalar function From the point of view of multivariate calculus, it is af of a variable x \in Rn: to find a (local) minimum, we seek a zero of the gradient$g(x) = ∇f (x)$, an n-vector. The derivative of g is the Jacobi an matrix known as the Hessian of$f$, with entries Hij (x(k)) = ∂x∂i 2∂xfj (x(k))$, 1 ⩽ i$, j ⩽ n,

IV.21. Numerical Analysis

and one may utilize it just as before in a Newton itera-tion to find a zero ofg(x), the new feature being that a Hessian is always symmetric. finding zeros were already established, the arrival ofcomputers created a new field of numerical optimiza-Though the Newton formulas for minimization and tion. One of the obstacles quickly encountered was that Newton’s method often fails if the initial guess is not good. This problem has been comprehensively addressed both practically and theoretically by the algorithmic technologies known as trust regions.
line searches and For problems with more than a few variables, it also quickly became clear that the cost of evaluating Jaco-bians or Hessians at every step could be exorbitant. Faster methods were needed that might make use ofinexact Jacobians or Hessians and/or in exact solutions of the associated linear equations, while still achieving superlinear convergence.
An early breakthrough of this kind was the discovery of quasi-Newton methods Powell, in which partial information is used to gen-in the 1960 s by Broyden, David on, Fletcher, and erate steadily improving estimates of the true Jacobi an or Hessian or its matrix factors. An illustration of the urgency of this subject at the time is the fact that in 1970 the optimal rank-two symmetric positive-definite quasi-Newton updating formula was published independently by no fewer than four different authors, namely Broyden, Fletcher, Goldfarb, and Shanno;
their discovery has been known ever since as the BFGS formula problems has increased exponentially, new ideas have. In subsequent years, as the scale of tractable also become important, including automatic differentiation puted functions to be determined automatically: the, a technology that enables derivatives of com computer program itself is “differentiated,” so that aswell as producing numerical outputs it also produces their derivatives.
The idea of automatic differentiation is an old one, but for various reasons, partly related toadvances in sparse linear algebra and to the development of “reverse mode” formulations, it did not become fully practical until the work of Bischof, Carle, and Griewank in the 1990 s. easy, but they are not typical; the true depth of this field is revealed by the methods that have been devel-Unconstrained optimization problems are relatively oped for dealing with constraints. Suppose a function$f$:
Rn \to R is to be minimized subject to certain equal- ity constraint sc (x) = 0 and inequality constraints jdj(x) ⩾ 0, where {cj} and {dj} are also functions from 613 Rn to R. Even the problem of stating local optimality conditions for solutions to such problems is nontrivial, a matter involving lagrange multipliers [III.64](/part - 03/optimization - and - lagrange - multipliers) and a distinction between active and in active constraints. This problem was solved by what are now known as the1951 and also twelve years earlier, it was subsequently KKT conditions, introduced by Kuhn and Tucker in
realized, by Karush. Development of algorithms for constrained nonlinear optimization continues to be an active research topic today. strand of numerical optimization, linear programming. This subject was born in the 1930 s and 1940 s with The problem of constraints brings us to the other Kantorovich in the Soviet Union and Dantzig in the United States. As an out growth of his work for the U.S. Air Force in the war, Dantzig invented in 1947 the famous simplex algorithm [III.84](/part - 03/the - simplex - algorithm) for solving linear programs.
A linear program is nothing more than a problem of minimizing a linear function ofables subject tom linear equality and/or inequalityn vari - constraints. How can this be a challenge? One answer isthatm and n may be large. Large-scale problems may arise through discretization of continuous problems and also in their own right. A famous early example was Leontiev’s theory of input–output models in economics, which won him the Nobel Prize in 1973.
Even inthe 1970 s the Soviet Union used an input–output computer model involving thousands of variables as a tool for planning the economy. The simplex algorithm made medium- and largescale linear programming problems tractable. Such a problem is defined by its objective function, the function set of vectorsf (x) to be minimized, and itsx \in Rn that satisfy all the constraints. For feasible region, the a linear program the feasible region is a polyhedron, a closed domain bounded by hyperplanes, and the optimal value ofthe vertex points.
(A point is called af is guaranteed to be attained at one of vertex if it is the unique solution of some subset of the equations that define the constraints.) The simplex algorithm proceeds by moving systematically downhill from one ver-tex to another until an optimal point is reached. All of the iterates lie on the boundary of the feasible region. by Narendra Karmarkar at AT&T Bell Laboratories. Kar-markar showed that one could some times do much In 1984, an upheaval occurred in this field, triggered better than the simplex algorithm by working in the interior of the feasible region instead.
Once a connection was shown between Karmarkar’s method and the logarithmic barrier methods popularized by Fiacco and 614 Mc Cormick in the 1960 s, new interior methods for lin-ear programming were devised by applying techniques previously viewed as suitable only for nonlinear prob - lems. The crucial idea of working in tandem with a pair of primal and dual problems led to today’s powerful primal–dual methods, which can solve continuous optimization problems with millions of variables and con - strain ts.
Starting with Karmarkar’s work, not only has the field of linear programming changed completely, but the linear and nonlinear sides of optimization are seen today as closely related rather than essentially different. 7 The Future Numerical analysis sprang from mathematics; then it spawned the field of computer science. When universities began to found computer science departments inthe 1960 s, numerical analysts were often in the lead. Now, two generations later, most of them are to be found in mathematics departments. What happened?
A part of the answer is that numerical analysts deal with continuous mathematical problems, where as computer scientists prefer discrete ones, and it is remarkable how wide a gap this can be. Nevertheless, the computer science side of numerical analysis is of crucial importance, and I would like to end with a prediction that emphasizes this aspect of the subject. Traditionally one might think of a numerical algorithm as a cut - and-dried procedure, a loop of some kind to be executed until a well-defined termination criterion is satisfied. For some computations this picture is accurate.
On the other hand, beginning with the work of de Boor, Lyness, Rice and others in the 1960 s, a less deterministic kind of numerical computing began to appear: adaptive algorithms. In an adaptive quadrature program of the simplest kind, two estimates ofthe integral are calculated on each portion of a certain mesh and then compared to produce an estimate ofthe local error. Based on this estimate, the mesh may then be refined locally to improve the accuracy.
This process is carried out iteratively until a final answer is obtained that aims to be accurate to a tolerance spec-ified in advance by the user. Most such computations come with no guarantee of accuracy, but an exciting on going development is the advance of more sophis-ti cated techniques of a posteriori error control that some times do provide guarantees. When these are com-bined with techniques of interval arithmetic, there is even the prospect of accuracy guaranteed with respect to rounding as well as discretization error. IV. Branches of Mathematics adaptive;
then programs for ODEs did as well. For PDEs, the move to adaptive programs is happening First, computer programs for quadrature became on a longer timescale. More recently there have been related developments in the computation of Fourier transforms, optimization, and large-scale numerical linear algebra, and some of the new algorithms adapt to the computer architecture as well as the mathematical problem.
In a world where several algorithms are known for solving every problem, we increasingly find that the most robust computer program will be one that has diverse capabilities at its disposal and deploys them adaptively on the fly. In other words, numeri-cal computation is increasingly embedded in intelligent control loops. I believe this process will continue, justas has happened in so many other areas of technology, removing scientists further from the details of their computations but offering steadily growing power inexchange.
I expect that most of the numerical computer programs of 2050 will be 99% intelligent “wrapper” and just 1% actual “algorithm,” if such a distinction makes sense. Hardly anyone will know how they work, but they will be extraordinarily powerful and reliable, and will often deliver results of guaranteed accuracy. of the fundamental distinctions in mathematics is be-This story will have a mathematical corollary. One tween linear problems, which can be solved in one step, and nonlinear ones, which usually require iteration.
A related distinction is between forward problems(one step) and inverse problems (iteration). As numerical algorithms are increasingly embedded in intelligent control loops, almost every problem will be handled by iteration, regard less of its philosophical status. Problems of algebra will be solved by methods of analy - sis; and between linear and nonlinear, or forward and inverse, the distinctions will fade. 8 Appendix:
Some Major Numerical Algorithms The list in table 1 attempts to identify some of the most significant algorithmic (as opposed to theoret - ical) developments in the history of numerical analysis. In each case some of the key early figures are cited, more or less chronologically, and a key early date is given. Of course, any brief sketch of history like this must be an over simplification. Distressing omissions of names occur through out the list, including many early contributors in fields such as finite elements, precondi - tion ing, and automatic differentiation, as well as more IV.22.
Set Theory Table 1 Some algorithmic developments in the history of numerical analysis. Year Development 16\,711\,795\,263 Gaussian elimination Newton’s method Least-squares fitting 18141855 Gauss quadrature Adams ODE formulas 18951910 Runge–Kutta ODE formulas Finite differences for PDE 19361943 Floating-point arithmetic Finite elements for PDE 19461947 Splines Monte Carlo simulation 19471952 Simplex algorithm Lanczos and conjugate gradient iterations 19521954 Stiff ODE solvers Fortran 19581959 Orthogonal linear algebra Quasi-Newton iterations 19611965 QR algorithm for eigenvalues Fast Fourier
transform 19711971 Spectral methods for Pde radial basis functions 19731976 Multigrid iterations EISPACK, LINPACK, LAPACK 19761977 Nonsymmetric Krylov iterations Preconditioned matrix iterations 19771977 Matlab ieee arithmetic 19821984 Wavelets Interior methods in optimization 19871991 Fast multipole method Automatic differentiation than half of the authors of the EISPACK, LINPACK, and LAPACK libraries. Even the dates can be questioned;
the fast Fourier transform is listed as 1965, for example, since that is the year of the paper that brought it to the world’s attention, though Gauss made the same dis - covery 160 years earlier. Nor should one imagine that the years from 1991 to the present have been a blank!No doubt in the future we shall identify developments from this period that deserve a place in the table. Further Reading Ciarlet, P. G. 1978.Problems. Amsterdam: North - Holland. The Finite Element Method for Elliptic Golub, G. H., and C. F. Van Loan. 1996.3 rd edn. Baltimore, MD:
Johns Hopkins University Press. Matrix Computations, Hairer, E., S. P. Nørsett (for volume I), and G. Wanner. 1993,1996. Solving Ordinary Differential Equations, volumes I and II. New York: Springer. 615 Key early figures Liu, Lagrange, Gauss, Jacobi Newton, Raphson, Simpson Gauss, Legendre Gauss, Jacobi, Christoffel, Stieltjes Euler, Adams, Bashforth Runge, Heun, Kutta Richardson, Southwell, Courant, von Neumann, Lax Torres y Quevedo, Zuse, Turing Courant, Feng, Argyris, Clough Schoenberg, de Casteljau, Bezier, de Boor Ulam, von Neumann, Metropolis Kantorovich, Dantzig Lanczos, Hestenes,
Stiefel Curtiss, Hirschfelder, Dahlquist, Gear Backus Aitken, Givens, Householder, Wilkinson, Golub David on, Fletcher, Powell, Broyden Rutishauser, Kublanovskaya, Francis, Wilkinson Gauss, Cooley, Tukey, Sande Chebyshev, Lanczos, Clenshaw, Orszag, Gottlieb Hardy, Askey, Duchon, Micchelli Fedorenko, Bakhvalov, Brandt, Hackbusch Moler, Stewart, Smith, Dongarra, Demmel, Bai Vinsome, Saad, van der Vorst, Sorensen van der Vorst, Meijerink Moler Kahan Morlet, Grossmann, Meyer, Daubechies Fiacco, Mc Cormick, Karmarkar, Megiddo Rokhlin, Greengard Iri, Bischof, Carle, Griewank Iserles, A., ed.
1992–.Cambridge: Cambridge University Press. Acta Numerica (annual volumes). Nocedal, J., and S. J. Wright. 1999.New York: Springer. Numerical Optimization. Powell, M. J. D. 1981.Cambridge: Cambridge University Press. Approximation Theory and Methods. Richtmyer, R. D., and K. W. Morton. 1967.ods for Initial-Value Problems. New York: Wiley Inter-Difference Methscience. IV.22 Set Theory Joan Bagaria 1 Introduction Among all mathematical disciplines, set theory occu-pies a special place because it plays two very different roles at the same time:
on the one hand, it is an area of 616 mathematics devoted to the study of abstract sets and their properties; on the other, it provides mathematics with its foundation. This second aspect of set theory gives it philosophical as well as mathematical signifi - cance. We shall discuss both aspects of the subject in this article. 2 The Theory of Transfinite Numbers Set theory began with the work of1874 he proved that there are more real numbers than cantor [VI.54](/part - 06/georg - cantor - 18451918). In there are algebraic ones, thus showing that infinite sets can be of different sizes.
This also provided a new proof of the existence of Recall that a real number is called transcendental numbers algebraic if it is the[III.41](/part - 03/irrational - and-\text{transcendental} - numbers). solution of some polynomial equation an Xn + (an)-1(Xn)-1 + · · · + a1 X + a0 = 0, where the coefficients0). Thus, numbers likea . qrti2, are integers (and3, and the golden ratio, an =12(1 + . qrt{5}), are algebraic. A transcendental number is4 one that is not algebraic. numbers than algebraic ones, when there are infinitely many of both?
Cantor defined two sets What does it mean to say that there are “more” real A and B to have the same size, ortion between them: that is, if there is a one-to-one cor-cardinality, if there is a bi jec respondence between the elements of ments of B. If there is no bijection between A and the ele-A and B, but there is a bijection between then A is of smaller cardinality than A and a B. So what cantor subset of B, in fact showed was that the set of algebraic numbers had smaller cardinality than that of all real numbers. ferent kinds of infinite set:
able In particular, Cantor distinguished between two dif-[III.11](/part-03/countable-and-uncountable-sets). A countable set is one that can be put into countable and uncountone-to-one correspondence with the natural numbers. In other words, it is a set that we can “enumerate,” assigning a different natural number to each of its ele-ments. Let us see how this can be done for the algebraic numbers. Given a polynomial equation as above, let the number

|an| + |(an)-1| + · · · + |a0| + n

be called its index. It is easy to see that for every$k > 0$ there are only a finite number of equations of indexk. For instance, there are only four equations of index3 with strictly positive X +1 = 0, and X -1 = 0, which have as solutions 0, an, namely$, X2 = 0, 2X =-0,1,$ and 1. Thus, we can enumerate the algebraic numbers by first enumerating all solutions of equations of index

IV. Branches of Mathematics

1, then all solutions of equations of index 2 that wehave not already enumerated, and so on. Therefore, the algebraic numbers are countable. Note that from this proof we also see that the sets Z and Q are countable. Cantor discovered that, surprisingly, the set R of real numbers is not countable. Here is Cantor’s orig-inal proof. Suppose, aiming for a contradiction, that r Choose the least0, r1, r2, . . . is an enumeration ofk such that a < r Rand put. Let a0 b == rr0.. Givenr < ba, and putn and bn, choose the leasta = r .
And choose the leas(t0)kl such that0 an mk< such thatwe haveln aan< a+1 < r< (am)n+< b1 <n, and put· · ·l < b b< bn+1 =< brm. Thus,. Now let different froma be the limit of the0 r1, for all2 nan, contradicting our assump-. Then a2 is a real numbe(r1)0 tion that the sequence numbers.$n r0$, r1, r2, . . . enumerates all real are at least two genuinely different kinds of infinite Thus it was established for the first time that there sets.
Cantor also showed that there are bijections between any two of the sets R$n$, n ⩾ 1, and even RN, the set of all infinite sequences numbers, so all these sets have the same (uncountable)$r0$, r1, r2, . . . of real cardinality. works that constitute the origin of set theory. An impor-tant concept that he introduced was that of infinite, or From 1879 to 1884 Cantor published a series of “transfinite,”bers to count a collection of objects, we assign a num-ordinals.
When we use the natural number to each object, starting with 1, continuing with2, 3, etc., and stopping when we have counted each object exactly once. When this process is over we have done two things. The more obvious one is that we have obtained a number that tells us how many objects there are in the collec-n, the last number in the sequence, tion. But that is not all we have done: as we count wealso define an ordering on the objects that we were counting, namely the order in which we count them. This reflects two different ways in which we can think about the set$\\{1}$,2, . . .
, n\\\\\\\\\\\\\\\\\\\\\}. Some times all we care about is its size. Then, if we have a set respondence with$\\{1}$, 2, . . . , n\\\\\\\\\\\\\\\\\\\\\}, we conclude that X in one-to-one cor-X has cardinality natural ordering on the setn. But some times we also take note of the\\{1,2, . . . , n\\}, in which case we observe that our one - to - one correspondence pro-vides us with an ordering on X too. If we adopt the first point of view, then we are regarding nal, and if we adopt the second, then we are regardingn as a cardi- it as an ordinal. IV.22.
Set Theory think of that from the ordinal point of view too. For instance, if we define a one - to - one correspondence If we have a countably infinite set, then we can between0, 1, -1,2 N,-2 and,3,-Z3, . . .by taking 0, then we have not only shown, 1, 2,3,4,5,6,7, . . . to that the obvious ordering on N and Z have the same cardinality, but also used N to define an ordering on Z. the unit interval shows that no matter how we assign numbers in this Suppose now that we want to count the points in[0, 1].
Cantor’s argument given above interval to the numbers 0, 1, 2, 3, etc., we will runout of natural numbers before we have counted all points. However, when this happens, nothing preventsus from simply setting aside the numbers we have already counted and starting again. This is where trans-finite ordinals come in: they are a continuation of the sequence 0 be used to count bigger infinite sets.,1,2,3, . . .“beyond infinity,” and they can resents the first position in the sequence that comes straight after all the natural numbers.
This is the first To start with, we need an ordinal number that rep infinite ordinal number, which Cantor denoted by In other words, after 0,1,2,3, . . . comes ω. The ordinalω.ωbecause although it has predecessors, it has no imme-has a different character from the previous ordinals, diate predecessor (unlike 7, say, which has immediate predecessor 6). We say thatω is a limit ordinal. But once we have very simple way, just by adding 1 repeatedly. Thus, theω, we can continue the ordinal sequence in a sequence of ordinal numbers begins as follows:
0, 1$, 2, 3, 4, 5, 6,7, . . . , ω, ω + 1, ω + 2, ω + 3, . . . .$ After this comes the next limit ordinal, which it seems natural to callω + ω, and which we can write as ω · 2. The sequence continues as ω · 2$, ω · 2 + 1, ω · 2 + 2, . . . , ω · n, . . . , ω · n + m, . . . .$ for generating new ordinals: adding 1 and passing tothe limit.
What we mean by “passing to the limit” is As this discussion indicates, there are two basic rules “assigning a new ordinal number to the position in the ordinal sequence that comes straight after all the ordinals obtained so far.” For example, after all the ordinalsω · n + m comes the next limit ordinal, which we write$as$ω · ω$, or ω2$, and we obtainω2$, ω2 + 1$, . . . , ω2 + ω, . . . , ω2 + ω · n, . . . , ω2 · n, . . . . Eventually, we reachω3 and the sequence continues asω3, ω3 + 1, . . . , ω3 + ω, . . .
, ω3 + ω2, $. . . , ω3 · n, . . . .$ The next limit ordinal is ordinal after all the$ωn ωis4$, and so on. The first limit$ω^{ω}$. And after ωω, ωω ω, 617
0, 1, 2, 3, 4, 5, 6, . . . , n, n + 1, . . . + 1 0, 1, 2, 3, 4, 5, 6, . . . , n, . . . . . . . . . . Figure 1ω and ω + 1 have the same cardinality.ωon and on it goes.ω ωω , . . . comes the limit ordinal denoted by ε0. And objects as sets. For ordinals this can be done in a par-ticular ly simple way: we represent 0 by the empty set, In set theory, one likes to regard all mathematical and the ordinal number of all its predecessors. For instance, the natural num-αis then identified with the set berhas cardinality nis identified with the setn) and the ordinal0, 1ω, . . .
, n+3 is identified- 1 (which with the set\\{0}$,
1, 2, 3, . . . , ω, ω + 1, ω + 2\\$. If we think of ordinals in this way, then the ordering on the set ofordinals becomes set membership: ifα comes beforeβcessors ofin the ordinal sequence, thenβ and therefore an element ofα is one of the prede-β. A critically important property of this ordering is that each ordinal is a well-ordered set, which means that every nonempty subset of it has a least element. As we said earlier, cardinal numbers are used for measuring the sizes of sets, while ordinal numbers indi-cate the position in an ordered sequence.
This distinction is much more apparent for infinite numbers than for finite ones, because then it is possible for two dif-ferent ordinals to have the same size. For example, the ordinals ing sets$\\{ω0}$, and1, 2, . . .ω +\\\\\\\\\\\\\\\\\\\\\}1 are different but the correspond-and$\\{0},1,2, . . . , ω\\\\\\\\\\\\\\\\\\\\\} have the same cardinality, as figure 1 shows. In fact, all sets that can be counted using the infinite ordinals we have described so far are countable. So in what sense are different ordinals different? The point is that although two sets suchas\\{0,1,2, . . .
\\} and \\{0,1,2, . . . , ω\\} have the same cardi- nality, they are not find a bijectionφ from one set to the other such that order isomorphic: that is, you cannot φ(x) < φ(y)“as sets” but not “as ordered sets.”when eve rx < y. Thus, they are the same Informally, the cardinal numbers are the possible sizes of sets. A convenient formal definition of a cardi-nal number is that it is an ordinal number that is bigger than all its predecessors. Two important examplesof such ordinals areω, the first infinite ordinal, and the set of all countable ordinals, which Cantor denotedbyω.
The second of these is the first uncountable ordinal: uncountable since it cannot include itself asan element, and the first one because all its elements1 are countable. (If this seems paradoxical, consider the

618

ordinal Therefore, it is also a cardinal number, and when weω: it is infinite, but all its elements are finite.) consider this aspect of it rather than its order structurewe call itא , again following Cantor. Similarly, when we think of The process used to defineω1 as a cardinal, we call itא can be repeated. Theא0.
set of all ordinals of cardinality1. leph1 (or equivalently the set of all ordinals that can be put in one-to-one corre-spondence with the first uncountable ordinal$ω^{1}) \text{is the}$ smallest ordinal that has cardinality greater thanan ordinal it is calledω and as a cardinal it is calledא1$. As\aleph2$. We can continue, generating a whole sequence of2 ordinalsity. More over, using limits as well, we can continue thisω1, ω2, ω3, . . . of larger and larger cardinal- sequence transfinitely: for example, the ordinal the limit of all the ordinalsω .
As we do this, weωω is also produce the sequence of infinite, or transfinite,$n$ cardinals: א0$,\aleph1, . . . ,\aleph^{ω}$, אω+1, . . . ,אω ω, . . . ,אω1, $. . . ,\aleph^{ω}2$, . . . , אω ω, . . . . sum and product. A convenient set-theoretic way to define these binary operations is as follows. Given two Given two natural numbers, we can calculate their natural numbers A and B of size mmandandnn, respectively;, take any two disjoint setsm + n is then the size of the union size of the set A . imes  B, the set of all ordered pairs A∪ B.
As for the product, it is the(a, b) witha \in  A and b \in  B. (For this set, which is called the Cartesian product, we do not need A and B to be disjoint.)The point of these definitions is that they apply just as well to infinite cardinal numbers: just replace and nin the above definitions by two infinite cardinalsmκnals is very simple, however. It turns out that for alland λ. The resulting arithmetic of transfinite cardi transfinite cardinals$\aleph^{α} and \aleph^{β}$,אα + אβ = אαאβ = . ax (אα$,\alephβ) = \aleph\max(α$,β).
nentiation, and for this the picture changes completely. If However, it is also possible to define cardinal expo-κ and . ambda are two cardinals, then κ. ambda is defined as the cardinality of the Cartesian product of. ambda copies of any set of cardinality the set of all functions from a set of cardinalityκ. Equivalently, it is the cardinality of. ambda into a set of cardinality bers, this gives us the usual definition: for instance, theκ. Again, if κ and . ambda are finite num number of functions from a set of size 3 to a set of size4 is 43.
What happens if we take the simplest nontrivial transfinite example, 2א0? Not only is this question

IV. Branches of Mathematics

extremely hard, there is a sense in which it cannot beresolved, as we shall see later. The most obvious set of cardinality 2א is the set of functions from N to the set\\{0}, 1\\$. If f is such a function, then we can regard it as giving the binary expansion of the number

x = f (n)(2-)((n+1)),

which belongs to the closed intervalis 2-^(n^+^1^) rather than 2^n\in^-^N^n because we are using the con-[0,1]. (The power vention, standard in set theory, that 0 is the first natural number rather than 1.) Since every point inat most two different binary representations, it follows[0, 1] has easily that 2 fore also the cardinality ofא^0 is also the cardinality of R. Thus, 2^א [0 is uncountable,,1], and there- which means that it is greater than or equal totor conjectured that it is exactlyא . This is the famousא1.
Can- continuum hypothesis, which will be discussed at length1 in section 5 below. It is not immediately obvious, but there are many mathematical contexts in which transfinite ordinals occur naturally. Cantor himself devised his theory of transfinite ordinals and cardinals as a result of his attempts, which were eventually successful, to prove the continuum hypothesis for closed sets. He first defined the derivative of a set X of real numbers to be the set you obtain when you throw out all the “iso-lated” points of X.
These are points x for which you can find a small neighborhood aroundtains no other points in X. For example, ifx that con-X is the set except for 0, so the derivative of${0} ∪ \{1$,1 2,1 3$, . . . \}$, then all points in X is the set X are isolated0. repeatedly. If we set X0 In general, given a set⊇ X1 ⊇ X2 ⊇ · · ·X0, where=XX, we can take its derivative, then we obtain a sequence (Xn)+1 is the derivative oftake the intersection of all the$X^{n}$. But the sequence does not stop here:
we can$X^{n} \text{and call it} X^{ω}$, and if we do that, then we can define(Xω)+1 to be the deriva- tive of$X^{ω}$, and so on. Thus, the reason that ordinals appear naturally is that we have the derivative and taking the intersection of everything two operations, taking so far, which correspond to successors and limits inthe ordinal sequence. Cantor initially regarded superscripts such as$ω +$1 as “tags” that marked the transfinite stages of the derivation. These tags later became the countable ordinal numbers.
Cantor proved that for every closed set X there must be a countable ordinal that Xα = (Xα)+1. It is easy to show that eachα(which could be finite) such$X^{β} \text{in the}$ sequence of derivatives is closed, and that it contains

IV.22. Set Theory

all but countably many points of the original set Therefore, Xα is a closed set that contains no isolated X. points. Such sets are called hard to show that they are either empty or have cardi-perfect sets and it is not too nality 2א . From this it follows that X is either countableor of cardinality 2א . tween transfinite ordinals and cardinals and the struc-ture of the continuum was destined to leave its mark The intimate connection, discovered by Cantor, beon the entire subsequent development of set theory.
3 The Universe of All Sets In the discussion so far we have taken for granted that every set has a cardinality, or in other words that for every setbe put into one-to-one correspondence with X there is a unique cardinal number that can X. If κ is such a cardinal and$f$: X \to κ is a bijection (recall that we identify then we can define an ordering onκ with the set of all its predecessors), X by taking x < y if and only ifthis makesf (x) < f (y)X into a well-ordered set. But it is far from. Since κ is a well-ordered set, obvious that every set can be given a well-ordering:
indeed, it is not obvious even for the set R. (If you need convincing of this, then try to find one.) ordinals and cardinals and to solve some of the fun-da mental problems—such as computing where in the Thus, to make full use of the theory of transfinite aleph hierarchy of infinite cardinals the cardinal of R is—one must appeal to the assertion that every set can be well-ordered. With out well-ordering principle: the this assertion, one cannot even make sense of the ques-tions.
The well-ordering principle was introduced by Cantor, but he was unable to prove it.listed proving that R could be well-ordered as part of hilbert [VI.63](/part-06/david-hilbert-18621943) the first problem in his celebrated list of twenty-three unsolved mathematical problems presented in 1900 at the Second International Congress of mathematicians in Paris.
Four years later, Ernst Zermelo gave a proof of the well-ordering principle that drew a lot of criti-cism for its use of the axiom of choice [III.1](/part-03/axiom-of-choice) (AC), a principle that had been tacitly used for many years but which was now brought into focus by Zermelo’s result. AC states that nonempty sets there is a set that contains exactly onefor every set X of pairwise-disjoint element from each set indetailed, proof published in 1908, Zermelo spells out X .
In a second, much more some of the principles or axioms involved in his proof of the well-ordering principle, including AC. at ization of set theory, the main motivation being the In that same year, Zermelo published the first axiom-

619

need to continue with the development of set theory while avoiding the logical traps, or paradoxes, that originated in the care less use of the intuitive notion of a set (see[II.7](/part-02/foundations-crisis)). For instance, it seems intuitively clear that every the crisis in the foundations of mathematics property determines a set, namely, the set of those objects that have that property. But then consider the property of determined a set, this would be the set of all ordinal being an ordinal number. If this property numbers.
But a moment of reflection shows that there can not be such a set, since it would be well-ordered and would therefore correspond to an ordinal greater than all ordinals, which is absurd. Similarly, the property of being a set that is not an element of itself cannot determine a set, for otherwise we fall into Russell’s paradox, that if A is such a set, then A is an element of A if and only ifnot every collection of objects, not even those that are A is not an element of A, which is absurd. Thus, defined by some property, can be taken to be a set. So what is a set?
Zermelo’s 1908 axiomatization provides the first attempt to capture our intuitive notion of set in a short list of basic principles. It was later improved through contributions from skolem [VI.81](/part-06/thoralf-skolem-18871963), Abraham Fraenkel, and von neumann [VI.91](/part-06/john-von-neumann-19031957), becoming what is now known as axiom of choice, or ZFC.Zermelo–Fraenkel set theory with the is a “universe of all sets” that we would like to under-stand, and the axioms give us the tools we need to build The basic idea behind the axioms of ZFC is that there sets out of other sets.
In usual mathematical practicewe take sets of integers, sets of real numbers, sets of functions, etc., but also sets of sets (such as sets ofopen sets in a topological space [III.90](/part-03/topological-spaces)), sets of sets of sets (such as sets of open covers), and so on. Thus, the universe of all sets should consist not only of setsof objects, but also of sets of sets of objects, etc. Now it turns out that it is much more convenient to dis-pense with “objects” altogether and consider only sets whose elements are sets, whose elements are also sets, etc.
Let us call those sets “pure sets.” The restriction to pure sets is technically advantageous and yields a more elegant theory. More over, it is possible to model traditional mathematical concepts such as real numbers using pure sets, so one does not lose any mathematical power. Pure sets are built from nothing, i.e., the empty set, by successively applying the “set of” operation. A simple example iswe start by forming{. mptyset}, then∅,{. mptyset{. mptyset,{. mptyset}}},∅: to build this, and putting these two sets together gives us{. mptyset}$,{\emptyset, {\emptyset}}$.
Thus, at every stage we form all the sets whose elements are sets

620. ambda V . ambdaα + 1

Vα$+ 1$α Vα Figure 2 The universe V of all pure sets.

already obtained in the previous stages. Once again, this can be continued transfinitely: at limit stages we collect into a set all the sets obtained so far, and keep going. The universe of all (pure) sets, represented by the letter axis representing the ordinals (see figure 2), therefore V and usually drawn as a V-shape with a vertical forms a cumulative well-ordered hierarchy, indexed bythe ordinal numbers, beginning with the empty set∅. That is, we let

$V^{0} = \emptyset$,(Vα)+1 = P.(Vα), the set of all subsets of Vα, Vλ = Vβ, the union of all the Vβ$, β < λ,$ if. ambda The universe of all sets is then the union of all theis a limit ordinal.^β<. ambda sets Vα such that α is an ordinal. More concisely,.V =α Vα.

3.1 The Axioms of ZFC

The ZFC axioms, stated informally, are the following. (i) Extensionality.they are equal. If two sets have the same elements, (ii) Power set. For every setx there is a set P(x) whose (iii) Infinity.(iv) Replacement.elements are all the subsets of There is an infinite set. Ifx is a set andx. φ is a function- class1 restricted to x, then there is a set y = \\{φ(u): \\} u \in x.

(v) Union.elements are all the elements of the elements of For every setx, there is a set "x whosex. definition rather than an object that has to exist as a set. The concept will be made precise in section 3.2.1. A function-class can be thought of as a function that is given as a

IV. Branches of Mathematics

(vi) Regularity.ordinalα. Every set x belongs to V^α, for some (vii) Axiom of choice (AC).disjoint nonempty sets there is a set that contains For every set X of pairwise- exactly one element from each set in X. Usually a further axiom appears on this list, called the pairing axiom the set$\\{A}$, B\\\\\\\\\\\\\\\\\\\\\}. It asserts that for any two sets exists. In particular, {A} exists. Apply-A and B ing the union axiom to the set union A ∪ B of A and B. But pairing can be derived\. \1, B\\} one then gets the from the other axioms.
Another important axiom that appeared in Zermelo’s original list, one that is both natural and very useful, is the axiom of separation. It states that for every setset of elements of AAand every that have the property definable property P is also P, the a set. But this axiom is a consequence of the axiom of replacement, so there is no need to include it in the list. Using the axiom of separation one can easily prove the existence of the empty set∅, as well as the inter sec- tion A ∩ Band difference A - B of any two sets A and Bof foundation.
The axiom of regularity is also known as theand it is usually stated as follows: every axiom nonempty set X has an \in -minimal element, i.e., an ele- ment that no element of X belongs to. In the presence of the other axioms the two formulations are equiva-lent. We chose the formulation in terms of the Vαs to stress the fact that this is a natural axiom based on the construction of the universe of all sets.
But it isimportant to notice that the notions of “ordinal” and the “cumulative hierarchy ofthe formulation of the axioms of ZFC.$V^{α}$s” need not appear in the one hand, they tell us the things we can do with The axioms of ZFC lead a kind of double life. On sets. In this sense, ZFC is just like any other collec-tion of axioms for algebraic structures, e.g., the axioms for groups [I.3 §2.1](/part-01/fundamental-definitions), or fields [I.3 §2.2](/part - 01/fundamental - definitions):
in both cases they give rules for creating new objects from old ones, though there are more rules for sets than there are for group or field elements and they are more complicated. Thus, just as one studies abstract groups, i.e., algebraic structures that satisfy the axioms for groups, so onecan study the mathematical structures that satisfy the axioms of ZFC. These are called models of ZFC. Since, for reasons to be explained below, models of ZFC arenot easy to come by, one is also interested in models of fragments of ZFC: that is, of axiom systems consist of just some of the axioms of ZFC.
A model of a A that fragment M is a nonempty set and Aof ZFC is defined to be a pair E is a binary relation on M, E , where M, IV.22. Set Theory such that all axioms ofof M are interpreted as the sets and A are true when the elements E is interpreted as the membership relation. For example, if A includes the union axiom, then for every element must be an ele men ty of M such that z Eyxif and only ifof M there there exists E by . nand “element ofw such that Mz Ew” by “set” in the last sentence, andw Ex.
(If we replaced then we would recover the usual union axiom.)The set V ,\in is a model of all the axioms of ZFC except infinity, and replacement. (To see why replacement fails, letω (Vω()+)ω, \in is a model of ZFC exceptx be the setequalωω+and define a functionn.
The range of φ belongs toφ on x Vby letting but notφ(n) toany set(Vω()+){ω}Vbe cause the ordina(lω)+n and (Vω()+){ω} is the union of the setsω +ω does not belong t(oω()+){ω} + 1 (Vω)+n.) For both these models, we took E to be \in , but one can also look at a completely different relation M, and see whether it happens to satisfy some of the E on a set axioms of ZFC. For example, take the pair N, E , wherem Ento left) in the binary expansion ofif and only if the mth digit (counting from rightn is 1. This is a model of ZFC with out the axiom of infinity, as the reader may care to check.
they tell us how to build up the hierarchy of the Axiom (i), the axiom of extensionality, states that a The other way of thinking of the ZFC axioms is that$V^{α}s$. set is something entirely determined by its elements. Axioms (ii)–(v) are tailored to construct V . The power- set axiom is what we use to get from axiom of infinity allows the construction to go into Vα to (Vα)+1. The the transfinite. Indeed, in the context of the other Zfc axioms, this axiom is equivalent to the assertion that ωthe construction of exists. The axiom of replacement is used to continue V at limit stages λ.
To see this, con- sider the function defined byx is an ordinal and y = V . The range of F(x) = y if and only if F restricted toof replacement these sets form a set. Now, by an appli-. ambda then consists of all Vxβ with β < λ. By the axiom cation of the union axiom to this set one obtains Finally, the axiom of regularity states that all sets are$V^{λ}$. obtained in this way: that is, the universe of all sets isprecisely V . This rules out pathologies, such as sets that belong to themselves. The point is that for every set there is a firstα such that X \in  V .
This α is called the X rank arc hy where of X and it marks the stage of the cumulative hier-X was formed. So (Xα)+could not possibly be1 an element of itself, since all elements of X must have a rank strictly smaller than the rank ofof choice is equivalent, in the context of the other ZFCX . The axiom axioms, to the well-ordering principle.

621

3.2 Formulas and Models

The ZFC axioms can be formalized using the languageof first-order logic for sets. The symbols of first-order logic are“∀” (for all) and “variables∃such as” (there exists); thex, y, z, . . .; the logical connec-quantifiers tives “¬” (not), “∧” (and), “∨” (or), “$\to$” (if ..., then ...), and “↔” (if and only if); the equality symbol “$=$”; and parentheses. To make this first-order logic add one other symbol, “$\in$,” standing for “is an ele-for sets we ment of,” and the quantifiers are understood to range over sets. Here is how the axiom of extensionality is expressed in this language:
$∀x∀y(∀z(z \in x ↔ z \in y) \to x = y)$. This reads as: for every sets etz belongs to x if and only if it belongs tox and every set y, if everyy (i.e., if equal. It is an example of ax and y have the same elements), then formula in our language.x and y are Formulas can be defined inductively as follows. The atomic formulas arex = y and x \in y. Using quan- tifiers and logical connectives one can build up more complicated formulas using the following rules: ifφ and(φ \to ψ ψ)are formulas, then so are, (φ ↔ ψ), ∀xφ, and¬∃φxφ, (φ.
Thus, formulas∧ ψ), (φ ∨ ψ), are the formal counterpart of sentences in English (orin any other natural language) that talk only about sets and the membership relation. (For another discussion of formal languages, see logic and model theory [IV.23 §1](/part - 04/logic - and - model - theory).)Conversely, any formula of the formal language can be interpreted as a sentence (in English) about sets, andit makes sense to ask whether the interpreted sentence is true or not.
Usually, by “true” we mean “true in the universe about the truth or falsity of a formula in any structure Vof all sets,” but it also makes sense to ask of the form For example, the formula M, E , where E∀xis a binary relation on∃y x \in y is true in all M. models M, E of ZFC, while the formula∃x∀y y \in x is false (because of the axiom of regularity). Any formula that can be deduced from the axioms of ZFC is true in all models of ZFC.Once we have defined what a formula is, we are in a position to make many statements precise that would otherwise not be.
For example, the axiom of replacement involves the notion of a proper sense of it one formulates it in terms of first-function-class. To make order formulas. For example, the operation that takes each seta to the singleton {a}is definable, and this depends on the fact that the statementbe expressed by the formula$∀z(z \in y ↔yz = {= x)x}$. It iscan

622

not a function, since it is defined on all sets, and the universe of all sets is not a set. This is why we use the different phrase “function-class.” In addition, we some times allow classes. For example, the function-class that, for a fixed parameters in our definitions of function set formul ab, takes each set∀z(z \in  y ↔a to the setz \in  x ∧ za\in ∩b)bis defined by the, which depends on the setb: we callb a parameter and we say that the function-class isgenerally, a function-class is a function on sets given definable with parameters. More by a formula.
But the function itself may not exist asa set, since its domain may contain all sets, or all ordinals, etc. Since the axiom of replacement is a statement about all function-classes, it is not in fact a single axiom but rather an “axiom scheme,” consisting of one axiom for each function-class. An important consequence of the fact that ZFC can be formalized in first-order logic is that it is subject to a remarkable theorem of Löwenheim and Skolem. The Löwenheim–Skolem theorem is a general result about first-order formal languages;
in the particular case of ZFC, it says that if ZFC has a model, then it has a countable model. More precisely, given any model$M = M$, E of ZFC, there is a model countable and that satisfies exactly the same sentences N of ZFC contained in M that is as ZFC have a countable model if one can prove in ZFC$M$. At first, this may seem paradoxical, for how can that there are uncountable sets? Does the theorem not lead to a contradiction and therefore imply that there are no models of ZFC? Not quite.
Suppose that we have a countable model to show that the statement “N of ZFC and a setais countable” is true ina in N. If we want N, then we must show thatfromω to a. But it is possible for such a map to exist in N there is a surjective map inout existing in V , or in some model N, because M Vthat is larger than and M contain more sets, N, with- and therefore more functions, than case, a is uncountable from the point of view of N does. In such a N but countable from the point of view of M or V .
tain set-theoretic notions, like being countable or hav-ing a certain cardinality, with respect to different mod-Far from presenting a problem, the relativity of cerels of ZFC is an important phenomenon which, even if a bit disconcerting at first, may be used to great advantage in consistency proofs (see section 5 below). true indesigned for that to happen. But the ZFC axioms may It is not difficult to see that all the axioms of ZFC are V , which is hardly surprising since they were conceivably hold in some smaller universes. That is, there may be some class M properly contained in V ,

IV. Branches of Mathematics

or even some set Skolem theorem also some countable set$M$, and therefore by the Löwenheim–M , which is a model of ZFC. As we shall see, while the existence of models of ZFC cannot be proved in ZFC, the fact that one can consistently assume that they exist— provided ZFC is consistent, of course—is of the greatest importance for set theory. Foundation of Mathematics4 Set Theory and the As we have seen, we can use ZFC to develop the theory of transfinite numbers.
But it turns out that all stan-dard mathematical objects may be viewed as sets, and all classical mathematical theorems can be proved from ZFC using the usual logical rules of proof. For example, real numbers can be defined as certain sets of rational numbers, which can be defined aslence classes [I.2 §2.3](/part-01/language-and-grammar) of ordered pairs of integers.equiva The ordered pairm, \\\\\\\\\\\\\\\\\\\{m, n\\\\\\\\\\\\\\\\\\\}}, integers can be defined as equivalence(m, n)can be defined as the set classes of ordered pairs of positive integers, and positive integers can be thought of
as finite ordinals, which as we have seen can be defined as sets. Tracing back, one finds that a real number can be regarded as a setof sets of sets of sets of sets of sets of finite ordinals. Similarly, all the usual mathematical objects— such as algebraic structures, vector spaces, topologi-cal spaces, smooth manifolds, dynamical systems, and so on—can be shown to exist in ZFC. Theorems con-cerning these objects can be expressed in the formal language of ZFC, as can their proofs.
Of course, writing out a complete proof using the formal language would be extremely laborious, and the result would not only be very long but also virtually impossible to understand. It is important, however, to convince one self that in principle it can be done. It is the fact that all standard mathematics can be formulated and devel-oped within the axiomatic system of ZFC that makes metamathematics ematical study of mathematics itself. For example, itpossible, that is, the rigorous math allows us to think about whether a mathematical statement has a proof:
once we have rigorous definitions of “mathematical statement” and “proof,” the question of whether a proof exists becomes a mathematical one with a determinate answer. 4.1 Undecidable Statements In mathematics the truth of a mathematical state - mentφ is established by means of a proof from basic IV.22. Set Theory principles or axioms. Similarly, the falsity oflished by a proof of¬φ.
It is tempting to believe thatφ is estab- there must always be a proof of eitherφ or ¬φ, but in 1931 ness theoremsgödel [VI.92](/part - 06/kurt - gdel - 19061978) proved in his famous[V.15](/part - 05/gdels - theorem) that this is not the case. The first incomplete incompleteness theorem says that in every axiomatic formal system that is consistent and rich enough to develop basic arithmetic there are undecidable statements: that is, statements such that neither they nor their negations are provable in the system.
In particular, there are statements of the formal language ofset theory that are neither provable nor disprovable from the ZFC axioms, supposing, that is, that ZFC is consistent. consistency of ZFC, usually written as con translation into the language of set theory of: But is ZFC consistent? The statement that asserts the(ZFC), is the$0$= 1 is not provable in ZFC. This statement asserts that the sequence of symbols0= 1 is not the last step of any formal proof from ZFC.
One can encode a formal proof as a finite sequenceof natural numbers that satisfies certain arithmetical properties, and there by regard the above statement as an arithmetical one. Gödel’s second incompleteness theorem says that in any consistent axiomatic formal system that is rich enough to develop basic arithmetic, the arithmetical statement that asserts the consistency of the system cannot be proved. Thus, if ZFC is con-sistent, then its consistency can neither be proved nor disproved in ZFC. tem in which to develop mathematics.
Thus, the truth of a mathematical statement is firmly established if its ZFC is currently accepted as the standard formal sys translation into the language of set theory is provablein ZFC. But what about undecidable statements? Since ZFC embodies all standard mathematical methods, the fact that a given mathematical statementφ is und ecid- able in ZFC means that the truth or falsity ofbe established by means of usual mathematical prac-φ cannot tice.
If all undecidable statements were like Con this would probably not be a cause of worry, since they(ZFC), seem not to directly affect the kind of mathematical problems that people are usually interested in. But for better or worse this is not so. As we will see, there are many statements of mathematical interest that are undecidable in ZFC.There is an obvious way of showing that a mathematical statement has a proof: you just find one. But howcan it be possible to prove, mathematically, that a given

623

mathematical statement question has a short but far-reaching answer. If we canφis undecidable in ZFC? This find a model can not be a proof of M of ZFC in whichφ (because that proof would showφ is false, then there that M andφ was true in N of ZFC with M). Therefore, if we can find modelsφ true in M and false in N, we can conclude that Unfortunately, a consequence of Gödel’s second in-φ is undecidable. completeness theorem is that it is not possible to prove in ZFC the existence of a model of ZFC.
This is because another theorem of Gödel, called the completeness theorem if and only if it has a model. However, we can get around for first-order logic, asserts that ZFC is consistent this difficulty by splitting the proof of the undecidabil-ity ofφ into two relative consistency proofs: the first is a proof that if ZFC is consistent, then so is ZFC plus and the second is a proof that if ZFC is consistent, thenφ; so is ZFC plus the negation ofthat there is a model M of ZFC and proves the exis-φ. That is, one assumes tence of two models of ZFC: one where one where it fails.
One can then conclude that eitherφ holds, andφ and its negation are both unprovable in ZFC, or ZFC is in consistent, in which case everything is provable. One of the most surprising results of twentieth-century mathematics is that the continuum hypothesis is undecidable in ZFC. 5 The Continuum Hypothesis Cantor’s continuum hypothesis (CH), first formulated in 1878, states that every infinite set of real numbers is either countable or has the same cardinality as R.
In ZFC, since AC implies that every set, and in par-ticular every infinite set of real numbers, can be put into one - to-one and onto correspondence with a cardi-nal number, one can easily see that CH is equivalent to the assertion that the cardinality oflently, that 2א = א , the version of the statement that R is א1, or equiva- we mentioned earlier. Solving CH was the first problem in Hilbert’s famous0 1 list of twenty-three unsolved problems, and has been one of the main driving forces for the development of set theory.
In spite of many attempts at proving CH by Cantor himself and by many leading mathematicians of the first third of the twentieth century, no major progress was made until, sixty years after its formulation, Gödel was able to prove its consistency with ZFC. 5.1 The Constructible Universe In 1938, Gödel found a way to construct, starting witha model M of ZFC, another model of ZFC, contained 624 in consistency of CH with ZFC. Gödel’s model is known M, where CH holds. He there by proved the relative as the constructible universe and is represented by the letter universe L. Since V of all sets.
Then M is a model of ZFC, we may view L is built inside M Min a wayas the that is similar to how we built important difference. When we passed from V, but with the following V to V+ we took all subsets of Vα, but to go from Lα toα(Lα)+1 oneα1 takes only those subsets of That is, L consists of all sets of the form Lα that are definable{a in}: a Lα\in .Lthe language of set theory that may mention elementsα and φ(a()α)+1 holds in Lα, where φ(x) is a formula of$of$ Lα. If . ambda is a limit ordinal, then L. ambda is just the union of all the ordinal.
Of course, we can also build Lα, α < λ, and L is the union of all the L inside VL. This isα, α an the One important observation is that to build real L, the universe of all constructible sets. L it is not necessary to use AC, and so we do not require AC to hold infied that AC holds in M. But once LL, as do the other axioms of ZFC.is constructed it can be veri- The verification of AC is based on the fact that every element of Lis defined at some stageα, and so it is uniquely determined by a formula and some ordinals.
Therefore, any sensible well-ordering of all the formu-las will naturally yield a well-ordering of L, and thus of every set in AC) is consistent, then so is ZFC. In other words, if L. This shows that if ZF (i.e., ZFC minus we add AC to the ZF axioms, then no contradiction is introduced into the system. This is very reassuring, for although AC has many desirable consequences it also has some that at first sight can appear counter intuitive, such as the banach–tarski paradox [V.3](/part - 05/the - banachtarski - paradox).
That CH holds in L is due to the fact that in L every real number appears at some countable stage of the construction, i.e., in some$L^{α}$, where α is countable in L. To prove this, one shows first that every realto some Lthat satisfies a finite number of axioms ofr belongs ZFC that are sufficient to buildβ L, where β is an ordinal that is not necessarily countable. Then, with the helpof the Löwenheim–Skolem theorem, one can show that there is a countable subset satisfies the same axioms as X of L L.
And then one showsβ that contains r and that X must be isomorphic toβLα for some countable ordinal$r$; this finishes the proof thatα, via an isomorphism that is the identity onr appears at a countable stage. But since there are only and L is countable for each countable ordinalא1 countable ordinals,α, there can be only$α \aleph^{1} \text{real numbers}$. that are strictly necessary, namely those that were Since, for each ordinalα, Lα contains only the sets

IV. Branches of Mathematics

explicitly definable in one of the previous stages, is the smallest possible model of ZFC containing all L the ordinals, and in it the cardinality ofsmallest possible, namelyא . In fact, in RL is also thethe gener- alized continuum hypothesis every ordinalα, (2א)α has the smallest possible value,1(GCH) holds: that is, for namely, The theory of constructible sets went through an(. lephα)+1. extraordinary development in the hands of Ronald Jensen.
He showed that in L a well-known conjecture called Suslin’s hypothesis was false (see section 10 below) and isolated two important combinatorial principles, known as♦ (diamond) and (square), that hold inhere, enable us to carry out constructions of un count-$L$. These two principles, which will not be defined able mathematical structures by induction on the ordi-nals in such a way that the construction does not break down at limit stages. This is extremely useful, because it allows one to prove consistency results with out going to the trouble of analyzing constructible sets:
if you can deduce a statementφ from ♦ or , then it holds in L, since, by Jensen’s results,♦ and hold in L; it follows that There is also an important generalization of theφ is consistent with ZFC. notion of construct i bility, called Given any set A it is possible to build the inner model theory constructible. closure contains all ordinals andof A, which is the smallest model of ZF that A.
This model, called L(A), is built in the same way as L, but instead of beginning with the empty set one begins with the sure of A, which consists of A, the elements of transitive clo-A, the elements of the elements ofthis sort are examples of inner models A, and so on. Models of: that is, models of ZF that contain all the ordinals and all the elementsof their elements. Especially prominent are the inner models L(r ), where r is a real number, and L(R), the constructible closure of the set of real numbers.
Also very important are the inner models of large-cardinal axioms, which will be discussed in section 6 below. After the result of Gödel, and given the repeated failed attempts to prove CH in ZFC, the idea started to take shape that maybe it was undecidable. To prove this, it was necessary to find a way to build a model of ZFC in which CH is false. This was finally accomplished twenty-five years later, in 1963, by Paul Cohen, using a revolutionary new technique called forcing. 5.2 Forcing The forcing technique is an extremely flexible and pow-erful tool for building models of ZFC.
It allows one to IV.22. Set Theory construct models with the most diverse properties and with great control over the statements that will hold in the model being constructed. It has made it possible to prove the consistency of many statements with Zfc that were not previously known to be consistent, and this has led to many undecidability results. In a manner reminiscent of the way one passes from a field K to an algebraic extension K[a], one goes from a model M[G] that is also a model of ZFC.
However, the forc - M of ZFC to a forcing extension ing method is far more complex, both conceptually and technically, involving set - theoretic, combinatorial, topological, logical, and meta mathematical aspects. Cohen’s original problem of starting from a model of ZFC and obtaining from it a model where CH fails. To give an idea of how it works, let us consider M The only thing we know about of ZFC, and as far as we know CH may hold in it. In M is that it is a model fact, for all we know, verse$L$:
perhaps when we build M might be the constructible uni-L inside M we obtain the whole ofhave to add to it some new real numbers to ensure that M. Therefore, when we extend M we shall in the extension M[G] there will be at least א2 of them. More precisely, we need the model sentence that says that there are at least M[G] to satisfy theא -many real numbers. However, the “real numbers” innot be real numbers in the actual universe2 M[G]V:
all that may matters is that in M[G] they satisfy sentences that say “I am a real number.” Similarly, the element ofthat plays the role of the cardinalא need not be the M[G] actual cardinal In order to explain the method, let us consider the$\aleph^{2} in V$. simpler problem of adding tonumberr . To make things even simpler, let us think of M just a single new real rot her words, as just the binary representation of a real inris an infinite binary sequence in the real[0,1]. In world V . nite binary sequences, in which case we will not be ableto find one to add.
However, by the Löwenheim–Skolem A first difficulty is that Mmay already contain all infitheorem, every model model Nthat satisfies exactly the same sentences of M of ZFC has a countable sub- the language of set theory as N is countable in the real world, that is, in M. Let us emphasize that V; so there is, out side Nevertheless, N, a function that enumerates all its elements. N will contain sets x for which the sen- tence that says “$x$is uncountable” is true in N. Since Mnot care about the size ofwas a model of ZFC, so is M , but only that it is a model N.
So, since we really do of ZFC, we may as well assume that$M = N$, so that M

625

itself is countable. And now, since there are un count-ably many infinite binary sequences, there are plenty of them that do not belong to M .Msequences that have a great influence on any model that? Well, no. The problem is that there are some binary So, can we just pick any one of them and add it to contains them. For example, we can encode any count-able ordinalα as a real number as follows. First let f be a bijection from{(m, n) \in N2}:$f$ (m) < f (n)N to αand define a subset. Now choose a bijection A ⊂ N^2 to beg from N to N^2 and let c(n) = 1 if and only if g(n) \in  A.
Ifbe), then any model$g$is sufficiently explicit (as it can easily be chosen to Mthat contains the infinite binary sequence built out ofc must contain the ordinalc using the axioms of ZFC.α, since α can be form To see why this matters, suppose that$L^{α}$, as constructed in V , where α is a countable M is of the ordinal inform follows, for instance, from the existence of large V. The existence of models of ZFC of this cardinals (see section 6 below), so we certainly can-not rule out this possibility.
Since we want to build a model sequence M[c]c and all the elements ofof ZFC that contains a new infinite binary M, it will have to contain fewer than Lα(c)α steps starting with, i.e., all sets that can be constructed inc. But if c is a sequence that encodes and still be a model of ZFC, since this would imply thatα, as above, then M[c] cannot equal Lα(c)Lα(c) contained itself.
If we try to circumvent the prob- lem by adding more sets to model of ZFC, then we may end up with M[c] so that it becomes a M[c] = L for some ordinal our purposes since CH holds in all models of ZFC of theγ greater than α. And this is not good forγ form Lγ. The conclusion is that we cannot just pick an arbitrary very carefully.c that is not in M: we will have to choose it that it should have no special property that singles itout.
The reason for this is that if, as before, The key idea is that$c$should be “generic,” meaning$M = L$, and we want to ensure that model of ZFC, then we do not want M[c] c=to have any spe-Lα(c) is still aα cial property that would interfere in the construction of M[c] and cause some ZFC axiom not to hold any more. To accomplish this we buildc little by little so that it avoids all the special properties that could pos-sibly have any undesirable effect on M[c].
For example, if we do not want ner sketched above, we simply set somec to encode the ordinal αc(n)in the man-equal to0 for some n such that g(n) \in  A. of Of course, if we have built up the firstc and φ is a property that holds for all real numbers N binary digits 626 that begin with thoseφ with out undoing our previous work. Let us call a N digits, then we cannot avoid property avoidable if every finite binary sequencep can be extended to a finite binary sequence infinite sequence that ex ten dsq has the property.
Forq such that no instance, the property “all terms in the sequence are zero” is avoidable, while the property “there are ten consecutive ones in the sequence” is not avoidable. if it avoids all avoidable properties that can be defined in A real number$M$, that is, properties that can be defined by meansc is called generic, or Cohen, over M of formulas that may mention sets insee thatc cannot belong to M , since if it did then the M .
It is easy to property “is equal tois certainly avoidable.$c$” would be definable in M, and it we use the fact that that there are only countably many avoidable proper-Why should a generic real number exist? Once again, M is countable. From this it follows ties. If we enumerate them aspick a finite sequenceq1 such that no infinite extensionφ1, φ2, . . . , then we can ofno infinite extension of$q1satisfiesφ1$. Then we can extendqsatisfiesφq1. Continuing into q2 such that this way we create an infinite binary sequence2 2 c that does not have any of the properties it is generic.φi.
In other words, struc ted, using in as many steps as the ordinals of Now let M[c]cbe the set of all sets that can be con-and the elements of MM. For instance, ifas parameters, MThe model were of the form M[c] is called a Lα, then M[c]Cohen-generic extension would just be Lα(c). of It turns out that, miraculously, M. M[c] is a model of ZFC. More over, it has the same ordinals as M and, there- fore, it is not of the formul ar, when we build$L inside L^{γ}$, for any ordinal M[c], c does not belong toγ. In partic- it.
These statements are by no means easy to prove, but very roughly what Cohen showed was that a formulaφ is true in M[c] if and only if there is an initial segment pt i on “of$cp$that “forces”forcesφto be true,” which relates finite binaryφ to be true. More over, the rela- sequences to formulas and is written defined in M . Therefore, to know whether a statementp φ, can beφ is true in M[c] one just needs to check whether there is an initial segment lar, using this result one can prove thatp of c such that p M[c]φ.
In particu-satisfies the ZFC axioms. In order to build a model where CH fails, one adds not just one generic real number butאM is the ordinal that plays the role ofאM 2 of them, whereא in M. That is, it is the second uncountable cardinal in2 2 M. This

IV. Branches of Mathematics

need not be the real for instance, M is of the formא2, and indeed it will not be if, L for some countable ordinalα in V . Adding אM 2 generic real numbers canα be done by finitely approximating any finite number ofthem while avoiding all avoidable properties they could have. Thus, instead of finite binary sequences we now work with finite sets of finite binary sequences indexed by ordinals less than sequence c:α < . leph(. leph M()M)2. A generic object will be aof Cohen reals over M , all different, and so CH is false in the generic extension M[ c:α <α. leph M ].2 addressed.
When we add the new real numbers toit is important that the However, there is an important point that needs to beα2 א of the new expanded model M , is the same asexpanded model and our work would have been wasted.(. leph M)2. Otherwise, CH might hold in the2 Fortunately, this is true, but again we must use the facts about forcing to prove it.
struct models where the cardinality ofor any other cardinal of uncountable The same kind of forcing argument allows one to con-cofinality R is$\aleph^{3}$, i.e., any, or א27, uncountable cardinal that is not the least upper bound of countably many smaller cardinals. The cardinality of the continuum is, therefore, undetermined by ZFC. Further more, since CH holds in Gödel’s constructible universe L and fails in the model constructed by Cohen using forcing, it is undecidable in ZFC. dent of ZF. Since AC holds instructing a model of ZF in which AC was false.
He did Cohen also used forcing to prove that AC is indepen-L, this amounted to con- this by adding a countable collection generic real numbers to a countable model$c^{n}$: Mnof ZF. To\in  N of see why this works, let M[ c: n \in  N ] that contains all the ordinals and the N be the smallest submodel of unordered set built inside$n M[Ac = {}$:$cn^{n} \in$: n N\in ]. One can then show that N. Thus, N is just L(A), as N is a model of ZF, but that inof A.
The reason is that any well-ordering ofn N there is no well-ordering A would be definable infinitely many elements of L(A)with a finite number of ordinals and A as parameters, and then each one of the indicating its ordinal position in the well-ordering. Butcnwould in its turn be definable by since the whole sequence of formula can distinguish one of thecns is generic over cns from another L, no unless they appear as parameters in the formula.
Since we can choose two differentc s that do not appear as parameters in the definition of the well-ordering ofand that well-ordering distinguishes all then c s from A, each other, we have a contradiction. Therefore, the set A cannot be well-ordered, so AC does not hold.n

IV.22. Set Theory

of AC from ZF and of CH from ZFC, a result for which he got the Fields Medal in 1966, many set theorists Immediately after Cohen’s proof of the independence started developing the forcing technique in its full gen-erality (notably Azriel Lévy, Dana Scott, Joseph Shoenfield, and Robert Solovay) and began to apply it to other well-known mathematical problems. For instance, Solovay constructed a model of ZF in which every set of real numbers is showing that AC is necessary for the existence of non-lebesgue measurable [III.55](/part-03/measures), there by measurable sets.
He also constructed a model of Zfc where every definable set of real numbers is Lebesgue measurable; therefore, nonmeasurable sets, although they can be proved to exist (see the example in sec-tion 6.1 below), cannot be explicitly given; Solovay and Stanley Tennenbaum developed the theory of iter-ated forcing and used it to prove the consistency of Suslin’s hypothesis (see section 10 below); Adrian Mathias proved the consistency of the infinitary form of ramsey’s theorem [IV.19 §2.2](/part-04/extremal-and-probabilistic-combinatorics);
Saharon Shelah proved the undecidability of the Whitehead problem in group theory; and Richard Laver proved the consistency of the Borel conjecture; to cite just a few remarkable examples from the 1970 s. It continues to be a research area of great interest, very sophisticated from the technical point of view and The forcing technique now pervades all of set theory. of great beauty. It keeps producing important results, with applications in many areas of mathematics, suchas topology, combinatorics, and analysis.
Especially influential has been the development over the last twenty-five years of the theory of proper forcing, introduced by Shelah. Proper forcing has proved very useful in the context of forcing iterations, and in the for-mulation and study of new forcing axioms, which will be dealt with in section 10, as well as in the analy-sis of cardinal invariants of the continuum. These are uncountable cardinals associated with various topolog-ical or combinatorial properties of the real line that can consistently take different values in different models obtained by forcing.
An example of a cardinal invariant is the least number of null sets needed to cover the real line. Another important development has been the use of class forcing by Anthony Dodd and Ronald Jensen for coding the universe into a single real num-ber, which shows that, amazingly, one can always use forcing to turn any model L(r ) for some real number Mr . A more recent con tr ibu-into a model of the form tion is the invention by W. Hugh Woodin of new powerful forcing notions associated with the theory of large

627

cardinals (see the next section), which have provided new insights into the continuum hypothesis (see the end of section 10). by forcing have made very clear that the axioms of ZFC are in sufficient to answer many fundamental math-The large number of independence results obtained ematical questions. Thus, it is desirable to find new axioms that, once added to ZFC, will provide a solution to some of those questions. We shall discuss some candidates in the next few sections. 6 Large Cardinals As we have already seen, the collection of all ordinal numbers cannot form a set.
But if it did, then to that set there would correspond an ordinal numberκ. This ordinal would coincide with the otherwiseא would be a larger ordinal. More over,κth cardinal אκ, since V would be a model of ZFC. We cannot prove in ZFC that there is an ordinalκ κ with these properties, for thenκ we would have proved in ZFC that ZFC has a model, which is impossible by Gödel’s second incompleteness theorem. So, why do we not add to ZFC the axiom that says that there is a cardinalκ such that Vκ is a model of ZFC?
regular cardinals, was proposed in 1930 by This axiom, with the further requirement that, that is, not the limit of fewer thansierpi ́nskiκ smaller[VI.77](/part-06/wacaw-sierpinski-18821969)κ be and cardinal axioms tarski [VI.87](/part-06/alfred-tarski-19011983), and it is the first of the. A cardinalκ with those properties is large- called inaccessible. cessibility, kept appearing during the twentieth cen - tury.
Some of them originated in generalizations to Other notions of large cardinals, which implied inac uncountable sets of the infinite version of Ramsey’stheorem, which states that if each (unordered) pair of elements ofω (i.e., of natural numbers) is painted either red or blue, then there is an infinite subsetω such that all pairs of elements of X have the same X of color. The natural generalization of the theorem toω turns out to be false.
However, on the positive side, Paul1 Erd ̋κ >os and Richard Rado proved that for every cardinal2א , if each pair of elements of κ is painted either red or blue, then there is a subset X of κ of size ω1 such that all pairs of elements ofis one of the landmark results of the X have the same color. this partition calculus, an important area of combinatorial set theory devel-oped mainly by the Hungarian school, led by Erd ̋os and András Hajnal. The problem of whether Ramsey’s the-orem can be generalized to some uncountable cardinal 628 leads naturally to cardinals that are calledpact.
A cardinalκ is weakly compact if it is uncountable weakly com- and satisfies the strongest possible Ramsey-type theo - rem: whenever all pairs of elements ofκ are painted either red or blue, there is a subset X of κ of size κ such that all pairs of elements of color. Weakly compact cardinals are inaccessible, so X have the same their existence cannot be proved in ZFC.
More over, it turns out that below the first weakly compact cardi - nal, assuming it exists, there are many inaccessible cardinals, so the existence of a weakly compact cardinal cannot be proved even if one assumes the existence of inaccessible cardinals. cardinals The most important large cardinals, the, are much larger than the weakly compact measurable ones, and were discovered in 1930 by Stanisław Ulam.
6.1 Measurable Cardinals A setbe obtained in countably many steps starting from the A of real numbers is a borel set [III.55](/part - 03/measures) if it can open intervals and applying the two operations of taking complements and countable unions. It ishas measure zero, if for everyε > 0 there is a sequence null, or of open intervals|I | < ε. It is ILebesgue measurable0, I1, I2, . . . such that Aif it is almost⊆ "n In and a Borel set, that is, if it differs from a Borel set by anull set.
To each measurable setnn A corresponds a num- ber\mu(A) \in [0,. nfty ], its measure, that is invariant under translation of measure of a countable union of measurable pairwise - A and is countably additive, that is, the disjoint sets is the sum of their measures. More over, the measure of an interval is its length. (See[III.55](/part - 03/measures) for a fuller discussion of these concepts.)measures measurable sets of real numbers.
For example, the fol-One can prove in ZFC that there exist non-Lebesgue low ing set was discovered in 1905 by Giuseppe Vitali. Define two elements of the closed interval[0,1] to beequivalent if they differ by a rational, and let A be a sub- set ofeach equivalence class. This requires one to make a[0,1] that contains precisely one element from large number of choices, which can be done by AC. To see thatp the set AAis not measurable, consider for each rational = {x + p}:$x \in A$. Any two of these sets are disjoint, because of the way we builtp A. Let B be the union of all interval[-1, 1].
AApcannot have measure zero, for then over all rational numbers p in the Bsible because itself would have measure zero, and this is impos-[0,1] ⊆ B. On the other hand, A can- not have positive measure either, since then B would IV. Branches of Mathematics have infinite measure, and this is impossible because B ⊆ [-1,2]. Since measurable sets are closed under taking complements and countable unions, all Borel sets are mea - sur able. In 1905 lebesgue [VI.72](/part - 06/henri - lebesgue - 18751941) showed that there are measurable sets that are not Borel.
While reading Lebesgue’s work, Mikhail Suslin noticed that Lebesgue had made a mistake in claiming that continuous images of Borel sets are Borel. Indeed, Suslin soon found a counterexample, which led eventually to the discovery of a new natural hierarchy of sets of reals beyond the Borel sets, the so-called projective sets. These are the sets that can be obtained from the Borel sets by taking continuous images and complements (see section 9 below). In 1917 Nikolai Luzin showed that all continuous images of Borel sets, the measurable.
If a set is measurable, then so is its com-analytic sets, are also ple ment, so all complements of analytic sets, the coanalytic natural to ask whether we can continue like this. In par-sets, are also Lebesgue measurable. It is therefore ticular, are continuous images of coanalytic sets, orsets, as they are known, also measurable? The answerΣ1 2 to this question turns out to be undecidable in ZFC:
in L there are Σ1 sets that are not Lebesgue measurable, and with forcing one can construct models where all sets are measurable.2(Σ1)2 Lebesgue-measurable set of reals hinges on the fact The proof given above of the existence of a non that Lebesgue measure is translation invariant. In fact, the proof shows that there cannot be any countably additive translation-invariant measure that extends Lebesgue measure and measures all sets of reals.
Thus, a natural question, known as the measure problem, is whether, if one drops the requirement of transla-tion invariance, there can exist some countably additive measure that extends Lebesgue measure and measures all sets of reals. If such a measure exists, then the cardinality of the continuum cannot beא with n < ω, etc. In fact, Ulam proved in 1930 that aא1, nor א2, nor any positive solution to the measure problem implies that the cardinality ofn Ris extremely large: it is greater than or equal to the least uncountable regular cardinal that is a limit of smaller cardinals.
He also proved that the existence of a nontrivial countably additive measure on any sure problem, or that there exists an uncountable car-set implies either a positive solution to the meadinalκ with a (nontrivial) \\{0,1\\}-valued κ-additive mea- sure that measures all its subsets. Such a cardinal is called compact, and therefore inaccessible. In fact, the set of measurable. Ifκ is measurable, then it is weakly

IV.22. Set Theory

weakly compact cardinals smaller than1, and soκ is itself the κth weakly compact cardinal. Itκ has measure follows that the existence of a measurable cardinal cannot be proved in ZFC, even if one adds the axiom that inaccessible, or weakly compact, cardinals exist (unless, of course, ZFC plus the existence of such cardinals is in consistent). A complete clarification of the measure problem was finally provided by Solovay, who showed that if the solution is positive, then there is an inner model with a measurable cardinal.
Conversely, if there is a measurable cardinal, then one can build a forcing extension where the measure problem has a positive solution. measurable cardinal is that the universe$L$: that is, there are non constructible sets, and even An unexpected consequence of the existence of a V cannot be non constructible real numbers. In fact, if there is ameasurable cardinal, then V is much larger than L. For instance, the first uncountable cardinal, inaccessible cardinal in$L$.
א1, is an avalanche of independence results, the hope arose that After the invention of forcing and the subsequent axioms asserting the existence of large cardinals, like measurable cardinals, would settle some of the questions that, thanks to the forcing technique, had been proved undecidable in ZFC. It was soon shown, however, by Lévy and Solovay, that large-cardinal axioms could not settle CH, as one could easily use forcing to change the cardinality of the continuum and make CHhold or fail with out destroying the large cardinals.
But Solovay proved in 1969 that, surprisingly, if there exists a measurable cardinal, then allΣ1 sets of real num- bers are Lebesgue measurable. So, while the axiom that2 asserts the existence of a measurable cardinal cannot settle the size of the continuum, it has a profound effect on its structure. It is indeed astonishing that measur-able cardinals, so far away from the sets of real numbers in the universe$V$, have such a strong influence on their basic properties.
While the relationship between large cardinals and the structure of the continuum is not yet fully understood, great progress has been madein the last thirty years through the work done in descriptive set theory and determinacy, which will be described in sections 8 and 9 below. Some of the deepest and most technically difficult work in set theory is currently devoted to the con struc-tion and analysis of canonical inner models for large cardinals.
These are analogues of L for large cardinals, that is, they are models built in some canonical way that contain all the ordinals and are transitive (i.e., they

629

contain all elements of their elements), and in which certain large cardinals exist. The larger the cardinal, the more difficult it is to build the model. This work is known as the One of the striking consequences of the inner model inner model program. program is that it provides a way of measuring the consistency strength of virtually any set-theoretic statementφ, using large cardinals. That is, there are large- cardinal axioms ZFC plusφ implies that of ZFC plus A1 and A2 such that the consistency of A1 and is implied by the consistency of ZFC plus A2.
We refer to A1 as aas an lower bound upper bound for the consistency of. In the fortunate cases when theφ and to A2 lower and upper bounds coincide, we obtain an exact measure of the consistency strength ofφ. An upper bound of ZFC plus A2 is usually obtained by forcing over a model A2, where as a lower bound A1 is obtained by inner model theory. Earlier in this section we saw that the consistency strength of a positive solution to the measure problem is exactly that of the existence ofa measurable cardinal. We shall see another important example in the next section.
strength of set-theoretic statements—or, even better, Knowing upper and lower bounds for the consistency knowing their exact consistency strength—is extremely useful for comparing them. Indeed, if the lower bound for a sentence another sentenceφ ψis greater than the upper bound for, then we can conclude, via Gödel’s incompleteness theorem, thatψ does not imply φ. 7 Cardinal Arithmetic Beyond the continuum hypothesis, understanding the behavior of the exponential function 2κ for arbitrary infinite cardinals theory.
Cantor proved that 2κ has been a motivating force in setκ > κ for all κ, and Dénes König proved that the cofinality of 2κ is always greater thanκ: that is, 2κ is not the limit of fewer than κ smaller cardinals. The GCH, which, as we saw, holds in the con-structible universe L, states precisely that 2κ has the least possible value, namely, the least cardinal greaterthanκ, usually denoted by κ+.
One might think that, as in the case of 2א0, by forcing it should be possi- ble to build models of ZFC where 2κ takes any pre- scribed value, subject only to the necessary requirement that its cofinality should be greater thanis true for cardinalsκ that are regular, that is, not theκ. This limit of fewer thanκ smaller cardinals. Indeed, William Easton showed that for any function lar cardinals such thatκ ⩽ . ambda implies F F(κ)on the regu-⩽ F(λ) 630 anding extension of F(κ)has cofinality greater than L in which 2κ = F(κ)κ, there is a forc-, for all regu - larwhere 2κ.
So, for instance, one can build a model of ZFCא0 = א , 2א1 = א , 2א2 = א , 2א3 = א , etc. This shows that the behavior of the exponential function for infinite regular cardinals is totally unde - 7 20 20 101 termined in ZFC, and anything possible can be attainedby forcing. dinals are called singular But how about nonregular cardinals? Nonregular car-if it is the supremum of fewer than singular . Thus, an infinite cardinalκ smallerκ is cardinals. For instance,א, n \in N, is the first singular cardinal.
Determining$\aleph^{ω}$, being the supremum of the the possible values of the exponential function at sin-gular cardinals is a very hard problem that has gen-$n$ erated much important research and involves, quite surprisingly, the necessary use of large cardinals. able cardinal with certain further properties that makeit much larger than ordinary measurable cardinals, Using a supercompact cardinal, which is a measur Matthew Foreman and Woodin built a model of ZFC in which GCH fails every where, i.e., 2κ > κ+ for all cardi- nalsκ.
But curiously, the value of the exponential func- tion at a singular cardinal of some how determined by its values at smaller regular uncountable cofinality is cardinals. Indeed, in 1975, Jack Silver proved that ifκis a singular cardinal of uncountable cofinality and 2α = α^+ for all α < κ, then 2^κ = κ^+. That is, if the GCH holds below is also the case for singular cardinals ofκ, then it also holds atcountableκ.
That this cofinality is a consequence of theesis (SCH), a general principle weaker than the Gch singular cardinal hypoth that completely determines singular cardinal exponentiation, relative to exponentiation for regular cardinals. A special case of SCH is the following. If 2א < א for all finite holds below$n$, thenא(2א)ω, then it must hold at= אω +1. So, in particular, if the GCHאn. Shelah usedω his powerful “PCF theory” to obtain the unexpected result that if 2ωאn < א for all n, then (2ω()א){ω} < א .
So, if GCH holds below on the possible values of 2(. lephω)ω, then there is a bound (in ZFC!)א . But can this value actuallyω4 be greater than the least possible one, namely particular, can the GCH first fail atω א? The answer is(. lephω)+1? In yes, but large cardinals are needed. Indeed, on the one hand Menachem Magidor proved the consistency of theω first failure of GCH atof the existence of a supercompact cardinal. Thus, the$\aleph^{ω}$, assuming the consistency existence of a supercompact cardinal is an upper bound for the failure of SCH.
On the other hand, using inner model theory, Dodd and Jensen showed that large car-

IV. Branches of Mathematics

III n0 n1 n2 n3 n4 n5 . . .. . . n2 k n2 k +1. . . . . . Figure 3 associated with a set A run of the infinite game A ⊆ [0, 1]. dinals are required for this to happen. An exact measure of the consistency strength of the failure of SCHwas later established by Moti Gitik. 8 Determinacy It turns out that the existence of very large cardi-nals, such as supercompact cardinals, has a dramatic effect on the properties of sets of real numbers, espe-cially when they can be defined in some simple way.
The link between the two appears through the analy-sis of certain infinite two-player games that are associated with sets of real numbers. Given a subset of[0,1], consider the following infinite game associ-$A$ ated with$A$: there are two players, I and II, who alternately choose a number begin with, player I plays ninth at equals either 0 or 1. To0, then player II plays n1, to which I answers by playing the game is displayed in figure 3. At the end of the run,$n2$, and so on. A run of the players have produced an infinite binary sequence: n , n , n , . . . .
This sequence can be regarded as the binary expansion of a real number0 1 2$r in [0$, 1]. Player I wins the game ifotherwise.r belongs to A and player II wins ning strategy for player I is simply to start by play-ing 0, where as if For example, if AA is the interval= [0,1 ), then player II wins the[0,1 2], then a win- game by playing 1 in her first move. But for most games, the question of who wins is not decided after4 any finite number of moves.
For instance, ifset of rational points of[0, 1], then one can easily see A is the that player II has a strategy for winning the game (for example, whatever player I does, player II will win if she plays 01001000100001. . . ), but she will not win at any finite stage of the run. The game is determined if one of the two players has a winning strategy. Formally, a player II is a functionf that assigns 0 or 1 to each strategy for finite binary sequence of odd length. It is a winning strategy f (n0, n1 if player II always wins the game if she plays, . . .
, n ) in her kth turn, whatever moves are made by player I. Similarly, one can define a winning2 kst rate gy for I. We say that the setthe game associated with A is determined. One might A is determined if

IV.22. Set Theory

guess that every game is determined, but actually it is quite easy, using AC, to prove the existence of a game that is not determined. ciated with certain classes of sets of reals implies that all sets in the class have properties similar to those of It turns out that the determinacy of the games assothe Borel sets.
For example, the(AD), which asserts that all sets of reals are determined, axiom of determinacy implies that every set of reals is Lebesgue measurable, has the property of Baire (i.e., differs from an open set by a set of first category), and has the perfect set prop-erty (i.e., contains a perfect set if it is uncountable). To give the flavor of a typical argument, let us indicate why every set First, one observes that it is enough to show that if A of reals is Lebesgue measurable. all measurable subsets ofbe null.
And for this one plays, for every A are null, then A ε >itself must0, the covering gameso that the sequence for A anda = ε. In this game, player I playsn , n , n , . . . represents an element ofof) finite unions of rational intervals, with measures A, and player II plays (binary encoding(s0()2)4 adding up to at most It can be shown that if every measurable subset ofε, while attempting to cover A ais. null, then player I cannot have a winning strategy. So by AD there must be a winning strategy for II. Using this strategy one can show that the outer measure ofat mostε.
And since this works for all ε > 0, A must A is be null. sets of reals, it implies the negation of AC, so AD is in consistent with ZFC. However, weaker versions of Ad while AD rules out the existence of badly behaved are compatible with, and even follow from, ZFC. Indeed, Donald Martin proved in 1975 that ZFC implies that every Borel set is determined. More over, if there exists ameasurable cardinal, then every analytic set, and therefore also every coanalytic set, is determined.
A natural question, therefore, is whether the existence of larger cardinals implies the determinacy of more complex sets such as the$Σ^{1} sets$. the determinacy of simple sets of reals was first made explicit by Leo Harrington, who showed that the deter-The intimate connection between large cardinals and2 minacy of all analytic sets is in fact equivalent to a large-cardinal principle slightly weaker than the exis-tence of a measurable cardinal.
As we shall shortly see, large cardinals imply the determinacy of certain sim-ply definable sets of reals, the so-called projective sets, while the determinacy of those sets implies in turn the existence of the same kind of large cardinals in some inner models.

631

Descriptive Set Theory9 Projective Sets and

As we have seen, very basic questions about sets ofreal numbers can be extremely hard to answer. However, it often turns out to be possible to answer them for sets that occur “in nature,” or that can be explicitly described. This raises the hope that one might be able to prove facts about definable sets of reals that can not be proved for arbitrary sets. The study of the structure of definable sets of reals is the subject ofsets are the Borel sets, and also the descriptive set theory.
Examples of such projective sets, which are sets that can be obtained from Borel sets by taking continuous images and complements. An equiv-alent definition of the projective sets is that they are subsets ofof Rn by a mixture of projecting to a lower dimension R that can be obtained from closed subsets and taking complements. To see how this relates to definability, consider projecting a subset$A ⊂ R^{2} down$ to the that there exist sx-axis. The result will be the set of ally with (x, y) \in  A. Thus, projectionx such corresponds to existential quantification.
Taking com-ple ments corresponds to negation, so one can combine the two and obtain universal quantification as well. Onecan therefore think of a projective set as a set that is definable from a closed set. sets, they are projective. And so are the complements Since analytic sets are continuous images of Borel of the analytic sets, the coanalytic sets, and the con-tinuous images of coanalytic sets, the$Σ^{1} sets$.
More complex projective sets are obtained by taking com-ple ments ofΣ1 sets, the so-called Π1 sets, their contin-2 uous images, called hierarchy of increasing complexity, in accordance with2(Σ3)1, etc. The projective sets form a2 the number of steps (always finite) that are necessaryto obtain them from the Borel sets. Many sets of reals that appear naturally in usual mathematical practice are projective.
More over, the results and techniques of descriptive set theory, although originally developed for the study of sets of reals, also apply to definable sets in any Polish space (a separable and completemetriza ble space). These include basic examples suchas Rn, C, separable [III.62](/part-03/normed-spaces-and-banach-spaces), etc., where projective sets arise in a very natural way.
For example, banach spaces in the space on[0, 1] with the sup norm, the set of every where dif-C[0,1] of continuous real-valued functions ferentiable functions is coanalytic, and the set of func-tions that satisfy the mean value theorem isΠ1. Thus, since descriptive set theory deals with rather natural2 632 sets in Polish spaces of general mathematical interest, it is not surprising that it has found many applications in other areas of mathematics such as harmonic analysis, group actions, ergodic theory, and dynamical systems.
all analytic sets, and hence also all coanalytic sets, are Lebesgue measurable and have the Baire property, and Classical results of descriptive set theory are that that all uncountable analytic sets contain a perfect set. However, as we have already pointed out, one cannot prove in ZFC that all since in L there are counterexamples. By contrast, ifΣ2 1 sets have those properties, there exists a measurable cardinal, then they do have them. But what about more complex projective sets?The theory of projective sets is closely tied to large cardinals.
On the one hand, Solovay showed that if the existence of an inaccessible cardinal is consistent, then so is the statement that every projective set of reals is Lebesgue measurable, has the Baire property, etc. On the other hand, Shelah showed, quite unexpectedly, that the inaccessible cardinal is necessary, in the sense that if allΣ1 sets are Lebesgue measurable, then א is an inaccessible cardinal in3 L.1 lytic sets are shared by the projective sets, assuming that they are determined.
So since the determinacy of Nearly all the classical properties of Borel and anaall projective sets cannot be proved in ZFC and since it allows for the extension of the theory of Borel and ana-lytic sets to all projective sets in a very elegant and satisfactory way, it constitutes an excellent candidate for anew set-theoretic axiom. This axiom is known as projective determinacy projective set is Lebesgue measurable, has the Baire(PD). It implies, for instance, that every property, and has the perfect set property.
In partic - ular, since every uncountable perfect set has the same cardinality as R, it implies that there is no projective counterexample to CH.One of the most remarkable advances in set theory over the last twenty years is the proof that PD follows from the existence of large cardinals. Martin and John Steel proved in 1988 that if there exist infinitely manyso-called Woodin cardinals, then PD holds. Woodin cardinals lie between measurable and supercompact in the hierarchy of large cardinals.
Subsequently, woodin showed that, surprisingly, the hypothesis that for each nis necessary in order to obtain the consistency of PD.it is consistent that there exist n Woodin cardinals Thus the existence of infinitely many Woodin cardinals is a sufficient, and essentially necessary, assumption for extending the classical theory of Borel and analytic IV. Branches of Mathematics sets to all projective sets of reals, and more generallyto all projective sets in Polish spaces.
cardinal axioms, not only in descriptive set theory but also in many other areas of mathematics, their status as In spite of the enormous success of the known large true axioms of set theory is still a matter of debate. Thisis more so in the case of very large cardinals such as the supercompact ones, the reason being that there isas yet no inner model theory available for them, which means that there is not even strong evidence for their consistency.
However, it should be noted that, as Harvey Friedman has shown, large cardinals are necessary even for proving quite simple-looking and rather nat-ural statements about finite functions on the integers, which provides evidence for their essential role in even the most basic parts of mathematics. Another shortcoming of the known large-cardinal axioms is that they can not decide some fundamental questions. The most conspicuous is CH, but there are others.
10 Forcing Axioms Another old and basic question about the continuum that the known large-cardinal axioms cannot solve is Suslin’s hypothesis linearly ordered set that is dense (i.e., any two distinct(SH). Cantor had proved that every elements have another element in between), complete(i.e., every nonempty subset with an upper bound has a supremum), separable (i.e., contains a dense countable subset), and with out endpoints is order-isomorphic tothe real line.
In 1920 Suslin conjectured that if instead of separability one assumes the weaker condition, or CCC, which demands that every pairwise-countable chain disjoint collection of open intervals should be at most countable, then it must still be isomorphic to R. The importance of SH for the development of set theory is that it led to the discovery of a new class of axioms, theso-called forcing axioms. In 1967, Solovay and Tennenbaum used forcing to construct a model in which SH holds. The idea is to usethe forcing to destroy any counterexamples that there might be to SH.
But when one does this one may create new ones, and the result is that one needs to force again and again, transfinitely many times. The iteration of forcing is technically cumbersome and difficult to control, for many unwanted things can happen at the limit stages. For instance, it may become countable.ω1 may be “collapsed,” i.e., general, a forcing argument involves a partially ordered Fortunately, these difficulties can be dealt with. In

IV.22. Set Theory

set. (In the case we looked at earlier, it was the setof all finite binary sequences, with$p < q if p was$ a proper initial segment ofq.) If one starts with a model where GCH holds, uses only partial orderings that are CCC—that is, in which every set of in compatible elements is countable—and takes so-called limits at the limit stages, then inω steps one can direct destroy all counterexamples so that SH holds in the final model.
On the other hand, Jensen proved in 19682 that a counterexample to SH exists inthe undecidability of SH in ZFC.L, there by proving Martin isolated a new principle now known as axiom From the construction of Solovay and Tennenbaum,(MA), which generalizes the well-known Martin’s Baire category theorempact Hausdorff topological space, the intersection of a. The latter states that in every com countable collection of dense open sets is nonempty. MA says the following: In every compact Hausdorff CCC topological space, the intersection ofא dense open sets is nonempty.
lection of pairwise-disjoint open sets is countable) isnecessary, for with out it the statement is false. It is easy The condition that the space be CCC (i.e., every colto see that MA implies the negation of CH, for if there are onlyא real numbers, then the intersection of theא1 dense open sets1 R \ {r }, as r ranges over all the real numbers, is empty. However, MA does not decide the cardinality of R. questions that are undecidable in ZFC. For example, it implies SH and that every MA has been used with great success to solve manyΣ1 set is Lebesgue mea- sur able. But is MA really an axiom?
In what sense, ifany, is it a natural, or at least plausible, assumption2 about sets? Is the fact that it decides many ZFC und ecid-able questions sufficient for it to be accepted as being on a par with the ZFC axioms or the axioms of large cardinals? We shall come back to this. MA has many different equivalent formulations. The original formulation of Martin was more closely con-nected with forcing—hence the term forcing axiom. Roughly speaking it said that if you have a CCC par-tial order, then you can avoidא avoidable properties, and not just countably many.
This allows one to prove the existence of generic subsets of the partial order,1 over models Stronger forcing axioms can be obtained by expand-$M \text{of size} \aleph^{1}$. ing the class of partial orderings to which MA applies while keeping the axiom consistent. An important such strengthening is the proper forcing axiom (PFA), which

633

is formulated for partial orderings that are Properness is a property weaker than the CCC that proper. was discovered by Shelah and is particularly useful when working with complicated forcing iterations. The strongest possible forcing axiom of this type was dis-covered by Foreman, Magidor, and Shelah in 1988. It is called with ZFC, assuming the consistency of a supercompact Martin’s maximum (MM) and is consistent cardinal. example, PFA, and therefore also MM, implies the axiom of projective determinacy (PD), the singular cardinal Both MM and PFA have striking consequences.
For hypothesis (SCH), and that the cardinality of R isא2. them with out having to go into the details of forcing, just as An advantage of forcing axioms is that one can apply♦ and save one from having to go into the details of constructible sets. A very good example ofthis is PFA and some combinatorial principles derived from it, like the so-called have been used with great success by Stevo Todor-open coloring axiom, which cevic to solve many outstanding problems in general topology and infinite combinatorics.
As we have already pointed out, forcing axioms are not as intuitively evident as the ZFC axioms, or even the axioms of large cardinals, so one can ask to what extent they should be considered as true axioms ofset theory rather than just useful principles for showing that certain statements are consistent with ZFC. In the case of MA and some weaker forms of PFAand MM, some justification for their being taken as true axioms is based on the fact that they are equiv-alent to principles of generic absoluteness.
That is, they assert, under certain restrictions that are necessary to avoid in consistency, that does exist. More precisely, if some set having certain everything that might exist, properties could be forced to exist over having the same properties already exists (in V , then a set V ). So, like the axioms of large cardinals, they are maximality principles, i.e., they attempt to make possible. V as large as a seton subsets of For example, MA is equivalent to the assertion that if X having some properties that depend exclusivelyω could be forced to exist over V using a CCC partial ordering V .
This character ization of MA in terms of generic abso-1 P, then such an X already exists in lu ten ess provides some justification for regarding MAas a true axiom of set theory. The analogous principle of generic absoluteness, but for proper partial order-ings instead of CCC, is known as the bounded proper forcing axiom (BPFA). Although weaker than PFA, BPFA

634

is strong enough to decide many questions that the large-cardinal axioms are unable to settle. Most notably, Justin Moore has recently proved, following a series of results by Woodin, David Asperó, and Todorcevic, that BPFA implies that the cardinality of R isא2. establish strong underlying connections between large To finish, we briefly mention some deep results that cardinals, inner models, determinacy, forcing axioms, generic absoluteness, and the continuum. These results hold under the assumption that for every ordinal there exists a Woodin cardinal greater thanα.
α theory of The first one, due to Shelah and Woodin, is that the L(R) is generically absolute. That is, all sen- tences with real numbers as parameters that would hold in the L(R) of any generic extension of V are already true in the real lu ten ess implies that all sets of reals in L(R). This kind of generic abso-L(R), and in particular the projective sets, are Lebesgue measur-able, have the Baire property, etc. Further more, by refining the Martin–Steel result that large cardinals imply PD, Woodin showed that in L(R) every set of reals is determined.
which he calls Another result of Woodin is that there is an axiom,$( {}^{*})$, that is intended to play the role for subsets ofin the sense that it decides “practically all” questionsω1 that PD plays for sets of natural numbers, about those sets. Of course, no consistent axiom can really decideω, since by Gödel’s incompleteness theorem there will all questions that refer only to subsets of always be undecidable arithmetical statements. So, toformulate precisely the notion of1 deciding practically all questionsΩ-logic, that strengthens ordinary first-order logic.
One, Woodin introduces a new logic, called of the main features of ments inΩ-logic are generically absolute. Under suit-Ω-logic is that the valid state- able large-cardinal hypotheses,$( {}^{*}) \text{is consistent in} Ω-$ logic and decides inΩ-logic all questions that refer only to subsets ofΩ-conjecture, whose formulation is quite technical andω1. The main open problem is the beyond the scope of this article.
If the true, then any axiom compatible with the existence ofΩ-conjecture is large cardinals that decides all questions that depend exclusively on subsets ofω in Ω-logic must imply the negation of CH. Thus, the theories ZFC plus CH and Zfc plus not-CH are not equally reasonable from the point1 of view ofΩ-logic, since in the presence of large car- dinals CH puts an unnecessary limitation on the pos-si bility of settling all natural questions about subsets of$ω^{1}$.

IV. Branches of Mathematics

11 Final Remarks

In this short account of set theory, we have reviewed some of the key developments since its beginnings inthe late nineteenth century. What started in the hands of Cantor as a mathematical theory of transfinite num-bers has developed to become a general theory of infinite sets and a foundation for mathematics. The fact that it has been possible to unify all of classical math-ematics into one single theoretical framework, the ZFC axiom system, is certainly remarkable.
But beyond this, and most importantly, the techniques developed by set theory, such as construct i bility, forcing, infinite combinatorics, the theory of large cardinals, determinacy, the descriptive theory of definable sets in Polish spaces, etc., have turned it into a discipline of great depth and beauty, with fascinating results that stimulate and challenge our imagination, and with numerous applications in areas such as algebra, topology, real and complex analysis, functional analysis, and measure theory.
In the twenty-first century, the ideas and techniques gen-erated within set theory will surely continue to contribute to the solution of outstanding mathematical problems, old as well as new, and will help mathematicians gain an ever deeper insight into the complexities and vastness of the mathematical universe.

Further Reading

Foreman, M., and A. Kanamori, eds. 2008.Theory. New York: Springer. Handbook of Set Friedman, S. D. 2000.De Gruyter Series in Logic and Its Applications, volume 3.Fine Structure and Class Forcing. Hrbacek, K., and T. Jech. 1999.Berlin: Walter de Gruyter.3 rd edn., revised and expanded. New York: Marcel Dekker. Introduction to Set Theory, Jech, T. 2003.Kanamori, A. 2003.Set Theory The Higher Infinite, 3 rd edn. New York: Springer., 2 nd edn. Springer Kechris, A. S. 1995.Monographs in Mathematics. New York: Springer.ate Texts in Mathematics. New York: Springer. Classical Descriptive Set Theory.
Gradu Kunen, K. 1980.Proofs. Amsterdam: North-Holland. Set Theory: An Introduction to Independence Shelah, S. 1998.York: Springer. Proper and Improper Forcing, 2 nd edn. New Woodin, W. H. 1999.Axioms, and the Nonstationary Ideal The Axiom of Determinacy, Forcing. De Gruyter Series in Logic and Its Applications, volume 1. Berlin: Walter de Gruyter. Zeman, M. 2001.Gruyter Series in Logic and Its Applications, volume 5.Inner Models and Large Cardinals. De Berlin: Walter de Gruyter.

IV.23. Logic and Model Theory

IV.23 Logic and Model Theory

David Marker

1 Languages and Theories

Mathematical logic is the study of formal languages that are used to describe mathematical structures and what these can tell us about the structures themselves. We can learn a lot about a formal language by inves-tig at ing which of its sentences are true for the structure it describes, and we can learn a lot about the structure by investigating the subsets of it that can be defined using the language. In this article, we shall see several examples of languages and the structures that they are used to describe.
We shall also see instances of the remarkable phenomenon that theorems in logic can some times be used to prove “purely mathemat i-cal” results that seem to have nothing to do with logic. This introductory section briefly introduces some of the basic ideas that will be needed to understand the later sections. All the formal languages that we consider will be extensions of a basic logical language that we shall denote by L .
The statements, or formulas, of this language are made up of the following components:0 variables, which are denoted by letters of the alphabet such asx or y, or letters with subscripts such as v , v , . . .; thethe parentheses logical connectives“(” and “∧, )∨”; the,¬, \to equality symbol, ↔, which we rea(d1)2“$=$”; as “and,” “or,” “not,” “implies,” and “if and only if”;
andthe quantifiers∃ and ∀, which we read as “there exists” and “for all.” (If these symbols are unfamiliar to you, then you should read the language and grammar of mathematics article.) Here are a couple of formulas of[I.2](/part-01/language-and-grammar) before attempting to read this$L$: (ii)(i)∀∀xx ∀(xy=∃yz ∨(zx==xz∧)$. z = y$); The first of these says that if any object exists at all then there are at least three objects, and the second says that y and z are the only objects. There is an important dif- ference between the two formulas:
the variables andzthat occur in the first formula are all boundxvari-, y, ables, which means that they are all attached to quantifiers, where as in the second formula, only the vari-ablex is bound, while the variables y and z are free. This means that the first formula expresses a statement about some mathematical structure, while the second

635

is a statement about not just a structure but also the particular element sy and z. formulas out of smaller ones. We will not give them all, but for example if There are various rules that allow one to build largerφ and ψ are formulas, then ¬φ,φ ∨ ψ, φ ∧ ψ, φ \to  ψ, and φ ↔ ψ are all formulas. In general, if using logical connectives (and parentheses), then weφ is built out of smaller formulas φ1, . . . , φn call important way to modify a formula is quantification:φ a Boolean combination of φ1, . . . , φn.
Another$if$∀xφ(x)φ(x) is a formula involving a free variable and ∃xφ(x) are both formulas.
 x, then which makes them not very useful for describing inter-esting mathematical structures. Suppose, for example, The formulas just discussed are “purely logical,” that we wanted to study real solutions to algebraic and exponential equations over the field [I.3 §2.2](/part-01/fundamental-definitions) of real numbers.
We can think of this as studying the“mathematical structure” R$\exp = (R$,+, ·, . xp , <,0,1), where the right-hand side is a septuple that consists ofthe set R of real numbers, the binary operations of addition and multiplication, the[III.25](/part-03/the-exponential-and-logarithmic-functions), the “less than” relation, and the real numbers 0 exponential function and 1.The various components of this structure are of course related to each other in many ways, but we can-not express these relationships unless we are prepared to extend the basic language wanted to write, in a formal way, the
statement that L0. For example, if we the exponential function turns addition into multipli-cation, then the obvious thing to write down would be (i)$∀x∀y \exp (x) · \exp (y) = \exp (x + y)$. Here we have two quantifiers, two bound variables andy, and the equals sign, but the rest of the for-x mula involves extraneous elements such as “$+$”, “·”, and “exp”. Thus, to discuss the structure the language L to a language L , by adding in the R. xp , we extend symbols “these come with various syntactic rules that reflect the$+$”, “$·^{0}$”, “exp”, “$<$”, “0”, and “1”.
Of course,$\exp$ fact that “$+$” is a binary operation, “exp” is a function, and so on. For instance, these rules would allow us to write exp(x + y) = z but would forbid us to write. xp Here are three more(x = y) + z. L-formulas:

$\exp$

(iii)(iv)(ii)$∀∃∃x \text{xy yx} (x >^{2}^{2}= −= 0x$1;.$→ ∃y \exp (y) = x)$;

636

We interpret these formulas as the assertions “for all posit i vex, there is a y such that ey = x,” “-1 is a square,” and “above are declarative statements about the structurexis a square.” The first three formulas R. xp . Formulas (i) and (ii) are true in R. xp , while (iii) is false. Formula (iv) is different because able: thus, it expresses a property ofxx. (For instance, is a free vari- it is true ifx = 8, but false if x = −7.) A sentence is defined to be a formula with no free variables. Ifan L -sentence, then φ is either true or false in Rφ is.aφ(a1 If, . . . , a1φ. xp , . . .
, ais a formula with free variablesn are real numbers, then we writen) if the formula φ is true for the partic-x1, . . . , x Rn . xp , and . xp 2 ular sequence$(a1$, . . . , an). We think of the formula as defining the set ${(a^{1}}$, . . . , an) \in Rn: R$\exp 2 φ(a1, . . . , an)$, that is, the set of all sequences$(a^{1}$, . . . , an) for which the formula is true when you seti. For example, the formula xi to equal ai for every∃z (x = z2 + 1 ∧ y = z · . xp (. xp (z))) defines the parametrized curve$/+$, 0 t2 + 1, t(ee)t:$t \in R$.

tant point, let us consider the structure For another example, one that illustrates an impor-(Z, +,·,0,1): that is, the integers, with addition, multiplication, 0, and 1. The language used to describe this structure is the tion here lists the symbols that we add to the basic language of rings,$Lrng = L(+$,·,0,1). (The nota- language usual ordering on$L^{0}$.) The language Z, but, surprisingly, this ordering can Lrng has no symbol for the nevertheless be defined in terms ofthe nonobviousness of this fact, the reader is encour-$L^{r}ng$.
(To appreciate aged to try to work out why it is true before reading on.) lagrange tive integer is a sum of four squares. It follows that the The trick is to use a well-known theorem due to[VI.22](/part-06/joseph-louis-lagrange-17361813), which asserts that every nonneg a statementx ⩾0 can be defined by the formula∃y1∃y2∃y3∃y4 x = (y1)2 + (y2)2 + (y3)2 + (y4)2. (Of course, we are also using the fact that a negative integer cannot be written as a sum of four squares.
Note too that a similar trick would work even if all one knew was that every nonnegative integer was a sum ofa hundred squares.) Once one has a way of expressing the statement thatxis nonnegative, it is easy to define the symbol “$<$”. The interesting aspect of this is that

IV. Branches of Mathematics

the reformulation was not obvious—it depended on a genuine mathematical theorem. restricted in several ways, of which two stand out in particular. It is important to understand that formulas are •Formulas are finite. We do not allow formulas like ∀x > 0 (x < 1 ∨ x < 1 + 1 ∨ x < 1 + 1 + 1 ∨ · · · ), which would express the fact that R has the so called Archimedean property. (If we did, then it would be much easier to define “$<$” above.) •Quantifiers range over elements of the structure, and not subsets.
This rules out a “second-order”formula such as ∀S ⊆ R (if Sthenis bounded above S has a least upper bound, ), which would express the completeness of R by quantifying over all subsets S of R. Since we look just at “first-order” formulas, what we are studying is often called first-order logic. let us discuss them more generally. Acally something like Now that we have seen some examples of languages, L or Labove: that is, a set language is basiof symbols (combined with the basic logical symbols)together with some rules concerning their use.
If$\exp ^{r}ng L \text{is a}$ language, then anture in which all the sentences of L-structure is a mathematical struc-L can be interpreted. (This concept will become clearer in a moment, whenwe give a couple of examples.) An L-theory T is just a set ofthat an LL-sentences, which one can think of as axioms-structure might or might not satisfy. A model$of$ T is then an L-structure M in which all the sentences ofstructure was a model for the formulas (i) and (ii) of T, suitably interpreted, are true.
For instance, the the language model for the same two formulas would be one in which L. xp  that we discussed earlier. (Another we replaced the exponential function by the function2$x$ and interpreted “exp” as referring to that function instead.)The justification for the word “theory” is clearer in another example, the language of$L = L(\circ$, e). Here, ◦ is a binary operation symbol groups[I.3 §2.1](/part-01/fundamental-definitions), andgrpe is a constant. We might look at the theory T grp consisting of the sentences (iii)(ii)(i)∀∀∀xx xx∀∃y xy◦∀ez x◦=ye◦◦=(yxy=◦◦ z)xx;==e(x;◦ y) ◦ z;
which are the usual axioms for groups.

IV.23. Logic and Model Theory

mat ical structure M, a binary operation In order to interpret this language in some mathe-M we needf: M2 M\to  Mto consist of a set, and an element a \in  M. We then interpret “◦” as referring tof, “ e” as referring to the element$a$, and quantification as being over the setof (iii) is that for every M. Thus, for example, the interpret at io nx in M there exists a y in M such thatf (x, y) = a. Under this interpretation of the symbols ofstructure. This LLgrp, the structure-structure is a model of M becomes an T Lif ingrp- addition the sentences (i), (ii), and (iii) are all true.
since sentences (i)–(iii) are the axioms for groups, a model ofgrp grp

Tgrp is nothing other than a group.

of a theory model of We say that an T . That is, T, and write L-sentence T 2 φT if2φφφis a, ifis true in every struc-logical consequenceφ is true in every ture in which all the sentences of symbol “2” has two different meanings, according to T are true. Thus, the whether there is a structure or a theory on the left-hand side. However, these two meanings are closely related in that they are both concerned with truth in models: M 2 φ means that φ is true in the model M, and T 2 φ, sible model ofa “semantic” notion of entailment.as we have just said, means that T.
Either way, the symbol “φ is true in every pos-2” stands for in Returning to the example of groups, if Lgrp, then Tgrp 2 φ if and only if φ is true for everyφ is a sentence group. So, for instance, Tgrp 2 ∀x∀y ∀z (xy = xz ∨ y = z),

because ifxy = xz, then we can multiply both sides on the leftx, y , and z are elements of any group and by the inverse of x to deduce that y = z. logic. We can now describe some of the basic problems in (i) Given an L-theory T, can we decide if a sentenceφ is a logical consequence of T, and if so how? (ii) Given an interesting mathematical structure, like R , or(N$, +, ·, 0, 1)$, or the complex field, and a languagewe determine which. xp  L that describes the structure, can L-sentences are true of the (iii) Given a structure described by a language, do the structure?
subsets of the structure that can be defined inthe language have special properties? Are they in some sense “simple”? For example, earlier we sawhow to use Lto define a certain curve in the plane. Now consider a very complicated set such$\exp$

637

as a[IV.14 §2.8](/part-04/dynamics). Is it possible to prove that these sets cantor set [III.17](/part - 03/dimension) or the mandelbrot set cannot complex” in some sense?be defined in L . xp because they are “too 2 Completeness and Incompleteness Let show that T be an T L2-theory and letφ, we must show thatφ be anφLholds in every - sentence. To model ofdaunting task, but fortunately it is not necessary, since T . Checking all models of T sounds like a instead we can use a mathematical logic is to say precisely what this means.proof.
One of the first tasks in set of sentences inφ Suppose, then, thatis a formula of LL. Informally speaking, a proof of, i.e., an L is some language and that L - theory. Suppose also that T is aφ assumes the statements ofφ. We express this idea formally as follows. AT and ends up establishing proof ofφ(which one can think of as the lines of the proof) with from Tis a finite sequence of L - formulas ψ1, . . . , ψm the following properties: (i) eachof T, or a formula that follows from the previousψi is either a logical axiom, or a sentence formulasψ1, . . .
, ψi - 1 by means of simple logical (ii) rules;ψm = φ. We shall not say precisely what a “simple logical rule”is, but three examples are • from φ and ψ it follows that φ ∧ ψ; •• from from φφ(x)∧ ψit follows thatit follows that∃φv φ(v); . The other possible rules are similarly elementary. stressed. The first is that they are finite, which may seem too obvious to mention but is important because There are three points about proofs that need to be it has a number of consequences that are not obvious. The second is that proof systems have to be sound:
if there is a proof ofφ from T , then φ is true in every model ofduce the notation T. To put this more succinctly, let us intro - T * φ for the statement that there is a proof ofthat if T * φφ then from TT2. Then soundness is the assertionφ. This is why we can prove thatφthan by looking at all the models. The third point is thatis true in every model of Tby finding a proof rather it is easy to check whether a sequence of sentences isa proof. More precisely, there is an algorithm that can 638 look at a sequence really is a proof ofφψfrom1, . . .
, ψT.m and decide whether it It is not too surprising that ifφ can be proved from T, then able is that the converse is also true: ifφ is true in all models of T . Much more remark-φ cannot be proved fromwhichφis false. This tells us that two very different T , then there must be a model of T in notions—the finitistic, syntactic notion of “proof” and the semantic notion of “logical consequence,” which concerns truth in models—always agree. This result is known as Gödel’s completeness theorem. Here is its formal statement. Theorem. L-sentence.
Then Let T Tbe an2 φ if and only if L-theory and let T * φ. φ be an there is an algorithm to decide whether a sentence is Suppose that T is a simple theory like Tgrp, where in simple, but some theories might have infinitely many T. (In the case of Tgrp this algorithm is particularly sentences.) We could write a computer program which, given a formulaφ as its input, would systematically generate all possible proofs whetherσ was a proof of φσ. If such a program finds afrom T and check to see proof ofφ, then it halts and tells us that T 2 φ. We say that However, one might hope for more. If{φ}:
T 2 φ is recursively enumerable T. 2 φ, our program above will go on searching for ever, so it will never tell us that there is no proof ofφ. We say that an L - theory T is decidable if there is a computer program which, when given anhalt and tell us, one way or another, whether L - sentence φ as input, will always T 2 φ. Such a program would have to be cleverer than theone that just checks all possible proofsσ, and unfortu- nately such a program does not have to exist:
as gödel [VI.92](/part - 06/kurt - gdel - 19061978) proved in his famous rem [V.15](/part - 05/gdels - theorem), many important theories are undecidable.incompleteness theo Here is a first version of his theorem, concerning the theory of the natural numbers (or theory of N for short), which means the set of all sentences in the language L that are true of the structure (N, +,·,0,1). rng Theorem.cid able. The theory of the natural numbers is undeis the theory of about At first, this might seem rather strange: after all, if N.
So a sentence N, then Tφ contains all true sentencesis provable from T if and T only if it has a one-line proof (the line being However, this does not makeφ decidable, because theφ itself). theory for deciding whether T is very complicated and there is no algorithmφ belongs to T . IV. Branches of Mathematics rem is to associate a natural number with each com-One approach to proving the incompleteness theoputer program in such a way that statements about programs can be recast as statements about natural numbers.
The theory of N then determines whether a program as the halting problem P halts on input. Since the halting problem wasx, thus solving what is known shown byof the proof can be found in turing [VI.94](/part - 06/alan - turing - 19121954) to be undecidable (a sketch the insolubility of the halting problem N is undecidable. [V.20](/part - 05/the - insolubility - of - the - halting - problem)), it follows that the theory of How can we understand the theory of N? One might hope to find a much smaller theory that yielded the same true sentences.
That is, we could try to find a simple set of axioms about N that we know are true and hope that every true sentence follows from these axioms. A good candidate ismetic, or PA. This is a theory in the language first-order Peano arith-$L(+$, ·, 0, 1) that involves a few simple axioms about addition and multiplication, such as

$∀x∀y x · (y + 1) = x · y + x$,

together with axioms for induction.

The reason is that the obvious statement that expresses the principle of mathematical induction, namely Why do we need more than one axiom of induction? ∀A (0 \in  A ∧ ∀x x \in  A \to  x + 1 \in  A) → ∀x x \in  A, is not a first-order sentence, because the quantifier is applied to all subsets A of N. (It is also not a sentence in Lrng since it uses the symbol “$\in$”, but this is a less fundamental problem.) To get around this difficulty, onehas a separate axiom of induction for each formulaφ. It is the assertion that $[φ(0) ∧ ∀x (φ(x) \to φ(x + 1))] → ∀x φ(x)$.
In words, this says that ifφ(0) is true and φ(x + 1) is true when eve rx in N. φ(x) is true, then φ(x) is true for every one might hope that PAin Most of number theory can be formalized in PA and N. Sadly, this is not true. Here is a second ver-* φ for every φ that is true sion of Gödel’s incompleteness theorem. Recall that thenotation N2 ψ means simply that ψ is true in N. Theorem. There is a sentenceψ such that N 2 ψ but PA$* ψ$. is a sentence Another way to state this result is to say that thereψ such that PA * ψ and PA * ¬ψ. To see

IV.23. Logic and Model Theory

that this is an equivalent statement, let tence. Then precisely one ofψ and ¬ψ is true. There-ψ be any sen- fore, if the theorem is false, then PA must prove eitherψ or ¬ψ. But this means that we can decide which by simply going through all possible proofs in PA until wefind a proof ofψ or a proof of ¬ψ. sentence was a self-referential sentence that effectively asserted Gödel’s original example of a true but unprovable “I am not provable from PA.” More precisely, he found a sentence was able to show thatψ is true in N if and only ifψ for which heψ is not provable from PA.
With more work he showed that there is a sentence that asserts “PA is consistent” that is unprovable from PA. The some what artificial and meta mathematical nature of these sentences might lead one to hope that all “mathematically interesting” sentences about N are settled by PA. However, more recent work has shown that even this is a forlorn hope, since there are undecidable statements related to ramsey’s theorem Undecidability also appears in number theory in[IV.19 §2.2](/part-04/extremal-and-probabilistic-combinatorics) in finite combinatorics. a very basic way.
Hilbert’s tenth problem asked if there is an algorithm to decide whether a polynomialp(X1, . . . , Xn)with integer coefficients has an integer zero. Davis, Matijasevic, Putnam, and Robinson showed that the answer is no. Theorem.isn > 0 and For any recursively enumerablep(X, Y , . . . , Y ) \in  Z[X, Y , . . . , YS ⊆ N] there such that zero.m \in  S if and only if1 p(m, (Yn)1, . . . , Yn)1 has an integern Since the halting problem provides an undecidable recursively enumerable set, the answer to Hilbert’stenth problem is no.
An important open question is whether there is an algorithm to decide if a polynomial with rational coefficients has a rational zero. Hilbert’s tenth problem is also discussed inof the halting problem [V.20](/part-05/the-insolubility-of-the-halting-problem), and other interesting the insolubility examples of undecidability can be found inand combinatorial group theory [IV.10](/part-04/geometric-and-combinatorial-group-theory).geometric 3 Compactness A theory that satisfy all of the sentences in T is called satisfiable if there are structures T (that is, if T has a model), and we call
contradiction from TT. Since our proof system is sound, consistent if we cannot derive a

639

any satisfiable theory is consistent. On the other handif Tis not satisfiable, then every sentenceφ is a logi- cal consequence of T, for the trivial reason that there are no models of But the completeness theorem then tells us that T in which φ is required to be true. T * φ for every ment, of the formφ. Choosingψ∧¬φψto be some contradictory state-, for instance, we see that T is in consistent.
This way of reformulating the complete-ness theorem has the following simple consequence, called the surprisingly important, as we shall see.compactness theorem, which turns out to be Theorem. Tis satisfiable. If every finite subset of Tis satisfiable, then then it is in consistent (as we have just seen), which means that a contradiction can be proved from The reason this is true is that if Tis not satisfiable T . Since this proof, like all proofs, must be finite, it involves only finitely many sentences from T.
Therefore, T has a finite subset that implies a contradiction, which con-tradicts our assumption that all finite subsets of T are satisfiable. sequence of the completeness theorem, it has many immediate intriguing consequences and lies at the Although the compactness theorem is an easy con heart of many constructions in model theory. Here aretwo simple applications that show that theories have many models that you might not expect. If L-structure, let us write Th(M) for the theory of M is some M: that is, for the set of all L-sentences that are true in M.
We also extend our earlier notationgle formulas to collections of formulas, so if M 2 φ from sin-M is an L-structure and T is an L-theory, then M 2 T means that every sentence ofthat M is a model of TT. is true in M, or in other words Corollary.an infinite element There exists ana (which means that L. xp -structurea >M1 containing, a > 1+1, a > 1 + 1 + 1, etc.), such that M 2 Th(R . xp ). That is, there is a structure M in which all the true first-order statements about the structure true, but Mis different from R because it contains R. xp  are still an infinite element.
To prove this, we add one more. xp constant symbol theory T that consists of all the statements of Thc to our language and consider the(R ) (that is, all true statements about the infinite sequence of statements R$\exp c >)$, together with1, c > 1 +. xp 1, c > 1 + 1 + 1, and so on. If Δis any finite subset of T , then we can make R a model ofΔ simply by interpreting

640

csatisfy all the statements of the formas a sufficiently large real number—large enough toc > 1 + 1+· · ·+ 1 that belong toΔ of T, the compactness theorem tells us that we canΔ. Since we can model every finite subset model T itself. If M 2 T, then the element named by c must be infinite. The element 1/a will be an infinitesimal element of M(which means that it satisfies statements that effectively say that it is smaller than 1/n for every positive integer rigorous development of calculus with infinitesimals.$n$). This observation is the first step toward a language of rings.
Letare true in every finite field. We call For another example, let T be the set of Lrng = LT the(L+-sentences that, theory of finite·,0,1) be the fields. Recall that a field is said to have characteristic p if prime) such that 1 p is the smallest positive integer (which has to be + 1 + · · · + 1 = 0 in the field, where the number of 1 s in the sum isthen the field is said to have characteristic zerop. If there is no such. Thus, p, the fields Q, R, and C all have characteristic zero. Corollary.such that FThere is a field2 T.
F with characteristic zero axioms that characterizes the finite fields: given any setof statements that are true in all finite fields, there is This result tells us that there is no possible set of an infinite field in which they are also all true. To prove it, we look at the theory T^ that consists of T together with the statements 1 Any finite set of statements in$+ 1 = 0$, 1 T +will be true of a finite1$+ 1 = 0$, and so on. field of sufficiently large characteristic, and thus sat isf i-able.
By the compactness theorem T^is satisfiable, but a model of T clearly has to have characteristic zero.
The compactness theorem can some times be used to show the existence of interesting algebraic bounds. The next result allows us to deduce from hilbert’s nullstellensatz is our first example of a statement that does not appear[V.17](/part-05/hilberts-nullstellensatz) a stronger “quantitative version.” It to be logical in nature but which can be proved using logic. Recall that a field is algebraically closed if every polynomial with coefficients in the field has a root in the field.
(the fundamental theorem of algebra [V.13](/part-05/the-fundamental-theorem-of-algebra) is the assertion that C is an algebraically closed field.) Proposition.there is a positive integer For any three positive integer sl such that if K is an alge-n, m, d bra ically closed field and$f^{1}$, . . . , fm are polynomials ind and no common zero, then there are polynomials nv a ri ab les with coefficients in K, degree at mostg1, . . . , gm of degree at most l such that gifi = 1.

IV. Branches of Mathematics

but with out the extra information about the degrees of Hilbert’s Nullstellensatz itself is the same statement the polynomials$g^{i}$. our attention to the case notational simplicity: the proof is almost identical in To see how the proposition is proved, we will rest ri ctn = d = 2. This is just for larger cases. For eachi between 1 and m let Fi = ai X2 + bi Y2 + ci XY + di X + ei Y + fi. For each there are no poly nom i a lsk write down a formula G , . . . , Gφk that asserts that with degree at most algebraically closed fields with the formul ask such that 1 = Fi(G1)i.
Let Tmbe the theory ofφ , φ , . . . and the assertion that the polynomials no common zero. If there is no positive integer$F1$, . . . , (F1)ml2 have sat- i sfy ing the conclusion of the proposition, then every finite subset ofness theorem, TTis satisfiable. Ifis satisfiable. Hence, by the compact-$K 2 T$, then F , . . . , F are polynomials over an algebraically closed field withno common zero, but it is impossible to find polyno-1$m$ mials$G^{1}$, . . . , Gm such that Gi Fi = 1. This contradicts Hilbert’s Nullstellensatz.
Notice that in the above argument we did not say anything about the dependence of$d$. This is because the proof does not actually find al on n, m, and bound: it merely shows that some sort of bound must exist. However, good explicit bounds were recently discovered—see algebraic geometry [IV.4](/part-04/algebra) for more details. 4 The Complex Field A surprising counterpoint to Gödel’s incompleteness theorem is a result of tarski [VI.87](/part-06/alfred-tarski-19011983), which states that the theories of the fields of real and complex numbers are known asdecidable.
The key to these results is a method quantifier elimination. If we have a formula with out quantifiers that concerns the natural numbers, then it is easy to decide whether it is true or false. The negative solution to Hilbert’s tenth problem shows that as soon as we start adding existential quantifiers (as wedo if, for example, we assert that a polynomial has a zero), then we leave the realm of decidability. it will be very useful if we can find an equivalent for-Thus, if we want to show that a formula is decidable, mula that does not have quantifiers.
And in some set-tings, this turns out to be possible. For example, let

φ(a, b, c) be the formula∃x ax2 + bx + c = 0.

IV.23. Logic and Model Theory

The usual rule for solving quadratics tells us that, aslong asa = 0, this is true in R if and only if b2 ⩾ 4 ac. Therefore, R2 φ(a, b, c) if and only if[(a = 0 ∧ b2 - 4 ac ⩾ 0) ∨ (a = 0 ∧ (b = 0 ∨ c = 0))]. As for the complex numbers, it is easy to see that C2φ(a, b, c) if and only ifa = 0 ∨ b = 0 ∨ c = 0.

In either case, quantifiers.φ is equivalent to a formula with no For a second example, letφ(a, b, c, d) be the formula∃x∃y ∃u∃v (xa + yc = 1 ∧ xb + yd = 0∧ ua + vc = 0 ∧ ub + vd = 1). The formula ing that the matrixφ(a, b, c, d)(a b ) is invertible. However, by theis the obvious way of assert - determinant F, F 2 φ(a, b, c, d)[III.15](/part - 03/determinants) test, we know that, for any field if and only if c d ad - bc = 0. Thus the existence of an inverse can be expressed by the quantifier-free formula$ad - bc = 0$.
fiers in algebraically closed fields. Tarski proved that we can always eliminate quanti Theorem.free formula For anyψ such that Lrng-formulaφ is equivalent toφthere is a quantifier-ψ in every algebraically closed field. eliminating the quantifiers. Further more, Tarski gave an explicit algorithm for The equivalent quantifier-free formulas above were both finite Boolean combinations of formulas of the for mp(v $, . . . , v ) = q(v , . . . , v )$, where p and q are polynomials inis not hard to see that this is true of any quantifier-1 nnvariables with integer coefficients.
It1$n$ free sentence$L^{r}ng$-formula. It follows that a quantifier-freeis particularly simple: if no free variables are$L^{r}ng-$ allowed and no quantifiers are allowed, then there can-not be any variables! Therefore, the polynomial sp an dq free have to be constant, which means that a quantifier-L -sentenceis a finite Boolean combination of formulas of the form regarded as an abbreviation for 1 rngk = l (where this should be + 1 + · · · + 1 = 1+ 1 + · · · + 1, with k 1 s on the left-hand side andl 1 s on the right-hand side).This leads to the decidability result.
If we want to know whether C2 φ, then we use Tarski’s algorithm to convert But the very simple form of such sentences makes theirφinto an equivalent quantifier-free sentence. truth or falsity easy to decide. In the remainder of this section, we shall discuss a number of other consequences of Tarski’s theorem.

641

The first is that sentences in the language not distinguish between different algebraically closed Lrng can- fields of the same characteristic. That is, if L -sentence that is true for some algebraically closedφ is any field of characteristic then it is true in every algebraically closed field ofrngp (where p is allowed to be zero), characteristic To see why this is true, letp.
K and F be two alge- bra ically closed fields of characteristic that K 2 φ (or in other words that φp, and suppose is true of K).$Let$ kbe the field Q if the characteristic is zero and the field with tells us that there is a quantifier-free sentence pe le ments otherwise. Tarski’s theoremψ that is equivalent to character i st i cp. However, the extremely simple natureφin all algebraically closed fields of of the quantifier-free sentences of truth or falsity in any given field depends only on the Lrng means that their$elements 0$, 1, 1$+ 1$, and so on. Therefore, K 2 ψ k 2 ψ F 2 ψ.
Since K 2 φ and φ and ψ are equivalent in all alge- bra ically closed fields of characteristic F 2 φ as well. p, it follows that tence if it is true of the algebraic numbers A consequence of this theorem is that anφ is true of the complex numbers if and only Qalg. (Recall that Lrng - sen- these are all roots of polynomials with integer coef - ficients.
As one would expect, the algebraic numbers form an algebraically closed field, though this is nota wholly obvious fact.) Thus, rather surprisingly, if we wish to prove something about Qalg, we have the option of working in C and using the methods of complex analysis; similarly, if we want to prove something about C we can, if it makes things easier, work in Qalg and use number-theoretic methods. rem gives another useful tool. Ifthen the following are equivalent: Combining these ideas with the completeness theo-φ is any Lrng - sentence, (i)φcharacteristic zero;
is true in every algebraically closed field of (ii) for somem > 0, φ is true in every algebraically (iii) there are arbitrarily large closed field of characteristic some algebraically closed field of character i st i cp such thatp > m;φ is true inp. in every algebraically closed field of characteristic 0.Let us see why this is so. Suppose first thatφ is true The completeness theorem then implies that there isa proof ofφ from the axioms for algebraically closed 642 fields combined with the sentences 11 + 1 + 1 = 0, and so on.
Since proofs are finite sequences= 0, 1 + 1 = 0, of formulas, there must be some used only the firstm of these sentences (not ne ces sar-m such that the proof ily all of them). Ifthis proof shows thatp is some prime bigger thanφ holds in algebraically close dm, then fields of characteristic used are true in such fields.p, since all the sentences we that (ii) implies (iii). To see that (iii) implies (i), let us suppose that (i) fails, so that there is an algebraically We have just shown that (i) implies (ii).
It is obvious closed field of characteristic zero in which Then, by the principle we proved earlier,¬φ¬φis true inis true. every Thus, since (i) implies (ii), there is an algebraically closed field of characteristic zero.m such that ¬φ is true in every algebraically closed field of characteristic$p > m$. Therefore (iii) fails. by Ax. It is another example of a statement that has An interesting application of this theorem was found nothing to do with logic, but which can be proved using logical tools.
It is perhaps more striking than the previous example because in this case one does not even feel with hindsight that the statement did after all have some logical content. Theorem. If a polynomial map from C$n to C^{n} \text{is an}$ injection, then it must also be a surjection. very simple indeed: what is remarkable is that it is of The basic thought behind the proof of this result is any help. It is the observation that ifthen every injective polynomial map from kis a finite field,$k^{n} to k^{n} \text{is a}$ surjection.
This is true because every injection from a finite set to itself is automatically a surjection. vious results tell us that, in several situations, state-How do we exploit this observation? Well, the pre ments are true for one field if and only if they are true for another. We shall use these results to transfer our problem from C, where it is hard, to a finite fieldk, where it is trivial. The first step is a routine exercise:
one shows that for each positive integerd there is a sentence injective polynomial map fromφd in Lrng that expresses the fact that every Fn to Fn, with the n polynomials all of degree at most would like to prove that all the sentencesd, is surjective. Weφ are trued

when$F = C$.

it is enough to prove that the sentences when The equivalences in the previous theorem imply that Fis the field Falg, the algebraic closure of theφd are truep

IV. Branches of Mathematics

ptained in an algebraically closed field. Roughly speak--element field. (It can be shown that any field F is con- ing, the bra ically closed field that contains algebraic closure of F is the smallest alge-F.) Suppose, then, that someφd fails for Falgp. Then there must be an injec-Falgn Falgn tive polynomial map surjective. Since every finite subset off from (p ) to (Falgp )is contained that is not in a finite subfield, there is a finite subfield all then polynomials used to definefhave coefficient sp k such that ink, from which it follows that f maps kn to kn.
More- over, by enlarging there is an element ofk if necessary, we can ensure thatkn that is not in the image of f . But now we have succeeded in transferring ourselves toa finite field: this function$f$: kn \to  kn is an injection between finite sets that is not a surjection, which is a contradiction. Letbe a quantifier-free formula, and let Quantifier elimination has other useful applications. Fbe a field, let Kbe a subfield of F , leta , . . . , aψ(v1, . . . , vbe ele-n) ments of quantifier-free formulas are just Boolean combina-K.
Since, as we have already mentioned,1 n tions of equalities between polynomials, the statement$ψ(a^{1}$, . . . , an) involves just the elements of K, and is therefore true intifier elimination, if K if and only if it is true in K and F are algebraically closed, F. By quan- then the same is true for those that are quantifier free. From this observation weall formulasψ, and not just can prove the “weak version” of Hilbert’s Nullstellen-satz. (For the proof, we shall need to assume a certain degree of familiarity with the basics of[III.81](/part-03/rings-ideals-and-modules).
We shall also write K[X] for the polynomial ring ring theory K[X1, . . . , Xn] an. ardv for the n - tuple (v1, . . . , vn).) Proposition.field, P is a prime ideal in Suppose that K[KXis an algebraically closed], and g is a polynomialin a =K[(a X], . . . , athat does not belong to) in Kn such that Pf (a). Then there is some = 0 for every f that belongs to1 n P , and such that g(a) = 0. Proof.of the integral domain Let Fbe the algebraic closure of the fraction field K[X]/P . We can view F as an extension field of K[X] \to F .
Let b = Kη(Xwith a natural homomorphism) and let b \in Fn be the elementη: (b We would like to find such an element in1,. . . , bn). Theni f (b)i= 0 for all f \in  P Kand. Since idea lsg(b) = 0. in polynomial rings are finitely generated, we can find polynomials f1, . . . , fm that generate P . The sentence∃v1 · · · ∃vn(f1(v) ̄= · · · = fm(v) ̄$= 0 ∧ g(v)$= 0) is true in Kn such that each F . Thus it is also true inf \in P vanishes at Kand we can finda but g(a) = 0.a \in IV.23.
Logic and Model Theory ture as the result about polynomial maps onidea was to come up with a different field, in this case Notice that the above proof has the same basic struc - Cn. The Fcal ideas to deduce the result for the field we were, where the result was easy to prove, and use log i originally interested in, in this case K. 5 The Reals Quantifier elimination in the language of rings does not work in the field of real numbers. For instance, the formula∃y x = y · y,

which asserts “quantifier-free formula in the language of rings. Ofxis a square,” is not equivalent to a course, x is a square if and only if x ⩾ 0. So we could eliminate this quantifier if we were prepared to add a symbol for the ordering to our language. An amazing result of Tarski shows that this is the only obstruction to quantifier elimination. Let Lor be the language of ordered rings, which is the language of rings with the addition of the symbol “for an ordering. Which L -sentences are true in the real<” field? Some of the properties ofin Linclude:
or R that we can formalize or (i) the axioms for ordered fields, such as the sentence∀x∀y (x > 0 ∧ y > 0) \to x · y >0; (ii) the intermediate-value property for polynomials, which states that ifp(x) is a polynomial and there existp(b), then there exists a real number a and b such that a < b and p(a) <c such that0 <a < c < b and p(c) = 0.

The intermediate-value property is expressed not byjust one sentence, but by the infinite sequence of sentences

$∀d^{0} · · · ∀\sum d^{n}∀a∀bd^{i}a^{i} < 0 < d^{i}b^{i} → ∃c d^{i}c^{i} = 0$,

one for each positive integer An ordered field that satisfies the intermediate-valuen. property is called a real closed field. It turns out that an equivalent way of axiomatizing real closed fields isas ordered fields for which every positive element is a square and every polynomial of odd degree has a zero. Tarski’s theorem is the following statement. Theorem.free L -formula For anyψ Lsuch thator-formulaφ andφthere is a quantifier-ψ are equivalent in every real closed field.or

643

out (and is not hard to show) that they are finite boolean combinations of formulas of the form What are the quantifier-free formulas ofp(v Lor, . . . , v? It turns$) =q(vq(v^{1}$, . . . , v, . . . , vn)), where, as in the case ofand formulas of the form Lp(v,1 1 p, . . . , vand (qn)n) <are polynomials in integer coefficients. As for quantifier - free1 n n and m variables, respectively, with rng sentences, they are Boolean combinations of sentences of the formk = l and sentences of the form k < l.
lowing result, which tells us that every that is true in One consequence of quantifier elimination is the fol - R can be proved from the real - closed- Lor statement field axioms. One says that these axioms axiomatize the theory of the real field. completely Corollary. L -sentence. Then Let Kbe a real closed field and let K 2 φ if and only if R 2 φ.φ be an or quantifier-free sentence a le nt in any real closed field.
Every ordered field has To prove this, first use Tarski’s theorem to find aψ such that φ and ψ are equiv- characteristic zero and contains the rational numbers as an ordered subfield. Therefore Q is a subfield of both Ksen ten ces inand R. But the very simple nature of quantifier-free Lmeans that Kor2 ψ Q 2 ψ R 2 ψ. since follows thatφ and ψKare equivalent in all real closed fields, it2 φ if and only if R 2 φ.
closed field if and only if we can prove axioms for real closed fields, and By the completeness theorem,φ is true in every realφ is false in everyφ from the real closed field if and only if we can prove the axioms for real closed fields. It follows that the¬φ from L - theory of the real field is decidable. Indeed, ifin R, then by the corollary above, it is true in everyφ is trueor real closed field, so it has a proof. Ifthen¬φ is true in R, so for the same reasonφ is false in¬φ has a R, proof.
Therefore, to decide whether search through all possible proofs from the axioms ofφ is true, one can real closed fields until one proves eitherφ or ¬φ. Let M be a mathematical structure consisting of a set Mop erations. A subset and various other parts such as functions and binary X of M is called definable, with respect to some language L that describes M, if there is an${x \in LM - formula}:φ(x)$. Quantifier elimination gives us a goodφ with a free variable x such that X = geometric understanding of the definable sets.
Ifan ordered field, we say that X ⊆ Kn is semialgebraic K is if it is a finite Boolean combination of sets of the form ${x \in K^{n}}$:$p(x) = 0 and {x \in K^{n}}$:$q(x) > 0$,

644

where the definable sets in a real closed field are easily shown$p$, q \in K[X1, . . . , Xn]. By quantifier elimination, to be exactly the semialgebraic sets. algebraic subset of A simple application of this fact is that if Rn, then the closure of A is a semi-A is also semialgebraic. Indeed, the closure ofthe set$A$is, by definition, $x \in R^{n}$:∀ > 0 ∃y \in Ai = {}n1(xi - yi)2 <. This is a definable set, and hence a semialgebraic set. simple.
For any real polynomial set Semialgebraic subsets of the real line are particularly${x \in R}$:$f (x) > 0$is a finite union of open inter-f in one variable, the vals. Therefore, any semialgebraic subset of R is a finite union of points and intervals. This simple fact is the starting point of the modern model-theoretic approachto R. Let L* be a language extending L and let R* denote the reals considered as an example, below we will be interested in the case where L*-structure. Foror Levery subset of* = L. xp  and RR*definable using= R. xp .
We say that L*-formulas is a finite R${}^{*} is o - \text{minimal if}$ union of points and intervals. The “o” in “o-minimal”stands for “ordered.” R*is o-minimal if every definable subset of R can be defined using only the ordering. alizing an earlier idea of van den Dries. It turned out Pillay and Steinhorn introduced o-minimality, gener to be a key definition, because although o-minimality is defined in terms of the one-dimensional set R, it has remarkably strong consequences for definable subsets of R$n when n > 1$.
basic sets called To explain this, we inductively define a collection of cells as follows. • A subset X of R is a cell if and only if it is either a• point or an interval. Iffunction from X is a cell in Xrn to and R, then the graph offis a continuous definablef (which is a subset of Rn+1) is a cell.• If X is a cell in Rn and f and g are continu- ous definable functions fromf (x) > g(x) for every x \in  XX, thento R such that\\{(x, y)\\}: $x\\{(x}$, y)\in X and\\\\\\\\\\\\\\\\\\\\\}: x \in f (x) > y > g(x)X and f (x) > y andis a cell$, \text{as are}\\\\{(x, y)\\\\}:$ x \in X and y > f (x).

the role of open intervals inthat any cell is homeomorphic to Cells are topologically simple definable sets that play R. It is not hard to see(0,1)n for some n. Remarkably, all definable sets can be decomposed into

IV. Branches of Mathematics

cells. The following theorem is a precise version of this statement. Theorem. (i) If R*is an o-minimal structure, then every definable set disjoint cells. X can be partitioned into finitely many (ii) If$f$:$X$ \to Ris a definable function, then there is a partition off is continuous on each cell. Xinto finitely many cells such that ture, definable sets have many of the good topological and geometric properties of the semialgebraic sets. For This is just the beginning. In any o-minimal struc example:
•Any definable set has finitely many connected • components. Definable bounded sets can be definably triangu• each lat ed. Suppose thata \in  Rm, let Xis a definable subset of Xbe the “cross-section”R$n^{+m}{}$. Forx \in}$R$ n:(x$, a) \in X$. Then there are only finitely many$a$ different homeomorphism types for the sets$X^{a}$. the real interest is in finding new o-minimal structures. The most interesting example is As these results were known for semialgebraic sets, R . It is known that Rguage$\exp$ does not have quantifier elimination in the lan-L .
Wilkie showed that the next best thing is. xp true. We say that. xp  Rn is an exponential variety if it is the zero set of a finite system of exponential terms. For example, the set$\\{(x}$, y, z):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}$x$ = . xp (y)2 - z3 ∧. xp (. xp (z)) = y - x is an exponential variety. Theorem.form Every$L \exp$-definable subset of Rn is of the{x \in Rn}:$∃y \in R^{m} (x$, y) \in V  for some exponential variety V ⊆ (Rn)+m. nential varieties themselves, are projections of expo-nential varieties, which makes them tractable.
Indeed, In other words, the definable sets, though not expoa theorem from real analytic geometry, due to Khovan-skii, states that every exponential variety has a finite number of connected components. Since this propertyis preserved by projections, it follows that every definable set has a finite number of connected components, and also that every definable subset of the real line is a finite union of points and intervals. Thuso-minimal and all of the results above about definable R$\e\text{xp is}$ sets in o-minimal structures apply.

IV.23. Logic and Model Theory

question remains open, but the answer is known to follow from the following conjecture of Schanuel in Tarski asked if the theory of R$\e\text{xp is decidable}$. This transcendental number theory. Conjecture.bers that are linearly independent over Suppose thatλ1, . . . , . ambda n are complex num - Q. Then the field Q$(λ^{1}$, . . . , . ambda n$, e^{λ}1$, . . . , e^. ambda n ) has transcendence degree at leastn. conjecture is true, then the theory of Macintyre and Wilkie have shown that if Schanuel’s R$\e\text{xp is decidable}$.
6 The Random Graph Model-theoretic methods give interesting information about random graphs [III.34]. Suppose we construct a graph as follows. The vertex set is the setral numbers N. To decide whether we will have an edge N of all natubetween$x and y (with x = y$) we flip a coin, putting an edge there if and only if we get heads. Although these constructions are random, we will show below that, with probability 1, any two such graphs are isomorphic. The proof depends on the following extension property.
Let A and Bbe disjoint finite subsets of N, and suppose that they have sizes We would like to find a vertex nx and\in  N mthat is joined to, respectively. every element of A and to no element of B. Now for any particular desired property isx, the probability that it doesp = 1 - (2-)(n+m). Therefore, if wenot have the look atof them has the desired property is Ndifferent vertices, the probability that none$p^{N}$. Since this con- verges to zero withx \in  N has the property is 1.
More over, since there are N, the probability that at least one only countably many disjoint pairs with probability 1 it is the case that for(A, B)every of finite sets, such pair (A, B)one can find a vertexx that is joined to every vertex in We can formalize this observation in a model-theo-A and to no vertex in B. retic way. Let$L = L(∼)$, where “∼” is a binary relation g symbol (which we read as “is joined to”). We letthe$L$-theory: T be g (iii)(ii)(i)$∀∀Φ^{n}$, mxx∀¬y xfor(x ∼n, m∼x)y;$\to ⩾ y0$. ∼ x;
HereΦn, m is the sentence∀x1 · · · ∀xn∀y1 · · · ∀ym1 n 1 m xi = yj → ∃z 1 n xi ∼ z ∧ 1 m ¬(yi ∼ z).i=1 j=1 i=1 i=1 645 The first two sentences tell us that the relation “∼” defines a graph, and for each pairΦ tells us that the extension property holds for all(n, m) the sentence pairs of disjoint setsn, m A and B with A of size n and B of size extension property holds for any pair of disjoint fin item.
Thus, a model of T is a graph for which the sets of vertices. The argument above shows that with probability 1 the random graphs we constructed are models of Now let us see why they are isomorphic (again with T .$probability 1)$. This will be an immediate consequence of the following theorem. Theorem.of T, then GIf1 Gis isomorphic to1 and G2 are any two countable models G2.
a bijectionof Recall that an G such thatf from the vertex set of xi so morphism is joined to ybetweenin GGif and only if1 Gto the vertex set1 and G2 meansf (x) is joined to sketch, is a “back - and - forth” argument that gradually2 f (y) in G2. The proof, which we shall now1 builds up an isomorphism betweenleta , a , . . . be an enumeration of the vertices of G1 and G2. First, G and let G2. Let us set0 (b1)0, b1, . . .f (a0 be an enumeration of the vertices of) to be b0. Next, we choose an image1 for vertex that is joined to a1:
ifa1 is joined tob(a0)0 and ifthen we need to find somea1 is not joined to a0 then we need to find a vertex that is not joined to Either way, we can do it because G is a model of T, so itb0. satisfies the extension property. (The particular cases we use here areΦ and Φ .) and so on, in each case using the extension property tomake sure that the images are joined to each other if It is tempting to continue finding images for1$,0 0\\\{$,\\1 a2$, a3$, and only if the original vertices are.
The trouble with this is that we may not end up with a bijection, since for any particularb there is no guarantee that we willj ever choose it as the image of somea . However, we canj remedy this by alternately choosing an image for thefirstai that does not yet have an image, and a preimage for the first way we build the desired isomorphism.bj that does not yet have a preimage. In this above result. However, it has the following very nice model-theoretic consequence. It was not essential to use model theory to prove the Corollary.
For any L - sentence φ either φ is true in g every model of T or ¬φ is true in every model of T. More over, there is an algorithm that will tell us whichofφ or ¬φ is true in every model of T. ing of the compactness theorem, which allows one to To prove this, one first applies a slight strengthen - 646 conclude that if the result is false then there are able models G and G of T such that φ is true in count - G andnot isomorphic, and therefore directly contradicts the¬φ is true in1 G2.
But this shows that2 G1 and G2 are1 previous theorem. To decide which ofφ or ¬φ is true in every model of Tsentences of, one searches through all possible proofs from the T. By the completeness theorem, one or other of the statements has a proof, so we will eventu-ally find either a proof ofφ or a proof of ¬φ. At that point we will know which ofφ and ¬φ is true in every model of T . finite graphs. Let ti ces The theory\\{1,2, . . . , NT also gives us information about random\\}.
We consider the probability measure GN be the set of all graphs with ver- onis the same as constructing a random graph on GN in which we make all graphs equally likely. This N ver- tices, where for eachin order to decide whether i and ji is joined towe toss an unbiased coinj. For any L - g sentence a random graph onφ, let us write Nvertices satisfiesp N (φ) for the probability thatφ. shows that for each extension axiom bility An easy variant of the argument for infinite graph sp N(Φn, m)tends to 1.
Therefore, for any fixedΦn, m, the proba-M, ifa random graph on Nis sufficiently large, then with very high probability Nvertices satisfies all the axioms Φn, m This observation allows us to use the theory with n, m ⩽ M. T to get a good understanding of the asymptotic properties of random graphs. The following result is called a zero one law. Theorem. Given any L -sentence φ, the probability g pover, N(φ)T either tends to axiomatizes the set of statements0 or tends to 1 as Nφ→ . nftysuch that.
More- the limit is which is a decidable theory.1, called the almost sure theory of graphs, lier that either true in every model of This follows from our previous results. We saw ear-φ is true in every model of T. In the first case, by the com-T or ¬φ is pleteness theorem there must be a proof of Since proofs are finite, this proof can use only finitelyφ from T. many of the statements some$M \text{such that if} G 2Φ^{n}$, mΦ . Therefore, there exists, then G 2 φ.
But if Ga bility thatis a random graph on G 2 Φ tends to 1, and therefore the NM, Mvertices, then the prob- probability same argument holds ifp N (φ) that M, M G¬φ2 is true in every model ofφ tends to 1 as well. The T and shows thatp N(φ) tends to 0.p N (¬φ) tends to 1, which implies that

IV. Branches of Mathematics

result. It is not hard to prove that the probability that a random graph contains at least Note the following interesting consequence of this1 N edges converges to 12 as Ntends to infinity. Combining this simple2 2 observation with the theorem we can deduce that the property “contains at least as many edges as nonedges” cannot be expressed by a first-order formula in L . This g is a purely syntactic result, but to prove it we made essential use of model theory.

Further Reading

Shoenfield (2001) is an excellent introduction to logic including the completeness and incompleteness theorems, basic computability theory, and elementary model theory. The examples described here give only a small part of the flavor for modern model theory. Hodges (1993)$, Marker (2002)$, and Poizat (2000) are comprehensive introductions. Marker et al. (1995) contains several introductory articles on the model theory of fields.
ability in particular structures, a major goal in model theory is proving structure theorems for wide classes In addition to providing tools for analyzing definof mathematical structures. A key feature is the devel-opment by Shelah of notions of dependence generalizing linear dependence in vector spaces and algebraic dependence in fields. Led by Hrushovski and Zilber, model theorists have studied the geometry of depend-ence and found that frequently it can be used to detect hidden algebraic structure. te resting applications in classical mathematics.
Hrush-ovski used these ideas to give a model-theoretic proof In recent years, abstract model theory has found inof the Mordell–Lang conjecture for function fields in Diophantine geometry. Bouscaren (1998) is an excellent collection of survey articles leading up to Hrushovski’sproof. Bouscaren, E., ed. 1998.etry. An Introduction to E. Hrushovski’s Proof of the Geo-Model Theory and Algebraic Geom Hodges, W. 1993.metric Mordell–Lang conjecture ematics and Its Applications, volume 42. Cambridge: Model Theory. Encyclopedia of Math-. New York: Springer. Marker, D.
2002.Cambridge University Press. Springer. Model Theory: An Introduction. New York: Marker, D., M. Messmer, and A. Pillay. 1995.of Fields. New York: Springer. Model Theory Poizat, B. 2000.to Contemporary Mathematical Logic A Course in Model Theory. An Introduction. New York: Springer. Shoenfield, J. 2001.Peters. Mathematical Logic. Natick, MA: A. K.

IV.24. Stochastic Processes

IV.24 Stochastic Processes

Jean-François Le Gall

1 Historical Introduction

Stochastic processes are one of the major themes of modern probability theory. Roughly speaking, they are mathematical models that describe the evolution of random phenomena as time goes by. In this article, we shall introduce and illustrate the fundamental ideas ofthe theory of stochastic processes by concentrating on the single most important example: Brownian motion. We start with a brief historical introduction, in order to provide some motivation for the mathematical theory that follows.
In 1828, the British botanist Robert Brown observed the very irregular and wiggly motion of small particlesof pollen suspended in water. Brown pointed out the unpredictable character of the motion, which appearedto obey no known physical rule. During the nineteenth century, several physicists tried to understand the ori-gin of this “Brownian motion,” which turned out to be present in many other physical phenomena. several theories were proposed, some of them rather fanciful: perhaps Brownian particles were living microscopic animals, or perhaps the motion was due to electro-static forces.
By the end of the century, however, physicists had concluded that the constant changes of direc-tion in Brownian motion could be explained by the impacts on a particle from the molecules of the sur-rounding medium. If the particle was sufficiently light, then these numerous collisions could have a macroscopic influence on its displacement. This explanation was also consistent with the experimental observation that the motion became faster if the temperature of the water, and thus the thermal agitation of its molecules, increased.
Albert Einstein, in one of his three famous 1905 papers, was responsible for a major step forward inthe understanding of Brownian motion. He worked out that if a Brownian particle starts at the origin, then after a fixed timet its position should be randomly dis- tributed according to the (three-dimensional)[III.71 §5](/part-03/probability-distributions) with mean 0 and variance gaussian$σ2t$, distribution where$σ^{2} \text{is a constant}$, called the diffusion constant, that measures how quickly the distribution spreads out with time.
(One can think of this loosely as the speed of the Brownian motion, but we shall see later

647

that the word “speed” is not really appropriate.) Ein-stein’s method was based on considerations of statistical physics, which led him to the heat equation [I.3 §5.4](/part-01/fundamental-definitions) and then to the Gaussian density that solves this equation (see section 5.2). cian Louis Bachelier, in his work about the mathemat-ical modeling of stock markets, had already noticed A few years before Einstein, the French mathemat i the Gaussian distribution of Brownian motion.
How-ever, Bachelier was dealing not with the physical phenomenon known as Brownian motion, but rather with random walks where the step size was very small. As we shall see in sections 2 and 3, the two concepts are essentially equivalent from a mathematical viewpoint. Bachelier pointed out what we call today the Markov property displacement after timeof Brownian motion: if we wish to predict thet of a Brownian particle, then knowledge of the path followed by the particle before time the position at timet does not help us any more than just know i ngt.
Bachelier’s arguments were not completely satisfactory, and his ideas were not fully appreciated in his time. How does one go about modeling a particle that moves in a random way? A first remark is that the posi-tion of the particle at timet will be a random variable [III.71 §4](/part-03/probability-distributions)B . But these random variables will depend ont

each other: if you know where the particle is at timet, it will affect your knowledge of how likely it is to be ina certain region at some later time. These two considerations can be accommodated if we take as our basic model a set of random variables B , one for each non-t

negative real number, all defined on the same under ly-ing probability space. This, formally speaking, is what a stochastic process is. This may seem a rather simple definition, but in order for a stochastic process to be interesting it needs tohave additional properties, and difficult mathematical questions arise as soon as one tries to obtain them. Let us write each of the random variablesΩ for the underlying probability space.
Then Bt is a function from Ω to R3, and therefore we associate a point in R3 with each pair(t, ω) (where t is a positive real number and ω belongs to ability distribution ofΩ). So far we have thought about the prob-Bt, so we have been focusing on what happens when we fixwe must also consider what happens when we look att and let ω vary. However, a “single instance” of a stochastic process, by fixingω and letting to Bt(ω) is called atvary. For fixed sample pathω, the function that takes. If we want a rigoroust mathematical theory of Brownian motion, then a very

648

important property it should satisfy is that all the sam-ple paths are continuous: that is, for fixedω the point B^t (ω)Physical observations, as well as the contributions of depends continuously on t. Einstein and Bachelier described above, suggested a few other properties that Brownian motion should satisfy. It then became a substantial mathematical problem to prove that there existed a stochastic process with those properties.
Wiener was the first person to establish this, which he did in 1923, and for this reason the mathematical concept of Brownian motion is some times called the Wiener process. the twentieth century, including The most famous names of probability theory in kolmogorov [VI.88](/part-06/andrei-nikolaevich-kolmogorov-19031987), Lévy, Itô, and Doob, all made important contributions to the study of Brownian motion.
Detailed properties of the sample paths have received particular attention, ever since the physicist Jean Perrin observed that these functions are no where differentiable (despite Wiener’slater result that they were continuous). The nondifferentiab ility of Brownian trajectories led Itô to introduce a differential calculus for functions of brownian motion and more general stochastic processes. This Itô stochastic calculus, which will be briefly presentedin section 4, has found many applications in many different areas of modern probability theory.
2 Coin Tossing and Random Walks One of the easiest ways to understand Brownian motion is via another important concept of probability: that of where you repeatedly tossed a coin, winning random walks. Suppose you were to play a game€1 if it came up heads, and losing €1 if it came up tails. One could then define a sequence of random variables gain (which could well be negative) after S0$, S1$, S2, . . . , where Sn represented your totaln tosses of the coin. Two simple properties of this sequence are that S must be 0 and that S and S-always differ by 1.
One can see this in figure 1, which plots a graph of the sequence in the case where the coin tosses are0(nn)1 HTTTHTHHHTHHTH .... sequence of random variables A third property becomes clear if one defines anotherε1, ε2, . . . , representing the out come of each toss of the coin. These are inde-pendent, and eachεn takes the value 1 with probability12 and-1 with probabilit(y1)2. More over, for each n we can write Sn = ε1 + · · · + εn. The distribution of sums of this kind depends in a very simple way on the well-known binomial distribution [III.71 §1](/part - 03/probability - distributions).
(To be pre-

IV. Branches of Mathematics

S

n

$210$

n

−1−2

Figure 1 The accumulated gain in coin tossing. cise, the binomial distribution tells you that the probability that the number of heads after2-n n. If it is k, then S = k - (n - k) =n 2 tosses isk -n.) Whatk is is more, if which is also a sum ofk m > 0 then Snnm+of then - Smε=, so the distributionεm+1 + · · · + εm+n, i

ofis independent of the values of(Sm)+n -Sm is the same as that of S0$, S(S1)n$, . . . , S. Note too that itm. we can think of the sequence a succession of random steps, each of either 1 or The name “random walk” comes from the fact that S0, S1, S2, . . . as taking-1. Brownian motion can be thought of as the limit of this process as the number of steps gets larger and larger and the sizes of the steps get correspondingly smaller.
peal to the To see what “correspondingly” means here, we ap-central limit theorem [III.71 §5](/part-03/probability-distributions), which tells us about the limiting behavior of the distribution of Sn when n gets large. Or rather, it tells us about the distribution ofto divide by. qrtn(is that1/. qrtn)S. qrtnn: the reason it is appropriate is the standard deviation [III.71 §4](/part - 03/probability - distributions) ofsize”: thus, when we divide by it, the “renormalized” Sn.
This one can think of as its “typical distribution will have “typical size” 1 (and therefore we will get the same typical size for each The precise information that the central limit theo-n). rem gives us is that for any real numbers a < b, the probability that a < (1/. qrtn)Sn a< band tends tob with. qrt21πa b (e-x()2()/)2 dxas n tends to . nfty . That is, the limiting behavior of the. qrt distribution ofstandard deviation 1.
Since the distribution of(1/ n)Sn is Gaussian with mean 0 and S -Sm is the same as that of Sn (as we saw earlier), thi(sm)+n also tells us the limiting behavior of the distribution of(1/. qrtn)(S+ - S ) for any m.(mn)m

IV.24. Stochastic Processes

(n)

St

t

Figure 2 The rescaled random walk S(n) for n = 100. 3 From Random Walks to Brownian Motion In the previous section, we looked at a sequence of ran-dom variables S , S , S , . . . . This is another stochastic process, except that “time” is now represented by a pos-0 1 2 itive integer. (One says that it is a Now let us try to do justice to the idea that brownian discrete-time process.) motion is something like a random walk with infinitely many infinitesimally small steps.
(We are now looking at one-dimensional Brownian motion, rather than the three-dimensional Brownian motion discussed right at the beginning of this article.) motion hope that the distributions of It will be slightly simpler to think about a Brownian B^t that runs just for times B^t, and in particular oft between 0 and 1. We B^1, will be Gaussian, and the results from the last section suggest that this is exactly what we should expect ifthey are appropriately scaled limits of the distributions of the that of figure 1 but with some large number of steps S^n.
To be precise, suppose we have a graph liken. Then the deviation of the height of the end of the graph will bex-axis will go from 1 to n and the standard. qrt

a factor of obtain the graph of a random functionn. Therefore, if we shrink the graph horizontally byn and vertically by a factor of S(n). qrt{fromn} we will[0,1] to R, and the standard deviation of$S^{(}n)(1) \text{will be} 1$. Effectively, we are shrinking the time between the steps of the random walk from 1 to 1/n and shrinking the step size from 1 to 1 S(n)are defined every where, we “join the dots” of the$/\sqrt{n}$. Also, so that the functions graph with straight lines, just as we did in figure 1. Are scaled random walk of this kind is shown in figure 2.
tributions of these rescaled random walks converge, in At this point, we shall simply assume that the dis-

649

B

t

t

Figure 3 Simulation of linear Brownian motion. an appropriate sense, to a stochastic process with con-tinuous sample paths. This stochastic process is the Brownian motion is illustrated in figure 3. Notice how similar its general B^t. The graph of a typical sample path behavior is to that of the graph in figure 2. goes on for ever rather than stopping at 1, all we haveto do is let the rescaled random walk go on for ever, If we want to approximate a Brownian motion that rather than stopping after Now let us give a more precise definition. An steps.
linear Brownian motion starting atof real-valued random variables with the followingx is a collection (Bt()t()⩾){0} properties. • B0 = x. (In other words, B0(ω) = x for every ω in•• the underlying probability space.)The sample paths are continuous. Given any s < t the distribution of B - B ists• Gaussian with mean 0 and variance More over, Bt - Bs is independent of the pro ces st - s. up to time mentioned in section 1.)s. (This implies the Markov property Each of these properties has its counterpart for ran-dom walks, as we saw in the previous section.
Therefore, even though it is not easy to prove that brownian motion exists, the result is nevertheless highly plausible. (It turns out to be easy to construct a stochastic process that satisfies all the properties above apart from the second; the difficulty is in obtaining the continuity of the sample paths.) Another important remark is that the above properties characterize Brownian motion: any two stochastic processes with those properties are essentially the same.

650

random walks Rather than defining this notion precisely, we shall We have not yet said what it means for the rescaled$S^{(}n)$to “converge” to Brownian motion. merely remark that any “reasonable” function thatwe can define on the processes$S^{(}n) \text{will converge to}$ the “corresponding” function of the limiting brownian motion$B^{t}$. For example, as we have already seen, the probability that S(n)(1) lies between a and b convergesto. qrt21πa b (e-x()2()/)2 dx.

Butis also the probability that B1 is governed by the Gaussian distribution, so this B1 lies between a and b. times rather the way that this proportion (which is a random A more interesting example is the proportiont between 0 and 1 for which S(n)(t) is positive, or Xn of variable that depends on the walk S(n)) is distributed. This “converges in distribution” to the distribution of the corresponding proportion That is, for anya < b, the probability that the propor-X for Brownian motion.
tion bility that the proportion Xn lies between a and X blies between converges to the proba-a and b. The probability distribution foris called Paul Lévy’s arcsine law X is known explicitly, and:

$P [a ⩽ X ⩽ b] = {}^{ab} π x(d1x - x)$.

Perhaps surprisingly, or 1 than to 1 . The basic reason for this is that if X is more likely to be close to 0 s andtare two different times, then the events2 B > 0 ands B > 0 are positively correlated.t

tion is just one special case of a much more general phenomenon (see, for example, Billingsley 1968). For The convergence of random walks to Brownian moin stance, we can allow other probability distributions for the individual steps of the random walk. A typical result is that if each individual step has mean 0(as is the case when we have+1 or - 1 with probabil- ity 12 ) and finite variance, then the limiting process will always be a simple rescaling of Brownian motion. In this sense Brownian motion appears as a universal object: it is the continuous limit of a wide range of discrete models.
(See the introduction to probabilistic models of critical phenomenaof universality.) [IV.25] for a discussion ian motion, let us think about how to model random Now that we have discussed one-dimensional brown continuous paths in three dimensions. An obvious wayof doing it would be to take three independent Brownian motions, coordinates of a point in a random path in$(B1)t$, (Bt)2$, and (Bt)3$, and let these be the three R3. And

IV. Branches of Mathematics

Figure 4 Simulation of planar Brownian motion. indeed, this is how three-dimensional Brownian motion is defined. However, it is not quite so obvious that this is a good definition. In particular, it seems to depend on our choice of coordinate system, which is worryingif we want a good model for physical Brownian motion. However, a central property of higher-dimensional Brownian motion (the definition just given clearly gen-eralizes to any dimensiond) is rotational invariance.
That is, if we choose a different[III.37](/part-03/bayesian-analysis) as our coordinate system, then we obtain the orthonormal basis same stochastic process. The proof of this is a simple deduction from the basic fact that the density function one-dimensional Gaussian random variables is[III.71 §3](/part-03/probability-distributions) of a vector made up ofd independent(2π)1 d/2 (e-)((x2)1+···+x 2 d)/2. Since the quantity the distance from 0 to(x1)2 + · · · +(x , . . .
, x(x2)d is just the square of), the density does not change when you rotate. In the planar cased = 12, there is a much deep erd invariance property, which we shall explain in sec - tion 5.3. sion constant into our model. (This is the constant mentioned in section 1 that measures how quickly the It is not hard to incorporate the notion of a diffu-σ2 Brownian motion tends to spread out.) All one has todo is rescale from$B^{t} to B^{2}$. As one might expect, higher-dimensional Brown-$σ^{t}$ ian motions are limits of higher-dimensional random walks.
This helps to explain why mathematical Brownian motion is a good model for the physical phe-nomenon observed by Brown: the erratic displacements caused by collisions with molecules resemble the steps of a random walk with very small step size. See figure 4

IV.24. Stochastic Processes

for a simulation of the curve of a planar brownian motion over the time interval[0, 1]. 4 Itô’s Formula and Martingales Let that we are told the values of$f$be a real-valued differentiable function. Sup pos ef^ (x) at 0, 1/n, 2/n, . . . ,(nasked to estimate- 1)/n for some large positive integerf (1) - f (0). If the derivativen and aref^ did not vary too rapidly, then we would expect the difference f ((j + 1)/n) - f (j/n) to be approximately(1/n)f^ (j/n), so a good approximation ought to be$1$ f^ (0) + f^  1 + f^  2 + · · · + f^  n - 1 .
the fundamental theorem of calculus implies that this argument is indeed correct if then n n n[I.3 §5.5](/part-01/fundamental-definitions) derivativef is continuous. similar. This time, let us suppose that the numbersx0 Now let us look at a setup that is superficially, x1$, x2$, . . . , xn are the positions of a random walk with step size 1 a well-behaved derivative, and that we know the val-$/\sqrt{n}$. Suppose that f is a function with ues of about estimating$f (x) at x^{0}f (x$, x1, . . . , x) - f ((xn)-1. This time, let us think).
then we will comment that imately If we follow the lines of our previous argument,(x - x )fn^ (x )f (x, which would lead to a(n0()j)+1) - f (xj) is approx-(j + 1()j)j estimate of$(x1 - x0)f (x0) + (x2 - x1)f (x1)+ · · · + (xn - (xn)-1)f ((xn)-1)$.

Now it is not obvious that this will still be a good esti-mate. The reason is that, typically, the random walk will have gone backwards and forwards, covering the same ground several times before reaching its eventual destination tions a chance to accumulate. To see that this is a seri-$x^{n}$, and this gives the errors in the approxima- ous problem, consider the very well-behaved functionf (x) = x2 and let x = 0. In this case, f ((xj)+1)0- f (xj) = (x2()j)+1 - (xj)2 and a simple calculation shows that this is equal to ((xj)+1 - xj)2 xj + ((xj)+1 - xj)2.
The first term here equals therefore the approximation that we are considering, so((xj)+1 - xj)f (xj) and is the error we have to worry about isis the square of the step size of the random walk. In((xj)+1 - xj)2, which other words, it is 1 so the total error (all of which is positive) is 1. Since the/n. But there are n steps to the walk, order of magnitude of$x^{n}$, and hence (xn)2, is typically

651

about 1, this is a significant fraction ofand therefore our estimate is not a good one.$f (xn) - f (x0)$, that can occur, and we can get around it rather eas-Remarkably, this turns out to be the “only” problem ily. All we have to do is use one more term in the Tay-lor expansion. That is, we use the slightly more refined approximation f ((xj)+1) - f (xj) = ((xj)+1 - xj)f (xj)+ {}12((xj)+1 - xj)2 f (xj).

(Of course, now we are assuming that thetivef^   exists and is continuous.) Notice that in the second deriva- ex amp lef (x) = x2 just considered$, f (x) = 2 \text{for everyx}$, and so if we add up all the above approx- imations we get exactly the right answer. In general, as this observation would suggest, one can show that f (xn) - f (x0) is well - approximated byn-1((xj)+1 - xj)f^ (xj) + (1 n)-1((xj)+1 - xj)2 f^ (xj).j=0 2 j=0

Now let us think about what happens to these two sums if we allow our random walks to converge to a Brownian motion Bt. A relatively straightforward argu- ment, based on the fact that((xj)+1 - xj)2 is just the reciprocal of the number of steps, shows that the lim-iting distribution of the second sum exists and is given by the integral first sum should also converge to a limit, which indeed12 0 t f^  (Bs )ds. This suggests that the it does: the limit is called thewrittent f^ (B ) d B .
More precisely, one ends up with stochastic integral and isthe formula0 ssf (Bt) = f (B0) +0 t f^ (Bs) d Bs + 1(20)t f^  (Bs) ds, (1) which is known as Itô’s formula. Note the similarity to the fundamental theorem of calculus. The main differ-ence is the extra term involving the second derivative, the so-called Itô term. wish to estimate the difference between two values of a function by integrating its derivative, why not choose a Why, one might wonder, is this interesting? If we smooth path rather than a very wiggly one? The point, however, is that we are not interested in just one path.
For any fixed sample path, the two sides of the above formula are just numbers, but if we think ofdom variable, then they too become random variables. Bt as a ran- And since both sides are defined for all$t ⩾ 0$, they are actually stochastic processes. So what we are discussing is a way of integrating one stochastic process to produce another.

652

tic integrals have properties that allow one to prove The reason Itô’s formula is so useful is that stoc has many facts about them. In particular, if we view the stochastic integralt f^ (B )d B as a collection of ran- dom variables indexed by the parameter0 ss t, then we have a stochastic process of an especially nice sort called a martingale.
A martingale is a stochastic process(Mt ()t()⩾){0} with the property that, whenever s ⩽ t, the expected value of M for all r ⩽ s, is just MMt, conditional on the values of.r Brownian motion is a particularly simple kind of mar-s tingale, but martingales are much more general because M - M is not independent of the values of M withrgiven those values, is zero. Here is an example that illus-t⩽ s: all one knows is that the expectation ofs (Mt)r-Ms, trates the difference: start running Brownian motion at0;
when it first reaches 1 (if it ever does), continue with Brownian motion but at double the speed (or rather, double the diffusion constant). In this case, the behav-ior of M -M certainly depends on what has happened up tos, but its expectation is nevertheless zero.t s In a certain sense, the stochastic integral term in Itô’s formula behaves like a Brownian motion “run at a vary-ing speed,” rather like the example just given. The precise result is that there exists another Brownian motion$β = (β ) \text{such that}$, for every t ⩾ 0,(tt()⩾){0}t

This is in fact true for any continuous martingale—not0 f (Bs )d Bs = (β0()t){f}((Bs)()2()d)s. just one given by a stochastic integral—and the relevant time change is a quantity called the quadratic variation of the martingale. Therefore, the graph of a continuous martingale is obtained from that of a brownian motion by a time-change operation. This is why Brownian motion is such a central example, and why it is important to understand its behavior before going onto deal with more general stochastic processes. ivation of Itô’s formula to multi dimensional brownian motion.
If It is straightforward to generalize the previous der-$x = (x$, . . . , x ) and y = (y , . . . , y ) belong totion to Rdand are close together, then the first approxima-f (x) - f (y)1 is no(wd)1 dd(xi - yi)∂if (y)$, i = 1$

where∂ f (y) denotes the ith partial derivative of f , i

evaluated aty is usually denote dy. The vector of partial derivatives at. abla f (y). It is called the gradient off at y(or “grad$f$” for short). As for the second

IV. Branches of Mathematics

derivative ofcianΔf (for reasons that are explained inf , it naturally generalizes to the Lapla-some fun- da mental mathematical definitions [I.3 §5.4](/part-01/fundamental-definitions)), and we therefore arrive at the formul at 1 tf (Bt ) = f (B0) +0 . abla f (Bs) · d Bs + 20 . elta f (Bs) ds. The stochastic integral term is defined formally in terms of one-dimensional stochastic integrals in the obvious way:
t . abla f (Bs) · d Bs =d t . artial f (Bs )d(Bs)j.$0$ j=1 0 ∂xj chastic process Since stochastic integrals are martingales, the sto(Mt)f = f (Bt) - 1(20)t . elta f (Bs )ds is (under appropriate conditions on This observation leads to the martingale probl emf ) a martingale.for Brownian motion. To state a martingale problem fora stochastic process(Xt )t⩾0 is to give a collection of martingales defined as functionals of this stochastic process—just as Mfabo ve is defined as a certain function ofwell-posed(Bs)if it characterizes the distribution of thes⩾0.
The martingale problem is said to be given stochastic process. In the preceding example, the martingale problem is well-posed: if we know nothing about the distribution of the process(Bt()t()⩾){0} apartf

from the fact that M is a martingale for every (twicet

continuously differentiable) function that B must be a Brownian motion. f , we can infer modern probability theory (see in particular Stroock and Varadhan (1979), and also Martingale problems play a fundamental role inthe mathematics of money ting a le problem is often the most convenient way[VII.9 §2.3](/part-07/the-mathematics-of-money)). The introduction of a suitable marto specify a stochastic process, or more precisely to characterize its probability distribution. 5 Brownian Motion and Analysis

5.1 Harmonic Functions

A continuous function U of Rd is called harm on i ch defined on an open subset if the average value ofh over any closed ball contained inthe average value over the boundary of any such ball, U , or equivalently is equal to its value at the center of the ball. A basic result of analysis is thath is harmonic if and only if it is twice continuously differentiable and. elta h = 0. Harmonic functions play an important role in several

IV.24. Stochastic Processes

Bτ

U

x

B

T

Figure 5 of the Dirichlet problem. The probabilistic solution areas of mathematics as well as in physics. For instance, the electrical potential of a conduct or in equilibrium is a harmonic function out side the conduct or. And ifthe temperature of the boundary of a body is kept fixed (that is, although different parts of the boundary may have different temperatures, these tempera-tures do not change over time), then the equilibrium temperature inside the body is also a harmonic func-tion.
(See the discussion of the heat equation in the next section.)Harmonic functions have a very close relationship with Brownian motion, which leads to one of the most important connections between probability and analy-sis. This connection is already apparent from the fact that$Mf$, defined in the previous section, is a martin$t$ gale. It follows from this thath(B ) is a martingale ift

(and in fact only if)h is harmonic, since then the sec- ond term vanishes. However, we will explain the link between Brownian motion and harmonic functions in a more elementary way, from the classical lem. Let U be a bounded open set, and let Dirichlet prob-g be a contin- uous real-valued function defined on the boundaryof$U$. The classical Dirichlet problem is to find a func-∂U tion boundary.h that is harmonic on U and is equal to g on the tion in terms of Brownian motion:
take Brownian motion from The Dirichlet problem has a remarkably simple solu-x, and evaluate xg at the point\in  U, start a Bτ where this Brownian motion leaves U(see figure 5); then define does this work? That is, why is the functionh(x) to be the average value you get. Whyh, defined in this way, harmonic, and why does it equal (or, to bemore accurate, converge to)$g$at the boundary? is very close to the boundary, then a Brownian motion The answer to the last question is roughly that if$x$

653

started atx. Therefore, sincex is very likely to leaveg is continuous, the average value U at a point close to$of$ gat the first exit point will be close to the value of g at any point near To show that h is harmonic is more interesting. Letx.xr be a point in about x is contained in U and suppose that the ball of radius U. We would like to show thath(x) equals the average value of h on the bound- ary of this ball. Nowat the point where a Brownian motion that starts ath(x) is the average value of xg leaves on the first point U.
Let us work out this average by conditioning B where the Brownian path leaves the ball of radius$r$(see figure 5). By the rotational invari-T ance of Brownian motion, this point will be evenly dis-tributed around the boundary of this ball. If we reach the boundary at a pointg when the path leaves Uy, then the average value of(conditioning on this extra information) ish(y), by definition. Therefore, h(x) is indeed the average value ofball of radiu sr .
h on the boundary of the is a subtlety concealed within it, connected with the fact that a Brownian path will typically cross the bound-Convincing though this argument might seem, there ary of the ball many times. Suppose we tried a similar argument, but this time we conditioned on the value at the point wa sl as ty point where the path left the ball.
If this, we could not then say that the expected value ofgwhere the path first reached the boundary of Uwould be forbidden to enter the ball again, and would was h(y) because from that point onward the path therefore not be a Brownian motion. Recall that the Markov property of a Brownian motion states that, given a fixed time T < t, the value of B -B is independent of T and another time B for st with⩽ T. It may seem that we are applying this principle in the argument above, tak i ngt T Tto be the first time that thes Brownian motion reaches the boundary of the ball.
Butif we do that, then Tis not a fixed time since it depends on the Brownian motion. However, the argument can still be made to work because T is a so-called stopping time what the Brownian motion does after. Informally, this means that T does not depend on T .
(Therefore the last time it leaves the ball of radiu sr is not a stopping time, because whether or not a given time is this last time depends on the subsequent behavior of the Brownian motion.) Brownian motion can be shown to have the strong Markov property, which is like the usual Markov property except that T is allowed to be a stopping time. Given this fact, it is not hard to show rigorously thatis harmonic. h654 5.2 The Heat Equation Letf be a function on Rd (which we shall assume to be continuous and bounded).
If we think ofperature distribution at time 0, then the heat equa - f as a tem- tionat subsequent times. To find a solution to this equation[III.36](/part - 03/the - heat - equation) models what happens to the temperature with initial valueu(t, x), defined for everyfmeans to find a continuous functiont ⩾ 0 and x \in  Rd, that solves the partial differential equation

$\partial u\partial t = 1 2 \Delta u (2) whenever$ u(0, x) = f (x)t > for every0, and that satisfies the conditionx. (The factor1 in this equa- tion is not important but it makes the probabilistic interpretation easier to express.) 2 terms of Brownian motion: The heat equation also has a simple solution inu(t, x)is defined to be the expected value ofthat starts atx. This tells us that heat propagates likef (Bt) when Bt is a Brownian motion a collection of infinitesimal Brownian particles.
The preceding probabilistic representation is quite easy to derive since one can write down an explicit for-mula for the expectation off (B ) in terms of the Gauss-t

ian density function. Given this formula, all we haveto do is differentiate it and check that the equation is satisfied. However, the connection between brownian motion and the heat equation is much deeper, and in many other cases there is a probabilistic representation for a solution but no explicit formula. To take one example, suppose that we want to solve the heat equation in an open set tions. This means that we specify an initial value U with Dirichlet boundary condi-f (x) for the temperature of each point$x \in U \text{and stipu}-$ late that the temperature at the boundary is kept at

0. In other words, we want to find a function such that$u(0$, x) = f (x) for every x \in U, u(t, x)u(t, x)= 0 for every timet ⩾ 0 and every x in the boundary ofthis case, the solution is obtained as follows. Run a U, and usatisfies the heat equation inside U . In Brownian motion it has not left U at any time before(Bt) starting at x. Lett, and letgt = f (Bgt=) if0 t

otherwise. Then define ofg . u(t, x) to be the expected valuet

make just a small modification to the solution of theheat equation in Thus, in order to obtain the solution, we had to Rd. An analytic treatment of this version of the heat equation would be much more complicated.

IV. Branches of Mathematics

5.3 Holomorphic Functions

Let us now concentrate on the case identify R2 with the complex planed C. Let= 2. As usual, wef = f + if be a Then the real part holomorphic functionf and the imaginary part[I.3 §5.6](/part-01/fundamental-definitions) defined onf1 of Cf2. are both harmonic functions, so that are martingales. More precisely, Itô’s formula tells us1 f1(Bt) and2 f2(Bt) that, for$j = 1$, 2, fj(Bt) = fj(x) +0 t ∂x∂(fj)1 (Bs ) d(Bs)1 +0 t ∂x∂(fj)2 (Bs) d(Bs)2, since the Itô term vanishes.
As we saw in section 3, each of the two process esf (B ) can be expressed as a time change of a linear Brownian motion stronger result can also be proved, namely that the timejt βj. However, a change is the same in both cases and that the brownian motionsβ1 and β2 are independent. This makes it pos- sible to prove a “localized” rotational invariance, which leads to the importantof Brownian motion.
Roughly speaking, this states that conformal invariance property the image of a planar Brownian motion under a con-formal (that is, angle-preserving) mapping is another planar Brownian motion run at a different speed. 6 Stochastic Differential Equations Imagine a Brownian particle in some water. If the tem-per at ure of the water rises, then we expect there to be more collisions with faster-moving molecules; this canbe modeled easily by increasing the diffusion constant. But what if the temperature in the water varied from place to place?
Then the particle would be more agitated in some parts of the water than in others. Andif the water was moving, with different parts moving at different speeds, then one would need to superimpose on the Brownian motion a “drift” term, to take into account that on average we would expect the particle to move with the surrounding water. Stochastic differential equations are used to model more complicated situations like this. Let us begin by considering the one-dimensional case. Letσ and b be two functions (which we shall assume to be continuous)defined on R.
We think ofσ (x) as telling us the rate of diffusion atthe sake of a picture, one could think ofx and of b(x) as the drift atσ (x)xas the. (For local temperature atof some “one-dimensional water.”) Letx and b(x) as the velocity at(B ) be a one-xt

dimensional Brownian motion. The notation used for the associated stochastic differential equation is d$X^{t} = σ (X^{t} )dB^{t} + b(X^{t} )dt$. (3)

IV.24. Stochastic Processes

Here(X ) is an unknown stochastic process. The ideat

is that, infinitesimally speaking, its behavior is like that of a Brownian motion with diffusivity the diffusivity at the point that X has reached) super-σ (Xt) (which ist

imposed onto a linear motion at speedb(X ). More pre-t

cisely, a solution to the above equation is defined to bea continuous stochastic process(Xt)that satisfies, for everyt ⩾ 0, the integral equation Xt = X0 +0 t σ (Xs) d Bs +0 t b(Xs) ds. Notice that ifthe ordinary differential equationσ (x) = 0 for every xx, this boils down to^ (t) = b(x(t)). The stochastic integral 0 t σ (Xs )d Bsis defined by approximations similar to those described in section 4. (For this to work, there are certain technical conditions that the process(X ) must satisfy.) In fact, stochastic dif-t

ferential equations were Itô’s original motivation for developing stochastic integrals. for each Itô proved, under suitable conditions onx \in  R the above equation has a unique solu-σ and b, that tion Markov process in the sense that was explained above:(Xt) that starts at x. Further more, this solution is a the way that(X ) evolves after time T given the valuet

of distributed in the same way as a solution of the equa-XT is independent of what happens before T, and is tion that starts at$X^{T}$. In fact, it is also a strong Markov process in the sense explained in section 5. black–scholes modelnance. In this model, the price of a share solves a An important example can be found in the famous[VII.9 §2](/part-07/the-mathematics-of-money) of mathematical fi stochastic differential equation of the type above withσ (x) = σ x and b(x) = bx, where σ and b are positive constants.
This is motivated by the simple idea that the price fluctuations of a share should be roughly proportional to its current value. In this context, the number σ is called the volatility of the share. stochastic differential equations in higher dimensions. The solution of a The previous discussion generalizes fairly easily tod-dimensional stochastic equation (which whend = 3 could model the water example mentioned at the beginning of this section) is once again a strong Markov process, known as a diffusion process tion ship between Brownian motion and partial differ-.
Much of what was said earlier about the relaential equations can be generalized to diffusion processes as well. Roughly speaking, with each diffusion process one can associate a differential operator L, and this operator plays the role that the Laplacian plays for Brownian motion.

655

7 Random Trees

Brownian motion and more general diffusion processes appear as limits of many discrete models in probability theory, combinatorics, and statistical physics. The most striking recent example of this is given by the so-called stochastic Loewner evolution (commonly abbreviated to SLE) processes, which are discussed in [IV.25 §5]). These are expected to describe the asymptotic behavior of a large number of two-dimensional models, and their definition involves both linear Brownian motion and the Loewner equation from complex analysis.
Rather than trying to give a general presentation of the relationship between Brownian motion and discrete models, in this final section we shall discuss a surprising application of Brownian motion to random trees, which can be used to describe the genealogy of a population. with a single “ancestor,” which we label place a probability distribution The basic discrete model is the following. We start\mu on the nonnegative∅. Then we integers, and use this to determine the number of chil-dren the ancestor has.
Then each child is assumed to have children, the numbers of children being indepen-dent and also determined by the probability distributionμ. And so on. The case that we shall be inter- ested in is the so-called number of children is exactly 1 (and the variance iscritical case, where the expected finite). labeled tree, called the We can represent the out come of this process as a genealogical tree, in a natural way. To draw the tree one simply joins each member ofthe population to its children. As for the labels, the children of the original ancestor are labeled 1,2, . . .
, left to right, the children of 1 are labeled children of 2 are labeled(2,1), (2,2), . . .(1,1), (, and so on. (For1, 2), . . . , the instance, the children of(3,4,2), if it is ever born, are labeled of figure 6 for a simple example of a tree. It is known(3, 4, 2, 1), (3, 4, 2, 2), . . . .) See the left-hand side that in this critical case the population will eventually die out with probability 1. (To avoid the certainty ofthis fate, the average number of children must be more than 1.
A particular case of this process is discussed in[IV.25 §2].) The genealogical tree, which we shall denote byθ, is a random variable. It is called the with offspring distribution\mu. A convenient way to repre - Galton–Watson tree sent this tree is via its so-called is illustrated on the right-hand side of figure 6. Infor-contour function, which mally, we imagine the motion of a particle that starts from the root and explores the tree from the left to the 656 θ C t (1,2,1) (1,2,2) (1,1) (1,2) (1,3) 2 1 2 ∅ Figure 6 Left: a treeθ. Right:
the contour function right, moving continuously along the edges at constant vertical speed (we set the height of each edge to 1), until it has completely explored the tree and come back to its starting point, after which it stays at this point. Since the particle will go along each edge exactly twice in this evolution, once upward and once downward, the total time ber of edges. The value T (θ) needed to explore the tree is twice the num-Cθ of the contour function att

time should be clear from figure 6.t is the height of the particle at time t. All this It may be that a typical tree dies out fairly quickly. However, our goal is to understand the shape of the tree when it is “conditioned to be large.” This is a bit like the difference between on the one hand picking a random person alive one thousand years ago and looking at the tree of all his or her descendants, and on the other hand looking at the tree of a random ancestor, alive one thousand years ago, of an individ-ual who is alive today.
In the latter case the tree is guaranteed to continue for many generations with out dying out. rather the population it represents) survives for Suppose we condition on the event that the treenθgen-(or erations. We may now ask all sorts of questions about this genealogical tree. How many individuals are there in a given generation of the tree? If we pick two individuals in the same generation, how far do we typically have to go back in the tree to reach a common ancestor? Asymptotic answers to such questions are also of interest in computer science and in combinatorics.
the event that tree is called We will condition on a slightly different event, namely$θθ^{n}$. It is a random tree with has exactly n edges. The condition edn edges, so T (θn) = 2 n. IV. Branches of Mathematics 1 2 3 T( )θ t C^θ.

having the distribution of In the particular case where the probabilityk children is 2θn-will actually be uniform over all(k+1), it is not hard to prove thatμ(k) of trees with the asymptotic behavior of the contour functionn edges. A famous theorem of Aldous gives (Cθ)n$as$ n → . nftyfor general offspring distributions, and it turns out to be very closely related to a linear Brownian motion. exhibits some behavior that is very untypical: it begins Notice that it cannot be a Brownian motion because it and ends at zero and remains positive for all time.
How-ever, we can use Brownian motion in a simple way to define a notion called a Brownian excursion, for which the sample paths have the right shape. The rough ideais to start a linear Brownian motion at zero, draw its graph, and then pick out the part of the graph betwee nx = x and x = x , where x is the point where it last crosses the where it first crosses the1 x-axis before^2 x-axis afterx^1= 1 andx =x^21. The corre-is the point sponding portion of the Brownian motion will start andend at zero and not cross zero in between.
We then need to rescale it so thatx to x , and we also need to rescale the height appro-x goes from 0 to 1 instead of from priately, by dividing by 11 2/. qrt{x}2 - x1. Also, if the path is every where negative between turn it upside down to make it positive.$x^{1} and x^{2}$, we simply tion of the contour function the factor 1 Aldous’s theorem states that the limiting dis tr ibu-/2 n and in space by the factor 1 C^θn (rescaled in time by/. qrt{2 n}, like the rescaling in section 3) is a Brownian excursion.
The surprising fact about this result is that it does not depend on the offspring distributionμ. Since the con- tour function completely determines the shape of the corresponding tree, we find that the limiting shape of

IV.25. Probabilistic Models of Critical Phenomena a large critical Galton–Watson tree does not depend onthe offspring distribution. This is another example of universality. This result and variants of it provide a lot of useful information about the asymptotic behavior of large trees. Many interesting functions of the tree can berewritten in terms of the contour function and by Aldous’s theorem they will converge to similar func-tions of the Brownian excursion, whose distribution can be computed explicitly with the help of stochastic cal-culus.
To give just one example, this technique can be used to calculate the limiting distribution of the height of the treeθn. Let the variance of the offspring distribution betree to be its original height multiplied byσ, and let us define the rescaled heightσ /2 . qrt{n}. Theof a probability that this is at least asn gets large, to the quan tit yx turns out to converge,$2$ k. nfty=^1(4 x^2 k^2 - 1) . xp (-2 k^2 x^2). Acknowledgments.for his help with the simulations and to Gordon Slade for The author is indebted to Gilles Stoltz his remarks on the first version of this article.
Further Reading Aldous, D. 1993. The continuum random tree. III.Probability 21:248–89. Annals of Bachelier, L. 1900. Théorie de la spéculation.tifiques de l’École Normale Supérieure (3) 17:21–86.Annales Scien Billingsley, P. 1968.New York: John Wiley. Convergence of Probability Measures. Durrett, R. 1984.sis. Belmont, CA: Wadsworth. Brownian Motion and Martingales in Analy Einstein, A. 1956.ian Movement. New York: Dover. Investigations on the Theory of the Brown Revuz, D., and M. Yor. 1991.Brownian Motion. New York: Springer. Continuous Martingales and Stroock, D. W., and S. R. S. Varadhan.
1979.Diffusion Processes. New York: Springer.multi dimensional Wiener, N. 1923. Differential space. Physics Massachusetts Institute of Technology Journal of Mathematical2:131–74. IV.25 Probabilistic Models of Critical Phenomena Gordon Slade 1 Critical Phenomena 1.1 Examples A population can explode if its birth rate exceeds its death rate, but otherwise it becomes extinct. The 657 nature of the population’s evolution depends critically on which way the balance tips between adding new members and losing old ones. A porous rock with randomly arranged microscopic pores has water spilled on top.
If there are few pores, the water will not percolate through the rock, but if there are many pores, it will. Surprisingly, there is a critical degree of porosity that exactly separates these behaviors. If the rock’s porosity is below the critical value, then water cannot flow completely through the rock, but if its porosity exceeds the critical value, even slightly, then water will percolate all the way through. A block of iron placed in a magnetic field will become magnetized.
If the magnetic field is extinguished, then the iron will remain magnetized if the temperature is below the Curie temperature 770◦C (1418◦F), but not if the temperature is above this critical value. It is strik-ing that there is a specific temperature above which the magnetization of the iron does not merely remain small, but actually vanishes. enatem change abruptly as a relevant parameter (fertility, The above are three examples of. In each example, global properties of the sys-critical ph en om degree of porosity, or temperature) is varied through a critical value.
For parameter values just below the critical value, the over all organization of the system is quite different from how it is for values just above. The sharpness of the transition is remarkable. How does it occur so suddenly?

1.2 Theory

The mathematical theory of critical phenomena is cur-rently under going intense development. Intertwined with the science of phase transitions, it draws on ideas from probability theory and statistical physics. The theory is inherently probabilistic: each possible configuration of the system (e.g., a particular arrangement of pores in a rock, or of the magnetic states of the individual atoms in a block of iron) is assigned a probability, and the typical behavior of this ensemble of random configurations is analyzed as a function of parameters of the system (e.g., porosity or temperature).
large degree by a profound insight from physics known as The theory of critical phenomena is now guided to a universality, which, at present, is more of a philosophy than a mathematical theorem. The notion of universality refers to the fact that many essential fea-tures of the transition at a critical point depend on relatively few attributes of the system under consid-eration. In particular, simple mathematical models can

658

capture some of the qualitative and quantitative fea-tures of critical behavior in real physical systems even if the models dramatically oversimplify the local inter ac-tions present in the real systems. This observation has helped to focus attention on particular mathematical models, among both physicists and mathematicians.
nomena that have attracted much attention from math-This essay discusses several models of critical ph ee maticians, namely branching processes, the model of random networks known as the random graph, the percolation model, the Ising model of ferromagnetism, andthe random cluster model. As well as having applications, these models are mathematically fascinating. Deep theorems have been proved, but many problems of central importance remain unsolved and tantalizing conjectures abound. 2 Branching Processes Branching processes provide perhaps the simplest example of a phase transition.
They occur naturally asa model of the random evolution of a population that changes in time as a result of births and deaths. The simplest branching process is defined as follows. that reproduces immediately before death. The organ-Consider an organism that lives for a unit time and ism has two potential offspring, which we can regard as the “left” offspring and the “right” offspring. At the moment of reproduction, the organism has either no offspring, a left but no right offspring, a right but no left offspring, or both a left and a right offspring.
Assume that each of the potential offspring has a probability of being born and that these two births occur inde-$p$ pendently. Here, the number and 1, is a measure of the population’s fecundity. Sup-$p$, which lies between 0 pose that we start with a single organism at time zero, and that each descendant of this organism reproduces independently in the above manner. A possible family tree is depicted in figure 1, showing all births that occurred.
In this family tree, ten offspring were produced in all, but twelve potential offspring were not born, so the probability of this particular tree occurring isp10(1 - p)12.$If$ p =$0$, then no offspring are born, and the family tree always consists of the original organism only. If$p =$1, then all possible offspring are born, the family tree is the infinite binary tree, and the population always survives for ever. For intermediate values ofp, the population may or may not survive for ever: letθ(p)

IV. Branches of Mathematics

Figure 1 with probability A possible family tree,$p10(1 - p)12$. denote theity that the branching process survives for ever when survival probability, that is, the probabil the fecundity is set at between the two extreme sp. How doesθ(0) = 0 andθ(p)θ(1 interpolate) =1?

2.1 The Critical Point

Since an organism has each of two potential offspring independently with probabilityp, it has, on average, 2 for all time will not occur ifp offspring. It is natural to suppose that survival$p <^{1}$, since then each organism, on average, produces less than 1 offspring. On the other hand, if$p >1$, then, on average, organ-2 isms more than replace themselves, and it is plausi-2 ble that a population explosion can lead to survival forall time. Branching processes have a recursive nature, not present in other models, that facilitates explicit com-putation.
Exploiting this, it is possible to show that the survival probability is given by$\{||\{0 if p ⩽^{1}^{2}$,θ(p) =⎪⎪⎩ p12 (2 p - 1) if p ⩾1 2.

The value graph of$θ(p)p = p$ has a kink (see figure 2). The inter valc = 1 2 is a critical value, at which thep < ps up er critic alc is referred to as. subcritical, where as p > pc is the initial organism has infinitely many descendants, one could ask for the probability Rather than asking for the probability P (p) that the num-θ(p) that ber of descendants is at leastk + 1 descendants, then there are certainly at leastk. If there are at leastk k, so Pk(p) decreases as k increases.
In the limit as k increases to infinity, ticular, whenp > p , PPk(p)(p) approaches a positive limit decreases to θ(p). In par - as whe nk approaches infinity, whereasp ⩽ p . When cpk is strictly less than Pk(p) goes to zerop , it can be c c

IV.25. Probabilistic Models of Critical Phenomena

θ1 p = 0 1 2 Figure 2 The survival probabilityθ versus p. shown that but at the critical value itself we have Pk(p) goes to zero exponentially rapidly, Pk(pc) ∼ . qrt{2πk}. The symbol “∼” denotes asymptotic behavior, and means that the ratio of the left- and right-hand sides in the above formula goes to 1 ask goes to infinity. In other words, whenk is large. Pk(pc) behaves essentially like 2/. qrt{πk} nential decay of decay at There is a pronounced difference between the expo - p .
When Pk(pp = c)1 for, family trees larger than 100 p < pc and the square-root are sufficiently rare that in practical terms they do not occur: the probability is less than 10 c 4 - 14. However, whenp = p , roughly one in every ten trees will have size at c least 100, and roughly one in a thousand will have sizeat least 1 000 000. At the critical value, the process is poised between extinction and survival. Another important attribute of the branching process is the average size of a family tree, denoted A calculation shows thatχ(p)$.\{|\{ 1 if p <1$,= 1 - 2 p2χ(p)⎪⎩. nfty if p ⩾1 2.
In particular, the average family size becomes infiniteat the same critical valuep = 1 above which the prob- ability of an infinite family ceases to be zero. The graphofχis shown in figure 3. Atcp = 2 p, it may seem at first c sight contradictory that family trees are always finite(sinceθ(p ) =0) and yet the average family size is infic nite (sinceχ(p ) =$\infty)$. However, there is no inconsis- c tency, and this combination, which occurs only at the critical point, reflects the slowness of the square-root decay of$P^{k}(p^{c})$.$659$χ1$p = 0$2 1

Figure 3 The average family sizeχ versus p.

2.2 Critical Exponents and Universality

Some aspects of the above discussion are specific to twofold branching, and will change for a branching process with higher-order branching. For example, if each organism has not two but again independently with probabil i tym potential offspring, p, then the aver- age number of offspring per organism ismp and the critical probability las written above for the survival probability, for thepc changes to 1/m. Also, the formu- probability of at leastk descendants, and for the aver- age family size must all be modified and will involve the parameterm.
However, the way thatθ(p) goes to zero at the critical point, the way that Pk(pc) goes to zero as k goes to infinity, and the way thatp approaches the critical pointχ(p) pdiverges to infinity aswill all be governed c by exponents that are independent ofm. To be more specific, they behave in the following manner: θ(p) ∼ C1(p - pc)β, as p \to  p+c, Pk(pc) ∼ C2 k - 1/δ, as k → $\infty$,χ(p) ∼ C3(pc - p()-)γ$, as p \to p - c$.

Here, the numbers$C^{1}$, C2, and C3 are constants that depend ontake on the same values for everym. By contrast, the exp one ntsm ⩾ 2. Indeed, thoseβ, δ, and γ values areβ = 1, δ = 2, and γ = 1. They are called critical exponents, and they are universal in the sense that they do not depend on the precise form of the law that governs how the individual organisms repro-duce. Related exponents will appear below in other models.

660

3 Random Graphs

An active research field in discrete mathematics with many applications is the study of objects known as graphs as the Internet, the World Wide Web, and highway net-[III.34]. These are used to model systems such works. Mathematically, atices (which might represent computers, Web pages, or graph is a collection of ver cities) joined in pairs by between computers, hyperlinks between Web pages, edges (physical connections highways). Graphs are also called networks, vertices are also called or bonds. nodes or sites, and edges are also called links

3.1 The Basic Model of a Random Graph

A major subarea of graph theory, initiated by Erd ̋Rényi in 1960, concerns the properties that a graph typ-os and ically has when it has been generated randomly. A nat-ural way to do this is to taken vertices and for each pair to decide randomly (by the toss of a coin, say) whether it should be linked by an edge. More generally, one can choose a numberp between 0 and 1 and letp be the probability that any given pair is linked.
(This would correspond to using a biased coin to make the decisions.) The properties of random graphs come into their own when the fact that there is a phase transition.n is large, and of particular interest is 3.2 The Phase Transition Iftoxyandis a sequence of vertices that starts withy are vertices in a graph, then a path fromx andx ends withy in such a way that neighboring terms of the sequence are joined by edges.
(If the vertices are represented by points and the edges by lines, then a path is a way of getting from the lines.) Ifx and y are joined by a path, then theyx to y by traveling along are said to be cluster, in a graph is what you obtain if you take a vertex connected. A component, or connected together with all the other vertices that are connected to it. Any graph decomposes naturally into its connected clusters.
These will, in general, have different sizes (asmeasured by the number of vertices), and given a graph it is interesting to know the size of its largest cluster, which we shall denote by random graph withn vertices, then the value of N. If we are considering a N will depend on the multitude of random choices made when the graph was generated, and thus N is itself a ran- dom variable. The possible values of N are everything

IV. Branches of Mathematics

from 1, the value it takes when no edges are present and every cluster consists of a single vertex, ton, when there is just one connected cluster consisting of all the vertices. In particular, N = 1 when p = 0$, and N = n$ whenp = 1. At a certain point between these extremes, N under goes a dramatic jump.

It is possible to guess where the jump might take place, by considering the This means the number of degree neighbors of a typical vertex ofx, that is, otherx. vertices that are directly linked to Each vertex hasn - 1 potential neighbors, and for eachx by a single edge. one the probability that it is an actual neighbor isso the expected degree of any given vertex is p(n - 1 p),. Whenp is less than 1/(n - 1), each vertex has, on aver- age, less than one neighbor, where as when1$/(n - 1)$, it has, again on average, more than one.
Thisp exceeds suggests thatp = 1/(n-1) will be a critical value, with c N being small when p is below p , and large when p is c above This is indeed the case. If we set$p^{c}$. p = 1/(n - 1) and c write$p = p (1 + ε)$, with εa fixed number between c -1 and +1, then ε = p(n - 1) - 1. Since p(n - 1) is the average degree of each vertex, how much the average degree differs from 1. Erd ̋ε is a measure ofos and Rényi showed that, in an appropriate sense, asto infinity,$n goes\{|||2ε^{-2} \log n if ε < 0$, N ∼ ⎨⎪⎪⎪⎩A(n2()/){3} if ε = 0,$2$εn if ε > 0.

The A in the above formula is not a constant but a cer- tain random variable that is independent oftribution of which we have not specified here). Whenn (the dis-ε = 0 and n is large, the formula will tell us, for anya < ba(n2()/)3, the approximate probability that and bn2^/3. To put it another way, ANis the lies between limiting distribution of the qu anti tyn-2/3 N when ε = 0. the functions log There is a marked difference between the behavior of$n$, n2/3, and n, for large n.
The small clusters present fora subcritical phase, where as in the so-call edp < pc correspond to what is called super cr it i- cal phase, where$p > p$, there is a “giant cluster” whose c size is of the same order of magnitude as the entire graph (see figure 4). It is interesting to consider the “evolution” of the random graph, ascritical values. (Here one can imagine more and morep is increased from subcritical to super- edges being randomly added to the graph.) A remarkable coalescence occurs, in which many smaller clusters

IV.25. Probabilistic Models of Critical Phenomena (a) p =34 pc = 0.0012$(b) p =$54 pc = 0.0020 Figure 4 cluster (dots) in random graphs with 625 vertices. These The largest cluster (black) and second largest clusters have sizes (a) 17 and 11 and (b) 284 and 16. The hundreds of edges in the graphs are not clearly shown. rapidly merge into a giant cluster whose size is proportional to the size of the entire system. The coales-cence is thorough, in the sense that in the supercritical phase the giant cluster dominates everything:
indeed, the second-largest cluster is known to have asymptotic size only 2ε-2 . og n, which makes it far smaller than the giant cluster.

3.3 Cluster Size

For branching processes, we defined the quantityχ(p) to be the average size of the family tree spawned by an

661

individual when the probability of each potential off-spring being born wasp. By analogy, for the random graph it is natural to take an arbitrary vertexv and define cluster containingχ(p) to be the average size of the connect edv. Since all the vertices play iden- tical roles, of$v$. If we fix a value ofχ(p) is independent of the particular choiceε$, set p = p (1 + ε)$, and let n c tend to infinity, it turns out that the behavior ofis described by the formula$χ(p)\{|||\{1/|ε| if ε < 0$,χ(p) ∼ ⎪⎪⎪⎩c(n1()/){3} if ε = 0, 4$ε2n if ε > 0$,

where is independent ofc is a constant. Thus the expected cluster sizen when ε < 0, grows like (n1()/){3} whenp = p, and is much larger—indeed, of the same order c of magnitude nas the entire system—when$ε > 0$. let To continue the analogy with branching processes, Pk(p) denote the probability that the cluster con- taining the arbitrary vertextices. Again this does not depend on the particularv consists of at least k ver- choice ofv . In the subcritical phase, when p = p (1+ε) c for some fixed negative value ofε, the probability Pk(p) is essentially independent of small ink.
Thus, large clusters are extremely rare. How-n and is exponentially ever, at the critical point$\sqrt{p} = p^{c}$, Pk(p) decays like a multiple of 1 This much slower square-root decay is similar to what/ k (for an appropriate range of k). happens for branching processes.

3.4 Other Thresholds

It is not only the largest cluster size that jumps. An-other quantity that does so is the probability that a random graph is connected, meaning that there is a single connected cluster that contains all the ti ces. For what values of the edge-probabilityp nis this ver- likely? It is known that the property of being connected has a sharp threshold, at p = (1/n). og n, in the following sense. Ifnegativeε, then the probability that the graph is con - p = pc onn conn(1 + ε)for some fixed nected approaches 0 asn →. nfty. If on the other hand ε is positive, then the probability approaches 1.
Roughly speaking, if you add edges randomly, then the graph suddenly changes from being almost certainly not connected to almost certainly connected as the proportion of edges present moves from just below above it. pconn to justof this sort. Other examples include the absence of any There is a wide class of properties with thresholds 662 Figure 5 for Bond - percolation configurations on a 14$p = 0$.25, p = 0.45, p = 0.55, p = isolated vertex (a vertex with no incident edge), and the presence of a Hamiltonian cycle (a closed loop that vis-its every vertex exactly once).
Below the threshold, the random graph almost certainly does not have the prop - erty, where as above the threshold it almost certainly does. The transition occurs abruptly. 4 Percolation The percolation model was introduced by broadbent and Hammersley in 1957 as a model of fluid flow in a porous medium. The medium contains a network ofrandomly arranged microscopic pores through which fluid can flow.
Aeled with the help of the infinit ed-dimensional medium can be mod - d-dimensional lat- tice Zd, which consists of all points x of the form(xbe made into a graph in a natural way if we join each1, .
 . . , xd), where each xi is an integer. This set can point to the 2 dpoints that differ from it by±1 in one coordinate and are the same in the others. (So, for example, in Z2 the neighbors of(2,3) are the four points(1, 3), (3, 3), (2, 2)$, and (2$, 4).) One thinks of the edges as representing all pores potentially present inthe medium. porosity parameter and 1. Each edge (or bond) of the above graph is then To model the medium itself, one first chooses ap, which is a number between 0 retained with probability1 - p, with all choices independent.
The retained edgesp and deleted with probability are referred to as “occupied” and the deleted ones as“vacant.” The result is a random subgraph of Zd whose edges are the occupied bonds. These model the pores actually present in a macroscopic chunk of the medium. set of pores connected together on a macroscopic scale. This idea is captured in the model by the existence of For fluid to flow through the medium there must be a an infinite cluster in the random subgraph, that is, a collection of infinitely many points all connected to one another.
The basic question is whether or not an infinite cluster exists. If it does, then fluid can flow through IV. Branches of Mathematics 0.75. The critical value is . imes 14 piece of the square lattice pc =1 2 . Z2 the medium on a macroscopic scale, and otherwise it cannot. Thus, when an infinite cluster exists, it is said that “percolation occurs.” Percolation on the square lattice Z2 is depicted in figure 5. Percolation in a three-dimensional physical medium is modeled using Z3.
It is instructive, and mathematically interesting, to think how the model’s behavior might change as the dimension Ford = 1, percolation will not occur unlessd is varied.p = 1. The simple observation that leads to this conclusion isthe following. Given any particular sequence ofm con- secutive edges, the probability that they are all occu-pied is$pm$, and if p < 1, then this goes to zero asmd ⩾goes to infinity. The situation is quite different for2. 4.1 The Phase Transition Forthe probability that any given vertex ofd ⩾ 2, there is a phase transition.
Let θ(p)Zd is in an denote infinite connected cluster. (This probability does not depend on the choice of vertex.) It is known that ford ⩾ 2 there is a critical value p , depending on d, such c thatθ(p) is zero if p < pc and positive if p > pc. The exact value ofsymmetry of the square lattice allows for a proof thatpc is not known in general, but a special pc = 1 2 when d = 2.
Using the fact thatθ(p) is the probability that any particular vertex lies in an infinite cluster, it can be shown that whenθ(p) >0 there must be an infinite connected cluster some where in Z d, while when θ(p) = 0 there will not be one. Thus, percolation occurs when p > p but not when p < p, and the system’s behavior changes abruptly at the critical value. A deeper argu-ment shows that whencp > pc there must be exactly one c infinite cluster; infinite clusters cannot coexist on Zd.
This is analogous to the situation in the random graph, where one giant cluster dominates whenp is above the critical value.

IV.25. Probabilistic Models of Critical Phenomena cluster containing a given vertex. Certainly ni te for Letχ(p)p > pde note the average size of the connected, since then there is a positive proba-χ(p)is infic bility that the given vertex is in an infinite cluster. It is conceivable that values ofp less thanχ(p) pcould be infinite also for somec, since infinite expectation is in principle compatible withθ(p) = 0. However, it is a nontrivial and important theorem of the subject that this is not the case:χ(p)is finite for allp < pc and diverges to infinity asp approaches p from below.
c ance depicted for the branching process in figures 2 and 3, although the critical value will be less than Qualitatively, the graphs ofθ and χ have the appear-1 for dth at⩾ 3. There is, however, a caveat. It has been provedθ is continuous in p except possibly at pc, and2 right-continuous for allis equal to zero at the critical point, so thatp. It is widely believed thatθ is con-θ tinuous for all critical point. But proofs thatp and percolation does not occur at theθ(p ) = 0 are currently c known only ford = 2, for d ⩾ 19, and for certain related models whend > 6.
The lack of a general proof is all the more intriguing since it has been proved for alld ⩾2 that there is zero probability of an infinite cluster in any half-space whenp = p . This still allows for an c infinite cluster with an unnatural spiral behavior, for example, though it is believed that this does not occur. 4.2 Critical Exponents Assuming thatis decreased toθ(p)p , it is natural to ask in what man-does in fact approach zero as p c ner this occurs. Similarly, we can ask in what man - nerχ(p) diverges as p increases to pc.
Deep argu- ments of theoretical physics, and substantial numerical experimentation, have led to the prediction that this, as well as other, behavior is described by certain powers known as critical exponents. In particular, it is predicted that there are asymptotic formulas$θ(p) ∼ C(p - pc)β$, as p \to p + c,χ(p) ∼ C(pc - p()-)γ, as p \to  p-c. The critical exponents here are the powers which depend, in general, on the dimensiond.
(The let-β and γ, teris inessential and may change from line to line.)C is used to denote a constant whose precise value Whenp is less than p , large clusters have exponen- c tially small probabilities. For example, in this case the probability P (p) that the size of the connected cluster containing any given vertex exceeds exponentially ask k →. nfty. At the critical point, this expo - k is known to decay nential decay is predicted to be replaced by a power - law 663 decay involving a number exponent:δ, which is another critical Pk(pc) ∼ C(k-1)/δ as k →. nfty.

vertices ter decays exponentially like e Also, forx p < pand yc, the probability are in the same connected clus-^−(|x)-yτ^|p^/ξ(p)(x, y)as the sep-that two a ration betweenξ(p) is called th ex correlation length and y is increased. The number. (Roughly speak- ing, tance betweenτp (x, y) starts to become small when the dis-x and y exceeds ξ(p).) The correlation length is known to diverge aspredicted form of this divergence is$p \text{increases to} p^{c}$, and theξ(p) ∼ C(pc - p)^-^ν as p \to  p-c, where decay at the critical point is no longer exponential. Itν is a further critical exponent.
As before, the is predicted thatτp c (x, y) decays instead via a power law, traditionally written in the form (τp)c (x, y) ∼ C |x - y1(|d()-2()+){η}, as |x - y| →. nfty, for yet another critical exponent The critical exponents describe large-scale aspects ofη. the phase transition and thus provide information relevant to the macroscopic scale of the physical medium. However, in most cases they have not been rigorously proved to exist.
To do so, and to establish their values, is a major open problem in mathematics, one of central importance for percolation theory. In view of this, it is important to be aware of a prediction from theoretical physics that the exponents are not independent, but are related to each other by what are called scaling relations. Three scaling relations areγ = (2 - η)\nu$, γ + 2β = β(δ + 1)$, d\nu = γ + 2β.

4.3 Universality

Since the critical exponents describe large-scale behav-ior, it seems plausible that they might depend only weakly on changes in the fine structure of the model. In fact, it is a further prediction of theoretical physics, one that has been verified by numerical experiments, that the critical exponents are that they depend on the spatial dimension universal, in the sensed but on little else. For example, if the two-dimensional lattice Z2 is replaced by another two-dimensional lattice, such as the triangular or the hexagonal lattice, then the values of the critical exponents are believed not to
change. Another modification, for general d ⩾ 2, is to replace the standard percolation model with the so - called 664 spread-out model of Zd is enriched so that now two vertices are joined. In the spread-out model, the edge set whenever they are separated by a distance of where L ⩾1 is a fixed finite parameter, usually taken L or less, to be large. Universality suggests that the critical expo-nents for percolation in the spread-out model do not depend on the parameter The discussion so far falls within the general frame - L.
work of bond percolation, in which it is bonds (edges) that are randomly occupied or vacant. A much-studied variant is site percolation, where now it is vertices, or “sites,” that are independently “occupied” with proba - bility pand “vacant” with probability 1- p. The con- nected cluster of a vertex itself together with those occupied vertices that canx consists of the vertex x be reached by a path that starts at edges in the graph, and visits only occupied vertices.x, travels along Ford ⩾ 2, site percolation also experiences a phase transition.
Although the critical value for site percola-tion is different from the critical value for bond percolation, it is a prediction of universality that site and bond percolation on Zd have the same critical exponents. ing: the large-scale properties of the phase transition described by critical exponents appear to be insensitive These predictions are mathematically very intriguto the fine details of the model, in contrast to features like the value of critical probability heavily on such details.
pc, which depends been proved to exist, and their values rigorously com - puted, only for certain percolation models in dimen-At the time of writing, the critical exponents have sionsd = 2 and d > 6, while a general mathematical understanding of universality remains an elusive goal. 4.4 Percolation in Dimensions d > 6

Using a method known as the been proved that the critical exponents exist, with lace expansion, it has values

$β = 1$, γ = 1, δ = 2, ν =1 2$, η = 0$,

for percolation in the spread-out model when and L is large enough. The proof makes use of thed > 6 fact that vertices in the spread-out model have many neighbors. For the more conventional nearest-neighbor model, where bonds have length 1 and there are fewer neighbors per vertex, results of this type have also been obtained, but only in dimensions$d ⩾ 19$. The above values ofβ, γ, and δ are the same as those observed previously for branching processes. Abranching process can be regarded as percolation on

IV. Branches of Mathematics

an infinite tree rather than on Zd , and thus percola- tion in dimensionsa tree. This is an extreme example of universality, ind > 6 behaves like percolation on which the critical exponents are also independent ofthe dimension, at least when$d > 6$. into the scaling relation Thus, the scaling relation (called a If the above values for the exponents are substituteddν = γ +2 hyperscalingβ, the result isrelationd = 6. because of the presence of the dimension tion) is false ford > 6. However, this particular rela-d in the equa- tion is predicted to apply only in dimensions$d ⩽ 6$.
In lower dimensions, the nature of the phase transition isaffected by the manner in which critical clusters fit into space, and the nature of the fit is partly described bythe hyperscaling relation, in whichd appears explicitly. ferent values below much light on the situation for The critical exponents are predicted to take on dif-d = 6. Recent advances have shedd = 2, as we shall see in the next section.

4.5 Percolation in Dimension 2

4.5.1 Critical Exponents and Schramm–Loewner Evolution For site percolation on the two-dimensional triangular lattice it has been shown, in a major recent achievement, that the critical exponents exist and take the remarkable values $β = {}^{3}6^{5}$, γ =4318 $, δ =915$, ν =4 3$, η =245$. The scaling relations play an important role in the proof, but an essential additional step requires understanding of a concept known as the To get some idea of what this is, let us look at the scaling limit. so-called ure 6.
In figure 6, hexagons represent vertices of the tri-exploration process, which is depicted in fig angular lattice. Hexagons in the bottom row have been colored gray on the left half and white on the right half. The other hexagons have been chosen to be gray or white independently with probability 1, which is the critical probability for site percolation on the triangu-lar lattice. It is not hard to show that there is a path,2 also illustrated in figure 6, which starts at the bottom and all along its length is gray to the left and white tothe right.
The exploration process is this random path, which can be thought of as the gray/white interface. The boundary conditions at the bottom force it to be infinite. The exploration process provides information about the boundaries separating large critical clusters of dif-ferent color, and from this it is possible to extract

IV.25. Probabilistic Models of Critical Phenomena Figure 6 The exploration process. information about critical exponents. It is the macro-scopic large-scale structure that is essential, so interest is focused on the exploration process in the limit as the spacing between vertices of the triangular lattice goes to zero. In other words, what does the curve in figure 6 typically look like in the limit as the size of the hexagons shrinks to zero?
It is now known that this limit is described by a newly discovered stochastic process tion (SLE) with parameter six, or SLE[IV.24 §1](/part-04/stochastic-processes) called the Schramm–Loewner evolu-6 for short. The SLE processes were introduced by Schramm in 2000, and have become a topic of intense current research activity. of two-dimensional site percolation on the triangular This is a major step forward in the understanding lattice, but much remains to be done. In particular, it is still an unsolved problem to prove universality.
There is currently no proof that critical exponents exist for bond percolation on the square lattice Z2, although universality predicts that the critical exponents for the square lattice should also take on the interesting values listed above.

4.5.2 Crossing Probabilities

In order to understand two-dimensional percolation, itis very helpful to understand the probability that there will be a path from one side of a region of the plane to another, especially when the parameter critical value pc. p takes its region in the plane (i.e., a region with no holes), andfix two arcs on the boundary of the region. The To make this idea precise, fix a simply connected crossing probability (which depends onp) is the probability that

665

Figure 7 formation, depicted in the upper figures. In the lower fig-The two regions are related by a conformal trans ures, the limiting critical crossing probabilities are identi-cal. there is an occupied path inside the region that joins one arc to the other, or more accurately the limit ofthis probability as the lattice spacing between vertices is reduced to zero. For much larger than the correlation length p < pc, clusters with diameterξ(p) (measured by the number of steps in the lattice) are extremely rare.
However, to cross the region, a cluster needs to be larger and larger as the lattice spacing goes to zero. It follows that the crossing probability is 0. When there is exactly one infinite cluster, from which it can p > pc, be deduced that if the lattice spacing is very small, then with very high probability there will be a crossing of the region. In the limit, the crossing probability is 1. Whatif p = p? There are three remarkable predictions for c critical crossing probabilities.
bilities are universal, which is to say that they are the The first prediction is that critical crossing proba same for all finite-range two-dimensional bond- or site-percolation models. (As always, we are talking about the limiting probabilities as the lattice spacing goesto zero.) ing probabilities are The second prediction is that the critical cross-conformally invariant. A conformal transformation is a transformation that locally preserves angles, as shown in figure 7.
The remarkable any two simply connected regions that are not the riemann mapping theorem [V.34](/part - 05/the-\text{uniformization} - theorem) states that entire plane are related by a conformal transformation. The statement that the critical crossing probability is 666 s Side = 1 Figure 8 Cardy’s formula asserts that the limiting critical crossing For the equilateral triangle of unit side length, probability shown is simply the lengths.
conformally invariant means that if one region with two specified boundary arcs is mapped to another region by a conformal transformation, then the critical crossing probability between the images of the arcs in the new region is identical to the crossing probability ofthe original region. (Note that the underlying lattice is not striking.)transformed; this is what makes the prediction so The third prediction is Cardy’s explicit formula for critical crossing probabilities. Assuming conformal in - variance, it is only necessary to give the formula for one region.
For an equilateral triangle, Cardy’s formula is particularly simple (see figure 8).In 2001, in a celebrated achievement, Smirnov studied critical crossing probabilities for site percolation on the triangular lattice. Using the special symmetries of this particular model, Smirnov proved that the limiting critical crossing probabilities exist, that they are conformally invariant, and that they obey Cardy’s formula. To prove universality of the crossing probabilities remains a tantalizing open problem.
5 The Ising Model In 1925, Ising published an analysis of a mathematical model of ferromagnetism which now bears his name (although it was in fact Ising’s doctoral supervisor Lenz who first defined the model). The Ising model occupies a central position in theoretical physics, and is of considerable mathematical interest.

5.1 Spins, Energy, and Temperature

In the Ising model, a block of iron is regarded as a col-lection of atoms whose positions are fixed in a crystalline lattice. Each atom has a magnetic “spin,” which is assumed for simplicity to point upward or downward.

IV. Branches of Mathematics

Each possible configuration of spins has an associated energy, and the greater this energy is, the less likely the configuration is to occur. their immediate neighbors, and the energy reflects this: it increases according to the number of pairs of neigh-On the whole, atoms like to have the same spin as boring spins that are there is an external magnetic field, also assumed to benot aligned with each other. If directed up or down, then there is an additional contri-bution:
atoms like to be aligned with the external field, and the energy is greater the more spins there are that are not aligned with it. Since configurations with higher energy are less likely, spins have a general tendency to align with each other, and also to align with the direc-tion of the external magnetic field. When a larger fraction of spins points up than down, the iron is said tohave a positive magnetization.
Although energy considerations favor configurations with many aligned spins, there is a competing effect. As the temperature increases, there are more random thermal fluctuations of the spins, and these diminish the amount of alignment. Whenever there is an external magnetic field, the energy effects predominate and there is at least some magnetization, however high the temperature. However, when the external field is turned off, the magnetization persists only if the tempera-ture is below a certain critical temperature. Above this temperature, the iron will lose its magnetization.
tures the above picture. The crystalline lattice is mod-eled by the lattice The Ising model is a mathematical model that cap-Zd. Vertices of Zd represent atomic positions, and the atomic spin at a vertex modeled by one of the two numbers+1 (representingx is simply spin up) or-1 (representing spin down). The particular number chosen at choices, one for eachx is denote dx in the lattice, is called aσx, and a collection of configuration of the Ising model. The configuration as a whole is denoted simply asa function from the lattice to the setσ.
(Formally, a configuration$\\{−1}$, 1\\\\\\\\\\\\\\\\\\\\\}.) σ is gy, defined as follows. If there is no external field, the energy of Each configurationσ consists of the sum, taken over all pairsσ comes with an associated ener- of neighboring vertices This quantity is-1 if σ x, y= σ , of the quantity, and is +1 otherwise, so-σxσy. the energy is indeed larger the more nonaligned pairs there are.
If there is a nonzero external field, mod- xyeled by a real number additional contributi onh-, then the energy receives anhσ , which is larger the more spins there are with a different sign from that of Thus, in total, the energy E(σ )xof a spin con fig ur at i onh. IV.25.
Probabilistic Models of Critical Phenomena σis defined by E(σ ) = −x, y σx σy - hx σx, where the first sum is over neighboring pairs of ver - tices, the second sum is over vertices, andh is a real number that may be positive, negative, or zero. The sums defining E(σ ) actually make sense only when there are finitely many vertices, but one wishes to study the infinite lattice Zd. This problem is handled by restricting Zdto a large finite subset and later taking an appropriate limit, the so-called limit.
This is a well-understood process that will not be thermodynamic described here. Two features remain to be modeled, namely, the manner in which lower - energy configurations are “pre - ferred,” and the manner in which thermal fluctuations can lessen this preference. Both features are handled simultaneously, as follows. We wish to assign to each configuration a probability that decreases as its energy increases.
According to the foundations of statistical mechanics, the right way to do this is to make the probability proportional to the so - called tor e - E(σ )/T , where T is a nonnegative parameter that Boltzmann fac- represents the temperature. Thus, the probability is1 P (σ ) = Z e-E(σ )/T,

where the normalization constant, or$Z$, is defined by partition function,

$Z = e^{-E}(σ )/T$,

where the sum is taken over all possible configurationsσ(again it is necessary to work first in a finite subsetσ of Zd to make this precise). The reason for this choice of Z is that once we divide by it then we have ensured that the probabilities of the configurations add up toone, as they must. With this definition, the desired preference for low energy is achieved, since the probabil-ity of a given configuration is smaller when the energy of the configuration is larger.
As for the effect of the temperature, note that when T is very large, all the numbers e - E(σ )/T are close to 1, so all probabilities are roughly equal. In general, as the temperature increases the probabilities of the various configurations become more similar, and this models the effect of random thermal fluctuations. There is more to the story than energy, however. The Boltzmann factor makes any individual low-energy con-figuration much more likely than any individual highenergy configuration.
However, the low-energy config-urations have a high degree of alignment, so there are 667 far fewer of them than there are of the more randomly arranged high - energy configurations. It is not obvious which of these two competing considerations will predominate, and in fact the answer depends on the value of the temperature T in a very interesting way. 5.2 The Phase Transition For the Ising model with external fieldh and tem- per at ure with the probabilities defined above.
The T, let us choose a configuration randomly magnetization spin M(h, T )σ at a given vertex is defined to be the expected value of thex. Because of the symmetry of the lattice ular vertex chosen. Accordingly, if the magnetization x Zd, this does not depend on the partic-M(h, T ) is positive, then spins have an over all tendency to be aligned in the positive direction, and the system is magnetized. M(reverses the magnetization) for all The symmetry between up and down implies that-h, T ) = −M(h, T )(i.e., reversing the external fieldh and T.
In partic- ular, whenh = 0, the magnetization must be zero. On the other hand, if there is a nonzero external field then configurations with spins that are aligned withhh, are overwhelmingly more likely (because their energy is lower), and the magnetization satisfies

$\{|||< 0 if h < 0$, M(h, T ) ⎨⎪⎪⎪⎩= 0 if h = 0,> 0 if h > 0.

tive and then is reduced to zero? In particular, is the spontaneous magnetization What happens if the external field is initially posi-, defined by

M+(T ) = h . im \t(o0)+ M(h, T ),

positive or zero? Iftization persists after the external field is turned off. In M+(T ) is positive, then the magne- this case there will be a discontinuity in the graph of versus h at h = 0. M Whether or not this happens depends on the temperature difference in the energies of two configurations results T. In the limit as T is reduced to zero, a small in an enormous difference in their probabilities. Whenh > 0 and the temperature is reduced to zero, only the minimal energy configuration, in which all spins are+1, has any chance of occurring.
This is the case no matter how small the external field becomes, so$M (0) = 1$. On the other hand, in the limit of infinitely high tempera-$+$ ture, all configurations become equally likely and the spontaneous magnetization is equal to zero.

668

)

T

,

h(M TT <  = TTc

c

T > T

c

M

+

h

)

T(

+

M

0 T = 0 T = T

c

Figure 9 spontaneous magnetization versus temperature. Magnetization versus external field, and For dimensionsd ⩾ 2, the behavior of M+(T ) when T lies between these two extremes is quite surprising. in particular, it is not differentiable every where: there is a critical temperature T , depending on the dimension, c such that the spontaneous magnetization is strictly positive for$T$ = Tthat differentiabili ty fails.
Schematic graphs of$T < T^{c} \text{and zero for} T > T^{c}$, and it is at c the magnetization versush and the spontaneous mag- net ization versus pens at the critical temperature itself is delicate. In all$T$are shown in figure 9. What hap dimensions exceptd = 3 it has been proved that there is no spontaneous magnetization at the critical temper-ature, which is to say that M (T ) = 0. It is believed that this is true when problem to prove it.d = 3 as well, but it remains an open+c

5.3 Critical Exponents

The phase transition for the Ising model is again described by critical exponents. The critical exponent given byβ, M+(T ) ∼ C(Tc - T )β, as T \to  (Tc)-, indicates how the spontaneous magnetization disap-pears as the temperature increases toward the critical

IV. Branches of Mathematics

temperature Tc. For T > Tc, the magnetic susceptibil-$ity$ M(h, T ), denoted with respect toχ(T ), is defined to be the rate of change ofh, at h = 0. This partial deriva- tive inh diverges as T approaches T from above, and c the exponentγis defined by χ(T ) ∼ C(T - Tc()-)γ, as T \to  (Tc)+. Finally,δ describes the manner in which the mag net i- zation goes to zero as the external field is reduced tozero at the critical temperature. That is,

M(h, T ) ∼ C(h1)/δ, as h \to 0+.

c

These critical exponents, like those for percolation, are predicted to be universal and to obey various scaling relations. They are now understood mathematically inall dimensions except$d = 3$. 5.4 Exact Solution ford = 2

In 1944, Onsager published a famous paper in which he gave an exact solution of the two-dimensional Ising model. His remarkable computation is a landmark inthe development of the theory of critical phenomena. With the exact solution as a starting point, critical expo-nents could be calculated. As with two-dimensional percolation, the exponents take interesting values:

$β = {}^{18}$, γ =7 4$, δ = 15$. 5.5 Mean-Field Theory for$d ⩾ 4$

Two modifications of the Ising model are relatively easyto analyze. One is to formulate the model on the infinite binary tree, rather than on the integer lattice Zd. Another is to formulate the Ising model on the so-called “complete graph,” which is the graph consisting ofvertices with an edge joining every pair of vertices, and$n$ then take the limit as known as the Curie–Weiss modelngoes to infinity.
In the latter,, each spin interacts equally with all the other spins, or, put another way, each spin feels the each of these modifications, the critical exponents take mean field of all the other spins. In on the so-called mean-field values

$β =1 2$, γ = 1, δ = 3.

Ingenious methods have been used to prove that the Ising model on Zd has these same critical exponents in dimensionsd ⩾ 4, although in dimension 4 there remain unresolved issues concerning logarithmic corrections to the asymptotic formulas.

IV.25. Probabilistic Models of Critical Phenomena 6 The Random-Cluster Model The percolation and Ising models appear to be quite different. A percolation configuration consists of a random subgraph of a given graph (usually a lattice asin the examples earlier), with edges included independently with probability model consists of an assignment of values$p$. A configuration of the Ising±1 to spins at the vertices of a graph (again usually a lattice), with these spins influenced by energy and temperature.
and Kasteleyn had the insight to observe that the two models are in fact closely related to each other, as mem-In spite of these differences, in around 1970 Fortuin bers of a larger family of models known as the random-cluster model. The random-cluster model also includes a natural extension of the Ising model known as the Potts model In the Potts model, spins at the vertices of a given. graphwhereq Gis an integer greater than or equal to 2. When may take on any one of qdif fer ent values, q = 2 there are two possible spin values and the model is equivalent to the Ising model.
For general ven ient to label the possible spin values as 1 q, it is con-, 2, . . . , q. As before, a configuration of spins has an associated energy that is smaller when more spins are aligned. The energy associated with an edge is-1 if the spins at the vertices joined by the edge are identical, and 0 other-wise. The total energy E(σ )of a spin configurationσ, assuming no external field, is the sum of the energies associated with all edges. The probability of a particular spin configurationσ is again taken to be proportional to a Boltzmann factor, namely P (σ ) = Z1 e-E(σ )/T,

where the partition function ensure that the probabilities add up to 1.Z is once again there to tion of the Potts model on a finite graph as Fortuin and Kasteleyn noticed that the partition func- G can be recast(p|()S){|} (1 - p()|)G\S |qn(S).(S⊂)G In this formula, the sum is over all subgraphsbe obtained by deleting edges from G, |S| is the number S that can of edges in S, |G\S| is the number of edges deleted from Gclusters ofto obtain SS, and, n(S)pis the number of distinct connectedis related to the temperature byp = 1 - (e - 1)/T .
The restriction that equal to 2 is essential for the definition of the Pottsq be an integer greater than or 669 model, but the above sum makes good sense for any positive real value ofq. its partition function. Given any real number a configuration of the random-cluster model is a set The random-cluster model has the above sum asq > 0, Sc on fig ur at i on of bond percolation. However, in theof occupied edges of the graph G, exactly like a random-cluster model we do not simply associate with each occupied edge and 1 - p with each vacantp edge.
Instead, the probability associated with a config-uration is proportional to(p|()S)|(1 - p()|)G. \1|qn(S). In par- ticular, for the choiceq = 1, the random - cluster model is the same as bond percolation. Thus the random-cluster model provides a one-parameter family of models, indexed byq = 1, to the Ising model forq, which corresponds to percolation forq = 2, and to the Potts model for integer a phase transition for gener alq ⩾ 2. The random-cluster model hasq ⩾ 1, and provides a unified setting and a rich family of examples.
7 Conclusion The science of critical phenomena and phase transi-tions is a source of fascinating mathematical problems of real physical significance. Percolation is a central mathematical model in the subject. Often formulated on Z$d$, it can also be defined instead on a tree or on the complete graph, as a result of which it encompasses branching processes and the random graph. The Ising model is a fundamental model of the ferromagnetic phase transition. At first sight unrelated to percolation, it is in fact closely connected within the wider setting ofthe random-cluster model.
The latter provides a unified framework and a powerful geometric representation for the Ising and Potts models. Part of the fascination of these models is due to the prediction from theoretical physics that large-scale fea-tures near the critical point are universal. However, proofs often rely on specific details of a model, even when universality predicts that these details should not be essential to the results.
For example, the under-standing of critical crossing probabilities and the calculation of critical exponents has been carried out for sitepercolation on the triangular lattice, but not for bond percolation on Z2. Although the progress for the triangular lattice is a triumph of the theory, it is not the last word. Universality remains a guiding principle but it is not yet a general theorem. sion 3, a very basic feature of percolation and the Ising model is not understood at all: it has not yet been In the physically most interesting case of dimen-

670

proved that there is no percolation at the critical point and that the spontaneous magnetization is zero. be done, and it seems clear that further investigation of models of critical phenomena will lead to highly Much has been accomplished but much remains to important mathematical discoveries. Acknowledgments.selman, Department of Mathematics, University of British The figures were produced by Bill Cas Columbia, and Graphics Editor of Mathematical Society. Notices of the American

Further Reading

Grimmett, G. R. 1999.Springer. Percolation, 2 nd edn. New York: Discrete Structures York: Springer.. 2004. The random-cluster model. In, edited by H. Kesten, pp. 73–124. New Probability on Janson, S., T. Łuczak, and A. Ruci ́Graphs. New York: John Wiley. nski. 2000. Random Thompson, C. J. 1988.chanics. Oxford: Oxford University Press. Classical Equilibrium Statistical Me Werner, W. 2004. Random planar curves and Schramm–Loewner evolutions. In Lectures on Probability Theory and Statistics. École d’Eté de Probabilités de Saint–Flour XXXII—2002, edited by J. Picard.
Lecture Notes in Mathematics, volume 1840. New York: Springer. IV.26 High-Dimensional Geometry and Its Probabilistic Analogues

Keith Ball

1 Introduction

If you have ever watched a child blowing soap bubbles, then you cannot have failed to notice that the bubbles are, at least as far as the human eye can tell, perfectly spherical. From a mathematical perspective, the reason for this is simple. The surface tension in the soap solu-tion causes each bubble to make its area as small as possible, subject to the constraint that it encloses afixed amount of air (and cannot compress the air too much). The sphere is the surface of smallest area that encloses a given volume.
recognized by the ancient Greeks, although fully rig-orous demonstrations did not appear until the end of As a mathematical principle, this seems to have been the nineteenth century. This and similar statements are known as “isoperimetric principles.”1 refers to the two-dimensional formulation: if a disk and another region have equal perimeter, then the area of the other region cannot be1. The prefix “iso” means “equal.” The name “equal perimeter” larger than that of the disk.

IV. Branches of Mathematics

Figure 1 A soap film has minimum area.

is the shortest curve that encloses a given area? The answer, as we might expect by analogy with the three-The two-dimensional form of the problem asks: what dimensional case, is a circle. Thus, by minimizing the length of the curve we force it to have a great deal ofsymmetry: the curve should be equally curved every where along its length. In three or more dimensions, many different kinds of curvature [III.78](/part-03/ricci-flow) are used in different contexts.
One, known asthe appropriate one for area-minimization problems.mean curvature, is point, but then it is pretty clear from its symmetry that the sphere would have the same curvature at every The sphere has the same mean curvature at every point whatever measure of curvature we used. more illustrative examples are provided by the soap films (much more varied than simple bubbles) that are a pop-ular feature of recreational mathematics lectures: figure 1 shows such a soap film stretched across a wire frame.
The film adopts the shape that minimizes its area, subject to the constraint that it is bounded by the wire frame. One can show that the minimal surface (the exact mathematical solution to the minimization prob-lem) has constant mean curvature: its mean curvature is the same at every point. Isoperimetric principles turn up all over mathematics: in the study of partial differential equations, the calculus of variations, harmonic analysis, computational algorithms, probability theory, and almost every branch of geometry.
The aim of the first part of this article is to describe a branch of mathematics, high-dimensional geometry, whose starting point is the fundamental isoperimetric principle: that the sphere is the surface of least area that encloses a given volume. The most remarkable feature of high-dimensional geometryis its intimate connection to the theory of probability: geometric objects in high-dimensional space exhibit many of the characteristic properties of random distributions. The aim of the second part of this article is to out line the links between the geometry and probability.

IV.26. High-Dimensional Geometry and Its Probabilistic Analogues 2 High-Dimensional Spaces So far we have discussed only two- and three-dimen-sional geometry. Higher-dimensional spaces seem to be impossible for humans to visualize but it is easy to provide a mathematical description of them by extend-ing the usual description of three-dimensional space in terms of Cartesian coordinates. In three dimen-sions, a point(x, y, z) is given by three coordin- ates; in(x , x , . . . , xn-dimensional space, the points are).
As in two and three dimensions, then-tuples points are related to one another in that we can add twoof them together to produce a third, by simply adding1 2 nc or responding coordinates: (2, 3, . . . , 7) + (1, 5, . . . , 2) = (3, 8, . . . , 9). By relating points to one another, addition gives the space some structure or “shape.” The space is not justa jumble of unrelated points. also need to specify the distance between any two points.
In two dimensions, the distance of a point To describe the shape of the space completely, we(x, y) from the origin isx2 + y2 by the Pythagorean theo- rem (and the fact that the axes are perpendicular). Simi-larly, the distance between two points(u, v) and (x, y)$is$(x - u)2 + (y - v)2.$In$(un, udi men sions we define the distance between points, . . . , u ) and (x , x , . . . , x ) to be 1 2$(n1)2 n(x1 - u1)2 + (x2 - u2)2 + · · · + (xn - un)2$. follows.
We start by defining a cube in The two- and three-dimensional cases, the square and Volume is defined inn-dimensional space roughly asn dimensions. the usual three-dimensional cube, are very familiar. Theset of all points in thexy-plane whose coordinates are between 0 and 1 is a square of side 1 unit (as shown in figure 2), and, similarly, the set of all points(x, y, z) for whichx, y, and z are all between 0 and 1 is a unit cube. In those points whose coordinates are all between 0 and 1.n-dimensional space the analogous cube consists of We stipulate that the unit cube has volume 1.
Now, ifwe double the size of a plane figure, its area increases by a factor of 4. If we double a three-dimensional body, its volume increases by a factor of 8. Inn-dimensional space, the volume scales as the cube of sidet has volume tn. To find the volume of anth power of size: so a more general set we try to approximate it by covering it with little cubes whose total volume is as small aspossible. The volume of the set is calculated as a limit of these approximate volumes. 671 (0,1) (1,1) (0,0) (1,0) Figure 2 The unit square.
played by the Whatever the dimension, a special geometric role isunit sphere: that is, the surface consisting of all points that are a distance of 1 unit froma fixed point, the center. As one might expect, the corresponding solid sphere, orall points enclosed by the unit sphere, also plays aunit ball, consisting of special role. There is a simple relationship between the ((n - n1 - dimensional) volume of the unit ball and the)-dimensional “area” of the sphere. If we let v denote the volume of the unit ball inthen the surface area is$nv^{n}$.
One way to see this isn dimensions, n to imagine enlarging the unit ball by a factor slightly greater than 1, say 1$+ ε$. This is pictured in figure 3. The enlarged ball has volume of the shell between the two spheres is(1 + ε)nvn and so the volume((1 +ε)n -1)v . Since the shell has thickness mately the surface area multiplied byε, this volume is approx i-ε. So the surfac en area is approximately

$(1 + ε)n - 1ε vn$.

By taking the limit as surface area exactly:ε approaches 0 we obtain the. imε\to0 (1 + ε)εn - 1 vn.

One can check that this limit isthe power(1 + ε)n or by observing that the expression nvn either by expanding is the formula for a derivative. space with out being too precise about what kind of sets So far we have discussed bodies inn-dimensional we are considering. Many of the statements in this arti-cle hold true for quite general sets. But a special role is played in high-dimensional geometry by convex sets (a set is convex if it contains the entire line segment joining any two of its points). Balls and cubes are both examples of convex sets.
The next section describes a fundamental principle which holds for very general 672 1 +ε Figure 3 An inflated ball. sets but which is intrinsically linked to the notion of convexity. 3 The Brunn–Minkowski Inequality The two-dimensional isoperimetric principle was essentially proved in 1841 by Steiner, although there was a technical gap in the argument which was filled later. The general (by the end of the nineteenth century.
A couple ofn - dimensional) case was completed decades later a different approach to the principle, with far-reaching consequences, was found by hermann minkowski [VI.64](/part - 06/hermann - minkowski - 18641909)—an approach which was inspired by an idea of Hermann Brunn. Minkowski considered the following way to add together two sets, then the sumsets inn C-dimensional space. If + D consists of all points which C and D are can be obtained by adding a point of C to a point of D. Figure 4 shows an example in which triangle and D is a square centered at the origin.
We C is an equilateral place a copy of the square at each point of the triangle(some of these are illustrated) and the set C + D con- sists of all points that are included in all these squares. The out line of C + D is shown dashed. of the sum of two sets to the volumes of the sets them-selves. It states that (as long as the two sets The Brunn–Minkowski inequality relates the volume C and D are not empty) vol(C + D()1)/n ⩾ vol(C()1)/n + vol(D()1)/n.
(1) The inequality looks a bit technical, if only because the volumes appearing in the inequality are raised to the power 1 and D is a unit cube (with their edges aligned the same/n. However, this fact is crucial. If each of C way), then the sum$C + D$is a cube of side 2: a cube twice as large. Each of volume of$C + D is 2^{n}$. So, in this case, vol C and D has volume 1 while the(C+D)1^/n = 2

IV. Branches of Mathematics

Figure 4 Adding two sets.

and each of vol(C)1/n and vol(D)1/nis equal to 1: the inequality (1) holds and Dare copies of one another, the Brunn–minkowski with equality. Similarly, whenever$C$ inequality holds with equality. If we omitted the expo-nents 1$/n$, the statement would still be true; in the case of two cubes, it is certainly true that 2$n ⩾ 1 + 1$. But the statement would be extremely weak: it would give us almost no useful information.
The importance of the Brunn–Minkowski inequality stems from the fact that it is the most fundamental principle relating volume to the operation of addition, which is the operation that gives space its structure. At the start of this section it was explained that Minkowski’s formulation of Brunn’s idea provided a new approach to the isoperimetric principle. Let us see why. Let C be a [III.9](/part-03/compactness-and-compactication) in Rn whose volume is equal to that of the unit ball the surface area of compact set C is at least Bn.
We want to show that vol(B) since this is the surface area of the ball. We consider what happens to$C$ if we add a small ball to it. An example (a right-angled triangle) is shown in figure 5: the dashed curve out lines the enlarged set we obtain by adding toball B scaled by a small factor ε. This looks rather like C a copy of the figure 3 above but here we do not expand the original set, we add a ball. Just as before, the difference between C + εB and C is a shell around C of width ε, so we can express the surface area as a limit asε$approaches 0$: $\lim^{ε} \to 0 vol(C + εB)ε - vol(C)$.

Now the Brunn–Minkowski inequality tells us that vol(C + εB()1)/n ⩾ vol(C()1)/n + vol(εB()1)/n.

IV.26. High-Dimensional Geometry and Its Probabilistic Analogues C +ε Bε$C Figure 5 An$ε-enlargement.

The right-hand side of this inequality is

vol(C()1)/n + ε vol(B()1)/n = (1 + ε) vol(B()1)/n because vol(εB) = εn vol(B) and vol(C) = vol(B). So the surface area is at least

(1 + ε)n vol(B) - vol(C). imε\to0 ε= . imε\to0 (1 + ε)n volε(B) - vol(B).

Again as in section 2, this limit isconclude that the surface of C has at least this area.n vol(B) and we Minkowski inequality have been found, and most of the methods have other important applications. To finish Over the years, many different proofs of the Brunn this section we shall describe a modified version of the Brunn–Minkowski inequality that is often easier to use than (1).
If we replace the set half as large, 1(C + D), then its volume is scaled by C + D by a scaled copy 1 Therefore, the inequality can be rewritten/2 n and the n2 th root of this volume is scaled by1 2.$vol$(1 2(C + D)()1)/n ⩾1 2 vol(C()1)/n +1 2 vol(D). qr(t1)/n. Because of the simple inequality positive numbers, the right-hand side of this inequality12 x + 1 2 y ⩾ xy foris at least vol(C()1)/n vol(D()1)/n. It follows that vol(1 2(C + D)()1)/n ⩾ vol(C()1)/n vol(D()1)/n and hence that vol$(1 2 (C + D)) ⩾ vol(C) vol(D)$.
(2) We shall elucidate a striking consequence of this in-equality in the next section. The Brunn–Minkowski inequality holds true for very general sets init is the beginning of a surprising theory that was initi - n-dimensional space, but for convex sets ated by Minkowski and developed in a remarkable way 673 D C Figure 6 Expanding half a ball. by Aleksandrov, Fenchel, and Blaschke, among others: the theory of so-called mixed volumes. In the 1970 s Khovanskii and Teissier (using a discovery of D.
Bernstein) found an astonishing connection between the theory of mixed volumes and the Hodge index theorem in algebraic geometry. 4 Deviation in Geometry Isoperimetric principles state that if a set is reason-ably large, then it has a large surface or boundary. The Brunn–Minkowski inequality (and especially the argument we used to deduce the isoperimetric principle) expands upon this statement by showing that if we start with a reasonably large set and extend it (by adding a small ball), then the volume of the new set is quite a lot bigger than that of the original.
During the 1930 s Paul Lévy realized that in certain situations, this fact can have very striking consequences. To get an idea of how this works suppose that we have a compact setthe ball; for example, C inside the unit ball, whose volume is half that of C might be the set pictured in figure 6. ball that are within distance Now extend the set C by including all points of theε of C, much as we did when deducing the isoperimetric inequality (the dashed curve in figure 6 shows the boundary of the extended set). Let D denote the remainder of the ball (also illus - trated).
Then ifwe are guaranteed thatc is a point inc and d Care separated by a dis-and d is a point in D, tance of at leastε. A simple two-dimensional argument, pictured in figure 7, shows that in this case the mid-point 1(c + d) cannot be too near the surface of the ball. In fact, its distance from the center is no more than 12-1ε2. So the set1(C + D) lies inside the ball of$radius 1$-8 1 8ε2, whose volume is2 (1 -1 8ε2)n times the$674 c$ε

d

Figure 7 A two-dimensional argument.

volume of the ball exp one ntn is large andvn. The crucial point is that if theε is not too small, the factor(sion, a ball of slightly smaller radius has very much1 -1 8ε2)nis extremely small: in a space of high di men smaller volume. In order to make use of this we apply inequality (2), which states that the volume of 1(C + D) is at least vol(C)vol(D). Therefore,$vol$(C) vol(D) ⩽ (1 -^1^8ε^2)^nv^n or, equivalently, vol(C) vol(D) ⩽ (1 - {}18ε2()2)n(vn)2. Since the volume of C i(s1)2 vn, we deduce that vol(D) ⩽ 2(1 -1 8ε2()2)nvn.
It is convenient to replace the factora (pretty accurate) approximation e- nε((12)/ - 4, which i(s1)8 ε2()2)n by slightly easier to understand. We can then conclude that the volume vol(D) of the residual set Dsatisfies the inequality vol(D) ⩽ 2 e-nε2 / 4 vn. (3) tor ethan 1 If the dimension-nε/. qrt2/n4. What this means is that only a small frac-is very small, as long asn is large, then the exponential fac-ε is a bit bigger tion of the ball lies in the residual set fraction of the ball lies close to C, even though D.
All but a small some points in the ball may lie much farther fromif we start with a set (any set) that occupies half the C. Thus, ball and extend it a little bit, we swallow up almost the entire ball. With a little more sophistication, the same argument can be used to show that the surface of the ball, the sphere, has exactly the same property. If a set C occupies half the sphere, then almost all of the sphere is close to that set. This counter intuitive effect turns out to be characteristic of high-dimensional geometry. During the 1980 sa startling probabilistic picture of high-dimensional

IV. Branches of Mathematics

space was developed from Lévy’s basic idea. This pic-ture will be sketched in the next section. One can see why the high-dimensional effect has a probabilistic aspect if one thinks about it in a slightly different way. To begin with, let us ask ourselves a basic question: what does it mean to choose a random num-ber between 0 and 1? It could mean many things but if we want to specify one particular meaning, then our jobis to decide what the chance is that the random number will fall into each possible rangea ⩽ x ⩽ b: what is the chance that it lies between 0 ple?
For most people, the obvious answer is 0.12 and 0.47, for exam-.35, the difference between 0 our random number lands in the interval.47 and 0.12. The probability thata ⩽ x ⩽ b will just beb - a, the length of that interval. This way of choosing a random number is called sized parts of the range between 0 and 1 are equally uniform. Equal likely to be selected.
by a random number, we can use the volume measure in Just as we can use length to describe what is meantn-dimensional space to say what it means to select a random point of the decide what the chance is that our random point fallsn-dimensional ball. We have to into each subregion of the ball. The most natural choice is to say that it is equal to the volume of that subregion divided by the volume of the entire ball, that is, the proportion of the ball occupied by the subregion. With this choice of random point, it is possible to reformulate the high-dimensional effect in the following way.
Ifwe choose a subset C of the ball which has a1 chance of being hit by our random point, then the chance that our random point lies more thanε away from2 C is nomore than 2 e-nε2/4. the geometric deviation principle as a statement about functions rather than sets. We know that if To finish this section it will be useful to rephrase C is a set occupying half the sphere, then almost the entire sphere is within a small distance of C. Now suppose that real number to each point of the sphere. Assume thatfis a function defined on the sphere: f assigns af sphere:
for example, that the values cannot change too rapidly as you move around thef (x) and f (y) at two point sx and ycannot differ by more than the distance between meaning thatfxis at most and y. Let MMon half the sphere and atbe the median value of f , leastation principle that M on the other half. Then it follows from the devi-f must be almost equal to M on all but a small fraction of the sphere. The reason is that almost all of the sphere is close to the half where belowM; sof cannot be much more than M except onf is

IV.26. High-Dimensional Geometry and Its Probabilistic Analogues a small set. On the other hand, almost all of the sphere is close to the half wheref is at least M; sof cannot be much Thus, the geometric deviation principle says that if aless than M except on a small set. function on the sphere does not vary too fast, then itmust be almost constant on almost the entire sphere (even though there may be some points where it is very far from this constant value).
5 High-Dimensional Geometry It was mentioned at the end of section 3 that convex sets have a special significance in Minkowski’s theory relating volume to the additive structure of space. They also occur naturally in a large number of applications: in linear programming and partial differential equations, for example. Although convexity is a fairly restrictive condition for a body to satisfy, it is not hardto convince one self that convex sets exhibit considerable variety and that this variety seems to increase with the dimension. The simplest convex sets after the balls are cubes.
If the dimension is large, the surface of acube looks very unlike the sphere. Let us consider, not a unit cube, but a cube of side 2 whose center is the ori - gin. The corners of the cube are points like(1,1, . . . ,1)or1 or(1,--1, while the center of each1, -1, . . . , 1), whose coordinates are all equal toface is a point like(1 or1,0,0-, . . . ,1. The corners are at a distance0) which has just one coordinate equal to. qrtn from the center of the cube, while the centers of the faces areat distance 1 from the origin.
Thus, the largest sphere that can be fitted inside the cube has radius 1, while the smallest sphere that encloses the cube has radius. qrtn (this is illustrated in figure 8). also large. As one might expect, this gap between the ball and the cube is able to accommodate a wide vari-When the dimensionn is large, this ratio of . qrtn is ety of different convex shapes. Nevertheless, the prob-abilistic view of high-dimensional geometry has led to an understanding that, for many purposes, this enor-mous variety is an illusion:
that in certain well-defined senses, all convex bodies behave like balls. Probably the first discovery that pointed strongly in this direction was made by Dvoretzky in the late 1960 s. Dvoretzky’s theorem says that every high-dimensional convex body has slices that are almost spherical. more precisely, if you specify a dimension (say ten) and a degree of accuracy, then for any sufficiently large dimensionn, every n-dimensional convex body has a ten-dimensional slice that is in distinguishable from aten-dimensional sphere, up to the specified accuracy. 675 (1,1,. ots,1). qrtn (1,0,. ots,0)

Figure 8 A ball in a box in a ball.

r(  )θ Kθ Figure 9 The directional radius. tually simplest depends upon the deviation principle described in the last section and was found by Milman a The proof of Dvoretzky’s theorem that is concepfew years after Dvoretzky’s theorem appeared. The idea is roughly this. Consider a convex body sions that contains the unit ball. For each point K in nθdimen-on the sphere, imagine the line segment starting at the origin, passing through the sphere atθ, and extending out to the surface ofthis line as the “radius” of K(see figure 9).
Think of the length of K in the direction of θ and call itthe sphere. Our aim is to find (say) a 10-dimension alr (θ). This “directional radius” is a function on slice of the sphere on which In such a slice, the body K looks like a ball, since itsr (θ) is almost constant. radius hardly varies. The fact that K is convex means that the functionr cannot change too rapidly as we move around the sphere: if two directions are close together, then the radius of K must be about the same in these two

676

directions. Now we apply the geometric deviation prin-ciple to conclude that the radius of K is roughly the same on almost the entire sphere: the radius is close to its average (or median) value for all but a small frac-tion of the possible directions. That means that we have plenty of room in which to go looking for a slice on which the radius is almost constant—we just have to choose a slice that avoids the small bad regions. It can be shown that this happens if we choose the slice at random from among all possible slices.
The fact that most of the sphere consists of good regions means thata random slice has a good chance of falling into a good region. about the behavior of the entire body just its sections, by using the Minkowski sums defined Dvoretzky’s theorem can be recast as a statement K, rather than in the previous section. The statement is that if convex body inn dimensions, then there is a family of K is am K rotations+ · · · + KK1, Kis approximately a ball, where the num-2, . . .
, Km of K whose Minkowski sum ber Recently, Milman and Schechtman realized that the1 mis significantly smaller than the dimensionm n. smallest num berm that would work could be described almost exactly, in terms of relatively simple proper-ties of the body K, despite the apparently enormous complexity of the choice of rotations available. For somen-dimensional convex sets, it is possible to create a ball with many fewer thann rotations.
In the late 1970 s Kašin discovered that ifjust two rotations K1 and K2 are enough to produce K is the cube, then something approximating a ball, even though the cube itself is extremely far from spherical. In two dimensions it is not hard to work out which rotations are best: if we choose rotation through 45 K. irc1, thento be a square and K + K is a regular octagon K2 to be its which is as close to a circle as we can get with just two squares. In higher dimensions it is extremely hard to1 2 describe which rotations to use.
At present the only known method is to use randomly chosen rotations, even though the cube is as concrete and explicit an object as one ever meets in mathematics. The strongest principle discovered to date showing that most bodies behave like balls is what is usually called the reverse Brunn–Minkowski inequality. This result was proved by Milman, building on ideas of his own and of Pisier and Bourgain. The Brunn–minkowski inequality was stated earlier for sums of bodies. The reverse one has a number of different versions; the simplest is in terms of intersections.
To begin with, ifis a body and B is a ball of the same volume, then the K

IV. Branches of Mathematics

intersection of these two sets, the region that they havein common, is clearly of smaller volume. This obvious fact can be stated in a complicated way that looks like the Brunn–Minkowski inequality: vol(K ∩ B)1/n ⩽ vol(K)1/n. (4) intersect it with a ball of the same volume, we cap-If K is extremely long and thin, then whenever we ture only a tiny part ofof reversing inequality (4) as it stands: no possibility K. So there is no possibility of estimating the volume of K ∩ B from below. But if we are allowed to stretch the ball before intersecting itwith K, the situation changes completely.
A stretched ball inn-dimensional space is called an ellipsoid (in two dimensions it is just an ellipse). The reverse Brunn–Min-kowski inequality states that for every convex body K, there is an ellipsoid E of the same volume for which vol(K ∩ E()1)/n ⩾ α vol(K()1)/n, whereαis a fixed positive number. that an apparently much stronger principle is true: thatif we are allowed to enlarge the ellipsoid by a factor of There is a widespread (but not quite universal) belief (say) 10, then we can ensure that it includes half the vol-ume of K.
In other words, for every convex body, there is an ellipsoid of roughly the same size that contains half ofition about the huge variety of shapes in high dimen-K. Such a statement flies in the face of our intusions, but there are some good reasons to believe it. form, it is natural to ask whether the isoperimetric Since the Brunn–Minkowski inequality has a reverse inequality also does. The isoperimetric inequality guar-antees that sets cannot have a surface that is too small. Is there a sense in which bodies cannot have too largea surface area?
The answer is yes, and indeed a rather precise statement can be made. Just as in the case ofthe Brunn–Minkowski inequality, we have to take into account the possibility that our body could be long and thin and so have small volume but very large surface. So we have to start by applying a linear transformation that stretches the body in certain directions (but does not bend the shape). For example, if we start with a triangle, we first transform it into anand then measure its surface and its volume.
Once we equilateral triangle have transformed our body as best we can, it turns out that we can specify precisely which convex body hasthe largest surface for a given volume. In two dimensions it is the triangle, in three it is the tetrahedron, and inthen-dimensional convex set (called a simplex) whichn dimensions it is the natural analogue of these:

IV.26. High-Dimensional Geometry and Its Probabilistic Analogues hasn + 1 corners. The fact that this set has the largest surface was proved by the present author using an inequality from harmonic analysis discovered by Brascamp and Lieb; the fact that the simplex is the only con-vex set with maximal surface (in the sense described) was proved by Barthe. In addition to geometric deviation principles, two other methods have played a central role in the modern development of high-dimensional geometry; these methods grew out of two branches of probability theory.
One is the study of sums of random points in normed spaces [III.62](/part-03/normed-spaces-and-banach-spaces) and how big they are, which provides important geometrical information about the spaces themselves. The other, the theory of gaussian processes, depends upon a detailed understanding of how to cover sets in high-dimensional space efficiently with small balls. This issue may sound abstruse but it addresses a fundamental problem: how to measure (or estimate) the complexity of a geometric object.
Ifwe know that our object can be covered by one ball of radius 1, ten balls of radius radius 1 , and so on, then we have a good idea of how12 , fifty-seven balls of complicated the object can be.4 vealed that it is at once much more complicated than was previously thought and at the same time in other The modern view of high-dimensional space has reways much simpler. The first of these is well illustrated by the solution of a problem posed by Borsuk in the1930 s.
A set is said to have diameter at mostd if no two points in the set are further than In connection with his work in topology, Borsuk askedd from each other. whether every set of diameter 1 in could be broken inton + 1 pieces of smaller diameter.n-dimensional space In two and three dimensions this is always possible, and as late as the 1960 s it was expected that the answer should be yes in all dimensions. However, a few yearsago, Kahn and Kalai showed that inn dimensions it might require something like emore thann + 1.
. qrtn pieces, enormously space is reflected in a fact discovered by Johnson and Lindenstrauss: if we pick a configuration of On the other hand, the simplicity of high-dimension a ln points (in whatever dimension we like), we can find an almost perfect copy of the configuration sitting in a space ofdimension much smaller than$n$: roughly the logarithm of tions in the design of computer algorithms, since manyn. In the last few years this fact has found applica- computational problems can be phrased geometrically and become much simpler if the dimension involvedis small.

677

6 Deviation in Probability

If you toss a fair coin repeatedly, you expect that heads will occur on roughly half the tosses, and tails on roughly half. More over, as the number of tosses increases, you expect the proportion of heads to get closer and closer toexpected number of heads per toss. The number of12 . The number 12 is called the heads yielded by a given toss is either 1 or 0, with equal probability, so the expected number of heads is the average of these, namely 12 . about the tosses of the coin is that they are The crucial unspoken assumption that we make independent not influence one another.
(Independence and other: that the out comes of different tosses do basic probabilistic concepts are discussed in probability distributions or its generalization to other random experiments, is[III.71](/part-03/probability-distributions).) The coin-tossing principle, called theof a large number of independent repetitions of a ran-strong law of large numbers. The average dom quantity will be close to the expected value of the quantity. fairly simple to demonstrate.
The general form, which applies to much more complicated random quantities, The strong law of large numbers for coin tosses is is considerably more difficult. It was first established by kolmogorov [VI.88](/part - 06/andrei - nikolaevich - kolmogorov - 19031987) in the early part of the twentieth century. value is certainly useful to know, but for most pur-The fact that averages accumulate near the expected poses in statistics and probability theory it is vital to have more detailed information.
If we focus our attention near the expected value, we may ask how the average is distributed around this number. For example, if the expected value is 1 , as for coin tossing, we might ask, what is the chance that the aver - 2 age is as large as 0 to know how likely it is that our average number of.55 or as small as 0.42? We want heads will deviate from the expected value by a given amount. The bar chart in figure 10 shows the probabilities of obtaining each of the possible numbers of heads, with twenty tosses of a coin.
The height of each bar shows the chance that the corresponding num-ber of heads will occur. As we would expect from the strong law of large numbers, the taller bars are con-centrated near the middle. Superimposed upon the chart is a curve that plainly approximates the probabilities quite well. This is the famous “bell - shaped”or “normal” curve. It is a shifted and rescaled copy of 678 0.15 0.10 Probability 0.05 0 5 Number of heads10 15 20 Figure 10 Twenty tosses of a fair coin. the so-called is standard normal curve, whose equation y = . qrt{21π}$. xp (-1 2 x2)$.
(5) The fact that the curve approximates coin-tossing prob-abilities is an example of the most important principle in probability theory: the states that whenever we add up a large number of central limit theorem. This small independent random quantities, the result hasa distribution that is approximated by a normal curve. show that if we toss a coin the proportion of heads deviates from The equation of the normal curve (5) can be used ton times, then the chance that1 by more than ε is at most edeviation estimate (3) from section 4. This resemblance - 2 nε2.
This closely resembles the geometric2 is not coincidental, although we are still far from a full understanding of when and how it applies. limit theorem might apply to geometry is to replace the toss of a coin by a different random experiment. The simplest way to see why a version of the central Suppose that we repeatedly select a random number between - 1 and 1, and that the selection is uniform in the sense described in section 4. Let the first selections be the number sx , x , . . . , x . Instead ofn thinking of them as independent random choices, wecan consider the point(x , . . .
, (x1)2) as a randomly cho - n sen point inside the cube that consists of all points whose coordinates lie between1$-n1 and 1$. The expres- sion dom point from a certain(1/. qrt{n}()n)i = 1 xi measures the distance of the ran-(n - 1)-dimensional “plane,” which consists of all points whose coordinates addup to zero (the two-dimensional case is shown in figure 11). So the chance that from its expected value, 0, by more than(1/. qrt{n}()n)i=ε1 xis the samei deviates as the chance that a random point of the cube lies a distance of more thanε from the plane.
This chance is proportional to the volume of the set of points that are

IV. Branches of Mathematics

(1,1)(−1,1)ε

Plane: x + y = 0

Figure 11 A random point of the cube.

more than figure 11. When we discussed the geometric deviationεfrom the plane: the set shown shaded in principle, we estimated the volume of the set of points which were more thanε away from a set C which occu- pied half the ball. The present situation is really the same, because each part of the shaded set consists of those points that are more than half of the cube lies on the other side of the plane.ε away from which ever Arguments akin to the central limit theorem show that if we cut the cube in half with a plane, then the setof points which lie more than a distanceε from one of the halves
has volume no more than e$- {}^{ε2}$. This state- ment is different from, and apparently much weaker than, the one we obtained for the ball (3) because the factor of implies that if you take any plane through the centern is missing from the exponent. The estimate of the cube, then most points in the cube will be at a distance of less than 2 from it. If the plane is parallel to one of the faces of the cube, this statement certainlyis weak, because all of the cube is within distance 1 of the plane. The statement becomes significant when weconsider planes like the one in figure 11.
Some points of the cube are at a distance of plane, but still, the overwhelming majority of the cube$\sqrt{n}$ from this “diagonal” is very much closer. Thus, the estimates for the cube and the ball contain essentially the same information; what is different is that the cube is bigger than the ball$\sqrt{}$ by a factor of about In the case of the ball we were able to prove a devi-n. ation estimate for just the special sets that are cut off by planes.
Towards any set occupying half the ball, not the end of the 1980 s Pisier found an elegant argument that showed that the general case works for the cube as well as for the ball. Among other things, the argu-ment uses a principle which goes back to the early days of large-deviation theory in the work of Donsker and Varadhan.

IV.26. High-Dimensional Geometry and Its Probabilistic Analogues highly developed. In principle, more or less precise The theory of large deviations in probability is now estimates are known for the probability that a sumof independent random variables deviates from its expectation by a given amount, in terms of the original distribution of the variables. In practice, the estimates involve quantities that may be difficult to compute, but there are sophisticated methods for doing this.
The theory has numerous applications within probability and statistics, computer science, and statistical physics. of this theory is Talagrand’s deviation inequality for product spaces, discovered in the mid 1990 s. Tala-One of the most subtle and powerful discoveries grand himself has used this to solve several famous problems in combinatorial probability and to obtain striking estimates for certain mathematical models in particle physics. The full inequality of Talagrand is some what technical and is difficult to describe geomet-ri cally.
However, the discovery had a precursor which fits perfectly into the geometric picture and which captures at least one of the most important ideas.2 We look again at random points in the cube but this time the random point is not chosen uniformly from within the cube. As before, we choose the coordinate sx , x , . . . , x of our random point independently of one another, but we do not insist that each coordinate is chosen1 2 uniform lyn from the range between -1 and 1.
For example, it might be that ues 1, 0, or-1, each with probabilityx1 can take only the val-1, that x can take only the values 1 or perhaps thatx is chosen uniformly from the entire-1 each with probabilit(y3()2()1)2, and range between-31 and 1. What matters is that the choice of each coordinate has no effect on the choice of any others. each coordinate determines a way of choosing a ran-dom point in the cube. This in turn gives us a way of Any sequence of rules that dictates how we choose measuring a kind of volume for subsets of the cube:
the“volume” of a set A is the chance that our random point is selected frombe very different from the usual one; among other A. This way to measure volume might things, an individual point might have nonzero volume. Now suppose that C is a convex subset of the cube and that its “volume” isdom point will be selected from12 , in the sense that our ran-C with probability1. via an important contribution of Johnson and Schechtman.2. This precursor evolved from an original argument of Talagrand

679

Talagrand’s inequality says that the chance that our random point will lie a distance of more thanε from C is less than 2 e^-^ε2^/16. This statement looks like the deviation estimate for the cube except that it refers onlyto convex sets C. But the crucial new information that makes the estimate and its later versions important isthat we are allowed to choose our random point in so many different ways. probability theory that have a geometric flavor.
For the cube, we are able to show that if This section has described deviation estimates in C is any set occupying half the cube, then almost the entire cube is close to It would be extremely useful to know the same thing for C. convex sets more general than the cube. There are some other highly symmetric sets for which we do know it, but the most general possible statement of this type seems to be beyond our current methods. One potential application, which comes from theoretical computer science, is to the analysis of random algorithms for vol-ume calculation.
The problem may sound specialized, but it arises inalone is sufficient reason to justify the expenditure of linear programming [III.84](/part-03/the-simplex-algorithm) (which enormous effort) and in the numerical estimation of integrals. In principle, one can calculate the volume ofa set by laying over it a very fine grid, and counting how many grid points fall into the set.
In practice, if the dimension is large, the number of grid points will be so astronomically huge that no computer has a chance of performing the count. The problem of calculating the volume of a set is essentially the same as the problem of choosing a point at random within the set, roughly as we saw in section 4. So the aim is to select a random point with out identifying a huge number of possible points to select from. At present, the most effective way of generating a random point in a convex set is to carry out a random walkwithin the set.
We perform a sequence of small steps whose directions are chosen randomly and then select the point that we have reached after a fairly large num-ber of steps, in the hope that this point has roughly the correct chance of falling into each part of the set. Forthe method to be effective, it is essential that the random walk quickly visits points all over the set: that it does not get stuck for a long time in, say, half of the set. In order to guarantee this rapid mixing, as it is called, we need an isoperimetric principle or deviation princi-ple.
We need to know that each half of our set has a large boundary, so that there is a good chance that our random walk will cross the boundary quickly and landin the other half of our set.

680

years, Applegate, Bubley, Dyer, Frieze, Jerrum, Kannan, Lovasz, Montenegro, Simonovits, Vempala, and others In a series of papers published over the last ten have found very efficient random walks for sampling from a convex set. A geometric deviation principle of the kind alluded to above would make it possible toestimate the efficiency of these random walks almost perfectly. 7 Conclusion The study of high-dimensional systems has become increasingly important in the last few decades.
Practical problems in computing frequently lead to high-dimensional questions, many of which can be posed geometrically, while many models in particle physics are automatically high-dimensional because it is necessary to consider a huge number of particles in order to mimic large-scale phenomena in the real world. The literature in both these fields is vast but some general remarks can be made. The intuition that we gain from low-dimensional geometry leads us wildly astray if we try to apply it in many dimensions.
It has become clear that naturally occurring high-dimensional systems exhibit characteristics that we expect to arise in probability theory, even if the original system does not have an explicitly random element. In many cases these random characteristics are manifested as an isoperimetric or deviation principle, that is, a statement to the effect that large sets have large boundaries. In the clas-

IV. Branches of Mathematics

sical theory of probability, independence assumptions can often be used to demonstrate deviation principles quite simply. For the very much more complicated systems that are studied today it is usually useful to have a geometric picture to accompany the probabilis-tic one. That way one can understand probabilistic deviation principles as analogues of the isoperimetric prin-ciple discovered by the ancient Greeks. This article has described the relationship between geometry and probability in just a few special cases. A very much more detailed picture is almost certainly waiting to be found.
At present it seems to be just out of reach.

Further Reading

Ball, K. M. 1997. An elementary introduction to modern con-vex geometry. In Flavors of Geometry, edited by Silvio Bollobás, B. 1997. Volume estimates and rapid mixing. In Levy. Cambridge: Cambridge University Press. Flavors of Geometry, edited by Silvio Levy. Cambridge: Chavel, I. 2001.Cambridge University Press.bridge University Press. Isoperimetric Inequalities. Cambridge: Cam Dembo, A., and O. Zeitouni. 1998.niques and Applications. New York: Springer. Large Deviations Tech Ledoux, M. 2001.non. Providence, RI: American Mathematical Society. The Concentration of Measure Phenome Osserman, R.
1978. The isoperimetric inequality.the American Mathematical Society 84:1182–238.Bulletin of Pisier, G. 1989.Space Geometry The Volume of Convex Bodies and Banach. Cambridge: Cambridge University Press. Schneider, R. 1993.Theory. Cambridge: Cambridge University Press. Convex Bodies: The Brunn–Minkowski

Theorems and Problems

V.1 The ABC Conjecture

The ABC conjecture, proposed by Masser and Oesterlé in 1985, is a bold and very general conjecture in number theory with a wide range of important consequences. The rough idea of the conjecture is that it is impossible for one number to be the sum of two others if all three numbers have many repeated prime factors and no two have a prime factor in common (which would then have to be shared by the third).More precisely, one defines the radical of a positive integern, with each distinct prime included just once.
Forn to be the product of all primes that divide instance, 3960= 23 . imes 32 . imes 5 . imes 11, so its radical is$2$. imes  3 . imes  5 . imes  11 = 330. Let us write rad(n) for the radical oftive real numbern. The ABC conjecture asserts that for every posi-there is a constant K such that ifac < K, b, andradc(abc)are coprime integers an(d1)+$. a + b = c$, then sider the Fermat equation tive integers To get a feel for the meaning of this conjecture, con-x, y , and z solve the equation, then we canxr + yr = zr.
If three posi- divide through by any common factors they might have and obtain a solution for whichx, y, and z, and hence theirr th powers, are coprime. Set a = xr , b = yr, andc = zr. Then$rad$(abc) = rad(xyz) ⩽ xyz = (abc)1^/r ⩽ c3^/r, where the last inequality follows from the fact thatis greater than botha or b. If we set to be1, thenc the ABC conjecture gives us a constant cannot be more than K(c3/r )7/6 = Kc7/2 r K.
Ifsuch thatr ⩾64 thenc the power 7 can have at most finitely many solutions with/2 r is less than 1, so the Fermat equationx, y, andz coprime. It is clear that this is just one of a huge number of consequences of a similar kind. For instance, we could deduce that there are only finitely many solutions of the equation 2 ical of 2 r 3 s x2 is at most 6 r + x3 s, which is considerably= x2, since the rad-

Part V

smaller than$x^{2}$. But the ABC conjecture has other con- sequences that are less obvious, and more important, than this one. For instance, Bombieri has shown that the ABC conjecture implies Elkies has shown that it implies the roth’s theorem mordell conjec-[V.22](/part-05/liouvilles-theorem-and-roths-theorem), ture strengthening of the ABC conjecture implies the non-[V.29](/part-05/rational-points-on-curves-and-vi40-ernst-eduard-kummer-18101893), and Granville and Stark have shown that a existence of Siegel zeros (these are defined in number theory [IV.2](/part-04/number-theory)).
It is also equivalent to strong analytic forms, as yet unproven, of a famous theorem of Baker in transcendence theory, and of the theorem of Wiles about last theorem.modular forms [III.59](/part-03/modular-forms) that implies Fermat’s tational number theory The ABC conjecture is discussed further in[IV.3](/part-04/computational-number-theory).
compu V.2 The Atiyah–Singer Index Theorem Nigel Higson and John Roe 1 Elliptic Equations The Atiyah–Singer index theorem is concerned with the existence and uniqueness of solutions to linear partial differential equations ofthis concept, consider the two equations elliptic type. To understand . artial f. artial x + . artial y. artial f = 0 and . artial f. artial x + i . artial f. artial y = 0. They differ only by the factor i$= \sqrt{-1}$, but their solu- tions nevertheless have very different properties.
Any function of the form$f$ (x, y) = g(x - y) is a solu- tion to the first equation, but in the analogous gen-eral solutiong(x + iy) of the second equation, g must be a variable holomorphic functionz = x + iy, and it was already known in the[I.3 §5.6](/part-01/fundamental-definitions) of the complex nineteenth century that such functions are very spe-cial.
For example, the first equation has an infinite dimensional set of bounded solutions, but theorem [I.3 §5.6](/part-01/fundamental-definitions) in complex analysis asserts that the liouville’s only bounded solutions of the second equation are the constant functions.

682

equations can be traced to the differences between the symbols The differences between the solutions of the twoof the equations, which are the polynomials in real variablesξ, η that are obtained by substituting iξ for equations above are∂/∂x and iη for ∂/∂y. Thus the symbols of the two iξ + iη and iξ - η, respectively. An equation is said to bebol is zero only when$ξ = η =$0; thus, the second elliptic if its sym equation is elliptic but the first is not.
The fund a men-tal regularity theorem, which is proved using fourier analysis tial equation (subject to suitable boundary conditions,[III.27](/part-03/the-fourier-transform), states that an elliptic partial differenif needed) has a finite-dimensional solution space. 2 Topology of Elliptic equations and the Fredholm Index Consider now the general first-order linear partial dif-ferential equation a1 . artial x. artial f1 + · · · + an . artial x. artial fn + bf = 0, in which cie nts aj fandis a vector-valued function and the coeffi - b are complex matrix-valued functions.
It is elliptic if its symbol iξ1 a1(x) + · · · + iξnan(x) is an invertible matrix for every nonzero vectorξ =(ξin this generality, and it allows us to form the1, . . . , ξn) and every x. The regularity theorem applies Fredholm index conditions), which is the number of linearly indepen-of an elliptic equation (with suitable boundary dent solutions of the equation minus the number oflinearly independent solutions of the adjoint equation -. artial x. artial1 ((a*)1 f ) − · · · − . artial x. artial n ((a*)nf ) + b*f = 0.
The reason for introducing the Fredholm index isthat it is a topological invariant of elliptic equations. This means that continuous variations in the coefficients of an elliptic equation leave the Fredholm index unchanged. (By contrast, the number of linearly independent solutions of an equation can vary as the coef-ficients of the equation vary.) The Fredholm index is therefore constant on each connected component ofthe set of all elliptic equations, and this raises the prospect of using topology to determine the structure of the set of all elliptic equations as an aid tocomputing the
Fredholm index. This observation was made by Gelfand in the 1950 s. It lies at the root of the Atiyah–Singer index theorem.

V. Theorems and Problems

3 An Example

To see in more detail how topology can be used to deter-mine the Fredholm index of an elliptic equation, let us look at a specific example. Consider elliptic equations for which the coefficients mial functions ofx, with aaj(x)of degree and b(x)m are- 1 or lesspolyno-j andb of degree m or less. The expression$i$ξ1 a1(x) + · · · + iξnan(x) + b(x)

is then a polynomial in bothx and ξ of degree m or less. Let us strengthen the hypothesis of ellipticity byassuming that the terms in this expression that have degree exactly matrix when everm (jointly in either x orx andξ is nonzero. Let us alsoξ) define an invertible agree to consider only solutions adjoint that are square-integrablef , which means thatof the equation or its|f (x)|2 dx < . nfty .

All these extra hypotheses are types of boundary con-ditions (the behaviors of the equation and its solutions at infinity are controlled), and collectively they imply that the Fredholm index is well-defined. A simple example is the equation d$f$ + xf = 0. (1)

The general solution to this ordinary differential equa-tion is the one-dimensional space of multiples of thed$x$ square-integrable function e$- {}^{x2/2}$. By contrast, the solu- tions of the adjoint equation

$- ddfx + xf = 0$

are multiples of the function e+x 2/2, which is not square-integrable. Thus the index of this differential equation is equal to 1. gree Returning to the general equation, the terms of de-m in i$ξ1a1(x) + · · · + iξnan(x) + b(x)$ determine a map from the unit sphere into the set GL(C) of invertible k . imes  k complex matrices.(x, ξ)-space More over, every such map comes from an elliptic equa-$k$ tion (possibly of a more general type than we have dis-cussed up to now, but an equation to which the basic regularity theorem guaranteeing the existence of the Fredholm index applies).
It therefore becomes important to determine the topological structure of the space of all maps from the sphere(S2()n)-1 into GL (C). The which we shall call the A remarkable theorem of Bott provides the answer. Bott periodicity theorem Bott invariant associates an integer,, with each map$k$

V.2. The Atiyah–Singer Index Theorem

Sthat, provided tha(t2()n)-1 \to  GLk(C). Further more, Bott’s theorem assertsk ⩾ n, one such map can be con- tinuous ly deformed into another if and only if the bott invariants of the two maps agree. In the special case n = k = 1, where we are dealing with maps from the one-dimensional circle into the nonzero complex num-bers, or in other words closed paths in C that do not pass through the origin, the Bott invariant is just the classical winding number, which measures the number of times such a path winds around the origin.
We may therefore regard the Bott invariant as a generalized winding number. are considering in this section asserts that the Fred-holm index of an elliptic equation is equal to the Bott The index theorem for equations of the type that we invariant of its symbol. For instance, in the case of the simple example (1) considered above, the symbol iξ +xcor responds to the identity map from the unit circle in(x, ξ)-space to the unit circle in C. Its winding number is equal to 1, in agreement with our computation of the index. Bott periodicity and proceeds as follows.
Because ellip-tic equations are classified topologically by the Bott The proof of the index theorem depends strongly on invariant, and because the Bott invariant and the Fredholm index have analogous algebraic properties, one need only verify the theorem in a single example: that corresponding to a symbol with Bott invariant 1.
It turns out that this Bott generator can be represented by anand a computation in this case completes the proof.n - dimensional generalization of our example (1), 4 Elliptic Equations on Manifolds It is possible to define elliptic equations not just for functions defined on af ofmanifoldn variables, but also for functions[I.3 §6.9](/part - 01/fundamental - definitions). Particularly accessible to analysis are the elliptic equations onifolds, that is, on manifolds that are finite in extent closed manand that have no boundary.
For closed manifolds it isnot necessary to specify any boundary conditions in order to obtain the basic regularity theorem for elliptic equations (after all, there is no boundary). As a result, every elliptic partial differential equation on a closed manifold has a Fredholm index. equations on closed manifolds and it has roughly the same form as the index theorem that we studied in The Atiyah–Singer index theorem concerns elliptic the previous section. One builds out of the symbol aninvariant called the topological index, which generalizes 683 the Bott invariant.
The Atiyah–Singer index theorem then asserts that the topological index of an elliptic equation is equal to the Fredholm or analytical index of the equation. The proof has two stages. In the first, the-orems are proved that allow one to transform an elliptic equation on a general manifold into an elliptic equationon a sphere with out changing the topological or analytical indices.
For example, it may be shown that two ellip-tic equations on different manifolds that are the common “boundary” of an elliptic equation on a manifold of one higher dimension must have the same topological and analytical indices. In the second stage of the proof the Bott periodicity theorem and an explicit com put a-tion are applied to identify the topological and analytical indices of elliptic equations on spheres. through out both stages, an important tool is K - theory[IV.6 §6](/part - 04/algebraic - topology), which is a branch of algebraic topology invented by Atiyah and Hirzebruch.
rem makes use oflated into terms that do not mention Although the proof of the Atiyah–Singer index theo-$K$-theory, the final result can be trans-K-theory explic- itly. In this way one obtains an index formula roughly like this: index$= M I^{M} · ch(σ )$. The termby the curvature IM is a differential form[III.78](/part-03/ricci-flow) of the manifold[III.16](/part-03/dierential-forms-and-integration) determined M on which the equation is defined.
The term chform obtained from the symbol of the equation.(σ )is a differential 5 Applications In order to prove the index theorem, Atiyah and Singer were obliged to study a very broad class of generalized elliptic equations. However, the applications they first had in mind were related to the simple equation with which we began this article. Solutions of the equation

$\partial f + i \partial f = 0\partial x \partial y$

are precisely the analytic functions of the complex vari-ablez = x + iy. There is a counterpart to this equation on any riemann surface [III.79](/part-03/riemann-surfaces), and the Atiyah–Singer index formula, applied in this instance, is equivalent toa foundational result about the geometry of surfaces called the Singer index theorem then gives a means to generalize riemann–roch theorem [V.31](/part-05/the-riemannroch-theorem). The Atiyah the Riemann–Roch theorem to a[III.6 §2](/part - 03/calabiyau - manifolds) of any dimension. complex manifold tant applications out side of complex geometry.
The The Atiyah–Singer index theorem also has impor - 684 simplest example involves the elliptic equation dd$*ω =$0, concerning differential forms on a mani-$ω + fold$ M. The Fredholm index may be identified with theing sum of the numbers of Euler characteristic of Mr, which is the alternat--dimensional cells in a cell decomposition ofifolds, the Euler characteristic is the familiar quan-M. For two-dimensional man- tity V - E + F.
In the two-dimensional case, the index theorem reproduces the Gauss–Bonnet theorem, which asserts that the Euler characteristic is a multiple of the total Gaussian curvature. used to produce topological restrictions on the waysa manifold can curve. Many important applications of Even in this simple case, the index theorem can be the index theorem proceed in the same direction.
For example, Hitchin used a more refined application of the Atiyah–Singer index theorem to show that there isa nine-dimensional manifold that is homeomorphic to the sphere despite not being positively curved in even the weakest sense. (By contrast, the usual sphere is positively curved in the strongest possible sense.)

Further Reading

Atiyah, M. F. 1967. Algebraic topology and elliptic opera-tors. Communications in Pure and Applied Mathematics Atiyah, M. F., and I. M. Singer. 1968. The index of elliptic20:237–49.operators. I. Annals of Mathematics 87:484–530. Hirzebruch, F. 1966.ometry. New York: Springer. Topological Methods in Algebraic Ge Hitchin, N. 1974. Harmonic spinors.ics 14:1–55. Advances in Mathemat V.3 The Banach–Tarski Paradox T. W.
Körner The Banach–Tarski paradox states that there is a wayof decomposing a three-dimensional ball of unit radius into a finite number of disjoint pieces, then reassem-bling the pieces to form two balls of unit radius, where “reassembling” means that the pieces are translated and rotated and that they end up still disjoint. indeed it contradicts the naive assumption that one can consistently assign a finite volume to every bounded Such a result seems impossible at first sight, and set.
In other words, it shows that one cannot assign vol-umes to all bounded sets in such a way that these volumes are unaffected by translation and rotation, that the volume of a union of two disjoint sets is the sum of the volumes of the two sets, and that the volume

V. Theorems and Problems

of the unit ball is greater than zero. However, if wedrop this naive assumption, then the paradox disappears. Since there is no genuine paradox, we shall refer to the Banach–Tarski construction. an older construction due to Vitali, which concerns arearather than volume. Let us write The Banach–Tarski construction is a descendant ofl for the line segment in R2 that is given in polar coordinates by$θl^{θ} = \\{(r}$, θ)\\\\\\\\\\\\\\\\\\\\\}: 0$< r ⩽ 1$.

Note that the union of all such segments is the punc-tured unit disk D* (that is to say, the unit disk with the origin removed). We say that same equivalence class ifθ - lφθ andis a rational multiplelφ belong to the ofofπl , and we consider a set containing exactly one representative E that is the union of a set from each equivalence class. The rationals areθ countable [III.11](/part-03/countable-and-uncountable-sets), so we can enu- merate the rationals$x with 0 ⩽ x < 1 \text{as a sequencex}^{1}$, x2, . . . . If we write En = {lθ + 2πx}:$l^{θ} \in E$, n

then each origin (through an angle 2 En is obtained fromπxn E), theby a rotation about the En are disjoint (as Elence class), and the union of the contains only one representative from each equiva-E is D* (as E contains a representative from each equivalence class).$n$ the union of the sets the union of the sets Now take D* and split it into the set E(E2()n)+ and the set. Each E can be rotated to GF consisting of consisting of En, and the union of th(e2)n(En)1 gives u(s2)n D^*. Similarly, each Egives u(s2()n)+1 can be rotated to D^* again.
Thus the punctured unit disk can be En, and the union of the En split into a countable set of disjoint pieces (all obtained by rotation of one particular set) which can be rotated and translated to form disjoint sets whose union is two copies of$D^{*}$. choice from each equivalence class), and the same is true for Vitali’s construction makes use of[III.1](/part-03/axiom-of-choice) (because we chose one representative the axiom of the Banach–Tarski construction.
Solovay showed thatif we reject the axiom of choice, then there are models of set theory assign a volume to all bounded sets in[IV.22 §3](/part-04/set-theory) in which it Ris3 in a consis-possible to tent way. However, most mathematicians would agree that the natural moral to draw from our discussion is that when we define volume we should consider only arestricted collection of sets. lated to our final example, which requires a little group The Banach–Tarski construction is also closely re-

V.4. The Birch–Swinnerton-Dyer Conjecture

theory. To introduce this example of bad behavior, we first consider an example of good behavior. Suppose thatandf (xf: R+\to 1)R=is a reasonable function withf (x) for all x (thus, f is nonneg at iv ef (x) ⩾ 0 and periodic with period 1). Suppose that there existed real numbers$s$, t, u, v such thatf (x + s) + f (x + t) - f (x + u) - f (x + v) ⩽ -1 (1) for all integrating both sides of (1) from 0 to 1 would givex. Sinc(e0)1 f (x + w) dx =01 f (x) dx for all w,$0$⩽0 1(-1) dx = −1, which is impossible.
Thus (1) cannot hold. Now consider the free group [IV.10 §2](/part-04/geometric-and-combinatorial-group-theory)G generated byb where no nontrivial relations hold between a and b (that is to say, the group generated bya anda andb). Every element ofthe product of a sequence, each term of which is G can be written in shortest form asa, a-1, bof, orx bends with - 1. Define a F(x)or a=-11 if, and setx = e F(x)or the shortest form= 0 otherwise.
We see that F(x) ⩾ 0 for all x \in  G, and the reader can check, by going through cases, that F(xb) + F(xab) - F(xa-1) - F(xb-1 a) ⩽ -1 (2) for allto show that (1) was false forx \in  G. The averaging argument that enabled us R must fail for G since (2) is, in fact, true. If there is no averaging argument, then there can be no appropriate universal integral and no appropriate universal “volume” in This example bears a clear family resemblance to the G. “paradoxes” discussed earlier.
If we consider the group SO(3) of rotations in three dimensions, then (unless specific conditions hold) there is no nontrivial group relation between two generally chosen rotations A and Btains a copy of the group about two generally chosen axes. Thus SOG considered in the previous(3) con- paragraph. The Banach–Tarski construction is a mod-ification of a construction of Hausdorff that exploits this fact. There is a beautiful account of all these matters in The Banach–Tarski Paradox University Press, Cambridge, UK, 1993).by Stan Wagon (Cambridge V.4 The Birch–Swinnerton-Dyer

Conjecture

Given an elliptic curve [III.21](/part-03/elliptic-curves), there is a natural way of defining a binary operation on its points, and this turns the elliptic curve into an abelian group [I.3 §2.1](/part-01/fundamental-definitions). More over, the points on the curve with rational coordin-

685

ates form a subgroup of this group. Mordell’s theorem tells us that this subgroup is finitely generated. (These results are described in rational points on curves and the mordell conjecture Every finitely generated Abelian group is isomorphic[V.29](/part-05/rational-points-on-curves-and-vi40-ernst-eduard-kummer-18101893).) to a group of the form C stands for the cyclic group with Zr . imes (Cn)1 . imes (Cn)2 ×· · ·×n elements. The(Cn)k, where numbern r , which measures the maximum number of independent elements of this group that have infinite order, is called the rank of the elliptic curve.
Mordell’s theorem implies that the rank of every elliptic curve is finite, but it does not tell us how to calculate it. That turns out to be an extraordinarily hard problem: in fact, so hard that it is considered a remarkable achievement of Birch and Swinnerton-Dyer even to have come up with a plausible conjecture about it. Their conjecture relates the rank of an elliptic curve to a very different object associated with that curve: anties similar to those of the L-function [III.47](/part-03/l-functions).
This is a function with proper-riemann zeta function [IV.2 §3](/part-04/number-theory), but it is defined in terms of a series of num-bers N (E), N (E), N (E), . . . , one for each prime p; the number2 N^p(E)^3 is the number of points on the elliptic^5 curve when it is considered as a curve over the[I.3 §2.2](/part-01/fundamental-definitions) withp elements. One of the properties of the field Lfact that it can be extended to a holomorphic func--function of E is that it is holomorphic[I.3 §5.6](/part-01/fundamental-definitions).
(The tion every where on the complex plane is very far from obvious: it follows from the fact that all elliptic curves are modular. See fermat’s last theorem [V.10](/part-05/fermats-last-theorem).) Birch and Swinnerton-Dyer conjectured that the rank of the group associated with the elliptic curve is equal to the order of the zero of its L-function at 1.
(If the L-function does not take the value 0 at 1, then this order is defined to be 0.) This can be thought of as a sophisticated local-to-global principle the rational solutions to the equation for the elliptic[III.51](/part-03/local-and-global-in-number-theory), in that it relates curve to the solutions modp for each prime p. far less was known about elliptic curves when Birch and Swinnerton-Dyer made it. Now there are many reasons Another remarkable feature of the conjecture is that to find it plausible, but then it was much more of aleap in the dark:
they based it on numerical evidence gleaned from computations oftic curves and many prime sp. In other words, they did Np (E) for several ellip- not calculate the orders of zeros ofous elliptic curves, since that was too hard, but guessed L-functions of vari- them based on approximations. proved for curves with The Birch–Swinnerton-Dyer conjecture has now been L-functions that have a zero

686

of order 0 or 1 at 1, but a proof of the general case still appears to be a long way off. It is one of the problems for which the Clay Mathematics Institute offers aprize of a million dollars. For a further discussion of the problem and much more about its mathematical context, see arithmetic geometry [IV.5](/part-04/arithmetic-geometry). V.5 Carleson’s Theorem Charles Fefferman Carleson’s theorem asserts that the[III.27](/part - 03/the - fourier - transform) of a functionf in L2[0,2π] converges almost fourier series every where.
To understand this statement and appre-ciate its significance, let us follow the history of the subject, starting in the early nineteenth century.[VI.25](/part - 06/jean - baptiste - joseph - fourier - 17681830) great idea was that “any” (complex - valued) func - fourier’s tionf on an interval such as [0,2π] can be expanded in what we would now call a$\infty\text{Fourierseries}$, f (θ) =n=−$\infty$ an(ei)nθ, (1) for suitable the formula for the coefficients Fourier coefficients an a, and proved that (1)n.
Fourier obtained holds in interesting special cases. The next major advance, due to dirichlet [VI.36], was a formula for theis defined to be Nth partial sum SN f (θ), which SN f (θ) =n=−N N an(ei)nθ. (2)

Dirichlet realized that the precise meaning of (1) is that Dirichlet used his formula for certain circumstances (3) does indeed hold. For exam-N . im→$\infty$ SN f (θ) =SNf (θ).f to prove that under(3) ple, ifthen it holds for everyf is a continuous increasing function onθ \in  (0, 2π). [0,2π], Decades later, de la vallée poussin [VI.67](/part - 06/charles - jean - de - la - valle - poussin - 18661962) discovered an example of a continuous function whose Fourier series diverges at a single point.
More generally, given any countable set E ⊂ [0,2π], there exists a continuous function every point of E, a result that appears to restrict quitef whose Fourier series diverges at considerably the circumstances under which Fourier’soriginal vision is valid. progress in Fourier analysis and a significant change of viewpoint. We first sketch Lebesgue’s ideas and then The work of lebesgue [VI.72](/part - 06/henri - lebesgue - 18751941) led to fundamental trace their impact on Fourier analysis.
Lebesgue sought to define a notion of integration that could be applied to all but the most pathological V.
 Theorems and Problems nonnegative functions ing the measure [III.55](/part - 03/measures) of a set F on [0, 2π]E. He began by defin-⊂ [0,2π]. Loosely speaking, the measure ofset Ewould weigh” if the interval E, written[0,\mu(E)2π], is “what the were made of wire weighing one gram per centimeter. For instance, the measure of an interval(a, b) is equal to its len gthb - a. Certain sets E have measure zero, e.g., countable sets, or theare regarded as negligibly small.cantor set [III.17](/part - 03/dimension);
sets of measure zero Lebesgue integral functions Using his notion of measure, Lebesgue defined the F ⩾ 0 o(n0)2[π0 F(θ), 2π]d. All but the most patho-θfor the “measurable” logical functions are measurable, butbe infinite if F is too big. For example, i(f0)2 F(θ)π F(θ)=d1θ/θmayforθ \in (0, 2π], then the integral of Fis infinite. spacef Finally, given any real number on [L0 p,[20π], 2π]that are not too big, in the sense that consists of all measurable functionsp ⩾ 1, the Lebesgue for a slight, technical correction to this definition.)02π |f (θ)|p dθis finite.
(See function spaces [III.29](/part - 03/function - spaces) Fourier analysis. The Lebesgue space is also a We now turn to the impact of Lebesgue’s theory on hilbert space [III.37](/part - 03/bayesian - analysis), plays a fund a men- L2[0, 2π], which tal role. Iff belongs to L2[0,2π], then its Fourier coefficients an are such that. nfty|an|2 < . nfty . (4)

Conversely, any sequence of complex numbers$n=−\infty\text{a}$ (Fourier coefficients of a function−$\infty$ < n < . nfty ) satisfying (4) arises as the sequence off in L2[0,2π]. More-n over, the size of a functionan are related by the Plancherel formula fand its Fourier coefficients: 2$π \infty$ 2$π0 |f (θ)|2 dθ =n=−$. nfty$|an|2$. function Finally, the partial sumsf in the L2-norm. In other words, SNf (see (2)) converge to the$2$π|SN f (θ) - f (θ)|2 dθ −→ 0 (5)

as which the function Ntends to infinity. This gives us a precise sense in0 f is the sum of its Fourier series. Thus, we have justified Fourier’s formula (1) by rein-terpreting it as the statement (5) rather than using the more obvious interpretation of (3).However, it would still be nice to know to what extent the original, more straightforward interpretation canbe justified. In 1906, Luzin conjectured that iff is any function in L2[0$, π], then N \lim→$. nfty SN f (θ) = f (θ) (6) V.7.
The Classification of Finite Simple Groups for allone says that the Fourier series ofθ out side a set of measure zero. When this holds, f converges almost every where. If Luzin’s conjecture were true, it would validate Fourier’s vision from the early nineteenth century. conjecture might well be false.constructed a function For several decades it looked as though Luzin’sf in L1[0 kolmogorov, 2π] whose Fourier[VI.88](/part - 06/andrei - nikolaevich - kolmogorov - 19031987) series converges no where.
Also, a theorem of Kolmo - gorov, Seliverstov, and Plessner, which asserted that. im f is i(n N)→. nfty(S(L2)N[0 f (θ)/,2π], with stood all attempts at improve-. og N) = 0 almost every where when ment for over thirty years. leson proved in 1966 that Luzin’s conjecture is true. The main point of Carleson’s proof is to control the It therefore came as a big surprise when Lennart Car Carleson maximal function$C(f )(θ) = \su(p N()⩾){1}|SN f (θ)|$by proving that \mu(\\\{θ \in [0, 2π]\\\}:$C(f )(θ) > α) ⩽ α(A2()0()2)π |f (θ)|2 dθ$for all st ant independent off in L2[0, 2π] and allf and αα >.
It is not hard to show0, where A is a con-(7) that (7) implies Luzin’s conjecture, but it is very hard to prove (7).Shortly after Carleson’s work, Hunt proved the almost-every where convergence of Fourier series of func-tions in$Lp[0$, 2π] for any p >$1$. Kolmogorov’s counterexample shows that the result fails for$p = 1$. ematics and its applications.
(For a fuller discussion of this, see Fourier analysis has been immensely useful in math-the fourier transform [III.27](/part-03/the-fourier-transform) and harmonic analysis Hunt provide the sharpest known answer to the basic[IV.11](/part-04/harmonic-analysis).) The theorems of Carleson and question that started the subject.
Acknowledgments. NSF grant #DMS - 0245242.This work was partially supported by Cauchy’s Theorem See some fundamental mathematical definitions [I.3 §5.6](/part - 01/fundamental - definitions) V.6 The Central Limit Theorem The central limit theorem is a fundamental result in probability concerning sums of independent random variables. Let$X1$, X2, . . . be independent and suppose 687 that they are identically distributed. Suppose also that they have mean 0 and variance 1. Then$X + · · · + X$has mean 0 and variance the X are independent.) Therefore, n.
(The variance is Y = 1(Xn because+ · · · +n Xn)/. qrti n has mean 0 and variance 1. The central limi(tn)1 theorem states that, regard less of the distribution ofthe$Xi$, the random variable Yn converges to a standard normal distribution. It is easy to deduce from this a sim-ilar result for random variables with any finite mean and variance. Details may be found in distributions [III.71 §5](/part - 03/probability - distributions). probability V.7 The Classification of Finite Simple Groups Martin W.
Liebeck A finite group subgroups are the identity subgroup and G is said to be simple if its only normal G itself. To some extent, simple groups play an analogous role infinite group theory to that of prime numbers in number theory: just as the only factors of a prime itself, so the only factor groups of a simple groupp are 1 and G arep the identity group 1 and deeper: just as every positive integer (greater than 1)G itself. The analogy runs a bit is a product of a collection of primes, so every finite group is “built” from a collection of simple groups, in the following sense.
Leta maximal normal subgroup Hbe a finite group, and choose H of H (this means that Hany larger normal subgroup that is not the whole of1 is not the whole of H, and it is not contained in1 Hand so on. This gives a sequence of subgroups 1); then choose a maximal normal subgroup H2 = of HH1<;

r Hmal subgroup of the next, and, because of the maximal-r -1 < · · · < H1 < H0 = H, each one a maximal nor- ity, each factor group It is in this sense that one says that Gi = Hi/(Hi)+1 His a simple group.is built from the collection unlike the situation with prime numbers, there will in$G^{0}$, G1, . . . , Gr-1 of simple groups (although general be several different finite groups that are built from the same collection of simple groups).
lie at the heart of the theory of finite groups, andone of the driving forces of twentieth-century finite At any rate, it is abundantly clear that simple groups group theory was to study, and ultimately to classify completely, the finite simple groups. This classification was eventually achieved by the combined efforts of more than one hundred mathematicians in many published research articles and books written over along period, the most intensive being 1955–80. It was a truly monumental feat of prolonged collaboration, and

688

one of the most momentous theorems in the history of algebra. In order to state the classification theorem, it is necessary to describe some examples of finite sim-ple groups. The most obvious are the cyclic groups of prime order: these are clearly simple, since they have no subgroups at all apart from the identity and the whole group (by Lagrange’s theorem, for example, which states that the size of any subgroup is a factor ofthe size of the group). Next come the alternating groups Aeven permutations in the symmetric groupn:
here Anis defined as the group consisting of all the S (see per- mutation groups [III.68](/part-03/permutation-groups)). The alternating groupn A has example,12(n!)Aelements, and is simple provided5, of order 60, is the smallest non - Abel i ann ⩾ 5. Forn simple group. Next we introduce some simple groups of matrices. For an integer to be the set of alln ⩾n2 and a field. imes n matrices with entries in K, define SLn(K)K and with group under matrix multiplication, called a determinant [III.15](/part - 03/determinants) equal to 1. This is a special linear group. For each prime power group.
When the field Kis finite, SLq, there is up to isomor - n(K)is a finite phism a unique field of ordering special linear group in dimensionq, and the correspond - n is denoted by$SL$ Zn = {(Fq. ambda I)}. These groups are not in general simple, since:$λ^{n} = 1$, the subgroup of scalar matrices in Sl groups PSLn(Fq), is a normal subgroup. However, the factor(F ) = SL (F )/Z are simple (except when(n, q)special linear= (2, n2)groups.orq (2,3 n)).
This is the family ofq projective ple matrix groups, which, very roughly speaking, are defined as groups of matrices There are a number of other families of finite sim-A \in SL (F ) that satisfy an equation of the form singular symmetric or skew-symmetric ATJA = J, wher(en)qn . imes Jnis a non-matrix. Again factoring out by the subgroup of scalar matrices, this gives thetic families of finite simple matrix groups.
Similarly, projective orthogonal and sym plec if the finite field of orderα \to ᾱ of order 2, this can be extended to matri cesq has an automorphism A{A=\in (a SLij()F}by definin. ar{g}): ATĀ= IA, factored by its subgroup of= (. ar{a} ij), and then the group scalar matrices, gives the finite simple groups.nq projective unitary family of tic, orthogonal, and unitary groups comprise what are The families of projective special linear, sym plec known as the known early in the twentieth century, but it was not classical simple groups.
These were all until 1955 that further infinite families of finite simple V. Theorems and Problems groups were discovered by Chevalley. For each of the simple complex Lie algebras L, and each finite field K, Chevalley constructed a version of L over K, call it L(K), and defined his families of finite simple groups as auto-morphism groups of the Lie algebras L(K). Not long afterward, Steinberg, Suzuki, and Ree found some vari-ations of Chevalley’s construction and defined some further families of simple groups, known as twisted Chevalley groups.
The Chevalley and twisted Chevalley groups include all the classical groups, together with ten other infinite families, and are collectively known as the Until 1966, the only known finite simple groups finite simple groups of Lie type. were the cyclic groups of prime order, the alternating groups, the groups of Lie type, and a collection of five strange simple groups discovered by mathieu mu tat i ons of[VI.51](/part - 06/mile - lonard - mathieu - 18351890) in the 1860 s. These were groups of per-$n$ objects, where n = 11, 12, 22, 23, or 24.
Mathieu’s groups were termed “sporadic groups”—sporadic meaning that they do not fit into any of the known infinite families—and many thought that per-haps there were no more finite simple groups to be found. Then there was a bombshell, when Janko pub-lished a paper demonstrating the existence of a single, new finite simple group: the sixth sporadic group.
After this, new sporadic groups appeared at regular intervals, culminating in the monster [III.61](/part - 03/the - monster - group), an amazing group of order around 1054, which was predicted by Fischer and constructed by Griess as a group of196 884. imes  196 884 matrices. By 1980, twenty-six spo- radic groups were known. During this period the program to classify all the finite simple groups was proceeding at breakneck speed, and eventually in the early 1980 s the final classification theorem was announced.
Every finite simple group is either a cyclic group of prime order, or an alternating group, or a group of Lie type, or one of the twenty-six sporadic groups. Not surprisingly, this theorem has changed the face of finite group theory and its many areas of application:
one can now solve many problems in a concrete way, by reducing them to the study of the (now known) listof simple groups, rather than abstractly, by deducing them from the axioms for groups. The sheer length of the proof of the classification theorem (estimated at around ten thousand journal pages, spread across about five hundred research articles) meant that it was extremely difficult, perhaps impos-sible, for a single person to work through the entire

V.9. Ergodic Theorems

proof. It also meant that the chances were rather high that there were errors along the way. Fortunately, in the years since the announcement of the result, various teams of group theorists have been publishing summaries and revisions of many parts of the proof, anda series of volumes containing the whole proof is now well on the way to completion. V.8 Dirichlet’s Theorem A famous theorem of euclid [VI.2](/part-06/euclid-ca) asserts that there are infinitely many primes. But what if one wants more information about these primes?
For instance, are there infinitely many primes of the form 4 n -1?
A fairly straightforward modification of Euclid’s argu-ment shows that there are, and a slightly more difficult modification proves that there are infinitely manyof the form 4$n +$1 as well. However, modifications of Euclid’s argument are not enough to prove the general result in this direction, which is that if coprime (that is, have highest common factor 1), thena and m are there are infinitely many primes of the formmn +aare now called Dirichlet.
This was proved by dirichlet L-functions[VI.36] using what[III.47](/part-03/l-functions), which are closely related to the[IV.2 §3](/part-04/number-theory). The condition th atm riemann zeta function and a have highest com- mon factor 1 is clearly necessary, since any common factor ofm and a will be a factor of mn + a. Dirich- let’s theorem is discussed further in analytic number theory [IV.2 §4](/part-04/number-theory). V.9 Ergodic Theorems Vitaly Bergelson Consider the sequence number of modulus 1.
While for(zn). nftyn = 0, wherez . eq 1 our sequencez is a complex is not convergent, it is not hard to see that, on aver - age, it exhibits quite regular behavior. Indeed, using the formula for the sum of a geometric progression, and assuming thatz . eq 1, we have, for any N > M ⩾ 0, z M + (z M)+1 + · · · + (z N)-1 N - Mz M ((z N()-M)+1 - 1) 2= (N - M)(z - 1) ⩽ (N - M)|z - 1|, which implies that when N - M is large enough, the averages z M + (z M)+1 + · · · + (z N)-1 AN, M(z) = N - M 689 are small.
More formally, we have N- . im M→. nfty z M + z M+N1 + · · · +- M z N-1 = ⎧⎨⎩01, z, z . eq = 11,. (1) This simple fact is a special, one-dimensional case of von Neumann’s ergodic theorem mathematical statement to throw light on the so - called, which was the first quasi-ergodic hypothesis in statistical mechanics andthe kinetic theory of gases. ior of powers of hilbert spaces Von Neumann’s theorem concerns the average behav-[III.37](/part - 03/bayesian - analysis).
If unitary operators$U$is such an operator defined[III.50 §3.1](/part-03/linear-operators-and-their-properties) on on a Hilbert space H, then we can associate with U thetors Uf-invariant subspace∈ H such that Uf H=invf: that is, all vectors that that consists of all vecare fixed by U. Let P be the orthogonal projection [III.50 §3.5](/part-03/linear-operators-and-their-properties) onto that subspace. Then von Neumann’stheorem asserts that, for every$f \in H$, N - 1 N- . im M→$\infty$ N - 1 Mn = M Unf - P f = 0.

In other words, in a certain sense the averages

$N^{-1}U^{n}N - M$

converge to the orthogonal projection$n = M P$. (This is not actually the theorem as formulated by[VI.91](/part-06/john-von-neumann-19031957), but it is simpler to explain. He proved an equiv-von neumann alent statement about a continuous family of unitary operators$(U ) \in^{R}$.) ments of von Neumann’s theorem, let us briefly com-Before we discuss various applications and refine-$τ^{τ}$ ment on its proof. Von Neumann’s original proof used sophisticated machinery such as the spectral theory of one-parameter groups of unitary operators, obtainedby Marshall Stone.
Over the years many alternative proofs were offered, the simplest being a “geometric”proof due to riesz [VI.74](/part-06/frigyes-frdric-riesz-18801956), which we will describe below. To give the rough idea of von Neumann’s proof it is convenient to use the fact (which follows from the spectral theoremator U on a Hilbert space[III.50 §3.4](/part - 03/linear - operators - and - their - properties)) that any unitary oper-$H$has a “functional model.” That is, we can realize the Hilbert space H as a func- tion space, consisting of all (equivalence classes of) square-integrable functions with
respect to some finite measure [III.55](/part - 03/measures), in such a way that U becomes a multi- plication operator valued measurable function that satisfies$M^{φ}(f ) = φf$, where φ is a complex-|φ(x)| = 1 for almost every ing to such a functional model, that von Neumann’sx. It is not hard to see, after pass-

690

theorem follows immediately from its one-dimensional case as expressed by formula (1). Note that in this case the orthogonal projection to the space of invariant ele-ments takes a functionf to the function g such thatg(x) = f (x) if φ(x) = 1 and g(x) = 0 otherwise. orthogonal complement of the subspace variant vectors is spanned by the set of vectors of the Riesz’s proof is based on the observation that the Hinv of U - in- form Ug - g. To see this, note first that if$f \in H^{i}nv$, then

$f$, Ug = U-1 f , g = f , g ,

from which it follows that$f$, Ug - g = 0 and thus that the nf f , Ufis orthogonal to- f  = f , Uf Ug- − g. Conversely, iff , f . This is less thanf ∈ Hinv, 0, by the fact that cauchy–schwarz inequality Uf  = f but Uf = f . In particular,[V.19](/part-05/inequalities) and thef is not orthogonal to complement of the (closed) subspace of Uf -f . Thus, Hinv is the orthogonal H generated by functions of the form Ug - g. trivially if every Now the conclusion of von Neumann’s theorem holdsn. On the other hand, iff ∈ Hinv, since thenf P f= =Ugf-andg, then Unf P f= f=for0.
As for the averages, we know that from which it follows that N-1 U(Un)nff ==U(Un()N)+g1 g--U(UM)ngg,. Since$N$, we find that UN g - UM g is at most 2 n=M g for every M and N-1 Unf N - M

has norm at most 2 So the theorem is true in this case as well. It is straight-g /(Nn-=MM) and hence tends to 0. forward to check that the set of functions for which the theorem holds is a closed linear subspace of H , and therefore the theorem is proved.
similar results are relevant to physics is that it is often The reason that von Neumann’s theorem and other possible to represent the evolution of the parameters associated with a physical system by a subset X ⊂ Rd that has finite continuous familyd-dimensional volume, together with a(Tτ)τ\in R of volume-preserving trans- formations from tion T one can associate the unitary map X to X . With each such transforma-U, defined on tions on L2(X)τ (the Hilbert space of square-integrable func-X ) by the formula (U f )(x) =τ f (T x).
The fact that these maps are unitary follows from the fact that the transformationsτTτpreserve volume;τ also, it follows from the fact that the transformations Tas well.τ depend continuously on τ that the maps Uτ do V. Theorems and Problems the situation. Instead of considering the continuous families To simplify the discussion let us now “discretize”(T ) and (U )we shall fix a transformation Tun it ary operator.
Assume that our volume - preserving= (Tτ)0 (say, forτ τ0 =τ1) and let U be the corresponding transformation is no proper subset T is ergodic A ⊂ X, which means that there of positive volume such that T (A) ⊂ A. This assumption can easily be shown to be equivalent to the fact that the only elements of L2(X) that satisfy Uf = f are the constant functions. It follows from von Neumann’s theorem that for any f \in L2(X) the averages (N-1 A)N, M (f ) = N -1 Mn=M Unf

converge to a constant whose value is easy to findby performing term-by-term integration: it is equal to (tells us that limf dm)/ vol(X). Since von Neumann’s theorem also$- {}^{→}$. nfty A (f ) is always a U-invariant function, we see that the assumption of ergodicity is a(NM)N, M necessary and sufficient condition for the time average represented by lim$N^{-}M^{→}$. nfty$AN$, M (f ) to equal the space average,$( f dm)/ vol(X)$. to strengthen a classical theorem of called It is also possible to use von Neumann’s theorem Poincaré’s recurrence theorem.
This result statespoincaré [VI.61](/part-06/jules-henri-poincar-18541912), that if Xis a set of finite volume, as above, and A is a subset of points of Are turn infinitely often to Xwith nonzero volume, then “almost all$A$.” In other words, if we set  ̃Tnx \in  A Afor infinitely manyto be the set of all poin tsn, then the measure of thex \in  A such that set of points in$A$but not in  ̃A is 0.
The main step in the proof of Poincaré’s theorem is to prove the same about the set A , which consists of all points x \in  A such that why this is true, let Tnx \in1 A for B be the set of all points insome positive integer n. To see A but not in measure, since$A^{1}$. The sets T is volume preserving. (B, T^-1 B, T^-2 B, . . .
all have the same T^-n Bis defined to be the set of allx such that Tnx \in  B.) Since X has finite volume, there must exist positive integersn such that the intersection of T-m B and (T-)(mm+andn)B has positive measure, and from this it follows that the measure of B ∩ T-n B is also positive.
But if x \in  B thenx \in  A1, so Tnx \in  A and therefore Tnx \in  B, so this is a contradiction. Now let us apply the von Neumann ergodic theorem with(that is, f equal to the characteristic function of a setf (x) = 1 when x \in  A and f (x) = 0 otherwise)A andthe set Udefined in terms of X has volume 1 and write T as before. Suppose also that\mu for the measure on V.10. Fermat’s Last Theorem $X$. Then one can check that f , Unf  = μ(A ∩ T-n A). It follows that N - 1 f, AN$, M (f ) = N - 1 Mn = M \mu(A ∩ T - n A)$.
If we let N - Mtend to infinity, then$A^{N}$, Mf tends to af , g = U-invariant function Unf , g for ever ygn. Since, and thereforeg is U-invariant, f , g =Ag, g N, M. By the Cauchy–Schwarz inequality, this is at least(f ), g for every N and M, and finally$f$, g =( g(x) dμ)2 = ( f (x) dμ)2 = μ(A)2. Therefore, we deduce that (N - 1 N)- \li(m M)→$\infty$ N - 1 Mn = M μ(A ∩ T - n A) ⩾ (μ(A))2.
If you choose two “random sets” of measure then their intersection will typically be(\mu(A))2, so theμ(A), inequality above is saying that the average intersection of$A with T^{-n} A$is at least as big as the “expected” intersection. This result, due to Khinchin, gives more precise information about the nature of Poincaré recurrence. measure-preserving transformation as above, it is nat-When a unitary operator is defined in terms of a ural to ask whether the averages converge not just inthe sense of the L2-norm but also in the more clas- sical sense of convergence almost every where.
(For a related thought in a different context, see carleson’s theorem shown by [V.5](/part-05/carlesons-theorem).) The answer is that they do, as was birkhoff [VI.78](/part - 06/george - birkho - 18841944) soon after he learned of von Neumann’s theorem. He proved that for each inte-grable function fone could find a functionf* such thatf*(T x) = f*(x) for almost every x, and such that N - 1 N . im→. nf ty N1 n = 0 f (Tnx) = f*(x)for almost every is ergodic, let A ⊂x.
Suppose that the transformation X be a set of positive measure, and T let from Birkhoff’s theorem that for almost everyf (x) be the characteristic function of A. It follow sx \in X one has N . im→. nfty N(1 N)n=-0 1 f (Tnx) = \mu(X)f d\mu = \mu(X)\mu(A).

Since the expression

$N^{-1N} \lim^{→}$. nfty N1 n=0 f (Tnx)

describes the frequency of visits ofsee that in an ergodic system the images Tnx to the setx, T x, T2 Ax, . . ., we of a typical pointx \in  A visit A with a frequency that equals the proportion of the space occupied by A.

691

have been generalized over the years in many differ-ent directions. These far-reaching extensions of ergodic The ergodic theorems of von Neumann and Birkhoff theorems, and more generally the found impressive applications in such diverse fields ergodic method, have as statistical mechanics, number theory, probability theory, harmonic analysis, and combinatorics.

Further Reading

Furstenberg, H. 1981.Combinatorial Number Theory Recurrence in Ergodic Theory and. M. B. Porter Lectures. Krengel, U. 1985.Princeton, NJ: Princeton University Press. A. Brunel. De Gruyter Studies in Mathematics, volume 6.Ergodic Theorems, with a supplement by Mackey, G. W. 1974. Ergodic theory and its significance for Berlin: Walter de Gruyter.statistical mechanics and probability theory. Advances in Mathematics 12:178–268.
The Fermat–Euler Theorem See modular arithmetic [III.58](/part-03/modular-arithmetic) V.10 Fermat’s Last Theorem Many people, even if they are not mathematicians, are aware of the existence of triples of positive integers(x, y, z)Pythagorean triples such that x: that is,2+y2 =z2.
These give us examples of right-angled triangles with integer side lengths, of which the best known is the “we have that(3, 4, 5) (mtr i angle.” For any two integers2$-n2)2+(2mn)2 = (m2 + n2m)2$, which and n, gives us an infinite supply of Pythagorean triples, andin fact every Pythagorean triple is a multiple of a triple of this form.fermat [VI.12](/part-06/pierre-fermat-1601665) asked the very natural question of whether similar triples existed for higher powers: thatis, could there be a solution in positive integers of the equationxn + yn = zn for some power n ⩾3?
For instance, is it possible to express a cube as a sum of two other cubes? Or rather, Fermat famously claimed that it was not possible, and that he had a proof that space did not permit him to write down. Over the next three and a half centuries, this problem became the most famous unsolved problem in mathematics. Given the amount of effort that went into it, one can be virtually certain that Fermat did not in fact have a proof: the problem appears to be irreducibly difficult, and solvable only by techniques that were developed much later than Fermat.

692

The fact that Fermat’s question was an easy one to think of does not on its own guarantee that it is inter-esting. Indeed, in 1816 gauss [VI.26](/part-06/carl-friedrich-gauss-17771855) wrote in a letter that he found it too isolated a problem to interest him. At the time, that was a reasonable remark: it is often extremely hard to determine whether a given Diophan-tine equation has a solution, and it is therefore easy to come up with hard problems of a similar nature to Fer-mat’s last theorem.
However, Fermat’s last theorem has turned out to be exceptional in ways that even Gauss could not have been expected to foresee, and nobody would now describe it as “isolated.” solved for By the time of Gauss’s remark, the problem had beenn = 3 (by euler [VI.19](/part-06/leonhard-euler-17071783)) and n = 4 (by Fer- mat; this is the easiest case). The first serious connec-tion between Fermat’s last theorem and more general mathematical concerns came with the work ofmer [VI.40] in the middle of the nineteenth century.
ankum important observation that had been made by Euler isthat it can be fruitful to study Fermat’s last theorem in larger chosen, allow one to factorize the polynomial rings [III.81 §1](/part-03/rings-ideals-and-modules), since these, if appropriate lyzn - yn. Indeed, if we write 1, ζ, ζ2, . . . , ζn - 1 for the nth roots of 1, then we can factorize it as (z - y)(z - ζy)(z - ζ2 y) · · · (z - ζn - 1 y).
(1) Therefore, ifdifferent - looking factorizations ofxn + yn = zn then we have two rather xn inside the ring generated by 1 and above, andxxx · · · xζ), and it is reasonable to hope that(namely the factorization in (1) this information might be exploited. However, there is a serious problem: the ring generated by 1 andζ does not enjoy the [[IV.1 §§4–8]](/part - 04/algebraic - numbers), so one’s sense of being close to a contra-unique factorization property diction when faced with these two factorizations is not well - founded.
Kummer, in connection with the search for cul ty and had defined the notion of an higher reciprocity laws [V.28](/part - 05/from - quadratic - reciprocity - to - vi38 - augustus - de - morgan - 18061871), had met this diffi-ideal [III.81 §2](/part-03/rings-ideals-and-modules): very roughly, if you enlarge a ring by adding in Kum-mer’s “ideal numbers,” then unique factorization is restored. Using these concepts, Kummer was able to prove Fermat’s last theorem for every prime number p that was not a factor of thethe corresponding ring.
He called such primes class number [IV.1 §7](/part-04/number-theory) of regular. This connected Fermat’s last theorem with ideas that have belonged to the mainstream of algebraic number theory [IV.1](/part-04/number-theory) ever since. However, it did not solve the problem, since there are infinitely many irregular primes (though this was not known in Kummer’s day).

V. Theorems and Problems

used for individual irregular primes, and eventually an It turned out that more complicated ideas could be algorithm was developed that could check for any given$n$ whether Fermat’s last theorem was true for thatn. By the late twentieth century, the theorem had been verified for all exponents up to 4 000 000. However, a general proof came from a very different direction. The story of the eventual proof by Andrew Wiles has been told many times, so we shall be very brief about it here.
Wiles did not study Fermat’s last theorem directly, but instead solved an important special case of the Shimura–Taniyama–Weil conjecture, which connects[III.59](/part-03/modular-forms). The first hint that elliptic curves might be rel-elliptic curves [III.21](/part - 03/elliptic - curves) and modular forms evant came when Yves Hellegouarch noticed that the elliptic curvey2 = x(x - ap )(x - bp ) would have rather unusual properties if ap + bp was also a pth power. Gerhard Frey realized that such a curve might be so unusual that it would contradict the Shimura Taniyama–Weil conjecture.
Jean-Pierre Serre came up with a precise statement (the “epsilon conjecture”) that would imply this, and Ken Ribet proved Serre’s conjecture, thus establishing that Fermat’s last theorem was a consequence of the Shimura–Taniyama–Weil conjecture. Wiles suddenly became very interested indeed, and after seven years of intensive and almost secret work he announced a solution to a case of the Shimura–Taniyama–Weil conjecture that was sufficient to prove Fermat’s last theorem.
It then emerged that Wiles’sproof contained a serious mistake, but with the help of Richard Taylor he managed to find an alternative and correct argument for that portion of the proof. The Shimura–Taniyama–Weil conjecture asserts that “all elliptic curves are modular.” We finish by giving a rough idea of what this means. (A few more details can be found in arithmetic geometry [IV.5](/part - 04/arithmetic - geometry).) Associated with any elliptic curve E is a sequence of numbersapn, a(E)p (E), one for each positive integer is related to the number of points on the ellip-n.
For each prime tic curve (modthe values of$ap$); it is easy to derive from these values(E) for composite n. Modular forms are periodicity properties defined on the upper half-plane; holomorphic functions n[I.3 §5.6](/part-01/fundamental-definitions) with certain associated with each modular form series [III.27](/part-03/the-fourier-transform) that takes the formf is a four i erf (q) = a1(f )q + a2(f )q2 + a3(f )q3 + · · · . Let us call an elliptic curve ular formf such that a (E)E=modular a (f )for all but finitelyif there is a mod many prime sp. If you are presented with an ellipti(cp)p

V.11. Fixed Point Theorems

curve, it is not at all clear how to set about finding a modular form associated with it in this way. However, it always seemed to be possible, even if the phenomenon was a mysterious one. For instance, if E is the ellip- tic curve$y^{2} + y = x^{3} - x^{2} - 10x - 20$, then there is a modular formprimep apart from 11.
This modular form is the uniquef such that ap(E) = ap (f ) for every complex function (up to scaling) that satisfies a certain periodicity property with respect to the groupΓ (11), which consists of all matrices$( a b^{c} d ) \text{such that a}^{0}$, b, c, andd are integers,[III.15](/part-03/determinants) ad-cbcis a multiple of 11, and theis 1.
It is far from obvious that adeter- minant definition of this type should have anything to do with elliptic curves. Wiles proved that all “semistable” elliptic curves are modular, not by showing how to associate a modular form with each such elliptic curve, but by using a subtle counting argument that guaranteed that the modu-lar form had to exist. The full conjecture was proved a few years later, by Christophe Breuil, Brian Conrad, Fred Diamond, and Richard Taylor, which put the icing on the cake of one of the most celebrated mathematical achievements of all time.
V.11 Fixed Point Theorems 1 Introduction The following is a variant of a well-known mathematical puzzle. A man is on a train from London to cambridge and has a bottle of water with him. Prove that there is at least one moment on the journey when the volume ofair in the bottle, as a fraction of the volume of the bottle itself, is exactly equal to the fraction of his journey thathe has completed. (For instance, the bottle might be two fifths full, and therefore three fifths empty, at the precise moment when he is three fifths of the way from London to Cambridge.
Note that we do not assume that the bottle is full at the start of the journey or empty at the end.)The solution, if you have not seen this sort of question before, is surprisingly simple. For each0 and 1 letf (x) be the proportion of air in the bott lex between when the proportion of the journey that has been com-pleted isx. Then 0 ⩽ f (x) ⩽ 1 for every x, since the volume of air in the bottle cannot be negative and can-not exceed the volume of the bottle. If we now setg(x) to bex -f (x), then we see that g(0) ⩽ 0 and g(1) ⩾ 0.
Since some moment at whichg(x) varies continuously withg(x) = 0, so thatx, there must bef (x) = x, which is what we wanted. 693 of one of the simplest of all fixed point theorems. We could state it more formally as follows: if What we have just proved is a slightly disguised formf is a contin- uous function from the closed interval then there must exist anx such that f (x)[0,=1]xto itself,. This x we call athe intermediate value theorem fixed point off .
(We deduced the result from, a basic result in analy- sis that states that if[0,1] to R such that g(g0 is a continuous function from) ⩽ 0 and g(1) ⩾ 0, then there must be somex such that g(x) = 0.) asserts that a function that satisfies certain conditions In general, a fixed point theorem is a theorem that must have a fixed point. There are many such the - orems, a small sample of which we shall discuss in this article. On the whole, they tend to have a nonconstructive nature: they establish the existence of a fixed point rather than defining one or telling you how to find it.
This is part of the reason that they are impor - tant, since there are many examples of equations for which one would like to prove that a solution exists even when one cannot solve it explicitly. As we shall see, one way of going about this is to try to rewrite the equation in the form$f$(x) = xand apply a fixed point theorem. 2 Brouwer’s Fixed Point Theorem The fixed point theorem we have just proved is the one-dimensional version of Brouwer’s fixed point theorem, which states that ifset of all(x , . . .
, x B)nsuch thatis the unit ball ofx2 + · · · +Rnx(that is, the2 ⩽ 1) andfhave a fixed point. The setis a continuous function from1 n Bn is an(B1)nnto-dimensional solid Bn, thenn f must sphere, but all that matters is its topological character, so we could take it to be another shape such as ann- dimensional cube or simplex. tion from the closed unit disk to itself must have a fixed point.
In other words, if you had a circular sheet of rub-In two dimensions this says that a continuous func ber on a table and you picked it up and put it back downwithin the circle where it started, having folded it and stretched it as much as you liked, there would always have to be a point that ended up in the same place as before. To see why this is true, it is helpful to reformulate the statement. Let D = B2 be the closed unit disk.
If we had a continuous function fixed point, then we could define a continuous functionf from D to D with nog follow a straight path from from D to its boundary . artial Df (x)as follows: for each tox and continue onx, 694 f (x) x g(x) D Figure 1 can be used to define a retraction Iffhas no fixed points, then itg. in a straight line$;\partial D$(see figure 1), and it is well-defined because (andg(x)is the point where you first reach only because)f (x) = x. If x is already on the boundary ofg: DD, then\to  . artial Dg(x)such that= x.
So we have a continuous functiong(x) = x for every x \in  . artial D. Such a function is called a retraction from D to . artial D. from not, then we will have contradicted the assumption that It seems highly unlikely that a continuous retraction D to . artial D could exist. If we can prove that it can- there is a continuous function from D to Dwith no fixed point, and there by have proved Brouwer’s fixed point theorem in two dimensions.
retractions from disks to their boundaries cannot exist. There are several ways of proving that continuous Here we briefly sketch two. Suppose, first, thatg is such a retraction. For eachtradius, let us consider the restriction oft about the origin, and let us represent a typ-g to the circle of ical point in this circle as t(ei)θ. Let us write g (θ) fortg(tθ goes from 0 to 2(ei)θ). When t = 1 the circle of radiusπ, g (θ) = e^i^θ goes once aroun dt is ∂D, so ast

the unit circle. Whent = 0, the circle of radius t is a single point, so asθ goes from 0 to 2π, g (θ) ist

just the constant point the unit circle at all. Therefore, some where between$g(0)$, which does not go aroun dt = 1 and t = 0 there must be a change in the number of times from 0 to 2 gt (θ)π. But the functions goes around the unit circle asgt are a continuouslyθ goes varying family of functions, and a small change in$gt$

cannot cause a sudden jump in the number of timesthatgt(θ) goes around the circle. (To make this last step rigorous needs a bit of work, but the basic ideais sound.) A second proof uses basic tools from algebraic topology. The first is trivial, since every curve in the disk can be shrunk homology group [IV.6 §4](/part-04/algebraic-topology) of the disk$D$

V. Theorems and Problems

to a point. The first homology group of the unit circle∂D is Z. If there is a continuous retraction g from D to∂Dg: , then we can find continuous maps D \to  ∂D such that g ◦ h is the identity onh:∂D \to ∂DD. (Weand letwe leth be the map that takes a point ofg be the continuous retraction.) Now continuous∂D to itself and maps between topological spaces give rise tomorphisms [I.3 §4.1](/part-01/fundamental-definitions) between their homology groups, homoin such a way that compositions go to compositions and identity maps go to identity maps.
(That is, there is a functor spaces and continuous maps to the category of groups[III.8](/part-03/categories) from the category [III.8](/part-03/categories) of topological and group homomorphisms.) This means that there must be homomorphismsφ: Z→ 0 and ψ:0 → Z such thatψ ◦ φ is the identity on Z, which is obviously impossible. Both proofs generalize to higher dimensions:
the second straightforward ly (once one knows how to compute homology groups of spheres), and the first via thenotion of the degree of a continuous map from then- sphere to itself, which is a higher-dimensional analogueof the notion of the number of times a map from the circle to itself “goes around the circle.” tions. For example, the following fact is important inthe theory of random walks on graphs. ABrouwer’s fixed point theorem has many applica-stochastic matrix is ann . imes n matrix with nonnegative entries such that the sum of the entries in each row is equal to 1.
Brouwer’s fixed point theorem can be used to show that every such matrix has an eigenvector [I.3 §4.3](/part - 01/fundamental - definitions) with nonnegative entries and eigenvalue 1. The proof isas follows: the set of all column vectors with nonnegative entries that add up to 1 is, geometrically speak - ing, an(n - 1)-dimensional simplex. (For example, ifn = 3, this set is a triangle in R3 with vertices (1,0,0),(x0, belongs to this simplex, then so does1, 0), and (0, 0, 1).) If A is a stochastic matrix and Ax.
Since the map gives us anx \to x such that Axis continuous, Brouwer’s theorem Ax = x:
this is the required eigenvector. An extension of Brouwer’s theorem, called the Kakutani fixed point theorem establish the existence of a “social equilibrium,” a, was used by John Nash to state of affairs in which no household can individu-ally improve its well-being by altering the amount that it consumes of various items. Kakutani’s theorem con-cerns functions that take points in a closed ball$B^{n} not$ to other points innonempty closed convex subset of Bn but to subsets Bnoffor each Bn. If f (x)x and ifis af (x) varies continuously in an appropriate sense, then

V.11. Fixed Point Theorems

the theorem says that there must be some$x \in f (x)$. Brouwer’s theorem is the special case wherex such that eachf (x) is a set with just one element. 3 A Stronger Form of Brouwer’s

Fixed Point Theorem

So far, we have discussed maps from solid spheres to themselves, but there is nothing to stop us thinking about whether continuous maps on other spaces must have fixed points. For example, let S2 be the (nonsolid) sphere a continuous function from$\\{(x}$, y, z)\\\\\\\\\\\\\\\\\\\\\}$: x2 + y2 + S2zto2 = S21$. Must and letf have af be fixed point? At first one might think so: some obvi-ous functions from S2 to itself are rotations and reflections, both of which certainly have fixed points, and it ishard to see how one can “get rid” of those fixed points.
However, eventually one realizes that there is a simple example of a function with out a fixed point, namely the function$f (x) = −x$, which reflects each point through the origin. that the result we had hoped for is false and to turn our attention to something else. But this reaction is The obvious reaction to this example is to note a mistake, as it is in many other mathematical con-texts, because there was something importantly correct about the idea that it was impossible to get rid of the fixed points of a rotation.
It turns out that if you start with a rotation and try to get rid of the fixed points by continuously deforming it, then you are doomed to failure. In fact, in a certain sense there will always be exactly two fixed points. More generally, if you take any continuous function from$S^{2} to S^{2} \text{and continu}-$ ously deform it, then you cannot change the number of fixed points. false if taken at face value so some re interpretation Of course, these last two statements are patently is needed.
First, we must assume that the number of fixed points is finite, but this is not a huge assumption as it can be shown that a typical small perturbation ofany continuous function will have only finitely many fixed points. Second, we must count the fixed points with appropriate weights. To define these, suppose that f (x) = x, and imagine a point y(t) that goes aroun dx index in a tiny circle asof the fixed pointtgoes from 0 to 1.
We define thex to be the number of turns made by the vector from negatively if these turns are in the opposite directiony(t) to f (y(t)), counting this to the way that problematic iff (y(t))y(t) goes around = y(t) for somex. (This definition ist, but again

695

we can make small perturbations and assume that this does not happen.) Then the sum of the indices of all the fixed points is the quantity that does not change if you continuously deform It follows that if you continuously deform a rotation, f . then the sum of the indices will always be 2. From thisit follows that there must be at least one fixed point. It also follows that you cannot continuously deform a rotation so that it becomes the map that sends eachto-x.
x alized in a fairly straightforward way to higher dimen-The notion of the index of a fixed point can be gener sions (using the concept of degree mentioned earlier), and one can show under very general circumstances that the sum of the indices of fixed points remains constant when you continuously deform a continuous map. This implies Brouwer’s fixed point theorem as fol-lows. We can continuously deform any continuous map $f$: Bn \to  Bn into any other continuous map g:$B^{n} \to B^{n}$ by definingf (x) = (1 - t)f (x) + tg(x) and letting tt map vary from 0 to 1.
Let us therefore takex \to 1 x, which has a single fixed point. This fixedg to be the point has index 1 (as one can see easily in the two-2 dimensional case), and therefore the sum of the indices of the fixed points off is 1 as well. points of a function In general, the sum of the indices of the fixed$f$defined on a suitable topological space[I.3 §6.9](/part-01/fundamental-definitions)) can be calculated in terms of the effect of X (such as a smooth compact manifoldf on the homology groups ofis (a slight generalization of) the X . The resulting theorem Lefschetz fixed point theorem.
invariant of continuous deformations can be used togive a proof of The fact that the index of a continuous map is anthe fundamental theorem of algebra ing that the polynomial[V.13](/part-05/the-fundamental-theorem-of-algebra). Consider, for instance, the problem of prov-x5 + 3 x + 8 has a root. This is the same as asking for a fixed point of the functionx5 +4 x +8, since if this equals x then x5 + 3 x +8 = 0. Now if we regard the polynomialx5 as being defined on thetwo fixed points, at 0 and riemann sphere [IV.14 §2.4](/part-04/dynamics). nfty .
More over, their indices are C ∪ {$\infty$}, then it has both 5 (since ifthen x^5 goes around five times). Now the polynomialsx goes around 0 or . nftyin a “small circle,” x(x5)5 + to(x4 x5 ++48 x)t+give us a continuous deformation from8, and x5 + 4 x + 8 has a fixed point of index 5 at$\infty$. It follows that there must be other fixed points, with indices adding up to 5. These are the rootsofx5 + 3 x + 8, and the indices are the multiplicities of the roots.
696 Theorems and Applications to Analysis4 Infinite-Dimensional Fixed Point What happens if we try to generalize the Brouwer fixed point theorem to continuous maps defined on infinite dimensional closed balls? The answer is that we will not be able to, as the following example shows. Let B be the set of all sequences|a |2 ⩽1. This is our closed ball; it is the unit(a1, a2, . . . ) such that ball of the sequencenn a hilbert space= (a, a , . . . ), we write[III.37](/part - 03/bayesian - analysis)2. Given an infinite a for its norm(((1 n− |ana(|2)2)()1()1()/){2}/ 2.
Now consider the map$, a1$, a2, .
 . . ). It is easy to check thatf:$(a^{1}$, a2, $. . . )f \to is$ continuous and that fore, ifais a fixed point, we must have1 2 f (a) = 1 for everya = a. There - 1, from which we can see thata = 0, and then that aa1==0, and so on. In other words,0. From this it follows thata Therefore, the map2= 0. But this contradicts the condition thatfhas no fixed point$.3a = 1$.
tinuous map, then it is some times possible to prove fixed point theorems, and some of these theorems However, if we place extra conditions on a con have important applications, notably to establishing the existence of solutions to differential equations. ping theorem An easy result of this type is the.
This states that if X is a contraction map-metric space [III.56](/part-03/metric-spaces) with a property known asis briefly discussed in normed spaces and banach completeness (which spaces there exists a constant[III.62](/part-03/normed-spaces-and-banach-spaces)) andf is a map fromρ < 1 such that Xd(f (x), f (y))to X such that⩽ρd(x, y)fixed point. To prove this, one picks any point for everyx and y in X, then f must have ax \in  X and looks at the iterate sx, f (x), f (f (x)), f (f (f (x))), and so on. Denoting these by prove quite easily that$d(x^{n}$, xmx)0, xtends to 0 as1, x2, . . .
, one canm andnthen guarantees that the sequence both tend to infinity, and the completeness property(x ) has a limit. It is not hard to prove that this limit is a fixed point ofn f . point theorem K A more sophisticated example is theis a compact, which states that if[III.9](/part-03/compactness-and-compactication) convex subset of X is a Banach space, Schauder fixed X , and f is a continuous function from point.
Roughly speaking, to prove this one approx i-K to K, then fhas a fixed mates K and approximates Kby larger and larger finite-dimensional setsf by continuous maps f that take sequence$n K^{n} to(x K^{n})$. Brouwer’s fixed point theorem gives asuch that$f (x ) = x \text{for each nn}$. The compactness ofn K implies that the sequenc(en)n n (xn) has a convergent subsequence: its limit can be shown to bea fixed point off .

V. Theorems and Problems

a similar nature, lies more in their applications than in their basic statements. A typical application is a proof The importance of these two theorems, and others of that the differential equation d2 u= u - 10 sin(u2) - 10 exp(−|x|)

has a solution real numberdx2 x and tends to 0 asu such that u(x)x tends tois defined for every±. nfty. We can rewrite this equation as 1- dd(x2)2 u = 10 sin(u2) + 10 exp(−|x|). If we write the left-hand side as L(u), then this equation can be further rewritten as $u = L^{-1}(10 sin(u^{2}) + 10 exp(−|x|))$.
(It is possible to identify the operator$L^{-1} explicitly$.) If we now let tions defined on X be the Banach space of continuous func-R that tend to 0 at ±$\infty$, with the uni- form norm, then it can be shown that the right-hand side of this last equation defines a continuous function fromby the Schauder fixed point theorem, this highly non-X to a compact convex subset of X. Therefore, linear equation has a solution with the given bound-ary conditions, a result that is hard to prove in any other way. V.12 The Four-Color Theorem

Bojan Mohar

The four-color theorem asserts that the regions of anymap drawn in the plane (or, equivalently, on the two dimensional sphere) can be colored with no more than four colors in such a way that any two regions with a common boundary are given different colors. The example in figure 1 shows that four distinct colors are necessary since the regions A, B, C, and D are all adja-cent to each other. This result was conjectured by Francis Guthrie in 1852.
An in correct proof was given by Kempe in 1879, and for eleven years the problem was believed to have been solved, until Heawood pointed out the error in 1890. However, Heawood showed that Kempe’s basic idea, which we shall out line below, could at least be used to give a correct proof that five colors were always sufficient. After that, the problem became a famous example of a question that remained stub-bornly open despite being very easy to understand.
(Another such problem was fermat’s last theorem [V.10](/part-05/fermats-last-theorem).)In modern mathematics, map-coloring problems are usually formulated in the language of graph theory. To V.12. The Four-Color Theorem Fce bad gh Figure 1 A map with eight regions. any map we assign agraph correspond to the regions of the map, and we graph [III.34]: the vertices of the declare two vertices to be adjacent if the correspond-ing regions share a piece of their boundary. The graph for the map in figure 1 is shown in figure 2.
It is easyto see that the graph of any map in the plane can be drawn in such a way that no two edges cross each other: such graphs are called planar. Instead of coloring regions of maps, we now color vertices of the corresponding graphs. If no two vertices that are joined byan edge have the same color, then we say that the coloring is proper. After this reformulation, the four-color theorem states that every planar graph coloring with at most four colors. G has a proper due to Kempe and Heawood. It is a proof by con tr adic - tion, so we start by assuming that the result is false.
If Here, briefly, is the proof of the five-color theorem that is the case, then there must be a graph i mal size that has no proper coloring with five colors. G of min - euler’s formula [I.4 §2.2](/part - 01/general - goals) says that$V - E + F = 2 for$ any (connected) planar graph, where of vertices, E is the number of edges, and V is the number F is the num- ber of regions into which the plane is divided by any drawing of the graph. It is not hard to deduce from this formula that G has a vertex vwith at most five neighbors (that is, other vertices linked tov by an edge) in the graph.
If we remove a proper coloring of what is left, becausevfrom the graph, then we can find G is a minimal counterexample to the theorem. Ifneighbors, then we can colorv as well, since there arev has fewer than five at most four colors that need to be avoided and we have five colors at our disposal. So the only thing that can go wrong is ifvhas five neighbors and those five colors all get different colors when we color the rest of G. are red, yellow, green, blue, and brown, as we go clock-wise around Let us suppose that the colors of the neighbors ofv.
As it stands, we cannot color v , but wev could try to do so by adjusting the coloring of the rest of the graph. For instance, we could try recoloring the 697 Hf cab deg Figure 2 The graph of the map from figure 1. red vertex green, there by freeing up red to be used forv. Of course, if we did that we might have to recolor further vertices, but we could try to find a recoloring as follows: first change the color of the red neighbor of v to green. Then change all the green neighbors of that vertex to red, and all the red neighbors of those ver-tices to green, and so on.
When we have finished this process, the one thing that could go wrong is that we might end up recoloring the green neighbor ofv red, in which case we would not after all be free to use red for vtices from the red neighbor of. This will happen if and only if there is a chain of ver - v to the green neighbor that alternates red and green. However, if this circum-stance arises, we can try to recolor the yellow neighbor ofthat can stop us is an alternating chain of yellow andv blue in a similar way. Once again, the only thing blue vertices going from the yellow neighbor ofv to the blue neighbor.
But such a chain cannot exist, as it would at some point have to cross the red/green chain, and this contradicts the fact that the graph is planar. mathematician Heinrich Heesch proposed a general Returning to the four-color problem, the German method for tackling it that can be thought of as a more complicated version of the above argument. The idea is to identify a list Cof “configurations” with the following properties. First, every planar graph must contain a configuration X that belongs to C.
Second, given a planar graph Gthat contains a configuration X from C, and given a proper coloring of the rest of G that uses at most four colors, it is possible to adjust this coloring insuch a way that it can be extended to a proper coloring of the whole of G. In the proof of the five-color theorem above, there was a very simple list of five configura-tions: a vertexv with one edge, two edges, three edges, four edges, or five edges coming out of it. Nothing this simple works for the four-color problem, but Heesch’s

698

idea was that it might be possible to solve the problem by using a more complicated list of configurations. Such a list was found by Kenneth Appel and Wolfgang Haken in 1976. However, this is by no means the whole story, because the list of configurations that they found was not just “more complicated” but so much more complicated that it broke new ground: it was the first time that a major theorem had been proved with a proof that was too long to be humanly checkable.
Thereason for this was partly that their list C contained about 1200 configurations, but a more important rea-son was that for some configurations X it was neces- sary to check hundreds of thousands of cases in order to demonstrate that a coloring of the rest of the graph could be adjusted to accommodate a coloring of X as well. Therefore, there was no alternative but to use a computer to do the checking. (Heesch had himself proposed a list, but some of his configurations would have involved so many cases that even a computer could not have checked them all.) Appel and Haken was mixed.
Some hailed it as the addi-tion of a powerful new tool to the mathematical armory. The reaction of other mathematicians to the proof of Others were uneasy about having to trust that the rele-vant computer program had been written correctly and that the computer had operated as it should. And infact the proof turned out to have several flaws, though all those that were discovered were subsequently corrected by Appel and Haken in their monograph of1989.
Any doubts there may have been of this kind were removed once and for all in 1997, when Robert-son, Sanders, Seymour, and Thomas developed another proof based on similar principles. The part of the proof that was checkable by humans was made more trans-parent, and the computer-verified part was supported by a well-structured collection of data that enabled the proofs to be checked independently.
One could still question whether the compilers used were correct and whether the hardware was stable, but the proof has been checked on different platforms, using different programming languages and operating systems, so this proof is much less likely to be in correct than a typical human-checked proof of even moderate length. worried about whether the proof is correct. However, there are many who object to it for a different rea-The result is that very few mathematicians are now son.
Even if we can now be certain that the theorem is true, we can still ask why it is true, and not everybody regards the answer “Because hundreds of thou-sands of cases were checked and they all turned out

V. Theorems and Problems

to be OK” as a satisfactory explanation. As a result, if some one were to discover a shorter and more accessible proof it would be regarded by many as a break-through comparable to the solution of the problem by Appel and Haken. An unfortunate side effect of this isthat mathematics departments around the world still receive many in correct attempted proofs, several of which repeat the mistake of Kempe. provoked the development of many important new Like many good problems, the four-color problem mathematical ideas.
The theory of graph colorings, in particular, has evolved into a deep and beautiful area of research. (See tori cs [IV.19 §2.1.1](/part-04/extremal-and-probabilistic-combinatorics) and also Jensen and Toft (1995).)extremal and probabilistic combina Extensions of map-coloring problems to arbitrary surfaces led to the development of topological graph theory, and questions about the planarity of graphs culminated in the theory of One of the most prolific graph theorists, william graph minors [V.32](/part-05/the-robertsonseymour-theorem). T.
Tutte, judged the impact of the four-color theorem on mathematics by proclaiming: “The four-colour theorem is the tip of the iceberg, the thin end of the wedge, and the first cuckoo of Spring.” Further Reading Appel, K., and W. Haken. 1976. Every planar map is four colorable. Bulletin of the American Mathematical Society 82:711–12.. 1989. Every Planar Map Is Four Colorable. Contemporary Mathematics, volume 98. Providence, RI: American Mathematical Society. Jensen, T., and B. Toft. 1995.York: John Wiley. Graph Coloring Problems. New Robertson, N., D. Sanders, P. Seymour, and R. Thomas.1997.
The four-colour theorem. Journal of Combinatorial Theory B 70:2–44. V.13 The Fundamental Theorem of Algebra The what you obtain from the complex numbers [I.3 §1.5](/part - 01/fundamental - definitions) can be thought of asreal numbers [I.3 §1.4](/part - 01/fundamental - definitions) when you introduce a new number, denoted i, and stipulate that it is a solution of the equation x2 = −1, or equiv- alently a root of the polynomial x2 +1.
At first, this may seem an artificial thing to do—it is not obvious what is so important aboutx2 + 1 as opposed to any other polynomial—but that is a judgment with which no professional mathematician would concur. The fundamental theorem of algebra is one of the best pieces V.14. The Fundamental Theorem of Arithmetic of evidence that the complex number system is, infact, natural, and natural in a profound way. It states that, within the complex number system, every polynomial has a root.
In other words, once we introduce the number i, then not only can we solve the equation x2 + 1 = 0, we can solve all polynomial equations (even if the coefficients are themselves complex). Thus, when one defines the complex numbers, one gets much more out of them than one puts in. It is this that makes them seem not an artificial construction but a wonderful discovery. For many polynomials it is not hard to see that they have roots. For example, if$P (x) = x^{d} - u \text{for some pos}-$ itive integer root of P will be ad and some complex number dth root of u.
One can writeu, then au in the formr (ei)θ, and then (r1)/d(ei)θ/d will be such a root. This means that any polynomial that can be solved by a formula involving dth roots and the usual arithmetical operations, which includes all polynomials of degree less than 5, can be solved in the complex number system.
However, owing totic [V.21](/part-05/the-insolubility-of-the-quintic), not all polynomials can be dealt with in this the insolubility of the quinway, and in order to prove the fundamental theorem of algebra one must look for a less direct argument. In fact, this is true even if one is looking for real roots of real polynomials. For example, if10 x6 + x3 + 1, then we know that P (x)P (x)is large and = 3 x7 - positive whenx is, since the x7 term is by far the most significant, and large and negative when same reason.
Therefore, at some point the graph ofx is, for the Px crosses the with P (x) =x - axis, which means that there is some0. Notice that this argument does not tell us what$x$ is—that is the sense in which it is “less direct.”Now let us see how one might show that a polynomial has a complex root, by looking at the examplex4 + x2 - 6 x + 9. This can be rewritten x4+(x - 3 P (x))2, and= since bothx4 and (x - 3)2 are nonnegative, and since they cannot be zero simultaneously, real root.
To see that it has a complex root, we shall P cannot have a begin by fixing a large real number behavior of P (reiθ) as θ varies between 0 and 2 r and looking at theπ. Asθ varies in this way, r eiθ traces out a circle of radius r in the complex plane. Now(r eiθ)4 = r4 e4 iθ, so the x4 part of P (reiθ) traces out a circle of radiu sr is large enough, then the rest (that is, r4, but goes around it four times. If(reiθ - 3)2) is so small compared with behavior of P (r(ei)θ) is to make it deviate very slightly(r (ei)θ)4 that the only effect on the from the circle of radiusr4.
This small deviation is not 699 enough to stop the path of P (reiθ) going around zero four times. Next, let us consider what happens whenr is very small. Then value ofθ, since P (reiθ(r) eis very close to 9, whatever theiθ)4, (r eiθ)2, and (reiθ) are all small. But this means that the path traced out by P (r (ei)θ) does not go around zero at all. out by established is that for very large For any P (rr ewe can ask how many times the path trace(di)θ) goes around zero. What we have justr the answer is four and for very small in termed i at er the answer changes. But if you gradu - r it is zero.
It follows that at some ally shrinkr , the path traced out by P (r(ei)θ) varies in a continuous way, so the only way this change can come about is if for somer the path crosses 0. This gives us the root we are looking for, since the path consists of points of the form P (r(ei)θ) and one of these points is 0. a rigorous proof. However, this can be done, and it isnot hard to generalize the resulting argument to one Some care is needed to turn the above reasoning into that applies to any polynomial. tributed todoctoral thesis.
Though his argument (which was differ-The fundamental theorem of algebra is usually at - gauss [VI.26](/part - 06/carl - friedrich - gauss - 17771855), who proved it in 1799 in his ent from the one sketched above) was not fully rigor-ous by today’s standards, it was convincing and broadly correct. Later he went on to give three more proofs. V.14 The Fundamental Theorem of

Arithmetic

The fundamental theorem of arithmetic is the assertion that every positive integer can be expressed in exactly one way as a product of prime numbers. These prime numbers are known as the prime factors of the original number and the product itself is the tor ization. To give a few examples: 12= prime fac - 2 . imes 2 . imes 3, 343= 7 . imes  7 . imes  7, 4559 = 47 . imes  97, and 7187 is itself a prime. This last number shows that the word “product”should be interpreted so as to include the case where there is only one prime involved.
As for the phrase“exactly one way,” it is understood that the order in which the primes are multiplied is not significant, so, for example, the products 47. imes  97 and 97 . imes  47 are not regarded as different. The following inductive procedure allows one to find the prime factorization of a given positive integern is prime, then we have found it already. Otherwise, n. If$let$ p be the smallest prime factor of n and let m = n/p. Sincem is smaller than n, we know by induction how

700

to find the prime factorization ofwithp, gives it to us for n. In practice, what this meansm, and this, together is that we generate a sequence of numbers, where each number in the sequence is the previous one divided by its smallest prime factor. For example, if we start with the number 168, then the sequence begins 168, 84, 42,

21. At this point we cannot divide by 2, but 3 is a factorof 21 so the next number in the sequence is 7. Since 7 is a prime, the process stops. Looking back, we find thatwe have shown that 168$= 2 \times 2 \times 2 \times 3 \times 7$. inconceivable that a number could have two genuinely different prime factorizations. But the method does not Once one is used to this method, it comes to seem guarantee this at all. Suppose we successively divide by the largest prime factor rather than the smallest. Why should this not give a completely different set of primes?
It is hard to think of an argument that does not use a phrase such as “the prime factorization of$n$,” there by implicitly assuming what it sets out to prove. It is possible to show in a rather precise way that the fundamental theorem of arithmetic isby looking at an algebraic structure where the notionnot obvious, of prime factorization makes sense but numbers can have more than one prime factorization. This structure, denoted Z$(\sqrt{-5})$, is the set of all numbers of the form a can be added and multiplied just like ordinary integers$.+ b\sqrt{-5}$, where a and b are integers.
Such numbers For example, $(1 + 3 \sqrt{-5}) + (6 - 7 \sqrt{-5}) = 7 - 4 \sqrt{-5}$ and (1 + 3. qrt{-5})(6 -. qrt{7}. qrt{-5}) . qrt . qrt= 6 - 7 . qrt{-5} + 18 -5 - 21( -5)2= 6 + 11 -. qrt{5} + 21 . imes  5= 111 + 11 -5.bwould also be a natural definition if we wanted to. qrt{In} this structure, we can regard a number-5 as prime if its only factors are ±1 and ±xx=. (Thisa + extend the notion of primes from the positive integersto all integers.) It can be shown quite easily that 2 and 3 are both primes (though it is not immediately obvious since there are now more possibilities for factors).
Two other primes are 1 either as 2 . imes 3 or as+. qrt(-1 5 and 1+ . qrt{-5})(-. qrt{1} --5. But we can write 6. qrt{-5}), so 6 has two different prime factorizations. For a further discussion of this point see algebraic numbers [[IV.1 §§4–8]](/part - 04/algebraic - numbers). da mental theorem of arithmetic must use some feature of What this example shows is that any proof of the fun-Z, the set of integers, that is lacking in Z(. qrt{-5}). Since

V. Theorems and Problems

addition and multiplication work in a very similar wayin both structures, it is not very easy to find such a feature, or at least not one that is relevant. It turns out that the important property that Z(. qrt{-5}) does not have is an appropriate analogue of the following basic principle for integers: that ifone can writen = qm + r mwith 0 and n⩽ r <are integers, then|m|. This fact under lies important role in the most commonly given proof of euclid’s algorithm [III.22], which plays an unique factorization.
The Fundamental Theorem of Calculus See some fundamental mathematical definitions [I.3 §5.5](/part-01/fundamental-definitions) Gauss’s Law of Quadratic Reciprocity See from quadratic reciprocity to class field theory [V.28](/part-05/from-quadratic-reciprocity-to-vi38-augustus-de-morgan-18061871) V.15 Gödel’s Theorem Peter J. Cameron In response to problems in the foundations of mathematics such asall sets which are not members of themselves;
is it a Russell’s paradox (“consider the set of member of itself?”), hilbert [VI.63](/part-06/david-hilbert-18621943) proposed that the consistency of any given part of mathematics should be established by finitary methods that could not lead to a contradiction. Any part for which this had been done could then be used as a secure foundation for allof mathematics. metic of the natural numbers, which can be described in terms of An example of a “part of mathematics” is the arith-first-order logic [IV.23 §1](/part-04/logic-and-model-theory).
We begin with symbols, both logical (connectives such as “not” and“implies,” quantifiers such as “for all,” the equality symbol, symbols for variables, and punctuation) and nonlogical (symbols for constants, relations, and functions suitable for the branch of mathematics under consider at i on). Formulas are finite strings of symbols built according to certain precise rules (which allow themto be mechanically recognized). We fix a certain set of formulas as our rules of inference that allow us to infer some formulas axioms, and we also choose a few from others.
An example of a rule of inference is ponens: if we have inferred$φ and (φ \to ψ)$, then we can modus inferψ. A theorem is a formula that is at the end of a chain (or tree) of inferences that starts with axioms.

V.15. Gödel’s Theorem

[VI.62](/part-06/giuseppe-peano-18581932) (seecal symbols are zero, the “success or function”Axioms for the natural numbers were given bythe peano axioms [III.67](/part-03/the-peano-axioms)). The non log i-speano, addi- tion, and multiplication. (The last two can be defined in terms of the others by inductive axioms:
for example, the rules$x$ + 0 = x and x + s(y) = s(x + y)define addition.) The crucial axiom is the tion, which asserts that if P (n) is a formula such that principle of induc-P (0) is true and P (n) implies P (s(n)) for all n, then P (n)to give a formal proof of the consistency of this theory: is true for all$n$. Hilbert’s specific challenge was that is, a proof that no contradiction can be deduced from the axioms by the rules of first-order logic.
Hilbert’s program was undone by two remarkable incompleteness theorems first theorem states the following.proved by gödel [VI.92](/part-06/kurt-gdel-19061978). The There are (first-order) statements about the natural numbers that can be neither proved nor disproved from Peano’s axioms. (This is some times qualified by being prefixed with, “If Peano’s axioms are consistent, then since we accept the existence of the natural numbers,. . ..” However, we do know that Peano’s axioms are consistent, asthe natural numbers model them.
So the qualification is unnecessary here, although it would need to be included if we were discussing some axioms whose consistency was not clear.) ideas. The first isof encoding each formula or sequence of formulas as a Gödel’s proof is long, but it is based on two simple Gödel numbering, which is a means natural number in a systematic and mechanical way.
π(x, y)proof of It can be shown that there is a two-variable formula such thatm,” which is a shorthand way of saying thatπ(m, n)holds if and only if “n is am Gödel number of a string of formulas that constitutes ais the Gödel number of a formulaφ and n is the proof ofω(x, y)φsuch that. Slightly more elaborately, there is a formulaω(m, n) holds if and only if m is the Gödel number of a formula and$n$is the Gödel number of a proof ofφ that has one free variableφ(m). (A free variable is one that is not quantified over.
For example,φ(x) might be the formula (∃y)y2 = x, in which casexnwould be the Gödel number of a proof that the Gödelis the free variable. For this choice ofφ, the number number of Now letψ(x)φ was a perfect square.)be the formula (∀y)(¬ω(x, y)). If φ is a formula (with one free variable) with Gödel num berm, then ψ(m) tells us that there is no proof of φ(m). (It tells us this indirectly: what it actually says is that

701

there is no Let pbe the Gödel number of$y$that is the Gödel number of such a proof.)ψ itself, and let ζ be the formulaψ(p). reference asserts its own unprovability, since This brings us to the second idea in the proof:. The formulaζ is carefully devised so that itψ(p) tells us that self- there is no proof of the formula formula with Gödel numberp. In other words, it tells usφ(p), where φ is the that there is no proof ofψ(p).
Since ζ asserts its own unprovability, it must be unprovable (since a proof of would be a proof thatζ had no proof, which is absurd).ζ Since is true, and since it is true it cannot be disprovable.ζ asserts its unprovability and is unprovable, it (One might wonder why this argument thatζ is true does not constitute a proof ofalthough it is a rigorous demonstration of the truth ofζ. The answer is thatζnot an argument that starts from the Peano axioms and, it is not a proof in Peano arithmetic.
That is, it is uses the rules of inference of the kind we discussed earlier.) consistency of the axioms as a first-order formula: namely Gödel numbering also allowed Gödel to consider the(∀y)(¬(π(m, y))), where mis the Gödel number of the formula 0= s(0) (or any other contradiction). Here is Gödel’s second theorem. It is impossible to prove from Peano’s axioms that they are consistent. the Peano axioms, but apply to any (consistent) sys-tem of mechanically recognizable axioms that is pow-The proofs of these theorems are not specific to erful enough to describe the natural numbers.
Thus, completeness cannot be restored simply by adding a true but unprovable statement as a new axiom, forthe resulting system is still strong enough for Gödel’s theorem to apply to it. It might seem that we could obtain a complete axiomatization of the natural numbers by simply taking all true statements as axioms. However, one requirement for Gödel’s theorems is that the axioms should be rec-ogn iz able by some mechanical method.
(This is needed to construct the formulaπ(x, y) at the start of the proof.) Indeed, we can deduce from this that (as subse-quently pointed out by turing [VI.94](/part-06/alan-turing-19121954)) the true statements about the natural numbers ically recognized (that is, their Gödel numbers do not can not be mechanform a Gödel’s true but unprovable statement is impor-recursive set ). tant for the foundations of mathematics, but it hasno intrinsic interest in its own right. Later, Paris and

702

Harrington gave the first example of a mathematically significant statement that is unprovable from Peano’s axioms. Their statement is a variant oforem [IV.19 §2.2](/part-04/extremal-and-probabilistic-combinatorics). Subsequently, many other “natural ramsey’s the incompleteness es” have been found. Of course, the consistency of Peano’s axioms can be proved in a stronger system, since we could just add the(unprovable) consistency statement.
Less trivially, since a model of the natural numbers can be constructed within set theory, the consistency of Peano arithmetic can be proved from[IV.22 §3.1](/part-04/set-theory) (known as ZFC) for set theory. Of course, the zermelo–fraenkel axioms ZFC cannot prove its own consistency, but the consistency of ZFC can be deduced from a yet stronger sys-tem (for example, adding an axiom that asserts the existence of a suitably “large” cardinal number such as an inaccessible cardinal [IV.22 §6](/part-04/set-theory)).
times possible to find complete axiom systems (that For small enough parts of mathematics, it is someis, systems that allow one to prove every true state-ment). For instance, this can be done for the theory of the natural numbers with zero, the success or function, and addition alone. Thus, multiplication is essential to Gödel’s argument. not It is more elementary to see that Peano’s axioms are categorical: there are models for the axioms that are not isomorphic to the natural numbers.
such standard models of arithmetic contain infinitely large non numbers (that is, numbers that are larger than all natural numbers). phers arguing about whether the human brain is a Gödel’s theorem has been a battleground for philoso deterministic machine (in which case, presumably, we would not be able to prove any formally unprovable statement). Fortunately, there is not enough space inthis article for more details!
The Goldbach Conjecture See problems and results in additive number theory [V.27](/part - 05/problems - and - results - in - vi36 - peter - gustav - lejeune - dirichlet - 18051859) V.16 Gromov’s Polynomial-Growth Theorem Ifing that every element of G is a group and g1, . . . , g Gkcan be expressed as a prod-are generators of G (mean- uct of the gand their inverses), then we can define

$i$

a Cayley graph by taking the elements of G as vertices

V. Theorems and Problems

and joining either toggg or toto h if there is somegg-1. i such that h is equal For each$ri$, let γ be the number of elements that areir

at a distance of at most number of elements that can be written as a “word” ofr from the identity: that is, the length at most(For instance, ifr gin the generators and their inverses.= g g g-3, then we know that g belongs toγ5.) It turns out that i(f1()4)2 Gis an infinite group, then the rate of growth of the sizes of the sets tell one a great deal about$G$; this is particularly true$γ^{r} can$ when the growth is less than exponential.
(The growth is always bounded above by an exponential function, since there are at most exponentially many words of a given length in the generators If G is an Abelian group generated byg1, $. . . , grg.)1$, . . . , g , then every element ofa , . . . , a are integers such thatγr is of the formk |k ia=1|a⩽igri, where. It fol-k lows easily that the size of1 k γ is at mosti = 1 (i2 r + 1)k (andr

with a bit more effort one can improve this bound).Thus, asrtends to infinity, the growth rate of$γ^{r} is$ bounded above by a polynomial of degree the free group [IV.10 §2](/part-04/geometric-and-combinatorial-group-theory) generated byg , . . . , gk in r . If, then G is all words of len gthr in the elements g1(but not their ki

inverses) give rise to distinct elements ofof$γ \text{is at least} k^{r}$. Thus, in this case the growth rate G, so the sizer

is exponential. More generally, there will be an expo-nential growth rate whenever G contains a non-Abelian free subgroup. likely to be smaller if Gromov’s theorem is a remarkably precise result along These observations suggest that the growth rate is G is more like an Abelian group. these lines. It states that the growth rate of the setsγr

is bounded above by a polynomial inr if and only if Gtion does indeed say that has a nilpotent subgroup of finite index. This condi-G is some what like an Abelian group, since nilpotent groups are “close to Abelian” anda subgroup of finite index is “close to the whole group.” For example, a typical nilpotent group is theberg group, which consists of all 3. imes 3 matrices with Heisen- 0 s below the diagonal, 1 s on the diagonal, and integers above the diagonal.
Given any two such matrices X and Yhand corner, and the “error matrix”, the products XY and Y Xdiffer only in the top right-XY -Y X commutes with everything in the group. In general, a nilpotent group is built out of Abelian groups in a controlled manner in a finite number of steps. A fuller discussion of the theorem, including the exact definition of “nilpotent,” can be found in geometric and combinatorial group theory we highlight the fact that it is a beautiful example of a[IV.10](/part-04/geometric-and-combinatorial-group-theory). Here

V.19. Inequalities

rigidity theorem that a nilpotent group would (because the growth rate: if a group behaves roughly in the way of the setsγ is polynomial), then it must in fact ber related to a nilpotent group in a very precise and alge-braic way. (See mostow’s strong rigidity theorem [V.23](/part - 05/mostows - strong - rigidity - theorem) for another example of such a theorem.) V.17 Hilbert’s Nullstellensatz Let plex variablesf1, . . . , fn be a collection of polynomials inz, . . . , z . Suppose that it is possible tod com- find another collection of polynomials1 d g1, . . .
, gn such that f1(z)g1(z) + f2(z)g2(z) + · · · + fn(z)gn(z) = 1 for every complexlows immediately that no such$d - tuple z = (zd^{1}$, . . . , z-tuple can be a rootd ). Then it fol- of every single would equal 0. Remarkably, the converse also holds: fi, since otherwise the left-hand side that is, if there is nofall vanish simultaneously, then it is possible to findd-tuple for which the polynomials i

poly nom i a lsg such that the above identity holds. Thisi

result is known as the A short (but clever) argument can be used to deduce weak Nullstellensatz. Hilbert’s Nullstellensatz This again is a statement where a condition that is obvi-from the weak Nullstellensatz. ously necessary turns out to be sufficient. Suppose thath is another polynomial in d complex variables, that r is a positive integer, and that the polynomial$h^{r} \text{can be}$ written in the form collection of polynomials$f^{1}g^{1} + gf^{2}$, . . . , gg2 + · · · +. It follows imme-fngn for some diately thath(z) = 0 whenever1 f (z)n = 0 for every i.i

Hilbert’s Nullstellensatz states that if$h(z) = 0 when-$ everf (z) = 0 for every i, then there must be somei

positive integerg , . . . , g such thatr and some collection of polynomials hr = f g + f g + · · · + f g . 1 Hilbert’s Nullstellensatz is discussed further in(n1()1()2()2)nalge - n braic geometry [[IV.4 §§5, 12]](/part-04/algebraic-geometry). V.18 The Independence of the

Continuum Hypothesis

The real numbers are uncountable [III.11](/part-03/countable-and-uncountable-sets), but do they form the “smallest” uncountable set? Equivalently, isit the case that if A is any set of real numbers, then either and the set of all real numbers? The A is countable or there is a bijection between continuum hypoth-A esis (or CH) is the assertion that this is indeed true. The notions of countability and uncountability were invented by cantor [VI.54](/part-06/georg-cantor-18451918), who was also the first to

703

formulate CH. He tried hard to prove or disprove it, asdid many others after him, but nobody succeeded. Gradually, mathematicians came to entertain the idea that CH might be “independent” of normal mathe-matics: that is, independent of the usual zfc axioms [IV.22 §3.1](/part-04/set-theory) of set theory. This would mean that it could be neither proved nor disproved from the ZFC axioms. The first result in this direction was due to gödel [VI.92](/part-06/kurt-gdel-19061978), who showed that CH could not befrom the usual axioms.
In other words, one could not disproved reach a contradiction by assuming CH. To do this, he showed that inside every model of set theory [IV.22 §3.2](/part-04/set-theory) there is a model in which CH holds. This model is called the “constructible universe.” roughly speaking, it consists just of those sets that “have to exist” if the axioms are true. So, in this model, the setof reals is as small as it could possibly be. The “smallest uncountable size” is usually denoted construction the reals appear inא אstages, with only1, and in Gödel’s countably many reals appearing at each stage.
From this one can deduce that the number of reals is1א , which is precisely the assertion of CH.The other direction had to wait thirty years, until Paul Cohen invented the method ofmake CH false? Starting from some model of set theory forcing. How would we (in which CH might well hold), we would like to “add”some reals to it. Indeed, we would like to add enough that there are now more thanא1 of them. But how do we “add” a real?
We need to ensure that what we end upwith is still a model of set theory, which is hard enough, but also that when we add new reals we do not alter the value ofא(since otherwise the statement “the number of reals is1א1” may still be true in the new model). This is an extremely complicated task, both conceptu-ally and technically. See set theory [IV.22](/part-04/set-theory) for more details about how it is carried out. V.19 Inequalities Let(. qrt{xx}−√andy)2 y=be two nonnegative real numbers.
Thenx +y -2. qrt{xy} is a nonnegative real num- ber, from which it follows that the arithmetic mean ofx and (y1)2 (xis at least as big as the+y) ⩾ . qrt{xy}. That is, geometric mean ple of a mathematical inequality; its generalization to. This conclusion is a very simple examn numbers is called the In any branch of mathematics that has even the AM–GM inequality. slightest flavor of analysis, inequalities will be of great importance: as well as analysis itself, this in-cludes probability, and parts of combinatorics, number 704 theory, and geometry.
Inequalities are less prominentin some of the more abstract parts of analysis, but even there one needs them as soon as one wishes to apply the abstract results. For instance, one may not always need an inequality to prove a theorem about continuous[III.62](/part - 03/normed - spaces - and - banach - spaces), but the statement that some specific linear linear operators [III.50](/part-03/linear-operators-and-their-properties) between banach spaces operator between two specific Banach spaces is con-tinuous is an inequality, and often a very interesting one.
We do not have space to discuss more than asmall handful of inequalities in this article, but we shall include some of the most important ones in the toolbox of any analyst. ful inequality. A functionif Jensen’s inequalityf (. ambda x + \mu y) ⩽ . ambda f (x)is another fairly simple but use-+f\mu f (y): R\to  whenever R is called. ambda convex and \mu are nonnegative real numbers with$λ + \mu = 1$. Geo- metric ally, this says that all chords of the graph of the function lie above the graph.
A straightforward inductive argument can be used to show that this property implies the same property forn numbers: $f (λ^{1}x^{1} + · · · + λ^{n}x^{n}) ⩽ λ^{1}f (x^{1}) + · · · + λ^{n}f (x^{n})$ whenever all the1. This is Jensen’s inequality.$λ^{i} \text{are nonnegative and} λ^{1} +· · ·+λ^{n} =$ [III.25](/part-03/the-exponential-and-logarithmic-functions) is positive, from which it follows that the expo-nential function itself is convex. If The second derivative of the exponential function a , . . .
, a are posi- tive real numbers and we apply Jensen’s inequality tothe number sx = . og (a ), then we find, using standard1 n properties of exponentials andthatii logarithms[III.25 §4](/part-03/the-exponential-and-logarithmic-functions), (aλ()1)1 · · · (aλ()n)n ⩽ λ1 a1 + · · · + . ambda nan. This is called the weighted AM–GM inequality. When all the inequality. Applying Jensen’s inequality to other well-. ambda i are equal to 1/n it reduces to the usual AM–GM known convex functions produces several other well-known inequalities.
For instance, if we apply it to the functionx2, we obtain the inequality(λ1 x1 + · · · + . ambda nxn)2 ⩽ λ1(x1)2 + · · · + . ambda n(x2)n, (1) which can be interpreted as saying that ifdom variable [III.71 §4](/part-03/probability-distributions) on a finite sample space, then X is a ran-(EX)2 ⩽ EX2.

important inequality in all of mathematics. Suppose that The V Cauchy–Schwarz inequality is a real vector space with anis perhaps the most inner product [III.37](/part-03/bayesian-analysis)product is that· , · on it. One of the properties of an innerv, v ⩾ 0 for every v \in  V , with equality if and only ifv = 0. Let us write v for

V. Theorems and Problems

v, vx =1/2 y. If =x1, then 0 and y are any two vectors in⩽ x - y2 = x - y, x V- ywith =x, xx, y + ⩽ 1 y, y=  −x. um 2 yx, y. More over, equality holds only if = 2 - 2 x, y . It follows thatx = y. We can obtain a general pair of vectors by mul- tip lying number sx. ambda byand. ambda andμ. Then both sides of the inequalityy by μ, for some nonnegative real scale up by a factor ofthe inequalityx, y ⩽ λ\mu x. um , so we can conclude thaty holds in general, with equality if and only if Particular inner-product spaces lead to special casesx and y are proportional.
of this inequality, which are themselves often referredto as the Cauchy–Schwarz inequality. For instance, if we take the spacen a b , then we obtain the inequality Rn with the inner product a, b =i=1 i in a b ⩽n (a2)1/2 n (b2)1/2. (2)

It is not hard to deduce a similar inequality for complex scalars: one needs to replace i=1 i i i=1 i (a2)iand=1 ib2 by |a |2 and|b |2 on the right-hand side. It is also not too hard t(oi()i)ii

prove that inequality (2) is equivalent to the inequality(1) above. the Cauchy–Schwarz inequality. Again it has several versions, but the one that corresponds to inequality (2)Hölder’s inequality is an important generalization of is

n a b ⩽n |a (|p()1)/pn |b (|q()1)/q,

wherejugate index pi=belongs to the interva(l1)iofi p, which is defined to be the number i=1 i [1, i=. nfty1] andi q is the con- that satisfies the equation$(1/p) + (1/q) = 1$. (We inter- pret 1(n /|a. nfty |pto be 0.) If we write()1)/p, then this inequality can be rewritten inap for the quantity the succinct form It is a straightforward exercise to find, for each$i = {}^{1i} a$, b ⩽ ap bq. sequence equality occurs in the above inequality. Also, both sidesa, another (nonzero) sequence b such that of the inequality scale in the same way if you mul-tiplyb by a nonnegative scalar.
It follows that ap is the maximum ofthatb = 1. Using this fact, it is easy to verify thata, b over all sequences b such the function$x$ + yq ⩽ ax→ + apy satisfies. Minkowski’s inequality: important. Once one has Minkowski’s inequality, it isvery easy to check that This gives some idea of why Hölder’s inequality is sopp ·p is (as the notation suggests) aple of the phenomenon mentioned at the beginning ofnorm [III.62](/part-03/normed-spaces-and-banach-spaces) on Rn. This is an even more basic exam-p the article: just to show that a certain normed space

V.19. Inequalities

is about real numbers. In particular, looking at the casea normed space, we have had to prove an inequality p = 2, we see that the entire theory of hilbert spaces [III.37](/part-03/bayesian-analysis) depends on the Cauchy–Schwarz inequality. Minkowski’s inequality is a particular case of the triangle inequality three points in a, which states that if metric space [III.56](/part-03/metric-spaces), thenx, y, andd(x, z)z are⩽d(x, y) + d(y, z), where d(a, b) denotes the distance between inequality is a tautology, since it is one of the axioms a and b.
When put like this, the triangle of a metric space. However, the statement that a partic-ular notion of distance actually is a metric is far from vacuous. If our space isa - b, then Minkowski’s inequality is easily seen to Rnand we defined(a, b) to be be equivalent to the triangle inequality for this notionof distance.p analogues” as well. For example, here is a contin-The inequalities above have natural “continuous uous version of Hölder’s inequality. For two func-tionsf and gdefined on R, letf , gbe defined to be( . nfty −. nfty. nfty |f (x)f (x)g(x)|p ()1)/p.
Then, once again, dx, and write fpf , gfor the quantity⩽ f g , where−. nfty q is the conjugate index of p. Another example^p^q is a continuous version of Jensen’s inequality, which states, in a continuous setting, that iff is convex and X is a random variable, then f (EX) ⩽ Ef (X). In all the inequalities we have so far mentioned, we have been comparing two quantities has been easy to identify the extreme cases where the A and B, and it ratio ofities are like this. Consider, for instance, the follow-A to B is maximized.
However, not all in equal- ing two quantities associated with a sequence of realnumbersa = (a, a , . . . , a ). The first is the norm |such that each(an)i = 2 1 = ia(i| over all the (2 n)i = 1 (a2()i)1)is 1 or1/2 2. The second is the average of - n1. (In other words, for each ns equ en ces (1,2, . . . , n)ii you randomly decide whether to multiply a by - 1 i or not, add up the results, and take the expected absolute value of the sum.) It is not the case that the first quantity is always less than the second. For instance, let tity is n =. qrt{2}, and let2 and the second is 1.
However, a1 = a2 = 1. Then the first quan - Khinchin’s inequality (or to be more accurate an important special case of Khinchin’s inequality) is the remarkable statement that there is a constant Csuch that the first quantity is never more than not hard to prove, using the inequality C times the second. It is EX2 ⩾ (EX)2, that the first quantity is always at second; so the two rather different looking quantities least as big as the are in fact “equivalent, up to a constant.” But what 705 is the best constant? In other words, how much big-ger can the first quantity be than the second?
This question was not answered until 1976, by Stanislaw Szarek, over fifty years after Khinchin proved the orig-inal inequality. The answer turns out to be that the example given earlier is the extreme one: the ratio can never exceed. qrt{2}. This situation is typical. Another famous inequality for which the best constant was discovered much later than the inequality itself is the Hausdorff–Young inequality of their, which relates norms of functions with norms fourier transforms [III.27](/part-03/the-fourier-transform).
Suppose that 1⩽ p ⩽ 2, and that f is a function from R to C with the property that the norm. umfp =−. nfty. nfty |f (x)|p d(x1)/p

exists and is finite. Let ˆoff and let q be the conjugate index off be the Fourier transformp. Then onlem for many years to determine the best constant fˆpq only (and not on⩽ Cp fp for some constantf ). Again, it was an open prob-C^p that depends Cbe gleaned from the fact that the “extreme” functions p. Some idea of why it might have been difficult can in this case are Gaussians: that is, functions of the formf (x) = (e-)((x-)\mu()2()/){2}σ 2.
A sketch of a proof of the Hausdorff–Young inequality can be found in harmonic analysis There is an important class of inequalities known[IV.11 §3](/part-04/harmonic-analysis). as being compared are parameters associated with geo-geometric inequalities, where the quantities that are metric objects. A famous example of such an inequality is the low ing. Let Brunn–Minkowski inequality A and B be two subsets of, which states the fol - Rn, and define A + B to be the set {x + y}:$x \in A$, y \in B. Then(vol(A + B)()1)/n ⩾ vol(A()1)/n + vol(B()1)/n.
Here, vol(X) denotes the n-dimensional volume (or, more formally, theset$X$. The Brunn–Minkowski inequality can be used lebesgue measure [III.55](/part - 03/measures)) of the to prove the equally famous in Rn (which is one of a large class of isoperimet-isoperimetric inequality ric inequalities). Informally, this states that, of all sets with a given volume, the one with the smallest surface area is a sphere. An explanation of why this follows from the Brunn–Minkowski inequality can be found in high-dimensional geometry and its probabilistic analogues [IV.26 §3].
We finish this brief sample with one further inequality, thethe theory of partial differential equations. Suppose Sobolev inequality, which is important in

706

that can visualize its graph as a smooth surface in$f$is a differentiable function from R2 to R3 Rlying. We above thexy-plane. Suppose also that f is compactly supported thatf (x, y), which means that there exists an = 0 if the distance from (x, y) to M(0, such0) is greater thanf , as measured by some M. We would now like to bound the size of Lp norm, in terms of the size of its gradient [I.3 §5.3](/part - 01/fundamental - definitions). abla f , as measured by some other Lasp norm. The Lp norm of a function. um fis defined here fp = R 2 |f (x, y)|p dx d(y1)/p. is possible.
For instance, we could have a differ en-In one dimension, it is clear that no such bound tiable function that was 1 every where on the inter - val[-M, M], 0 every where out side the wider interval[-(M + 1), M + 1], and gently decaying from 1 to 0 in between. Then if we increased the size of the derivative: we would just move the two M we would not change nonzero parts of the derivative further apart. On the other hand, by increasing size off as much as we liked.
However, we cannot do M we could increase the this sort of construction in two dimensions, because now the “boundary” of the function increases as the size of the function increases. The Sobolev inequality tells us that if 1⩽ p < 2 and r = 2 p/(2 - p), then able, consider the case function that is 1 every where inside the circle of radius fr ⩽ Cp . abla fp. To see why this might be reason - p = 1, so that r = 2. Let f be a Mof radius about the origin and 0 every where out side the circle M + 1.
Then as M increases, the norm f increases in proportion to mately equal to the area of the circle of radius M (since (f2)2 is approx i - M ), and2 so does length of the boundary of the circle). As this infor-. abla f1 (since it is roughly proportional to the mal argument suggests, there are close connections between the Sobolev inequality and the isoperimetric inequality in the plane. And like the isoperimetric inequality, the Sobolev inequality has ann-dimensional version for each now the condition is that 1$n$: it is the same result, except that⩽ p < n, and r is equal tonp/(n - p).

V.20 The Insolubility of the

Halting Problem

What does it mean to understand a certain area of math-ematics completely? One possible answer is that you understand it when you can solve its problems ically. Consider, for instance, the following question.mechan-

V. Theorems and Problems

Jim is half the age of his mother, and in twelve years’time he will be three-fifths of her age. How old is his mother now? For a child who is just old enough to understand the concept of “three-fifths,” this is likely to be an impossibly difficult problem. A bright and slightly older child may be able to solve it after some hard thought, which will probably include a certain amount of trial and error. But for any body who has learned how to translate such problems into equations and who knows how to solve two simultaneous linear equations, the problem is utterly routine:
let xbe Jim’s age and$y$ his mother’s; then the problem tells us that 2 and 5$(x + 12) = 3(y + 12)$; the second equation can be$x = y$ rearranged to give 3 gives$x = 24$, so y = y48.- 5 x =$24$; substituting$y = 2x$ that problems that once seemed to be difficult and to require ingenuity have become routine in this sort of The more mathematics one learns, the more one finds way, and it is eventually tempting to ask whether all of mathematics might, ultimately, be reducible to amechanical procedure.
And even if you think that that is a bit much to hope for, you can still ask the ques-tion about certain natural classes of problems, such as simultaneous linear equations. Perhaps there is always a mechanical procedure for solving the problems inany sufficiently “natural” class, even if there is not necessarily a systematic way of finding the mechanical procedure. One class of problems that has been intensively studied for several centuries is that of tions, which are equations in one or more variables Diophantine equa where one stipulates that the solutions should be inte-gers.
The most famous Diophantine equation is the Fermat equation$x^{n} + y^{n} = z^{n}$, but this is some what com- plicated because one of the variables, exponent. Suppose we restrict attention ton, appears as an polynomial equations, such asx2 - xy + y2 = 157. Is there a sys- tematic way of telling whether such an equation has integer solutions?The left-hand side of the equation$x2 - xy + y2 = 157$ is equal tosolution(x, y)(x2 must satisfy+ y2 + (x -xy()2)2+)/y2.
Therefore, any2 ⩽ 314, which makes it a short task to search through all possibili-ties until one discovers the solution$x = 12 and y = 13$ (or vice versa). However, an exhaustive search is not always possible: consider, for example, the equation 2 x2 - y2 = 1. This is a special case of the Pell equa- tion Pell equation can be solved systematically, with the, discussed in algebraic numbers [IV.1 §1](/part-04/number-theory). The help of continued fractions [III.22], and this leads

V.20. The Insolubility of the Halting Problem

to a systematic solution of all polynomial equations of degree up to 2 in two variables. By the end of the nineteenth century, these and many other Diophantine equations had been com-pletely solved, but there was no single overarching method that dealt with all of them. This state of affairs prompted hilbert [VI.63](/part-06/david-hilbert-18621943) to include, as the tenth in his famous list of twenty-three unsolved problems, the question of whether there was a single, universal pro-cedure for solving all polynomial Diophantine equations in any number of variables.
Later, in 1928, he asked the more general question alluded to earlier: is there a universal procedure for determining the truth or falsity of any mathematical statement? This question became known as the means “decision problem” in German).entscheidungspr oblem (which to both questions would be yes. In other words, he Hilbert expected, or at least hoped, that the answers hoped that the mathematicians of his day were in the position of the child who has not yet learned how to solve simultaneous equations.
Perhaps a new age was dawning in which it would be possible, at least in principle, to solve all mathematical problems systematically and with out relying on native wit. strong: although problems of some kinds could be The evidence in favor of such a view was not very solved fully systematically, others, including Diophan-tine equations, stubbornly resisted, and the role of ingenuity in mathematical research appeared to be asimportant as ever. But if one wanted to give a negative answer to Hilbert’s questions, then one faced a major challenge:
in order to prove rigorously that there isno systematic procedure for accomplishing a particular task, one has to be absolutely clear about what a“systematic procedure” actually is. Nowadays there is an easy answer to this: a systematic procedure is anything that you can program a computer to do.
(Strictly speaking, this is an over simplification, because one also makes the idealizing assumption that the computer has unlimited storage space.) Our feeling that we do not have to think too hard to solve simultaneous equations is reflected in the fact that we can devise a computer program to do it for us (though if we want the program to be fast and numer-ically robust, we will face very interesting problems: see asked the questions before computers existed, so itnumerical analysis [IV.21 §4](/part-04/numerical-analysis)).
However, Hilbert was a remarkable achievement when in 1936 church [VI.89](/part-06/alonzo-church-19031995) and turing [VI.94](/part-06/alan-turing-19121954) independently managed to

707

formalize the notion of what we now call anrithm [IV.20 §1](/part-04/computational-complexity). That is, they each gave a precise def-algoinition of the notion of an algorithm. Their definitions were quite different, but later shown to be equivalent, which means that anything that can be done by an algorithm in Church’s sense can be done by an algorithmin Turing’s sense, and vice versa.
Turing’s formalization, which had a big influence on the design of modern computers, is discussed inity [IV.20 §1.1](/part-04/computational-complexity), while Church’s is described in computational complex-algorithms shall use the anachronistic definition with which this[II.4 §3.2](/part-02/algorithms), but for the purposes of this article we paragraph began. notion of “algorithm,” one is just a few short steps a way from a negative answer to Hilbert’s entscheidungspr ob-It turns out that once one has any sufficiently precise lem. To see this, imagine that language (such as Pascal or C++).
Given any string of L is some programming symbols, we can ask of it the following question: if Ipresent that string of symbols to my computer as a program inally stop? This is called the L, will the program run for ever, or will it eventu-halting problem. (Note that the word “problem” really means “class of problems.”) The halting problem may not seem very mathematical, but certain instances of it certainly are. For example, suppose that after a quick look at a program you realize that it does the following.
In one portion of the memory it stores an even numbern, which at the beginning is set to 6. It then checks for every odd numbern whether m and n - m are both prime. If the an swerm less than is yes for some the answer is no for allm, then it adds 2 tom, then it halts. This programn and repeats. If will halt if and only if the goldbach conjecture [V.27](/part-05/problems-and-results-in-vi36-peter-gustav-lejeune-dirichlet-18051859) is false. Turing proved that there is no systematic procedure for solving the halting problem analogous result for his notion of.
(Church proved anrecursive functions.) Let us see how Turing’s argument works for the language at ic procedure for recognizing which strings of sym-L. In this case, it shows that there is no system- bols form programs in The proof is a reductio ad absurdum, so we begin by L that halt, and which do not. assuming that there is such a procedure. Let us call it P . Suppose thata typical program asks for an L is like most computer languages, in that input, which affects its subsequent behavior.
Then any pair of strings(S, I), whether P will be able to tell, given S is a program in L that halts if the input is I. any string Now let us create a new procedure S, we start by getting Q to run Q out of P on the pair P . Given$708$(S, S)with itself as input, we then cause. If P judges that S does not halt when presented Q to halt. But if P judges that input, then we artificially send S does halt when presented with itself as Q into an end less loop, so that it does not halt.
(Ifthen let us say that$Q$halts—it does not really matter S is not a valid program in L, though.) To summarize, ifdoes not halt for S, and if SSdoes not halt for halts for input SS, then, then QQ does halt for S. But now let us suppose that S is the program for Q itself. Does with input SQ, sohalt with input Q does not halt. If it does not, then S? If it does, then S halts Sa contradiction, and therefore the procedure does not halt with input S, so Q does halt. This is P out of which Q was built could not have existed. That solves the general version of Hilbert’s problem:
there is no algorithm that will determine the truth or falsity of arbitrary mathematical statements. But it does so by constructing, for any given algorithm, a rather artificial statement. We do not yet have an answer to the question of what happens if we lookat more specific and more natural classes of statements, such as that a given Diophantine equation hasa solution. can often be shown to be Remarkably, however, specific questions of this kind equivalent to the general question, by a technique known as there is no algorithm that will take as its input a set encoding.
For example, of polygonal tiles (suitably represented) and tell you whether it is possible to tile the plane using copies of just those tiles. How do we know this? Well, given any algorithm, there is a clever way of devising a set of tiles(this is the encoding) that will tile the plane if and only if the algorithm fails to halt. Therefore, if there were analgorithm for determining whether the tiles could tile the plane, then there would be an algorithm for solving the halting problem—but there is not.
for which there is no algorithm is the Another famous example of a more specific problem word problem for groups relations for a group and asked whether the group is. Here you are given a set of generators and trivial—that is, whether it contains just the identity. Again, an algorithm that could decide this would give us an algorithm that could solve the halting problem, so there cannot be one. The encoding process used to prove this is much more difficult than it is for tiling the plane: the insolubility of the word problem for groups is a famous theorem proved by Pyotr Novikov in 1952.
For a much fuller explanation of this problem and its

V. Theorems and Problems

solution, see theory [IV.10](/part-04/geometric-and-combinatorial-group-theory).geometric and combinatorial group Finally, what about Hilbert’s tenth problem? This has become another famous and very hard theorem, due to Yuri Matiyasevitch in 1970, who built on work of Martin Davis, Hilary Putnam, and Julia Robinson. Matiya-sevitch managed to produce a system of ten equations, involving two paramete rsm and n, that could be solved in integers if and only if number.
From Robinson’s work it followed that, givenm was the 2 nth Fibonacci any algorithm with integer inputs, there was a sys-tem of Diophantine equations, involving a parameter qhalt ed at, that could be solved if and only if the algorithmq. That is, any instance of the halting problem can be encoded as a system of Diophantine equations, so there is no general algorithm for deciding whether Diophantine equations can be solved. Different people draw different morals from these results.
In the opinion of some mathematicians, they show that there will always be a place for human creativity in mathematics, however powerful the com-puters of the future might be. Others maintain that although we now know that we cannot systematically solve all problems in mathematics, the effect on most mathematics is very slight: one should be aware that certain kinds of problems are some times equivalent tothe halting problem, and that is it. Still others point out that it is often easy to devise an algorithm to solvea problem but much harder to make it efficient.
This issue is discussed in great detail in complexity [IV.20](/part-04/computational-complexity). computational ing problem is closely related to Turing’s argument for the insolubility of the halt-gödel’s theorem [V.15](/part-05/gdels-theorem), and both proofs useare discussed in countable and uncountable sets diagonal arguments, which [III.11](/part-03/countable-and-uncountable-sets). V.21 The Insolubility of the Quintic Martin W. Liebeck Every student will be familiar with the formula for the roots of a quadratic polynomialax2 + bx + c, namely(-b ± . qrt{b}2 - 4 ac)/2 a.
Perhaps less familiar is the fact that there is also a formula for the roots of a cubic: write the cubic asx3 + ax2 + bx + c, and make the sub st it ut io ny = x + 1 3 a to rewrite it in the form y3 + 3 hy + k. The roots of this are then of the form2 2 3 12$(-k + k2 + 4 h3) +3 1 2 (-k - k2 + 4 h3)$. V.21. The Insolubility of the Quintic While the quadratic formula was known to the Greeks, the cubic formula was not found until the sixteenth century.
In the same century a formula for the roots of quartic (degree 4) polynomials was also found. The formulas for quadratics, cubics, and quartics all arise by applying a sequence of arithmetic opera - tions (addition, subtraction, multiplication, division) together with extraction of roots (square roots, cube roots, and so on) to the coefficients of the original poly - nomial. Such a formula is called a radical expression for the roots. The next step, naturally enough, was the quintic (i.e., polynomial of degree 5).
However, several hundred years passed with out anyone finding a radical formula for the roots of a general quintic polynomial. such formula. Nor is there a formula for polyno-mials of degree greater than 5. This fact was first There was a good reason for this.
There is no established in the early nineteenth century by[VI.33](/part - 06/niels - henrik - abel - 18021829) (who died aged twenty - six), after which galois abel [VI.41](/part-06/variste-galois-18111832) (who died aged twenty-one) built an entirely new theory of equations that not only explained the nonexistence of formulas but laid the foundations for a whole edifice of algebra and number theory known as Galois theory, a major area of modern-day research. One of the key ideas of Galois was to associate with any polynomial$f = f (x) \text{a group}$[I.3
§2.1](/part-01/fundamental-definitions) Gal(f ) (the Galois group ofmutes the roots of$f$), which is a finite group that per-$f$. This group is defined in terms of certain can be thought of as subsets fields [I.3 §2.2](/part-01/fundamental-definitions), which for these purposes F of the complex num- bers any two elements of[I.3 §1.5](/part-01/fundamental-definitions) C having the property that if F , then all the numbers a, ab+areb, athat- bb, ab= , and0 in the last case to avoid dividing by 0).a/b also lie in F (where we assume The standard mathematical language for this property is to say
that operations of addition, subtraction, multiplication, and Fis “closed under” the usual arithmetic division. For example, the rationals does Q$(\sqrt{2}) = {a + b \sqrt{}}$2 : a, b \in QQform a field, as(this is clearly closed under addition, subtraction, and multiplication, and is also closed under division since 1/(a + b. qrt{2}) =a/(adegree2 -n2 with rational coefficients hasb2) - b. qrt{2}/(a2 - 2 b2)). A polynomialn complex rootsf (x) of bycall them the fundamental theorem of algebraα , . . . , α .
the splitting field offis defined[V.13](/part-05/the-fundamental-theorem-of-algebra)— to be the smallest field containing1 n Q and all the α , i

and is written asnomialx2 - 2 has roots Q(α1, . . . , α±. qrtn2, so its splitting field is). For example, the poly-709 Qα($, \sqrt{αω2})$, defined above. Less trivially,,$αω^{2}$, where α = 21^/3, the real cube root of 2, x3 - 2 has roots and consists of all complex numbersω = e2πi/3, so its splitting field isa +Qa(α, ω)α + a, whichα2 +ado not have to include4ω + a5αω + a6α2ω ωwith2 in such expressions sinceai \in 1 Q. (Notice that w(e2)3ωimplies that3 = 1, so (ωω2-= −1)(ωω2-+1.)ω + 1) = ω3 - 1 = 0, which$Let$ E = Q(α1, . . .
, αn)be the splitting field of our polynomialφ:$E \to E$ that preserves addition and multiplication—f . An automorphism of E is a bijection in other words,φ(a)φ(b) for allφ(aa, b+\in b)E=. Such a function necessarilyφ(a) + φ(b) and φ(ab) = also preserves subtraction and division, and fixes every rational number. Denote by Aut(E) the set of all auto- morphisms of$E$. For example$, when E = Q(\sqrt{2})$, any automorphismφ . qrt satisfies. qrt . qrt . qrt . qrt$2$= φ(2) = φ(. qrt{2} 2) =. qrt{φ}( 2)φ(. qrt{2}) = φ( 2)2, and thereforeφ(a + b. qrt{2}) =φ(a 2+)b=. qrt{2} for all2 or - a, b2.
In the first case\in  Q, while in the second are automorphisms of$φ(a + b \sqrt{2})E$; call them$= a - b \sqrt{2}$. Both of theseφ , φ , so that1 2 Aut The composition(E) = {φ1}, φ2. φ ◦ ψ of two automorphisms φ, ψ offunction E is again an automorphism, and so is the inverseφ-1, while the identity function ιdefined by ι(e) = e for all e \in  E is also an automorphism. Since composition of functions is an associative operation, it follows that Aut(E) is a group under composition. Define the with splitting field Galois group E to be this group Aut Gal(f ) of our polynomial(E).
Thus, forf (x) example, Galidentityι$, while(x^{2} φ- {}^{2}2)== {φφ\circ^{1}}$, φφ2}=. Notice thatφ , so this is just aφ1 is the cyclic group of order 2. Similarly, ifwith splitting field2 E =2 Q(α, ω)2 as above, then any1 f (x) = x3 - 2,φtherefore\in  Aut(E)φ(α)satisfies= α, αωφ(α)$, or^{3} =αωφ(α^{2}$; likewise3$) = φ(2φ(ω)) = 2$, and= ω orpletely determined (since$ω^{2}$. Once φ(α) and φ(ω)φ(aare specified,+a α +· · ·+aφαis com-2ω) =a possibilities for the automorphism1+a2φ(α)+· · ·+a6φ(α)2φ(ω)1 ), so there are just six2 φ.
It turns out that6 each of these is indeed an automorphism, and therefore Gal(x3 - 2) is a group of order 6. In fact, this group is isomorphic to thecan be seen by considering each automorphism as asymmetric group [III.68](/part - 03/permutation - groups) S3, as permutation of the three roots of Now that the Galois group is defined, it is poss ib lef (x). to state some of Galois’s fundamental results that leadto the insolubility of the quintic.
Each subgroup H of 710 G = Gal(f ) has afixed field H†, which is defined to be the set of all numbers a \in E such that φ(a) = a for all H andφ \in HH†.
Galois proved that the association between gives a one-to-one correspondence between subgroups of Gand fields which lie between Q and E (the so-called intermediate subfields of E). The con- dition that leads to certain special kinds of intermediate subfields, f (x) has a radical formula for its roots and hence to certain special subgroups oftually to Galois’s most famous theorem: the polyno-G, and even- mialonly if its Galois group Galf (x) has a radical formula for its roots if and(f ) is a soluble group.
(This means that1= G < G G<=· · ·Gal< G(f ) has a sequence of subgroups= G such that for each i, Gis agroupnormal subgroup0 G^+ /G^1 is Abelian.)[I.3 §3.3](/part-01/fundamental-definitions) ofr (Gi)+1 and the factori It follows from Galois’s theorem that to demonstrate(i1)i the insolubility of the quintic, it is enough to produce aquinticf (x) such that Gal(f ) is not a soluble group. An example of such a quintic is$f (x) = 2x^{5} - 5x^{4} +$5: one can show first that Gal(f ) is isomorphic to the symmet- ric group Here is a brief sketch of how the argument goes. First$S^{5}$;
and second that S5 is not a soluble group. one establishes that(i.e., is not the product of two rational polynomials off (x) is an irreducible polynomial smaller degree) with five distinct complex roots. Thus, as observed above, Gal(f ) can be regarded as a sub- group ofing the graph of S5 that permutes the five roots. By sketch-f (x) one can easily see that three of its roots are real and that the other two, call themandα , are complex conjugates of each other.
Sinceα1 the complex conjugation map automorphism in Gal2(f ), it follows that Galz \to  $\bar{z}$ always gives an(f ) is a subgroup of Another basic general fact is that the Galois group of an S5 that contains a 2 - cycle, namely (α1α2). irreducible polynomial permutes the roots meaning that for any two rootsα , α there exists an transitively, automorphism in Gal group Gal(f ) is a subgroup of(f ) that sends Sthat permutes the fivei αi jto αj. Thus, our roots transitively and contains a 2 - cycle.
At this point some fairly elementary group theory shows that Gal5(f ) must actually be the whole of S is not a soluble group follows easily from the fact S5. Finally, the fact that that the alternating group group (i.e., it has no normal subgroups apart from the5 A5 is a non - Abelian simple identity subgroup and$A5 itself)$. of any degree These ideas can be extended to produce polynomialsn ⩾ 5 that have Galois group Sn, and that are therefore not soluble by radicals. The reason V.
Theorems and Problems this cannot be done for quartics, cubics, and quadratics is that S and all its subgroups are soluble groups. V.22 Liouville’s Theorem and Roth’s Theorem One of the most famous theorems in mathematics is the statement that. qrt{2} is irrational. This means that there is no pair of integers equivalently that the equationp and q psuch that2 = 2 q2 has no integer. qrt{2} = p/q, or solutions apart from the trivial solutio np = q = 0.
The argument that proves this can be considerably generalized, and, in fact, if coefficients and leading coefficient 1, then all its roots P (x) is any polynomial with integer are either integers or irrational numbers. For example, sincex3 + x - 1 is negative when x = 0 and positive whenx = 1 it must have a root strictly between 0 and 1. This root is not an integer, so it must be irrational. may seem as though not much more can be said. How - ever, this is very far from true:
given an irrational num-Once one has proved that a number is irrational, it ber, one can ask fascinating and extremely difficult questions arise ashow close it is to being rational, and soon as one does so. means, since every irrational number can be approx-imated as closely as you like by rational numbers. It is not immediately obvious what this question For example, the decimal expansion of1.414213 . . ., which tells us that . qrt{2} is within 1. qrt{2} begins/100 000 of the rational number 141 421/100 000.
More gener - ally, for any positive integer integer such thatp/q < . qrt{2}, and thenq we can letp/qp be the largest will be within 1 to/q. qrt{of2} with accuracy 1. qrt{2}. In other words, if we want an approximation/q, we can obtain it if we use a denominator of However, we can now ask the following question: areq. there denominators accuracy much better than 1 q for which one can one obtain an/q? The answer turns out to be yes. To see this, let sider the numbers 0$,\sqrt{2N}$,2 be a positive integer and con-. qrt2, . . . , N . qrt{2}.
Each of these can be written in the formm+α, where m is an integer and there areα, the fractional part, lies between 0 and 1. Since N +1 numbers, at least two of their fractional parts must be within 1 can find integer sr < s between 0 and/N of each other. That is, we N such that if we write Thus, if we setr . qrt{2} = n+γα=andα-sβ. qrt, we have2 = m+β(s, then-r ). qrt|2α-=βn|-⩽m1/N+γ. and then|γ. qrt|2⩽=1/Np/q. If we now let+ γ/q, so |. qrt{q2}=-sp/q- r|and⩽ 1 p/q N= n. Since- m, N ⩾ q, 1/q N ⩽ 1/q2, so for at least some positive