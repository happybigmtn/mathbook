# Calabi–Yau Manifolds

III.6. Calabi–Yau Manifolds

III.6 Calabi–Yau Manifolds

Eric Zaslow

1 Basic Definition

Calabi–Yau manifolds, named after Eugenio Calabi and Shing-Tung Yau, arise in Riemannian geometry and algebraic geometry, and play a prominent role in string theory and mirror symmetry. to recall the notion of orientability on a realfold In order to explain what they are, we need first[I.3 §6.9](/part-01/fundamental-definitions). Such a manifold is orientable if youmanican choose coordinate systems at each point in sucha way that any two systemsx = (x1, . . . , xm) andygive rise to a positive Jacobian: det$= (y1$, . . . , ym)that are defined on overlapping sets(∂yi/∂xj) > 0. The notion of a Calabi–Yau manifold is the natural complex analogue of this. Now the manifold is complex, and for each local coordinate system$z = (z^{1}$, . . . , zn) one has avital that holomorphic functionf should be nonvanishing[I.3 §5.6](/part-01/fundamental-definitions): that is, it neverf (z). It is takes the value 0. There is also a compatibility condi-tion: i\bar{f}z(z) is another coordinate system, then the cor- responding function  ̃ f = f ̃$\det (\partial z$ ̃$a/\partial z^{b})$. Note that if we replace all complexf is related to f by the equation terms by real terms in this definition, then we have thenotion of a real orientation. So a Calabi–Yau manifold can be thought of informally as a complex manifold with complex orientation. 2 Complex Manifolds and Hermitian Structure Before we go any further, a few words about complex and Kähler geometry are in order. A complex manifoldis a structure that looks locally like Cn, in the sense that one can find complex coordinates$z = (z^{1}$, . . . , zn) near every point. Moreover, where two coordinate sys-tems$z$and  ̃zoverlap, the coordinates  ̃$z^{a} \text{are holomor}-$ phic when they are regarded as functions of the$z^{b}$. Thus, the notion of a holomorphic function on a com-plex manifold makes sense and does not depend on the coordinates used to express the function. In this way, the local geometry of a complex manifold does indeed look like an open set inpoint looks like Cn itself.Cn, and the tangent space at a Hermitian On complex vector spaces it is natural to consider inner products [III.37](/part-03/bayesian-analysis) represented by hermitian matrices$ea$. On complex manifolds, a Hermitian inner product[III.50 §3](/part-03/linear-operators-and-their-properties)(ga)b^ ̄ with respect to a basis on the tangent spaces is called a “Hermitian metric,”

163

and is represented in a coordinate basis by a hermitian matrixg , which depends on position.1 ab^ ̄

3 Holonomy, and Calabi–Yau Manifolds

in Riemannian Geometry

On avector along a path so as to keep it of constant length riemannian manifold [I.3 §6.10](/part-01/fundamental-definitions) one can move a and “always pointing in the same direction.”expresses the fact that the vector you wind up with at Curvature the end of the path depends on the path itself. Whenyour path is a closed loop, the vector at the starting point comes back to a new vector at the same point.(A good example to think about is a path on a sphere that goes from the North Pole to the equator, then aquarter of the way around the equator, then back to the North Pole again. When the journey is completed, the “constant” vector that began by pointing south will have been rotated by 90◦.) With each loop we asso- ciate a matrix operator called thewhich sends the starting vector to the ending vector; holonomy matrix, the group generated by all of these matrices is calledthe holonomy group of the manifold. Since the length of the vector does not change during the process ofkeeping it constant along the loop, the holonomy matrices all lie in the orthogonal group of length-preserving matrices, O(m). If the manifold is oriented, then the holonomy group must lie in SO(m), as one can see by transporting an oriented basis of vectors aroundthe loop. is also a real manifold of (real) dimension which one can think of as coordinatized by the real Every complex manifold of (complex) dimension$m = 2nn$, and imaginary parts of the complex coordinates$z^{j}$. Real manifolds that arise in this way have additional structure. For example, the fact that we can multiply complex coordinate directions by ithat there must be an operator on the real tangent$= \sqrt{-1} implies$ space that squares to±i, which can be thought of as “holomorphic” and-1. \text{This operator has eigenvalues} “anti-holomorphic” directions. The Hermitian property states that these directions are orthogonal, and we say that the manifold istransport around loops. This means that the holon-Kähler if they remain so after omy group is a subgroup of Usubgroup of SO(m): complex manifolds always have(n) (which itself is a realof the Kähler property: if orientations). \text{There is a nice local character izationg}^ ̄ \text{are the components ofa}b \text{Hermitian inner product}.1. \text{The notationga}^ ̄b \text{indicates the conjugate}-\text{linear property of a} 164 \text{the Hermitian metric in some coordinate patch}, \text{thenthere exists a function}φ \text{on that patch such that} g = ab^ ̄\partial2φ/\partial za\partia\bar{l} zb.

definition of a Calabi–Yau manifold given above—a Given a complex orientation—that is, the nonmetric compatible Kähler structure lies in SU(n) ⊂ U(n), the natural analogue of the caseleads to a holonomy that of real orientation. This is the metric definition of a Calabi–Yau manifold. 4 The Calabi Conjecture Calabi conjectured that, for any Kähler manifold of complex dimension there exists a functionn and any complex orientation, uand a new Kähler metric  ̃g, given in coordinates by g̃ a^ ̄b = ga^ ̄b + \partial z\partia(la)2\partial u\bar{z}b , \text{that is compatible with the orientation}. \text{In equations}, \text{the compatibility condition states that} \d\text{et ga}^ ̄b + \partial z\partia(la)2\partial u\bar{z}$b = |f |2$, \text{wherecussed above}. Thus, \text{the metric notion of a Calabi}–\text{Yauf is the holomorphic orientation function dis}- \text{manifold amounts to a formidable nonlinear partial dif}-\text{ferential equation foru}. \text{Calabi proved the uniqueness and Yau proved the existence of a solution to this equation}. \text{So in fact the metric definition of a Calabi}–\text{Yau manifold is uniquely determined by its} Kä\text{hler structure and its complex orientation}. Yau’s \text{theorem establishes that the space of metrics with holonomy group SUplex orientation is in} \text{correspondence} \text{with the space}(n) \text{on a manifold with com}- \text{of in equivalent} Kä\text{hler structures}. \text{The latter space can easily be probed with the techniques of algebraic geometry}. 5 Calabi–\text{Yau Manifolds in Physics Einstein}’s \text{theory of gravity}, \text{general relativity}, con-\text{structs equations that the metric of a Riemannian space}-\text{time manifold must obey} (\text{see general relativity equations involve three symmetric tensors}: \text{the metric}, \text{and the einstein equations} [IV.13](/part - 04/general - relativity - and - the - einstein - equations)). \text{The the ricci curvature} [III.78](/part - 03/ricci - flow) tensor, \text{and the} \text{energymomentum} \text{tensor of matter}. A \text{Riemannian manifold whose Ricci tensor vanishes is a solution to these equations when there is no matter}, \text{and is a special caseof an Einstein manifold}. A Calabi–\text{Yau manifold with III}. \text{Mathematical Concepts its unique SUtensor}, \text{and is therefore of interest in general relativity}.(n)-\text{holonomy metric has vanishing Ricci} A \text{fundamental problem in theoretical physics is the in corporation of Einstein}’s \text{theory into the quantum theory of particles}. \text{This enterprise is known as quantum gravity nent ly in the leading theory of quantum gravity},, \text{and Calabi}–\text{Yau manifolds figure promi}-\text{string theory} [IV.17 §2](/part - 04/vertex - operator - algebras). dimensional “strings.” \text{The motion of the strings inspace}-\text{time is described by two}-\text{dimensional trajecto}-\text{In string theory}, \text{the fundamental objects are oneries}, \text{known assheet is labeled by the point in space}-\text{time where it sits}.worldsheets, \text{so every point on the world In this way}, \text{string theory is constructed from a quan}-\text{tum field theory of maps from two}-\text{dimensional riemann surfaces The two}-\text{dimensional surface should be given a Rie}-[III.79](/part - 03/riemann - surfaces) \text{to a space}-\text{time manifold} M . \text{mannian metric}, \text{and there is an infinite}-\text{dimensional space of such metrics to consider}. \text{This means thatwe must solve quantum gravity in two dimensions}— \text{a problem that}, \text{like its four}-\text{dimensional cousin}, \text{is toohard}. If, however, \text{it happens that the two}-\text{dimensional worldsheet theory is conformal} (\text{invariant under local changes of scale}), \text{then just a finite}-\text{dimensional spaceof conformally in equivalent metrics remains}, \text{and the theory is well} - defined.\text{The Calabi}–\text{Yau condition arises from these} \text{considerations}. \text{The requirement that the two}-\text{dimensional theory should be conformal}, \text{so that the string theory makes good sense}, \text{is in essence the requirement that the Ricci tensor of space}-\text{time should vanish}. Thus, atwo-\text{dimensional condition leads to a space}-\text{time equation}, \text{which turns out to be exactly Einstein}’s \text{equation without matter}. \text{We add to this condition the} “phe-\text{no meno logical}” \text{criterion that the theory be endowed with} “supersymmetry,” \text{which requires the space}-\text{time manifold} M \text{to be complex}. \text{The two conditions together mean that} M \text{is a complex manifold with holonomy group SUtheorem}, \text{the choices of such}(n): \text{that is}, \text{a Calabi}–\text{Yau manifold}. \text{By Yau}’s M \text{can easily be described by algebraic geometric methods}.\text{We remark that there is a kind of distillation of string theory called} “\text{topological strings},” \text{which can be given a rigorous mathematical framework}. Calabi–\text{Yau mani}-\text{folds are both symplectic and complex}, \text{and this leads to two versions of topological strings}, called A and B, \text{that one can associate with a Calabi}–\text{Yau manifold}. \text{Mirror symmetry is the remarkable phenomenon that the} A \text{version of one Calabi}–\text{Yau manifold is related to the} B \text{version of an entirely different} “\text{mirror partner}.” \text{The III}.8. \text{Categories mathematical consequences of such an equivalence are extremely rich}. (\text{See mirror symmetry} [IV.16](/part - 04/mirror - symmetry) \text{for more details}. \text{For other notions related to those discussed in this article}, \text{see symplectic manifolds} [III.88](/part - 03/symplectic - manifolds).) \text{The Calculus of Variations See Variational Methods} [III.94](/part - 03/variational - methods) III.7 \text{Cardinals The cardinality of a set is a measure of how large thatset is}. \text{More precisely}, \text{two sets are said to have the same cardinality if there is a bijection between them}. \text{So whatdo cardinalities look like}? \text{nalities of finite sets}: \text{a set has} “\text{cardinality There are finite cardinalities}, \text{meaning the cardi} - n” \text{if it has precisely}[III.11](/part - 03/countable - and - uncountable - sets) \text{infinite sets}: \text{these all have the same cardinal} - n elements. \text{Then there are countable ity} (\text{this follows from the definition of} “countable”), usually writtenא . For example, the natural numbers, the integers, and the rationals all have cardinality However, the reals are uncountable, and so do not0א0.$\text{have cardinality by} 2$א . א0. In fact, their cardinality is denoted It turns out that cardinals can be added and multiplied and even raised to powers of other cardinals (so“2א0” is not an isolated piece of notation). For details, and more explanation, see set theory [IV.22 §2](/part-04/set-theory). III.8 Categories

Eugenia Cheng

When we study[I.3 §2.3](/part-01/fundamental-definitions), we pay particular attention to certain classes groups [I.3 §2.1](/part-01/fundamental-definitions) or vector spaces of maps between them: the important maps between groups are the group homomorphisms [I.3 §4.1](/part-01/fundamental-definitions), and the important maps between vector spaces are theear maps [I.3 §4.2](/part-01/fundamental-definitions). \text{What makes these maps important linis that they are the functions that} “\text{preserve structure}”: \text{for example}, ifφ \text{is a homomorphism from a group} G \text{to a group sense that} Hφ(g, \text{then it} “preserves \text{multiplication},” \text{in theg} ) = φ(g )φ(g ) \text{for any pair of ele} - mentsg1 and (g1()2)2 of G. Similarly, \text{linear maps preserv}(e1)2 \text{addition and scalar} \text{multiplication}.\text{The notion of a structure}-\text{preserving map applies far more generally than just to these two examples}, \text{andone of the purposes of category theory is to understand the general properties of such maps}. \text{For instance}, if B, and C \text{are mathematical structures of some given} A, 165 type, and A to B \text{and fromf and Bgtoare structure}-\text{preserving maps from} C, respectively, \text{then their compos}- ite g◦f is a structure-preserving map from A to C. That is, structure-preserving maps can beif the range of one equals the domain of the other). Wecomposed (at least also use structure-preserving maps to decide when to regard two structures as “essentially the same”: we call A and B isomorphic if there is a structure-preserving map from structure.A to B with an inverse that also preserves one to discuss properties such as these in the abstract.A category is a mathematical structure that allows It consists of a collection ofphisms between those objects. That is, ifobjects, together witha and bmor-are two objects in the category, then there is a collection of morphisms between composition of morphisms: ifa and b. There is also a notion off is a morphism from a to com posi teb and gofis a morphism fromf and g, which is a morphism fromb to c, then there is aa to c. This composition must be associative. In addition, foreach object$a$ there is an “identity morphism,” which has the property that if you compose it with another morphismf then you get f . a category is the category of groups. The objects of As the earlier discussion suggests, an example of this category are groups, the morphisms are group homomorphisms, and composition and the identity are defined in the way we are used to. However, it is by no means the case that all categories are like this, as the following examples show. (i) We can form a category by taking the natural num-bers as its objects, and letting the morphisms from n to m be all the n \times  m matrices with real entries. Composition of morphisms is the usual matrix multiplication. We would not normally think of ann \times  m matrix as a map from the number n to the number nevertheless satisfied.m, but the axioms for a category are (ii) Any set can be turned into a category: the objects are the elements of the set, and a morphism from x to yis the assertion “ x = y.” We can also make an ordered set into a category by letting a mor-phism fromx to ybe the assertion “x ⩽ y.” (The “composite” of “x ⩽ y” and “y ⩽ z” is “x ⩽ z.”) (iii) Any grouplows: you have just one object, and the morphisms G can be made into a category as fol- from that object to itself are the elements of the group, with the group multiplication defining the composition of two morphisms.

166

(iv) There is an obvious category where the objects are topological spaces [III.90](/part-03/topological-spaces) and the morphisms are continuous functions. A less obvious category with the same objects takes as its morphisms not continuous functions but homotopy classes [IV.6 §2](/part-04/algebraic-topology) of continuous functions. Morphisms are also called maps. However, as the above examples illustrate, the maps in a category donot have to be remotely map-like. They are also called arrows, partly to emphasize the more abstract nature of a general category, and partly because arrows areoften used to represent morphisms pictorially. morphisms” enable us to seek and study structural fea-The general framework and language of “objects and tures that depend only on the “shape” of the category, that is, on its morphisms and the equations they satisfy. The idea is both to make general arguments that are then applicable to all categories possessing partic-ular structural features, and also to be able to make arguments in specific environments without having to go into the details of the structures in question. The useof the former to achieve the latter is sometimes referred to, endearingly or otherwise, as “abstract nonsense.” As we mentioned above, the morphisms in a category are generally depicted as arrows, so a morphism

ffis depicted by concatenating the arrows from a to b is depicted as a −→- b and composition a −→-f b −→-g c. This notation greatly eases complex calculations and gives rise to the so-calledare often associated with category theory; an equality commutative diagrams that between composites of morphisms such as$g ◦f = t ◦s$ is expressed by asserting that the following diagram commutes, that is, that either of the two different paths froma to cyields the same composite:

$a^{f} // bs^{g}$

//

d ct

Proving that one long string of compositions equals another then becomes a matter of “filling in” the space inbetween with smaller diagrams that are already known to commute. Further more, many important mathematical concepts can be described in terms of commutative diagrams: some examples are free groups, free rings, free algebras, quotients, products, disjoint unions, function spaces, direct and inverse limits, completion, compact if ic at i on, and geometric realization.

III. Mathematical Concepts

unions. We say that aset Let us see how it is done in the case of disjoint U equipped with morphisms disjoint union Aof sets−→-p U and A and B B−→qis a U such that, given any setand B −→-g X, there is a unique morphism X and morphisms U -−→h AX−→-fthat X makes the following diagram commute: ;; XOO ccf??$U^{h}$__???$g$

~

~$p$~~~~ ???$q$?

$A$~$B$

Herejoint union. The “such that” part of the definition abovep and q tell us how A and B inject into the dis- is aing a function from the disjoint union to another set universal property. It expresses the fact that givis precisely the same as giving a function from eachof the individual sets; this completely characterizes a disjoint union (which we regard as defined up to isomorphism). Another viewpoint is that the universal property expresses the fact that a disjoint unionis the “most free” way of having two sets map into another set, neither adding any information nor col-lapsing any information. Universal properties are central to the way category theory describes structures that are somehow “canonical.” (See also the discus-sion of free groups in geometric and combinatorial group theory Another key concept in a category is that of an[IV.10](/part-04/geometric-and-combinatorial-group-theory).) isomorphism morphism with a two-sided inverse. Isomorphic objects. As one might expect, this is defined to be a in a given category are thought of as “the same, as far asthis particular category is concerned.” Thus, categories provide a framework in which the most natural way of classifying objects is “up to isomorphism.” kind, and as such they themselves form a category Categories are mathematical structures of a certain (subject to size restrictions so as to avoid a Russell-type paradox). The morphisms, which are the structure preserving maps for categories, are called other words, a functor F from a category Xfunctorsto a cate-. In gory Y takes the objects of X to the objects of Y and the morphisms ofa way that the identity of X to the morphisms ofa is taken to the identity Y in such ofcomposite of Fa and the composite of Ff and Fg. An important example of af and g is taken to the functor is the one that takes a topological spacea “marked point”s to its fundamental group π1 S(S, s)with:

III.9. Compactness and Compact if ic at i on

it is one of the basic theorems of algebraic topology that a continuous map between two topological spaces (that takes marked point to marked point) gives rise to a homomorphism between their fundamental groups.Further more, there is a notion of morphism between functors called aogous to the notion of homotopy between maps ofnatural transformation, which is anal topological spaces. Given continuous maps F, G: X \to YX, a homotopy from, a path in Y from Fx F toto GGxgives us, for every point; analogously, given func-x in tors F, G: X −→ Y , a natural transformation from F to GFxgives us, for every pointto Gx. There is also a commuting condition that isx in X, a morphism in Y from analogous to the fact that, in the case of homotopy, apath in X must have its image under F continuously transformed to its image underany “holes” in the space Y. This avoidance of holes is G without passing over expressed in the category case by the commutativity of certain squares in the target categoryas the “naturality condition.”Y , which is known the fact that every vector space isphic to its double dual; there is a functor from the One example of a natural transformation encodes canonically is om or category of vector spaces to itself that takes each vec-tor space to its double dual, and there is an invertible natural transformation from this functor to the iden-tity functor via the canonical isomorphisms. By contrast, every finite-dimensional vector space is isomorphic to its dual, but not canonically so because the isomorphism involves an arbitrary choice of basis; if we attempt to construct a natural transformation inthis case, we find that the naturality condition fails. In the presence of natural transformations, categories actually form a 2 generalization of a category, with objects, morphisms,-category, which is a two-dimensional and morphisms between morphisms. These last are thought of as two-dimensional morphisms; more generally ann-category has morphisms for each dimension up to Categories and the language of categories are usedn. in a wide variety of other branches of mathematics.Historically, the subject is closely associated with algebraic topology; the notions were first introduced in 1945 by Eilenberg and Mac Lane. Applications followedin algebraic geometry, theoretical computer science, theoretical physics, and logic. Category theory, with its abstract nature and lack of dependency on other fields of mathematics, can be thought of as “foundational.” In fact, it has been proposed as an alternative candidate for the foundations of mathematics, with the notion of

167

morphism as the basic one from which everything elseis built up, instead of the relation of set membership that is used in set-theoretic foundations [IV.22 §4](/part-04/set-theory). \text{Class Field Theory See from quadratic reciprocity to class field theory} [V.28](/part - 05/from - quadratic - reciprocity - to - vi38 - augustus - de - morgan - 18061871) \text{Cohomology See homology and cohomology} [III.38](/part - 03/homology - and - cohomology) III.9 \text{Compactness and Compact if ic at i on Terence Tao In mathematics}, \text{it is well}-\text{known that the behavior offinite sets and the behavior of infinite sets can be rather different}. \text{For instance}, \text{each of the following statements is easily seen to be true whenever Xis a finite set but false whenever Xis an infinite set}. \text{All functions are bounded}. If f:$X \to R \text{is a real}-$ valued function onthere exists a finite number X, then f Mmust be bounded (i.e., such that |f (x)| ⩽ M All functions attain a maximum.for all$x \in X)$. If f: X \to R \text{is a real}- valued function onone pointx \in  X Xsuch that, then there must exist at leastf (x ) ⩾ f (x) for all 0 0

$x \in X$.

All sequences have constant subsequences.x ,· · · ∈ X is a sequence of points in X, then there If x1$, x2$, must exist a subsequence constant. \text{In other words},3$x (xn)1=$, x(xn)2, x= · · · =n 3, . . . that isc for some infinite pigeonhole princi plec \in  X. (This fact is sometimes known as the.()n()1()n)2 are bounded—can be viewed as a very simple exam-ple of a The first statement—that all functions on a finite setlocal-to-global principle. The hypothesis is an assertion of “local” boundedness: it asserts that|f (x)| is bounded for each pointx \in X separately, \text{but with} a bound that may depend onof “global” boundedness: thatx|. The conclusion is thatf (x)| is bounded by a single bound$M \text{for all} x \in X$. However, in many areas of mathematics we like toendow our objects with additional structures, such as a So far we have viewed the object X only as a set. topology ture [I.3 §2.1](/part-01/fundamental-definitions). When we do this, it turns out that some[III.90](/part-03/topological-spaces), a metric [III.56](/part-03/metric-spaces), or a group struc-

168

objects exhibit properties similar to those of finite sets (in particular, they enjoy local-to-global principles), \text{even though as sets they are infinite}. \text{In the categories of topological spaces and metric spaces}, these “almostfinite” \text{objects are known asegories have} “almost - finite” \text{objects as well}. \text{For exam}-\text{compact spaces}. (\text{Other catple}, \text{in the category of groups there is a notion of apro}-\text{finite group}; \text{for linear operators} [III.50](/part - 03/linear - operators - and - their - properties) \text{between normed spaces} [III.62](/part - 03/normed - spaces - and - banach - spaces) \text{the analogous notion is that of aand so forth}.)\text{compact operator}, \text{which is} “\text{almost of finite rank}”; interval A \text{good example of a compact set is the closed unit} X = [0,1]. \text{This is an infinite set}, \text{so the previous three assertions are all false as stated forwe modify them by inserting topological concepts such} X. \text{But if as continuity and convergence}, \text{then we can restore these assertions for}[0$,1] \text{as follows}$. All continuous functions are bounded. If$f$:$X \to R is$ a real-valued continuous function on X, then f must be bounded. (This is again a type of local-to-global principle: if a function does not vary too much locally, then it does not vary too much globally.) All continuous functions attain a maximum.X \to  R is a real-valued continuous function on If f X:, then there must exist at least one pointthatf (x ) ⩾ f (x) for all x \in  X. x0 \in  X such All sequences have convergent subsequences.$x$, x , x0, · · · ∈ X is a sequence of points in X, then If there must exist a subsequence converges to some limit1 2 3 c \in  Xx. (This statement i(sn)1 , (xn)2, (xn)3, . . . that known as the Bolzano–Weierstrass theorem.) To these assertions we can add a fourth (which, like the others, has a rather trivial analogue for finite sets). All open covers have finite subcovers. If V is a col- lection of open sets and the union of all these opensets contains X (in which case V is called an open cover le ct i on of V X, V), then there must exist a finite subcol-, . . . , V of sets in V that still covers(n1()n()2()n)k X .

All four of these topological statements are false for sets such as the open unit interval line R, as one can easily check by constructing simple(0, 1) \text{or the real} counterexamples. Thewhen X is a subset of a Euclidean space Heine–Borel theorem Rnasserts that, the above statements are all true when X is topologically closed and bounded, and all false otherwise.

III. Mathematical Concepts

other. For instance, if you know that all sequencesin The above four assertions are closely related to each X contain convergent subsequences, then you can quickly deduce that all continuous functions have amaximum. This is done by first constructing a maximizing sequencef (x ) approaches the maximal value of—a sequence of pointsxnfin(or, more pre-X such that cisely, its supremum)—and then investigating a conver-$n$ gent subsequence of that sequence. In fact, given some fairly mild assumptions on the space X (e.g., that X is a metric space), one can deduce any of these four statements from any of the others. spacefour assertions holds for To oversimplify a little, we say that a topological X is compact if one (and hence all) of the above X. Because the four assertions are not quite equivalent in general, the formal defini-tion of compactness uses only the fourth version: that every open cover has a finite subcover. There are other notions of compactness, such asness, for example, which is based on the third version, sequential compact but the distinctions between these notions are technical and we shall gloss over them here. is used in many ways in many different areas of math-ematics. One is via appeal to local-to-global principles: Compactness is a powerful property of spaces, and it one establishes local control on a function, or on someother quantity, and then uses compactness to boost the local control to global control. Another is to locate maxima or minima of a function, which is particularly useful in the calculus of variations [III.94](/part-03/variational-methods). A third is to partially recover the notion of a limit when deal-ing with nonconvergent sequences, by accepting the need to pass to a subsequence of the original sequence. (However, different subsequences may converge to dif-ferent limits; compactness guarantees the existence of a limit point, but not its uniqueness.) Compactness ofone object also tends to beget compactness of other objects; for instance, the image of a compact set under a continuous map is still compact, and the productof finitely many or even infinitely many compact sets continues to be compact. This last result is known as Tychonoff’s theorem. An obvious example is the real linepact, because it contains sequences such as 1 Of course, many spaces of interest are not compact.R, which is not com-,2,3, . . . that are “trying to escape” the real line and that do notleave behind any convergent subsequences. However, one can often recover compactness by adding a fewmore points to the space: this process is known as compact if ic at i on. For instance, one can compactify the real

III.10. Computational Complexity Classes

line by adding one point at each end: we call the added points+$\i\text{nfty and} −$\infty. The resulting object, known as the extended real line[−$\i\text{nf ty}$, +$\i\text{nf ty}$], \text{can be given a topology} in a natural way, which basically defines what it meansto converge to$+$\infty or to −$\i\text{nf ty}$. The extended real line is compact: any sequence will have a subsequence that either converges toxn of extended real numbers+$\i\text{nf ty}$, or converges to−\infty, or converges to a finite number. Thus, by using this compact if ic at i on of the real line, we can generalize the notion of a limit to one that no longerhas to be a real number. While there are some drawbacks to dealing with extended reals instead of ordi-nary reals (for instance, one can always add two real numbers together, but the sum of$+$\infty and −$\i\text{nf ty}$ is unde- fined), the ability to take limits of what would otherwise be divergent sequences can be very useful, par-ticularly in the theory of infinite series and improper integrals. many different compactificatio ns. For instance, by the It turns out that a single noncompact space can have device ofcally identify the real line with a circle that has a sin-stereographic projection, one can topologigle point removed. (For example, if one maps the real number$x \text{to the point} (x/(1 + x^{2})$, x^2/(1 + x^2)), then R \text{maps to the circle of radius} 12 \text{and center}(0,1 2), with the north pole missing point, we obtain the(0,1) removed.) If we then insert theone-point compact if ic at i on R∪ {}\infty of the real line. More generally, any reason- able topological space (e.g., a locally compact Hausdorff space) has a number of compactificatio ns, rang-ing from the one-point compact if ic at i on X ∪{}\infty, which is the “minimal” compact if ic at i on as it adds only onepoint, to the Stone– ˇCech compactificationβX, which is the “maximal” compact if ic at i on and adds an enormous number of points. The Stone–ˇCech compactificationβN of the natural numbers N is the space of ultrafilters, which are very useful tools in the more infinitary parts of mathematics. tween different types of divergence in a space. For instance, the extended real line One can use compactificatio ns to distinguish be-[−\infty,+\infty] distinguishes$\text{between divergence to}+$\infty$\text{and divergence to} −$\infty. \text{In a} \text{similar spirit}, \text{by using} \text{compactificatio} \text{ns of the plane} R2 \text{such as the} [I.3 §6.7](/part - 01/fundamental - definitions), \text{one can distinguish a sequence that diverges along} (\text{or near}) thex-\text{axis from a sequence that diverges along} (\text{or near}) \text{the projective planeytions in which sequences that diverge in different ways} - axis. Such \text{compactificatio} \text{ns arise naturally in sit ua exhibit markedly different behavior}. 169 \text{view one type of mathematical object rigorously as alimit of others}. \text{For instance}, \text{one can view a straight Another use of} \text{compactificatio} \text{ns is to allow one to line in the plane as the limit of increasingly large circles by describing a suitable compact if ic at i on of the spaceof circles that includes lines}. \text{This perspective allows us to deduce certain theorems about lines from analo}-\text{gous theorems about circles}, \text{and conversely to deduce certain theorems about very large circles from theo}-\text{rems about lines}. \text{In a rather different area of mathematics}, \text{the Dirac delta function is not}, \text{strictly speaking}, \text{a function}, \text{but it exists in certain} (local) \text{compactificatio} \text{ns of spaces of functions}, \text{such as spaces ofsures} [III.55](/part - 03/measures) \text{or distributions} [III.18](/part - 03/distributions). Thus, one canmeaview the Dirac delta function as a limit of classical func-tions, and this can be very useful for manipulating it. One can also use compactificatio ns to view the continu-ous as the limit of the discrete: for instance, it is possible to compactify the sequence Z/2 Z, Z/3 Z, Z/4 Z, . . . of cyclic groups in such a way that their limit is the circle group T= R/Z. These simple examples can be general- ized to much more sophisticated examples of compact-ifications, which have many applications in geometry, analysis, and algebra. III.10 Computational Complexity

Classes

One of the basic challenges of theoretical computer sci-ence is to determine what computational resources are necessary in order to perform a given computational task. The most basic resource is time, or equivalently (given the hardware) the number of steps needed toimplement the most efficient algorithm that will carry out the task. Especially important is how this time scales up with the size of the input for the task: for instance, how much longer does it take to factorize an integer with 2 Another resource connected with the feasibility of an digits than an integer with ndigits? computation isage space a computer will need in order to implement memory: one can ask how much storan algorithm, and how this can be minimized. Aplexity class is a set of computational problems that cancombe performed with certain restrictions on the resources allowed. For instance, the complexity class P consists of all problems that can be performed in “polynomialtime”: that is, there is some positive integerk such that if the size of the problem issize was the number of digits of the integer to be fac-n (in the example above, the torized), then the computation can be carried out in at

170

mostnk steps. A problem belongs to P if and only if the time taken to solve it scales up by at most a constant factor when the size of the input scales up by a con-stant factor. A good example of such a problem is multiplication of two n-digit numbers: if you use ordinary long multiplication, then replacing the time taken by a factor of 4. n by 2 n increases ger Suppose that you are presented with a positive inte-x and told that it is a product of two primes p andqknows, but one thing is easy to see: if you are told. How difficult is it to determinep and q? Nobody$p$ andq, then it is not hard (for a computer, at any rate) to check thathave just seen, long multiplication takes polynomial pq really does equal x. Indeed, as we time, and comparing the answer withier. The complexity class NP consists of those compu-x is even eas- tational tasks for which a correct answer can beified in polynomial time, even if it cannot necessar-verily be found in polynomial time. Remarkably, although this is a fundamental distinction, nobody knows howto prove that$P = NP$: this problem is widely considered to be the most important in theoretical computer science. classes.solved using an amount of memory that grows at most We briefly mention two other important complexity PSPACE consists of all problems that can be polynomially with the size of the input. It turns out tobe the natural class associated with reasonable computational strategies for games such as chess. The com-plexity class NC is the set of all Boolean functions that can be computed by a “circuit of polynomial size anddepth at most a polynomial in log$n$.” This last class is a model for the class of problems that can be solved very rapidly using parallel processing. In general, complexity classes are often surprisingly good at character-izing large families of problems with interesting and intuitively recognizable features in common. another remarkable fact is that almost all complexity classes have “hardest problems” within them: that is, problems for which a solution can be converted into a solution forany other problem in the class. These problems are said to be complete for the class in question. These issues, as well as several other complexity classes, are discussed in[IV.20](/part-04/computational-complexity). A vast number of further classes can be found computational complexity at http://qwiki.stanford.edu/wiki/Complexity_Zoo along with a brief definition of each.

III. Mathematical Concepts

Continued Fractions

See the euclidean algorithm and

continued fractions [III.22]

III.11 Countable and Uncountable Sets

Infinite sets arise all the time in mathematics: the natu-ral numbers, the squares, the primes, the integers, the rationals, the reals, and so on. It is often natural to try to compare the sizes of these sets: intuitively, one feelsthat the set of natural numbers is “smaller” than the set of integers (as it contains just the positive ones), and much larger than the set of squares (since a typical large integer is unlikely to be a square). But can wemake comparisons of size in a precise way? ition about finite sets. Ifare two ways we might go about comparing their sizes.An obvious method of attack is to build on our intu-A and Bare finite sets, there One is to count their elements: we obtain two nonnega-tive integersm and n and just look at whether m < n, m = n, or m > n. But there is another important method, which does not require us to know the sizes ofeither A or B. This is to pair off elements from A with elements ofof elements: the first one to run out is the smaller set, B until one or other of the sets runs out and if there is a dead heat, then the sets have the samesize. for infinite sets as well: we can declare two sets tobe of equal size if there is a one-to-one correspon-A suitable modification of this second method works dence between them. This turns out to be an important and useful definition, though it does have some consequences that seem a little odd at first. For example, there is an obvious one-to-one correspondence between natural numbers and perfect squares: for each n \text{correspond to} n2. Thus, \text{according to this definitionn we let there are} “\text{as many}” \text{squares as there are natural num} - bers. Similarly, \text{we could show that there are as many primes as natural numbers by associating nth prime number}.1 n \text{with the large}” \text{asspondence between them}. \text{We just list the integers in What about} N, \text{but again we can find a one} - to-\text{one corre} - Z? \text{It seems that it should be} “\text{twice as the order} 0,1,-1, 2, -2, 3, -3, . . . \text{and then match the} sity” \text{that can be useful too}. \text{According to this definition}, \text{the even num}-\text{bers have density}1. \text{For sufficiently nice sets of integers there is a definition of} “den - 1 , \text{while the squares and the primes have density} 0, \text{as one might expect}. However, \text{this is not the notion of size under discussion here}. III.11. \text{Countable and Uncountable Sets natural numbers with them in the obvious way}: 1 with0, then 2 with 1, then 3 with - 1, then 4 with 2, then 5 with$-2$, \text{and so on}. size as the natural numbers. As the above example shows, this is exactly the same as saying that we can An infinite set is called countable if it has the same lista set asthe elements of the set. Indeed, if we have listeda , a , a , . . . , then our correspondence is just to send course many attempted listings that fail: for example,$n^{1} to^{2}(a^{n})^{3}$. It is worth noting that there are of for Z we might have tried-3, -2, -1,0,1,2,3,4, . . . . \text{So it is important to recognize that when we say that aset is countable we are not saying that every attempt to list it works}, \text{or even that the obvious attempt does}: \text{we are merely saying that there is some way of listing the elements}. \text{This is in complete contrast to finite sets}, \text{where if we attempt to match up two sets and find some elements of one set left over}, \text{then we know that the two sets cannot be in one} - to - one \text{correspondence}. \text{It isthis difference that is mainly responsible for the} “\text{odd consequences}” \text{mentioned above}.\text{Now that we have established that some sets that seem smaller or larger than} N, \text{such as the squares or the integers}, \text{are actually countable}, \text{let us turn toa set that seems} “\text{much larger},” namely Q. \text{How could we hope to list all the rationals}? \text{After all}, \text{between anytwo of them you can find infinitely many others}, \text{so it seems hard not to leave some of them out when you try to list them}. However, \text{remarkable as it may seem}, \text{it is possible to list the rationals}. \text{The key idea is that listing the rationals whose numerator and denominator are both smaller} (\text{in modulus}) \text{than some fixed number kis easy}, \text{as there are only finitely many of them}. \text{So we go through in order}: \text{first when both numerator and denominator are at most} 1, \text{then when they are at most} 2, \text{and so on} (\text{being careful not to relist any number}, \text{sothat for example} 1 \text{should not also appear as} 2 or 3). This leads to an ordering such as 03, -3,1, -1,2 ,-2 2,3 ,-3,4$,-4, . . . .,1,-1,2,-2^{4}$,1 2,-6 1 2, larger, such as, for example, thereal numbers, such as We could use the same idea to list sets that look even3 3 3 3 2 2$\sqrt{2}$, that satisfy a polynomial algebraic numbers (all equation with integer coefficients). Indeed, we note that each polynomial has only finitely many roots (which are therefore listable), so all we need to do is list the polynomials (as then we can go through them, in order, listing their roots). And we can do that by applying the same technique again: for eachd we list those polynomials of degree at most coefficients that are at mostd that we have not already listed, withd in modulus.

171

that Based on the above examples, one might well guess every infinite set is countable. But a beautiful argument ofment, shows that the real numbers are not countable.cantor [VI.54](/part-06/georg-cantor-18451918), called his “diagonal” argu We imagine that we have a list of all real numbers, sayr , r , r , . . . . Our aim is to show that this list cannot possibly contain all the reals, so we wish to construct areal that is not on this list. How do we accomplish this?1 2 3 We have eachnow we define a new number ri written as an infinite decimal, say, andsas follows. For the first digit ofis not the first digit ofs (after the decimal point), \text{we choose a digit thatr} . \text{Note that this already guaran}- \text{tees that recurring} 9 s \text{and the like}, \text{it is best to choose this firsts cannot equal}1 r1. (\text{To avoid coincidences with digit ofdigit ofss}, \text{we choose a digit that is not the second digitnot to be} 0 or 9 either.) Then, \text{for the second oftinuing in this way}, \text{we end up with a real number} r2; this guarantees thats \text{cannot be equal to} r2. Con-s that is not on our list: whatevern is, the number s cannot ber^n, as s and r^ndiffer in thenth decimal place! “an infinite number of independent choices” to make One can use similar arguments any time that we have in specifying an object (like the various digits ofexample, let us use the same ideas to show that thes). For set of all subsets of N is uncountable. Suppose we have listed all the subsets as$A^{1}$, A2$, A3$, . . .. We will define a new set include the point 1 in B that is not equal to any of the B if and only if 1 does not belong An. So we$\text{towe include} 2 in$ A1 (this guarantees that B if and only if 2 does not belong to B is not equal to A1), and A , and so on. It is amusing to note that one can write thisset$B \text{down as} {n \in N}$:$n \in A$, which shows a striking2 resemblance to the set in Russell’s paradox.$n$ Countable sets are the “smallest” infinite sets. However, the set of real numbers is by no means the“largest” infinite set. Indeed, the above argument shows that no setdence with the set of all its subsets. So the set of all X can be put into one-to-one correspon- subsets of the real numbers is “strictly larger” than theset of real numbers, and so on. The notion of countability is often a very fruitful one to bear in mind. For example, suppose we want toknow whether or not all real numbers are algebraic. It is a genuinely hard exercise to write down a particu-lar real that is transcendental [III.41](/part-03/irrational-and-transcendental-numbers) (meaning not algebraic; seerem [V.22](/part-05/liouvilles-theorem-and-roths-theorem) for an idea of how it can be done), but the liouville’s theorem and roth’s theoabove notions make it utterly trivial that transcenden-tal numbers exist. Indeed, the set of all real numbers is

172

uncountable but the set of algebraic numbers is count-able! Further more, this shows that “most” real numbers are transcendental: the algebraic numbers form only atiny proportion of the reals. III.12 C* - Algebras A[I.3 §2.3](/part - 01/fundamental - definitions) \text{and abanach space metric space}[III.62](/part - 03/normed - spaces - and - banach - spaces) \text{is both a}[III.56](/part - 03/metric - spaces), and the study ofvector space Banach spaces is therefore a mixture of linear algebra and analysis. However, one can arrive at more sophisticated mixtures of algebra and analysis if one looks at Banach spaces that have more algebraic structure. In particular, while one can add two elements of a Banach space together, one cannot in general multiply them. However, sometimes one can: a vector space with a mul-tiplicative structure is called an algebra, and if the vector space is also a Banach space, and if the multipli-cation has the property thatxy ⩽ x \sum y \text{for any} two elements bra. (This name does not really reflect historical real-x and y , then it is called a Banach alge- ity, since the basic theory of Banach algebras was notworked out by Banach. A more appropriate name might have been Gelfand algebras.)AC*-algebra is a Banach algebra with an involution, which means a function that associates with each ele-mentx another element x* in such a way that x∗∗ = x, x* = x , (x + y)* = x* + y*$, and (xy)^{*} = y^{*}x^{*}$ for any elements satisfy the$C^{*} - \text{identityx and yxx}$; this involution is required to$^{*} = x^{2}$. A basic example of a C*-algebra is the algebra B(H) of all continuous linear maps The norm of$TT$defined on ais defined to be the smallest constant hilbert space [III.37](/part-03/bayesian-analysis)H.Minvolution takessuch that T x T to its⩽ M adjointx for every. This is a mapx \in  H, and the T* that has the property that x, T y = T*x, y \text{for every} x andmap with this property.) Ify in H . (It can be shown that there is exactly one His finite dimensional, then TT*can be thought of as anis then the complex conjugate of the transpose ofn \times n matrix for some n, and T. states that every subalgebra of A fundamental theorem of Gelfand and Naimark B(H)C*for some Hilbert space-algebra can be represented as a H. For more information, see operator algebras [IV.15 §3](/part-04/operator-algebras). III.13 Curvature If you cut an orange in half, scoop out the inside, and try to flatten one of the resulting hemispheres of peel, then you will tear it. If you try to flatten a horse’s saddle, or a soggy potato chip, then you will have the opposite

III. Mathematical Concepts

problem: this time, there is “too much” of the surfaceto flatten and you will have to fold it over itself. If, however, you have a roll of wallpaper and wish to flatten it, then there is no difficulty: you just unroll it. Surfaces such as spheres are said to be positively curved, ones with a saddle-like shape arelike a piece of wallpaper are negatively curved flat. , and ones it does not lie in a plane. This is because curvature isdefined in terms of the Notice that a surface can be flat in this sense even ifintrinsic geometry of a surface, where distance is measured in terms of paths that lieinside the surface. There are various ways of making the above notion of curvature precise, and also quantitative, so that witheach point of a surface one can associate a number that tells you “how curved” it is at that point. In order todo this, the surface must have a riemannian metric [I.3 §6.10](/part-01/fundamental-definitions) on it, which is used to determine the lengthsof paths. The notion of curvature can also be generalized to higher dimensions, so that one can talk aboutthe curvature of a point in ad-dimensional Rieman- nian manifold. However, when the dimension is higher than 2, the way that the manifold can curve at a point is more complicated, and is expressed not by a single number but by the so-called Ricci tensor. See ricci flow [III.78](/part-03/ricci-flow) for more details.Curvature is one of the fundamental concepts of modern geometry: not only the notion just described but also various alternative definitions that measure in other ways how far a geometric object deviates from being flat. It is also an integral part of the theoryof general relativity (which is discussed in general relativity and the einstein equations [IV.13](/part-04/general-relativity-and-the-einstein-equations)). III.14 Designs Peter J. Cameron Block designs were first used in the design of experiments in statistics, as a method for coping with sys-tematic differences in the experimental material. Suppose, for example, that we want to test seven differ-ent varieties of seed in an agricultural experiment, and that we have twenty-one plots of land available for the experiment. If the plots can be regarded as identical, then the best strategy is clearly to plant three plotswith each variety. Suppose, however, that the available plots are on seven farms in different regions, with three plots on each farm. If we simply plant one variety on each farm, we lose information, because we cannot dis-tinguish systematic differences between regions from

III.14. Designs

3 5

2 6 4

Figure 1 A block design.

differences in the seed varieties. It is better to followa scheme like this: plant varieties 1, 2, 3 on the first farm; 1, 4, 5 on the second; and then 1, 6, 7; 2, 4, 6; 2, 5, 7; 3, 4, 7; and 3, 5, 6. This design is represented infigure 1. block design sets of seed varieties used on the seven farms. The This arrangement is called a, or BIBD for short. The blocks are the balanced incomplete blocks are “incomplete” because not every variety canbe planted on every farm; the design is “balanced” because each pair of varieties occurs in the same block the same number of times (just once in this case).\text{This is a}(7, 3, 1)design: \text{there are seven varieties}; \text{each block contains three of them}; \text{and two varieties occur together in a block once}. \text{It is also an example of a finite geometry}, \text{varieties are usually called} “points.”\text{projective plane}. \text{Because of the connection with of BIBDs and related classes of designs}. Indeed, the \text{Mathematicians} \text{have developed an extensive theory study of such designs predates their use in statistics}.In 1847, T. P. \text{Kirkman showed that a}(v$, 3, 1) design$\text{exists if and only ifdesigns are now calledv is congruent to} 1 or 3 mod 6. (\text{Such Steiner triple systems}, \text{although Steiner did not pose the problem of their existence until}1853.) \text{own words}, \text{Kirkman also posed a more difficult problem}. \text{In his Fifteen young ladies in a school walk out three abreast for seven days in succession}: \text{it is required to arrange them daily so that no two shall walk twice abreast}. \text{The solution requires awith the extra property that the thirty}-\text{five blocks can}(15, 3, 1) \text{Steiner triple system} 173 \text{be partitioned into seven sets called} “replicates,” \text{each replicate consisting of five blocks that partition the set of points}. \text{Kirkman himself gave a solution}, \text{but it wasnot until the late} 1960 s \text{that Ray}-\text{Chaudhuri and Wilson showed that}(v, 3,1) \text{designs with this property exist wheneverv} \text{is congruent to} 3 mod 6. \text{ments show that}, \text{given For whichv} , k, \l\text{ambda do designs exist}? \text{Counting argu} - k and λ, \text{the values of} v \text{for whichtain congruence classes}. (\text{We noted above that}(v, k, λ) \text{designs exist are restricted to cer}-(v, 3, 1) \text{designs exist only ifv is congruent to} 1 or 3 mod 6.) \text{An asymptotic existence theory developed by Richard Wilson shows that this necessary condition is sufficient for the existence of a design}, \text{apart from finitely many exceptions}, \text{for each value ofk and} λ. \text{The concept of design has been further generalized}: \text{aare contained in exactlyt}–(v, k, λ) \text{design has the property that any}\l\text{ambda blocks}. \text{Luc Teirlinck showedt points that nontrivialt}-\text{designs exist for all} t, \text{but examples} fort > 3 are comparatively rare. introductory example, if only six farms were available, The statisticians’ concerns are a bit different. In our we could not use a BIBD for the experiment, but wouldhave to choose the most “efficient” possible design (allowing the most information to be obtained from the experimental results). A BIBD is most efficient if itexists; but not much is known in other cases. There are other types of design; these can be important to statistics and also lead to new mathematics.Here, for example, is an orthogonal array: if you take any two rows of this matrix you obtain a 2$\times 9 matrix$ in which each ordered pair of symbols from$\\{0}$,1,2\\\\\\\\\\\\\\\\\\\\\\} occurs exactly once as a column. 0 0 0 1 1 1 2 2 2 0 1 2 0 1 2 0 1 2 0 1 2 1 2 0 2 0 1 0 2 1 1 0 2 2 1 0 It could be used if we had four different treatments, each of which could be applied at three different levels, and if we had nine plots available for testing. Design theory is closely related to other combinatorial topics such as error-correcting codes; indeed, Fisher “discovered” the Hamming codes as designs five years before R. W. Hamming found them in the context of error correction. Other related subjects include pack-ing and covering problems, and especially finite geometry, where many finite versions of classical geometries can be regarded as designs.

174

III.15 Determinants

The determinant of a 2$\times 2 \text{matrixac bd}$

is defined to bead - bc. The determinant of a 3 \times  3 matrix⎛a b c⎞⎜⎜⎝d e f ⎟⎟⎠g h i

is defined to beaei+bf g+cdh-af h-bdi-ceg. What do these expressions have in common, how do they generalize, and why is the generalization significant? simple observations. Both expressions are sums and differences of products of entries from the matrix. Each To begin with the first question, let us make a few one of these products contains exactly one element from each row of the matrix and also exactly one element from each column. In both cases, a minus signseems to attach itself to the products for which the entries selected from the matrix “slope upward” rather than “downward.” definition totake sums and differences of all possible products of Up to a point it is easy to see how to extend thisn \times  n matrices with n ⩾ 4. We simply none from each column. The difficulty comes in decid-entries, where one entry from each row is used and ing which of these products to add and which to sub-tract. To do this we take one of the products and use it to define a permutation follows. For eachi ⩽ n, the product contains exactlyσ of the set \\{1,2, . . . , n\\} as one entry in thethenσ (i) = j. The product is added if this permutation ith row. If it belongs to the jth column is even and subtracted if it is odd (seegroups [III.68](/part-03/permutation-groups)). So, for example, the permutation cor-permutation responding to the entryaf h in the 3 \times  3 determinant above sends 1 to 1, 2 to 3, and 3 to 2. This is an odd permutation, which is whyaf h receives a minus sign. products and minus signs that we have just definedis important. The reason is that it tells us something We still need to explain why the particular choice of about the effect of a matrix when it is considered as alinear map. Let A be an n \times  n matrix. Then, as explained in [I.3 §3.2](/part-01/fundamental-definitions), Aspecifies a linear mapα from Rn to Rn. The determinant ofdoes to volumes. More precisely, if A tells us what this linear map X is a subset of Rn with transformingn-dimensional volume X using the linear map V , then αXα, will have vol-, the result of

III. Mathematical Concepts

ume symbolically as follows: V times the determinant of A. We could write this vol$(αX) = \det A · vol(X)$.$\text{For example}$, \text{consider the} 2\times  2 matrix A = \cos \sin  θθ -\cos \sin θθ .

The corresponding linear map is a rotation of R2 through an angle ofaffect its volume, we should expect the determinant ofθ. Since rotating a shape does not A to be 1, and sure enough it is cos^2 θ + \sin^2 θ, which is 1 by Pythagoras’s theorem. tion in one respect: determinants can be negative, but clearly volumes cannot. If the determinant of a matrix The above explanation is a slight over sim pl if i ca is-2, to give an example, it means that the linear map multiplies volumes by 2 but also “turns shapes insideout” by reflecting them. become obvious once one knows the above interpre-tation in terms of volumes. (However, it is much less Determinants have many useful properties, which obvious that this interpretation is correct: in setting up the theory of determinants one must do some work somewhere.) Let us give three of these properties. (i) Let V be a vector space[I.3 §2.3](/part-01/fundamental-definitions) and letα:$V \to V$ be a linear map. Let A be the matrix of α vwith respect to this basis. Now let1, . . . , vn be a basis of V and letwof1α, . . . , with respect to this different basis. Thenwn be another basis of V and let B be the matrix A and B are different matrices, but since they both represent the linear map volumes. It follows that detα, they must have the same effect on$(A) = \det (B)$. To put this another way: the determinant is better thought of as aproperty of linear maps rather than of matrices. Two matrices that represent the same linear map in the above sense are calledand B are similar if and only if there is an invertible similar. It turns out that A matrix P such that P-1 AP = B. (An n \times  n matrix P is invertible then \times  n if there is a matrix identity matrix, I , which turns out to imply Q such that P Q equals that called the QP equals inverse Inofas well. If this is true, then P and is denotedn P-1.) What we Q is have just shown is that similar matrices have the same determinant. represent linear maps(ii) If A and B are any twoα andn \times βnofmatrices, then they Rn. The product ABmap that results from doing represents the linear mapβ followed byαβ: that is, the linearα. Since β multiplies volumes by det B and α multiplies them by

III.16. Differential Forms and Integration

\det \det (AB)A, αβ=multiplies them by det\det  A \det  B. (The determinant of a product A\det  B. It follows that equals the product of the determinants.) other matrix, thenby the multiplicative property just discussed. It follows(iii) If A is a matrix with determinant 0 and AB will have determinant 0 as well, B is any that Therefore a matrix with determinant 0 is not invert-$\text{AB cannot equal} I^{n}$, since In has determinant 1. ible. The converse of this turns out to be true as well: a matrix with nonzero determinant is invertible. Thus, the determinant gives us a way of finding out whethera matrix can be inverted. III.16 Differential Forms and

Integration

Terence Tao

It goes without saying that integration is one of the fundamental concepts of single-variable calculus. How-ever, there are in fact three concepts of integration that appear in the subject: theknown as the antiderivative indefinite integral), the unsigned definite inte-f (also gral[a, b] f (x) dx(which one would use to find the area under a curve, or the mass of a one-dimensional object of varying density), and the signed definite integral compute the work required to move a particle fromab f (x) dx (which one would use, for instance, toa tob functions). For simplicity we shall restrict our attention here tof: R\to  R that are continuous on the entire real line (and similarly, when we come to differential forms, we shall discuss only forms that are continuous on the entire domain). \text{We shall also informally use terminology such as} “infinitesimal” \text{in order to avoid having to discuss the} (routine) “epsilon–delta” \text{analytical issues that one must resolve in order to make these integration concepts fully rigorous}. \text{closely related to each other in single}-\text{variable calcu} - lus; indeed, \text{These three concepts of integration are of coursethe fundamental theorem of calculus} [I.3 §5.5](/part - 01/fundamental - definitions) \text{relates the signed definite integralto any one of the indefinite integrals} F = \text{a bff} (x)\text{by thedx} formula$bf (x) dx = F(b) - F(a)$, (1)

while the signed and unsigned integrals are related bythe simple identity ab f (x) dx = −a f (x) dx = f (x) dx, (2) \text{which is valid wheneverab a} ⩽ b.[a, b] 175 several-\text{variable calculus}, though, \text{these three concepts begin to diverge significantly from each other}. \text{The When one moves from single}-\text{variable calculus to indefinite integral generalizes to the notion of ato a differential equation}, \text{or to an integral of a connec}-\text{solution tion}, \text{unsigned definite integral generalizes to thevector field} [IV.6 §5](/part - 04/algebraic - topology), \text{or bundle} [IV.6 §5](/part - 04/algebraic - topology). \text{The lebesgue integral measure space}[III.55](/part - 03/measures), \text{or more generally to}. Finally, \text{the signed definite integral gen}-\text{integration on a eralizes to thefocus here}. \text{While these three concepts are still related integration of forms}, \text{which will be our to each other}, \text{they are not as} \text{interchangeable} \text{as they are in the single}-\text{variable setting}. \text{The integration} - of-\text{forms concept is of fundamental importance in differential topology}, geometry, \text{and physics}, \text{and also yieldsone of the most important examples of cohomology} [IV.6 §4](/part - 04/algebraic - topology), namely speaking) measures the extent to which the fundamen-de Rham cohomology, which (roughly tal theorem of calculus fails in higher dimensions andon general manifolds. informally revisit one of the basic applications of thesigned definite integral from physics, namely com-To provide some motivation for the concept, let us puting the amount of work required to move a one dimensional particle from point presence of an external field. (For example, one mighta to point b in the be moving a charged particle in an electric field.) Atthe infinitesimal level, the amount of work required to move a particle from a pointx \in  R to a nearby point ix place men(ti)+1 \in  R is (up to a small error) proportional to the dis-Δx = x - x , with the constant of pro- portion al it yf ((xi)i) depending on the initial locatio(ni()+1)i xi of the particle. Thus, the total work required for this is approximate lyf (x )Δx . Note that we do not requirexthe infinitesimal worki+1 to be to the right ofi f (xixi, so the displacement)Δx ) may well be negative.Δxi (or To return to the non infinitesimal problem of comput-$ii$ ing the work required to move fromtrarily select a discrete pathx = a, xa, xto, . . . , xb, we arbi-= b froma to b, and approximate the work a(s0)1 2 nb f (x) dx \approx n-1 f (xi)Δxi. (3)ai = 0

Again, we do not require(xi)+1 to be to the right of xi; it is quite possible for the path to “backtrack” repeat-edly: for instance, one might have$x < x^{+} > x^{+} for$ some backtracking eventually cancels itself out; regard less$i$. However, it turns out that the effect of such$(i^{i}()^{1}()^{i})^{2}$ of what path we choose, the expression (3) above con-verges as the maximum step size tends to zero, and the

176

limit is the signed definite integral

bf (x) dx, (4)

provided only that the total length path (which controls the amount of backtracking in-(an)i=-0 1 |Δxi| \text{of the} volved) stays bounded. In particular, in the case whena = b, so that all paths are closed (i.e., x = x ), we see 0 n that the signed definite integral is zero: af (x) dx = 0. (5)

integral it is obvious that we have the concatenation formula From this informal definition of the signed definite ac f (x) dx = b f (x) dx + c f (x) dx (6)regard less of the relative position of the real numbersa, b, andac. In particular (settinga a =b c and using (5)) we conclude that ba Thus, if we reverse a path froma path fromab f (x)to ad, then the sign of the integralx = −b f (x)adx.to b to form changes. This contrasts with thegralf (x) dx, since the set unsigned definite inte-[a, b] of numbers between bers between[a, b]a andbbandis exactly the same as the set of num-a. Thus we see that paths are not quite the same as sets: they carry ancan be reversed, whereas sets do not.orientation which to higher-dimensional integration: that is, from single-variable calculus to several-variable calculus. It turns Now let us move from one-dimensional integration out that there are increase: the “ambient space,”two objects whose dimensions may1 which will now be R ninstead of R, and the path, which will now become an oriented gr at i on will take place. For example, ifk-dimensional manifold S, over which the inte-n = 3 and k = 2, then one is integrating over a surface that lives in R3. Let us begin with the case n ⩾ 1 and k = 1. Here, we will be integrating over a continuously differentiable path (or oriented rectifiable curve)$γ in R^{n} \text{starting and}$ ending at pointsmay or may not be distinct, depending on whether thea and b, respectively. (These points path is open or closed.) From a physical point of view, we are still computing the work required to move froma to b, but now we are moving in several dimensions plicity, although the true power of the integration-of-forms concept ismuch more apparent when we integrate on more general spaces, such1. We will start with integration on Euclidean spaces Rn for sim- as abstractn-dimensional manifolds.

III. Mathematical Concepts

instead of one. In the one-dimensional case, we did notneed to specify exactly which path we used to get from a However, in higher dimensions, the exact choice of theto b, because all backtracking canceled itself out. pathγ becomes important. parametrizedγ Formally, a path fromfrom the unit interval) as a continuously differentiable function[a0,1 to] bto can be described (or Rn such that γ(0) =a and γ(1) = b. For instance, the line segment froma to b can be parametrized as γ(t) = (1 - t)a + tb. This segment also has many other par a me tr iz at i ons, such as  ̃γ(t) = (1 - t2)a + t2 b; however, as in the one dimensional case, the exact choice of parametrization does not ultimately influence the integral. On the other hand, the reverse line segment$(-γ)(t) = ta + (1 - t)b$ fromalongb-γtowill turn out to be the negative of the integralais a genuinely different path; the integral alongγ. approximate the continuous path As in the one-dimensional case, we will need to$γ \text{by a discrete pathx}^{0} = γ(t^{0})$, x1 = γ(t1)$, x2 = γ(t2)$, $. . . , xn = γ(tn)$, whereγ(t0) = a and γ(tn) = b. Again, we allow some backtracking: displacementtΔi +x1 is not necessarily larger than= x - x \in  Rn from x to xti. Theis now aon the generalization to manifolds, one should think vector rather than a scalar. (Indeed, with an eye$(i^{i}()^{+1}()^{i}()^{i}()^{i})^{+1}$ ofΔxas an infinitesimal tangent vector to the ambii ent space Rn at the point x .) In the one-dimensional i

case, we converted the scalar displacementΔx intoi

a new number$f (x^{i})\Delta x^{i}$, which was linearly related to the original displacement by a proportionality con-stantf (x ) that depended on the position x . In higher dimensions, we again have a linear dependence, but$i^{i}$ this time, since the displacement is a vector, we must replace the simple constant of proportionality by a linear transformation represents the infinitesimal “work” required to move$ω^{x}^{i} from R^{n} to R$. Thus, ωx i(Δxi) from$\text{xi to} (xi)+1$. In technical terms, ωx is a linear func-i

tional on the space of tangent vectors atx , and is thusi

a cotangent vector at$x$. \text{By analogy with} (3), the neti

workγ is approximated byγ ω required to move from a to b along the pathγ ω \approx n i=-0 1 ωx i(Δxi). (7) \text{As in the one}-\text{dimensional case}, \text{one can show thatthe right}-\text{hand side of} (7) \text{converges if the maximum step size supzero and the total length}0⩽i⩽n - 1 |\D\text{elta xi}|\text{nof the path converges to} - 1 |\D\text{elta xi}| \text{of the path staysi} = 0 III.16. \text{Differential Forms and Integration bounded}. \text{The limit is written asare restricting our attention to continuous functions}.γ ω. (\text{Recall that we The existence of this limit uses the continuity of The object}ω, \text{which continuously assigns}2 \text{a cotan}-ω.) \text{gent vector to each point in Rn}, \text{is called a} 1 - form, and (7) \text{leads to a recipe for integrating any} 1-\text{formon a path}γ. \text{That is}, \text{to shift the emphasis slightly}, itω \text{allows us to integrate the path}ω. Indeed, \text{it is useful to think of this integration as}γ“against” the 1-\text{form aproduct}) \text{that takes the curve binary operation} (\text{similar in some ways to the dot}γ \text{and the form} ω \text{as inputs}, \text{and returns a scalarin fact a} “duality” \text{between curves and forms}; compare,γ ω \text{as output}. \text{There is for instance}, \text{the identity which expresses} (\text{part of}) \text{the fundamental fact that integration of forms is a linear operation}$, \text{with the}$γ(ω1 + ω2) =γ ω1 +γ ω2, \text{identity which generalizes} (6) \text{whenever the initial point ofthe final point of}γ1γ+ γ, where2 ω =γγ1 ω+ +γ \text{is the}γ2 ω, concatenationγ2 is 1 1 2 \text{of Recall that if}γ1 and γ2.3 \text{fis a} \text{differentiable} \text{function from Rn tofrom} R, \text{then its derivative at a point Rn to} R(see [I.3 §5.3](/part - 01/fundamental - definitions)). If fis continuously differ-x is a linear map entiable, then this linear map depends continuously onx, and can therefore be thought of as a 1-form, which we denote by d This 1-form can be characterized as the unique 1-formf , writing dfx for the derivative at x. such that one has the approximation

$f (x + v) \approx f (v) + df^{x} (v)$

for all infinitesimal is that|f (x + v) - f (v)v . (More rigorously, the condition- df (v)|/|v| → 0 as v \to  0.) alizes to The fundamental theorem of calculus (1) now gener-$x$ d$f = f (b) - f (a) (8)$ whenever pointb. In particular, ifγ is any oriented curve from a pointγ γ is closed, then df = 0. Notea to a that in order to interpret the left-hand side of the above equation, we are regarding it as a particular example ofγ bundle2. More precisely, one can think of3. This duality is best understood using the abstract, and much.ω as a section of the cotangent more general, formalism of homology and cohomology. In particular, one can remove the requirement thatγ2 \text{begins where} γ1 leaves off by generalizing the notion of an integral to cover not just integration on paths, but also integration on formal sums or differences of paths. This makes the duality between curves and forms more symmetric.

177

an integral of the formbe the form df . Note also that, with this interpretation,γ ω: in this case,ω happens to dit does not appear under an integral sign.f has an independent meaning (it is a 1-form) even if small1-form that can be written as d A 1-form whose integral against every sufficiently4 closed curve vanishes is calledf for some continuously closed, while a differentiable function is called mental theorem implies that every exact form is closed.exact. Thus, the funda This turns out to be a general fact, valid for all mani-folds. Is the converse true: that is, is every closed form exact? If the domain is a Euclidean space, or indeedany other simply connected manifold, then the answer is yes (this is a special case of theit is not true for general domains. In modern terminol-Poincaré lemma), \text{but ogy}, \text{this demonstrates that the de Rham cohomology of such domains can be nontrivial}. \text{an object which we denote by As we have just seen}, a 1-\text{form can be thought of as}ω \text{that associates with each path}ω. \text{Of course}, ω \text{is not just}γ \text{a scalar}, \text{any old function from paths to scalars}: \text{it must sat}-\text{isfy the concatenation and reversing rules discussed}γ earlier, \text{and this}, \text{together with our continuity assump} - tions, \text{more or less forces it to be associated with some kind of continuously varying linear function that can beused}, \text{in combination with}γ, \text{to define an integral}. \text{Now let us see if we can generalize this basic idea from paths tostick to the two}-\text{dimensional case}, \text{that is}, \text{to int eg ratio nk}-\text{dimensional sets with} k > 1. \text{For simplicity we shall of forms on} (oriented) \text{surfaces in Rn}, \text{since this already illustrates many features of the general case}.Physically, \text{such integrals arise when one is computing aacross a surface}. \text{We parametrized one}-\text{dimensional ori}-\text{flux of some field} (e.g., \text{a magnetic field}) \text{ented curves as continuously} \text{differentiable} functionsγ \text{from the interval} [0, 1] \text{to Rn}. \text{It is thus natural to parametrize two}-\text{dimensional oriented surfaces as con} - tinuously \text{differentiable} functionsφ\text{defined on the unit square}[0, 1]2. \text{This does not in fact cover all possible surfaces one wishes to integrate over}, \text{but it turns outthat one can cut up more general surfaces into pieces that can be parametrized using} “nice” \text{domains suchas}[0,1]2. \text{intervalt In the one}-\text{dimensional case}, \text{we cut up the orientedto} t [0=, 1]\text{tinto infinitesimal oriented intervals from}+ \Delta t, \text{which led to infinitesimal curves fromi xi} + i 1= γ((ti)i) \text{to xi} + 1 = γ(ti + 1) = xi + \D\text{elta xi}. \text{Note that tract i ble point}.4. \text{The precise condition needed is that the curve should be}, \text{which means that it can be continuously shrunk down to acon} - 178 \Deltaγx^ (\text{ti and})\Delta t . \text{In the two}-\text{dimensional case}, \text{we will cut up}\Delta t \text{are related by the approximation} \D\text{elta xi} \a\text{pprox the unit square obvious way}.(ii)5 A \text{typical one of these will have cor}-[0,1]2 \text{into infinitesimal squares in an ners of the form}(t + \Delta t, t + \Delta t). \text{The surface described by}(t1$, t2)$, (t1 + Δt$, t2)$, (t1$, t2 +φ \D\text{elta cant})$, then be partitioned into regions, with corners$φ(t^{1} +\Delta t$, t2 ), φ(t $, t +\Delta t)$, φ(t +Δt$, t +\Delta t)φ(t, \text{each of}1$, t2), \text{which carries an orientation}. \text{Sinceit is approximately linear at small distance scales}, so1 2 1 2 1φis \text{differentiable},2 \text{this region is approximately an oriented parallelogram in Rn with corners} x, x + \Delta x, x + \Delta x, x + \Delta x +\Delta2 x, where x = φ(t1, t2) and1 \Delta1 x and2 \Delta2 x \text{are the}1 \text{infinitesimal vectors}$\partialφ \partialφ\Delta1 x = \partial t1 (t1$, t2)\Delta t, \Delta2 x = \partial t2 (t1, t2)\Delta t. Let us refer to this object as the infinitesimal parallel-ogram with dimensions\Delta x ∧ \Delta x and base point x. For now, we will think of the symbol “notational convenience and not try to interpret it. In1 2∧” as a mere order to integrate in a manner analogous with integration on curves, we now need some sort of func-tionalωx at this base point that depends continuously onmal parallelogram and return an infinitesimal number x. This functional should take the above infinitesiωof “flux” passing through this parallelogram.$x (\Delta^{1}x ∧ \Delta^{2}x)$, which one can think of as the amount certain properties. For instance, if you double double one of the sides of the infinitesimal parallel-As in the one-dimensional case, we expect$ω\Delt(a^{x})^{1}\text{to havex}$, you ogram, so (by the continuity ofthrough the parallelogram should double. More gener-ω) the “flux” passing ally,\Delta x ωandx (\Delta \1 elta1 xx∧: in other words, it isΔ2 x) should depend linearly on each ofbilinear. (This gen- eralizes the linear dependence in the one-dimensional case.)1 2 Another important property is that $ω^{x} (\Delta^{2}x ∧ \Delta^{1}x) = −ω^{x}(\Delta^{1}x ∧ \Delta^{2}x)$. (9) That is, the bilinear formthis has an intuitive explanation: the parallelogram rep-ωx is antisymmetric. Again, resented bybyΔ x ∧ ΔΔx2 xexcept that it has had its orientation∧Δ1 x is the same as that represented reversed, so the “flux” now counts negatively where itused to count positively, and vice versa. Another way1 2 of seeing this is to note that if al le lo gram is degenerate and there should be no flux.$\Delta^{1}x = \Delta^{2}x$, \text{then the par}- ograms, triangles, etc.; this leads to an equivalent concept of the integral.5. One could also use infinitesimal oriented rectangles, parallel-

III. Mathematical Concepts

Antisymmetry follows from this and the bilinearity. A2-formω is a continuous assignment of a functionalωx If with these properties to each pointω is a 2-form and φ:[0, 1]2 \to Rn \text{is a continuous lyx}. differentiable function, we can now define the integralω of ω“against”φ (or, more precisely, the inte- gral against the image under[φ0, 1]2) by the approximation φ of the oriented squareω \approx  ωx i(\Delta(x1), i ∧ \Delta(x2), i ), (10)φi

where the image ofinto parallelograms of dimensionsφ is (approximately) partitioned\Delta x ∧ \Delta x based at pointsx . We do not need to decide what orde(r1)$, (i2)$, \text{ii these} \text{parallelograms} \text{should be arranged in}, \text{because addition is both commutative and associative}. \text{One can show that the right}-\text{hand side of} (10) \text{converges to a unique limit as one makes the partition of parallelo} - grams “\text{increasingly fine},” \text{though we will not make this precise here}. \text{We have thus shown how to integrate} 2-\text{forms against oriented two}-\text{dimensional surfaces}. \text{More generally}, \text{onecan define the concept of ak}-\text{form on an} n-\text{dimensional manifold} (\text{such as Rn}) \text{for any} 0 ⩽ k ⩽ n \text{and inte}- \text{grate this against an orientedin that manifold}. \text{For instance}, a 0-\text{form on a manifoldk}-\text{dimensional surface} X \text{is the same thing as a scalar function} f: X \to R, \text{whose integral on a positively oriented pointis zero dimensional}) isf (x), \text{and on a negatively ori} - x (\text{which ented pointx is} - f (x). A k-form tells us how to assign a value to an infinitesimal with dimensionsΔx ∧· · ·∧k-dimensional parallelepipedΔx , and hence to a portion ofwe have seen when$k$-dimensional “surface,” in much the same way as1 k = 2. By convention, ifk k \ neq k^ , the integral of ak - \text{dimensional form on a} k^ -dimensional surface is understood to be zero. We refer to 0-forms, 1-forms, 2-forms, etc. (and formal sums and differences there of), collectively as differential forms. perform on scalar functions: addition pointwise product There are three fundamental operations that one can(f $, g) \to f g$, and differentiation(f , g) \to  f + g, f \to  df , although the last of these is not especially use- ful unless at i ons have various relationships with each other. Forfis continuously differentiable. These op er instance, the product is distributive over addition,

$f (g + h) = f g + f h$,

and differentiation is aproduct: derivation with respect to the d$(f g) = (df )g + f (dg)$.

III.16. Differential Forms and Integration

these operations to differential forms. Adding a pair It turns out that one can generalize all three of of forms is easy: if[0,1]k \to Rnis a continuously differentiable function,ω and η are two k-forms and φ: thenφ(ω + η)is defined to beφ ω +φ η. One multi- plies forms using the so-calledk-form and η is an l-form, thenwedge productω ∧η is a (k +. Ifl)-form.ω is a Roughly speaking, given a$(k + l)$-dimensional infinitesimal parallelepiped with base pointΔx ∧ · · · ∧ Δx , one evaluates ωxandand dimensionsη at the par- all el ep ip eds with base point· · · ∧1 Δx and Δk +xl ∧ · · · ∧xΔand dimensionsx , respectively, andΔx1 ∧ multiplies the results together.$(k^{k}()^{+1}()^{k})^{+l}$ tiablethat measures something like the “rate of change” of As for differentiation, ifk-form, then its derivative dωis a continuously differen-$ω \text{is a} (k + 1)-formω$. To see what this might mean, and in particular to seewhy dω is a (k + 1)-form, let us think how we might answer a question of the following kind. We are givena spherical surface in R3 and a flow, and we would like to know the net flux out of the surface: that is, the dif-ference between the amount of flux coming out and the amount going in. One way to do this would be to approximate the surface of the sphere by a union of tiny parallelograms, to measure the flux through each one, and to take the sum of all these fluxes. another would be to approximate the solid sphere by a union of tiny parallelepipeds, to measure the net flux out of each of these, and to add up the results. If a parallelepiped issmall enough, then we can closely approximate the net flux out of it by looking at the difference, for each pair of opposite faces, between the amount coming out ofthe parallelepiped through one and the amount going into it through the other, and this will depend on the rate of change of the 2-form. parallelepipeds is more rigorously described as inte-The process of summing up the net fluxes out of the grating a 3-form over the solid sphere. In this way, onecan see that it is natural to expect that information about how a 2-form varies should be encapsulated in a 3-form. a little bit of algebra and is omitted here. However, The exact construction of these operations requires we remark that they obey similar laws to their scalar counterparts, except that there are some sign changes that are ultimately due to the antisymmetry (9). \text{For instance}, \text{if commutative law for} \text{multiplication} becomesω \text{is a} k-\text{form and} η \text{is an} l - form, theω ∧ η = (-1)klη ∧ ω, 179 \text{basically because dimensions with}\text{lkl dimensions}; \text{and the derivation ruleswaps are needed to interchange} k for differentiation becomes d$(ω ∧ η) = (dω) ∧ η + (-1)^{k}ω ∧ (dη)$. Another rule is that the differentiation operator d isnilpotent: d(dω) = 0. (11) This may seem rather unintuitive, but it is fundamen-tally important. To see why it might be expected, let us think about differentiating a 1-form twice. The orig-inal 1-form associates a scalar with each small line segment. Its derivative is a 2-form that associates a scalar with each small parallelogram. This scalar essentially measures the sum of the scalars given by the 1-formas you go around the four edges of the parallelogram, though to get a sensible answer when you pass to the limit you have to divide by the area of the parallelo-gram. If we now repeat the process, we are looking at a sum of the six scalars associated with the six facesof a parallelepiped. But each of these scalars in turn comes from a sum of the scalars associated with thefour directed edges around the corresponding face, and each edge is therefore counted twice (as it belongs totwo faces), once in each direction. Therefore, the contributions from each edge cancel and the sum of all contributions is zero. tween integrating a 2-form over the surface of a sphere The description given earlier of the relationship beand integrating its derivative over the solid sphere canbe thought of as a generalization of the fundamental theorem of calculus, and can itself be generalized considerably: Stokes’s theorem is the assertion that for any oriented manifold oriented boundary of SSd(which we will not define here).ωS=\text{and form}\partial S ω ω, where \partial S is the(12) Indeed one can view this theorem as a definition of the derivative operationω \to dω; thus, \text{differentiation} \text{is the identity} (11) \text{is dual to the geometric observation that adjoint of the boundary operation}. (\text{For instance}, \text{the the boundary boundary}:\partial(\partial S)\partial S = ∅\text{of an oriented manifold itself has no}.) \text{As a particular case of Stokes}’s theorem, \text{we see that} dω = 0 whenever S \text{is a closed S} manifold, i.e., \text{one with no boundary}. \text{This observation lets one extend the notions of closed and exact forms to general differential forms}, which (\text{together with} (11)) \text{allows one to fully set up We have already seen that} 0-\text{forms can be identified de Rham cohomology}. \text{with scalar functions}. Also, \text{in Euclidean spaces one can} 180 \text{use the inner product to identify linear functionals with vectors}, \text{and therefore} 1-\text{forms can be identified with vector fields}. \text{In the special} (\text{but very physical}) \text{case ofthree}-\text{dimensional Euclidean space} R3, 2-\text{forms can also be identified with vector fields via the famous hand rule},6 and 3-\text{forms can be identified with scalar right functions by a variant of this rule}. (\text{This is an exam}-\text{ple of a concept known as Hodge duality}.) \text{In this case}, the \text{differentiation} operationω \to dω \text{can be identi}- \text{fied with the}0 - form, \text{with the gradient curl operation operation Xf}→ ∇ \times→ ∇f Xwhenwhenωω\text{is ais a} 1 - form, \text{and with the divergence operation} X → ∇ · X \text{when implies that}ω \text{is a} 2 - form. Thus, \text{for instance}, \text{the rule} (11)∇ \times ∇f = 0 and ∇ · (∇ \times X) \text{for any suit}- \text{ably smooth scalar function various cases of Stokes}’s theorem (12), \text{with this inter}-\text{fand vector field} X, \text{while pretation}, \text{become the various theorems about integralsof curves and surfaces in three dimensions that you may have seen referred to as} “\text{the divergence theorem},”“Green’s theorem,” and “Stokes’s theorem” \text{in a course on several}-\text{variable calculus}.\text{Just as the signed definite integral is connected to the unsigned definite integral in one dimension via}(2), there is a connection between integration of differential forms and the Lebesgue (or Riemann) inte-gral. On the Euclidean space Rn one has the n stan- dard coordinate functions Their derivatives dx , . . . , dxx1 are then 1-forms on, x2, . . . , xn: R$n \to RRn$.. Taking their wedge product, one obtains andx ∧ · · · ∧ dx . We can multiply this by any (contin-1 n n-form$uous) \text{scalar functionform}1$ f (x) dx ∧ · · · ∧n fd:$xR^{n}$. If\to ΩRis any open boundedto obtain another n- domain in Rn, we then have the identit(y1)n where on the left-hand side we have an integral of a dif-ferential form (withΩ f (x) dx1 ∧ · · · ∧Ω viewed as a positively oriented dxn =Ω f (x) dx, nhave the Riemann or Lebesgue integral of-dimensional manifold) and on the right-hand side wef on Ω. If we givethe sign of the left-hand side. This correspondenceΩ the negative orientation, we have to reverse$generalizes (2)$.There is one last operation on forms that is worth pointing out. Suppose we have a continuously differen-tiable mapΦ: X \to  Y from one manifold to another (we allow X and Yto have different dimensions). Then have used the left-hand rule to provide this identification, and apartfrom some harmless sign changes here and there, one gets essentially6. This is an entirely arbitrary convention; one could just as easily the same theory as a consequence.

III. Mathematical Concepts

of course every pointΦ(x) in Y. Similarly, if we letx in X pushes forwardv \in  T Xbe an infinites-to a point imal tangent vector togent vector also pushes forward X based atto a tangent vectorxx, then this tan-Φcan be defined by requiring the infinitesimal approxi-*v \in TΦ(x)Y \text{based at} Φ(x); informally speaking,$Φ^{*}v$ mation DΦ(x)(v)Φ(x$, where D + v) = Φ(x)Φ$: T+XΦ*\to v . One can write T Y is the deriva-Φ*v = tivek-dimensional oriented manifoldof the several-variable mapx ΦΦ(x)S atin x X. Finally, anyalso pushes forward to a X, although in some cases (e.g., if the image ofk-dimensional oriented manifold Φ(S)Φ hasin dimension less thanmay be degenerate.k) this pushed-forward manifold between manifolds and forms. Since manifolds push forward under We have seen that integration is a duality pairingΦ from X to Y , we expect forms to pull backcan define thefrom Y topullback X. Indeed, given anyΦ*ω as the uniquek-form ωk-form onon Y, we X such that we have the change-of-variables formula In the case of 0-forms (i.e., scalar functions)$, \text{the pull} - back$Φ*f: X \to R \text{of a scalar function}Φ(S) ω =S Φ*(ω).f:$Y \to R \text{is given}$ explicitly by$Φ^{*}f (x) = f (Φ(x))$, while the pullback of$a 1 - form$ω is given explicitly by the formula(Φ^*ω)x (v) = ω^Φ(x)(Φ^*v).

Similar definitions can be given for other differen-tial forms. The pullback operation enjoys several nice properties: for instance, it respects the wedge product,

$Φ^{*}(ω ∧ η) = (Φ^{*}ω) ∧ (Φ^{*}η)$,

and the derivative,

d$(Φ^{*}ω) = Φ^{*}(dω)$.

By using these properties, one can recover rather painlessly the change-of-variables formulas in severalvariable calculus. Moreover, the whole theory carries over effortlessly from Euclidean spaces to other manifolds. It is because of this that the theory of differ-ential forms and integration is an indispensable tool in the modern study of manifolds, and especially in differential topology [IV.7](/part-04/dierential-topology). III.17 Dimension What is the difference between a two-dimensional set and a three-dimensional set? A rough answer that onemight give is that a two-dimensional set lives inside a plane, while a three-dimensional set fills up a portion of

III.17. Dimension

space. Is this a good answer? For many sets it does seemto be: triangles, squares, and circles can be drawn in a plane, while tetrahedra, cubes, and spheres cannot. But how about the surface of a sphere? This we would nor-mally think of as two dimensional, contrasting it with the solid sphere, which is three dimensional. But the surface of a sphere does not live inside a plane. Does this mean that our rough definition was incorrect? Not exactly. From the perspective of linear alge-bra, the set\\{(x}$, y, z)\\:$ x2 + y2 + z2 = 1, \text{which is the surface of a sphere of radius} 1 in R3 \text{centered at the origin}, \text{contained in a plane}. (\text{One can express this in algebraicis three dimensional}, \text{precisely because it is not language by saying that the affine subspace generatedby the sphere is the whole of} R3.) However, \text{this sense of} “\text{three dimensional}” \text{does not do justice to the roughidea that the surface of a sphere has no thickness}. \text{Surely there ought to be another sense of dimension in which the surface of a sphere is two dimensional}?\text{As this example illustrates}, dimension, \text{though very important through out mathematics}, \text{is not a single con} - cept. \text{There turn out to be many natural ways of generalizing our ideas about the dimensions of simple sets such as squares and cubes}, \text{and they are often incom}-\text{patible with one another}, \text{in the sense that the dimension of a set may vary according to which definition you use}. \text{The remainder of this article will set out a few different definitions}. \text{set is that it is} “\text{the number of coordinates you need tospecify a point}.” \text{We can use this to justify our instinct One very basic idea we have about the dimension of a that the surface of a sphere is two dimensional}: \text{youcan specify any point by giving its longitude and latitude}. \text{It is a little tricky to turn this idea into a rigorous mathematical definition because you can in fact specify a point of the sphere by means of justber if you do not mind doing it in a highly artificial one numway}. \text{This is because you can take any two numbers and interleave the digits to form a single number fromwhich the original two numbers can be recovered}. \text{For instance}, \text{from the two numbers and} e = 2.718281828 . . . \text{you can form the number}π = 3.141592653 . . .$32$.174\,118\,529\,821\,685\,238 . . ., \text{and by taking alternate digits you get backto find a continuous}πfunctionand e again. \text{It is even possiblef from the closed inter} - valand 1, inclusive) \text{to the surface of a sphere that takes}[0,1] (\text{that is}, \text{the set of all real numbers between} 0 \text{every value}. ural” \text{coordinate system}. \text{One way of making this deci}-\text{We therefore have to decide what we mean by a} “nat - 181 \text{sion leads to the definition of atant concept that is discussed in} [I.3 §6.9](/part - 01/fundamental - definitions) \text{and also inmanifold}, \text{a very impor differential topology idea that every point in the sphere is contained in a}[IV.7](/part - 04/dierential - topology). \text{This is based on the neighborhood in the sense that there is a} “nice” one - to-\text{one correspon} - Nthat “\text{looks like}” \text{a piece of the plane}, dence R2. Here, “nice” \text{can have different meanings}: typicalφ between N \text{and a subset of the Euclidean plane ones are thatuous}, or \text{differentiable}, \text{or infinitely} \text{differentiable}.φ \text{and its inverse should both be contin}- \text{is one where you needcan be developed into a rigorous definition that tells Thus}, \text{the intuitive notion that ad numbers to specify a pointd}-\text{dimensional set us}, \text{as we had hoped}, \text{that the surface of a sphere is two dimensional}. \text{Now let us take another intuitive notion and see what we can get from it}.Suppose I \text{want to cut a piece of paper into two pieces}. \text{The boundary that separates the pieces will be a curve}, \text{which we would normally like to think of as one dimen} - sional. \text{Why is it one dimensional}? Well, \text{we could use the same reasoning}: \text{if you cut a curve into two pieces then the part where the two pieces meet each other is a single point} (\text{or pair of points if the curve is a loop}), which is zero dimensional. That is, there appears to bea sense in which a(d - 1)-dimensional set is needed if you want to cut a Let us try to be slightly more precise about this idea.d-dimensional set into two. Suppose that X is a set and x and y are points in X . Let us call a setis no continuous path from Y a barrier xbetweento y that avoidsx and y if there Y . For example, ifcenter of X, and X is a solid sphere of radius 2, y is a point on the boundary ofx Xis the, then one possible barrier betweenx and y is the surface of a sphere of radius 1. With this terminology in place, wecan make the following inductive definition. A finite set is zero dimensional, and in general we say thatmostd dimensional if between any two points in XXthereis at is a barrier that is at most$(d - 1) dimensional$. \text{We also} say thatbut not at most X is d dimensional(d - 1) dimensional.if it is at most d dimensional difficulties: one can construct a pathological set The above definition makes sense, but it runs into X that acts as a barrier between any two points in the plane, but contains no segment of any curve. This makes$X$ zero dimensional and therefore makes the plane one dimensional, which is not satisfactory. A small modification to the above definition eliminates such patholo-gies and gives a definition that was put forward by brouweris said to have dimension at most[VI.75](/part-06/luitzen-egbertus-jan-brouwer-18811966). A \text{complete metric spaced if}, \text{given any pair}[III.56](/part - 03/metric - spaces) X 182 Figure 1 \text{so that no four overlap}.\text{How to cover with squares of disjoint closed setsopen sets} U and V with A Aand⊂ BU, \text{you can find disjoint and} B ⊂ V \text{such that the complement} Y of U ∪ V (\text{that is}, \text{everything in} X \text{that does not belong to eitherat most}$d - 1$. \text{The set} \text{Yis the barrier}—\text{the main differ} - U or V ) \text{has dimension ence is that we have now asked for it to be closed}. \text{the induction starts with the empty set}, \text{which has dimension} - 1. Brouwer’s \text{definition is known as the inductive dimension of a set}. \text{inition of dimension}, \text{proposed by Suppose you want to cover an open interval of real Here is another basic idea that leads to a useful def} - lebesgue [VI.72](/part - 06/henri - lebesgue - 18751941). numbers (that is, an interval that does not contain its endpoints) with shorter open intervals. Then you will beforced to make the shorter ones overlap, but you can do it in such a way that no point is contained in morethan two of your intervals: just start each new interval close to the end of the previous one. (that is, one that does not contain its boundary) with smaller open squares. Again you will be forced to make Now suppose that you want to cover an open square the smaller squares overlap, but this time the situationis slightly worse: some points will have to be contained in three squares. However, if you take squares arranged like bricks, as in figure 1, and expand them slightly, then you can do the covering in such a way that nofour squares overlap. In general, it seems that to cover a typical need to have overlaps ofd-dimensional set with small open sets, youd + 1 sets but you do not need to have overlaps greater than this.The precise definition that this leads to is surprisingly general: it makes sense not just for subsets of R$n$ but even for an arbitrary topological space [III.90](/part-03/topological-spaces). We say that a setever you cover X Xwith a finite collection of open setsis at mostd dimensional if, how-

III. Mathematical Concepts

$UV^{1}$, . . . , V, . . . , Un, you can find a finite collection of open setswith the following properties: 1$m$ (i) the sets V also cover the whole of X;

$i$

(iii) no point is contained in more than(ii) every Vi is a subset of at least one Udi+$; 1 \text{of the}$ V .i

Ifsmall diameter, thereby forcing the X is a metric space, then we can choose our Vi to be small. So Ui to have this definition is basically saying that it is possible tocover X with open sets with no d + 2 of them overlap- ping, and that these open sets can be as small as youlike. be the smallest sion al. And again it can be shown that this definition We then define thed such that topological dimension X is at most dofdimen-X to assigns the “correct” dimension to the familiar shapes of elementary geometry.A fourth intuitive idea leads to concepts known as homological with any suitable topological spaceand cohomological dimension. Associated X, such as a man- ifold, are sequences of groups known asand cohomology groups [IV.6 §4](/part-04/algebraic-topology). Here we will dis-homology cuss homology groups, but a very similar discussion is possible for cohomology. Roughly speaking, the$nth$ homology group tells you how many interestingly dif-ferent continuous maps there are from closedn-dimen- sional manifolds less thann, then it can be shown that the M to X. If X is a manifold of dimension nth homology group is trivial: in a sense, there is not enough room in Xto define any map that is interestingly different from a constant map. On the other hand, thegroup of then-sphere itself is Z, which says that onenth homology can classify the maps from themeans of an integer parameter.n-sphere to itself by It is therefore tempting to say that a space is at least ning maps from dimensional if there is room inside it for interest-n-dimensional manifolds. This thought leads to a whole class of definitions. The homological dimension of a structure Xis defined to be the largest nnth homology group. (It is necessary to consider sub-for which some substructure of X has a nontrivial structures, because homology groups can also be trivial when there is too much room: it then becomes easy to deform a continuous map and show that it is equiva-lent to a constant map.) However, homology is a very general concept and there are many different homology theories, so there are many different notions of homo-logical dimension. Some of these are geometric, but there are also homology theories for algebraic struc-tures: for example, using suitable theories, one can

III.17. Dimension

define the homological dimension of algebraic struc-tures such as rings [III.81 §1](/part-03/rings-ideals-and-modules) or groups [I.3 §2.1](/part-01/fundamental-definitions). This is a very good example of geometrical ideas having an algebraic payoff.Now let us turn to a fifth and final (for this article at least) intuitive idea about dimension, namely the way itaffects how we measure size. If you want to convey how big a shape X is, then a good way of doing so is to give the length oftwo dimensional, and the volume if it is three dimen-X if X is one dimensional, the area if it is sional. Of course, this presupposes that you already know what the dimension is, but, as we shall see, there is a way of deciding which measure is the most appropriate Then the tables are turned: we can actually without determining the dimension in advance.define the dimension to be the number that corresponds to thebest measure. To do this, we use the fact that length, area, and volume scale in different ways when you expand a shape.If you take a curve and expand it by a factor of 2 (in all directions), then its length doubles. More generally, ifyou expand by a factor of C, then the length multiplies byexpand it by C. However, if you take a two-dimensional shape and C, then its area multiplies by C2. (Roughly speaking, this is because each little portion of the shape expands by C“\text{in two directions}” \text{so you have to multiply the area by dimensional shape multiplies by} C twice.) \text{And the volume of a three} - C3: \text{for instance}, \text{the volume of a sphere of radius} 3 \text{is twenty}-\text{seven timesthe volume of a sphere of radius} 1. \text{advance whether we will talk about length}, area, \text{or vol}-\text{It may look as though we still have to decide in ume before we can even begin to think about how the measurement scales when we expand the shape}. \text{But this is not the case}. \text{For instance}, \text{if we expand a squareby a factor of} 2, \text{then we obtain a new square that can be divided up into four congruent copies of the original square}. So, \text{without having decided in advance that we are talking about area}, \text{we can say that the size of thenew square is four times that of the old square}. \text{there are sets to which it is natural to assign a dimen}-\text{This observation has a remarkable consequence}: \text{sion that is not an integer}! \text{Perhaps the simplest exam}-\text{ple is a famous set first defined by cantor} [VI.54](/part - 06/georg - cantor - 18451918) \text{and now known as the follows}. \text{You start with the closed interval Cantor set}. \text{This set is produced as}[0, 1], and call itdle third of$X0$. Then you form a set X: that is, you remove all points between X1 \text{by removing the mid}- union of the closed intervals13 and 23, but leave0 13 and 23$[0themselves$. So,1 3] and [2 3, 1]. Next, you X1 is the

183

remove the middle thirds of these two closed intervalsto produce a set X , so X is the union of the intervals[0,1 9 ], [2 9,1 3 ], [2 3,7 9 2], and2[8 9,1]. is what you get by removing the middle thirds of each In general, Xn is a union of closed intervals, and (Xn)+1 of these intervals—sointervals as X , but they are a third of the size. Once you(Xn)+1 consists of twice as many have produced the sequence$n X^{0}$, X1$, X2$, . . ., you define the Cantor set to be the intersection of all the$X$: that

$i$

is, all the real numbers that remain, no matter how far you go with the process of removing middle thirdsof intervals. It is not hard to show that these are precisely the numbers whose ternary expansions consist just of 0 s and 2 s. (There are some numbers that have two different ternary expansions. For instance, be written either as 0.1 or as 0.02222 . . .. In such case(s1)3 can we take the recurring expansion rather than the ter-minating one. So 1 belongs to the Cantor set.) Indeed, when you remove middle thirds for the3 nth time, you are removing all numbers that have a 1 in theafter the “decimal” (in fact, ternary) point.nth place The Cantor set has many interesting properties. For example, it issure [III.55](/part-03/measures) zero. Briefly, the first of these assertions uncountable [III.11](/part-03/countable-and-uncountable-sets), but it also has meafollows from the fact that there is a different element of the Cantor set for every subset bers (just take the ternary number 0 A of the natural num-.a a a . . ., whereaare uncountably many subsets of the natural numbers.i = 2 whenever i \in  A and ai = 0 otherwise), \text{and ther}(e1()2){3}To justify the second, note that the total length of the intervals making up X is (2)n (\text{since one removes a} third ofcontained in every(Xn)-1 \text{to produce} Xn, its measure must be smaller (Xn)3). Since the Cantor set is thanzero. Thus, the Cantor set is very large in one respect$(^{2}^{3})^{n}$, whatever nnis, which means that it must be and very small in another. A further property of the Cantor set is that it is selfsimilar look at just one of these intervals as the middle thirds. The set X1 consists of two intervals, and if you are repeatedly removed, then what you see is just like the construction of the whole Cantor set, but scaled down by a factor of 3. That is, the Cantor set consists of two copies of itself, each scaled down by a factorof 3. From this we deduce the following statement: if you expand the Cantor set by a factor of 3, then you candivide the expanded set up into two congruent copies of the original, so it is “twice as big.” What consequence should this have for the dimension of the Cantor set? Well, if the dimension isd, then

184

the expanded set ought to be 3 fore, 3 d should equal 2. This means that^d times as big. There-d should be$log 2$/ log 3, which is roughly 0.63. is lessened. As we shall see in a moment, a theory of fractional dimension can be developed with the use-Once one knows this, the mystery of the Cantor set ful property that a countable union of sets of dimen-sion at mostd has dimension at most d. Therefore, the fact that the Cantor set has dimension greater than 0 implies that it cannot be countable (since single points have dimension 0). On the other hand, because the dimension of the Cantor set is less than 1, it is much smaller than a one-dimensional set, so it is no surprise that its measure is zero. (This is a bit like saying thata surface has no volume, but now the two dimensions are 0.63 and 1 instead of 2 and 3.)The most useful theory of fractional dimension is one developed by hausdorff [VI.68](/part-06/felix-hausdor-18681942). One begins with a concept known as Hausdorff measure, which is a nat-ural way of assessing the “$d$-dimensional volume” of a set, even ifin R3 and you want to work out its length by consider-d is not an integer. Suppose you have a curve ing how easy it is to cover it with spheres. A first idea might be to say that the length was the smallest youcould make the sum of the diameters of the spheres. But this does not work: you might be lucky and find thata long curve was tightly wrapped up, in which case you could cover it with a single sphere of small diameter. spheres were required to be small. Suppose, therefore, that we require all the diameters of the spheres to be However, this would no longer be possible if your at mostsum of the diameters to be. The smallerδ. Let L(δ) be the smallest we can then get theδ is, the less flexibility we have, so the larger L(δ)tends to a (possibly infinite) limit L(δ) will be. Therefore, L as δ tends to 0, and we call Now suppose that we have a smooth surface in L the length of the curve. R3 and want to deduce its area from information about covering it with spheres. This time, the area that you can cover with a very small sphere (so small that itmeets only one portion of the surface and that portion is almost flat) will be roughly proportional to thesquare of the diameter of the sphere. But that is the only detail we need to change: letcan make the sum of the squares of the diameters of a A(δ) be the smallest we set of spheres that cover the surface, if all those spheres have diameter at mostδ. Then declare the area of the surface to be the limit of A(δ) as δ \text{tends to} 0. (Strictly speaking, we ought to multiply this limit bythen we get a definition that does not generalize easily.)$π/4$, but

III. Mathematical Concepts

for shapes inwas that for length we considered the sum of the diam-We have just given a way of defining length and area, R3. The only difference between the two eters of small spheres, while for area we considered the sum of the In general, we define the squares of the diameters of small spheres.$d$-dimensional Hausdorff measuredth powers of the diameters.in a similar way, but considering the sum of the a rigorous definition of fractional dimension. It is not We can use the concept of Hausdorff measure to give hard to show that for any shapeone appropriate$d$, in the following sense: if X there will be exactlyc is less than Xis infinite, while ifd, then the c-dimensional Hausdorff measure ofc is greater than d, then it is 0. (For instance, thea smooth surface is 0 if$c$-dimensional Hausdorff measure of$c <$2 and infinite if$c > 2$.) Thisddorff dimension is very useful for analyzing fractal sets, is called the Hausdorff dimension of the set X. Haus- which are discussed further in It is important to realize that the Hausdorff dimen-dynamics [IV.14](/part-04/dynamics). sion of a set need not equal its topological dimension.For example, the Cantor set has topological dimension zero and Hausdorff dimension log 2/ log 3. A larger example is a very wiggly curve known as the snowflake. Because it is a curve (and a single point is Koch enough to cut it into two) it has topological dimen-sion 1. However, because it is very wiggly, it has infinite length, and its Hausdorff dimension is in factlog 4/ log 3. III.18 Distributions

Terence Tao

A function is normally defined to be an object f:$X \to Y$ which assigns to each pointx in a set X, known as the domain range (see, a pointthe language and grammar of mathe-f (x) in another set Y , known as the maticsset-theoretic and the fundamental operation that one[I.2 §2.2](/part-01/language-and-grammar)). Thus, the definition of functions is can perform on a function ismentx of X, one evaluates f a te va lu at io nx to obtain the element: given an elef (x)However, there are some fields of mathematics whereof Y . this may not be the best way of describing functions.In geometry, for instance, the fundamental property of a function is not necessarily how it acts on points, butrather how it pushes forward or pulls back objects that are more complicated than points (e.g., other functions, bundles sheaves, etc.). Similarly, in analysis, a function need not[IV.6 §5](/part-04/algebraic-topology) and sections, schemes [IV.5 §3](/part-04/arithmetic-geometry) and

III.18. Distributions

necessarily be defined by what it does to points, butmay instead be defined by what it does to objects of different kinds, such as sets or other functions; the for-mer leads to the notion of a measure; the latter to that of a distribution. like objects are related. In analysis, it is helpful to think Of course, all these notions of function and functionof the various notions of a function as forming a spec-trum, with very “smooth” classes of functions at one end and very “rough” ones at the other. The smooth classes of functions are very restrictive in their membership: this means that they have good properties, andthere are many operations that one can perform on them (such as, for example, differentiation), but it also means that one cannot necessarily ensure that the func-tions one is working with belong to this category. Conversely, the rough classes of functions are very general and inclusive: it is easy to ensure that one is working with them, but the price one pays is that the number of operations one can perform on these functions is often sharply reduced (see function spaces [III.29](/part-03/function-spaces)). often be treated in a unified manner, because it is Nevertheless, the various classes of functions can often possible to approximate rough functions arbitrar-ily well (in an appropriate topology [III.90](/part-03/topological-spaces)) by smooth ones. Then, given an operation that is naturally defined for smooth functions, there is a good chance that therewill be exactly one natural way to extend it to an operation on rough functions: one takes a sequence of better and better smooth approximations to the rough func-tions, performs the operation on them, and passes to the limit. rough end of the spectrum, but before we say what Distributions, or generalized functions, belong at the they are, it will be helpful to begin by considering some smoother classes of functions, partly for comparison and partly because one obtains rough classes of func-tions from smooth ones by a process known as duality: ais simply a linear maplinear functional defined on a spaceφ from E to the scalars E of functions R or C. Typically, topology, and the E is a normed space, or at least comes with adual space is the space of continuous linear functionals. The class Cω[-1, 1] of analytic functions. These are in many ways the “nicest” functions of all, and include many familiar functions such as exp(x), sin(x), poly - nomials, \text{and so on}. However, \text{we shall not discuss them further}, \text{because for many purposes they form too rigida class to be useful}. (\text{For example}, \text{if an analytic func} - 185 \text{tion is zero every where on an interval}, \text{then it is forcedto be zero every where}.) \text{The class} C\infty [-1, 1] \text{of test functions}. \text{These are the} c smooth (\text{that is}, infinitely \text{differentiable}) \text{functions defined on the interval}[-1, 1], \text{that vanish on neighbor} - f , \text{hoods of} 1 andf$(x) = 0 whenever - 1$. (\text{That is}, \text{one can findx} > 1 - δ or x < -1δ >+ δ0 \text{such that}.) \text{They are more numerous than analytic functions and therefore more tractable for analysis}. \text{For instance}, \text{it is often use}-\text{ful to construct smooth} “\text{cutoff functions},” \text{which are functions that vanish outside some small set but do notvanish inside it}. Also, \text{all the operations from calculus} (\text{differentiation}, integration, composition, convolution, evaluation, etc.) \text{are available for these functions}. \text{The class}$C0[-1$, 1] \text{of continuous functions}. These functions are regular enough for the notion of evalua-tion,$x \to f (x)$, to make sense for every x \in  [-1, 1], and one can integrate such functions and perform algebraic operations such as multiplication and compo-sition, but they are not regular enough that operations such as differentiation can be performed on them.Still, they are usually considered among the smoother examples of functions in analysis. The class L2[-1, 1] \text{of square} - \text{integrable functions}. These are measurable functions which the Lebesgue integral 1 f|f (x):[-|12$, d1 x]\text{is finite}$.$\to R for$\text{Usually one regards two such functions equal if the set ofx} \text{such that} - 1 f (x) =f g(x)\text{and ghasas} \text{measure zero}. (Thus, \text{from the set}-\text{theoretic point ofview}, \text{the object in question is really an equivalence class} [I.2 §2.3](/part - 01/language - and - grammar) \text{of functions}.) \text{Since a singleton}${x} has$\text{measure zero}, \text{we can change the value ofout changing the function}. Thus, \text{the notion of evalua} - f (x) with- \text{tion does not make sense for a square}-\text{integrable func} - tionf (x)\text{at any specific pointx}. However, \text{two func}- \text{tions that differ on a set of measure zero have thesame lebesgue integral} [III.55](/part - 03/measures), so integration does make sense. in the following sense. Any two functions in thisclass can be paired together by the A key point about this class is that it isinner product self-dual $\text{gtional onf}$, g \in L =2[-1 L-1,2 11[f (x)g(x)]-, the map1, 1], which turns out to be continuous.dfx→ . Therefore, given a functionf , gdefines a linear func Moreover, given any continuous linear functional L2[-1,1], there is a unique function g \in  L2[-1,1]φsuchon thatφ(f ) = f , g for every f . This is a special case of one of the Riesz representation theorems.

186

The class$C0[-1$, 1]*of finite Borel measures. Any finite Borel linear functional onmeasure C[III.55](/part-03/measures)0[-1,μ1]gives rise to a continuous defined byf → μ, f  = rems says that every continuous linear functional on C-1 0 1[f (x)-1, 1 d]\mu arises in this way, so one could in principle. Another of the Riesz representation theo- define a finite Borel measure to be a continuous linear functional on$C0[-1$, 1].\text{The class} C\i\text{nf ty} [-1, 1]* of distributions. Just as mea- c sures can be viewed as continuous linear functionals on C0[-1, 1], \text{a distribution} μ \text{is a continuous linear} functional on C\infty [-1,1] (with an appropriate topol- c ogy). Thus, \text{a distribution can be viewed as a} “\text{virtual function}”: \text{it cannot itself be directly evaluated}, \text{or even integrated over an open set}, \text{but it can still be paired with any test functiong} \in C \infty [-1, 1], \text{producing a num} - c berδ, \text{defined as the functional which}, \text{when paired with}\mu, g . A \text{famous example is the Dirac distribution} \text{any test function zero}:0δ$, g = g(g0, \text{returns the evaluation})$. Similarly, we have the derivativeg(0) of g at of the Dirac distribution, any test function0 g, \text{returns the derivative}-δ0, which, when paired withg^ (0) of g at zero: will be given later.) Since test functions have so many-δ0$, g = g^ (0)$. (The reason for the minus sign operations available to them, there are many ways todefine continuous linear functionals, so the class of distributions is quite large. Despite this, and despite theindirect, virtual nature of distributions, one can still define many operations on them; we shall discuss thislater. The class Cω[-1, 1]* \text{of \text{\text{hyperfunctions}}}. \text{There are} classes of functions more general still than distribu-tions. For instance, there are hyperfunctions, which roughly speaking one can think of as linear function-als that can be tested only against analytic functions g C \infty \in [-C1ω, [1-]. However, as the class of analytic functions1,1] rather than against test functions g \in is so sparse, hyperfunctions tend not to be as useful inanalysis as distributions. ited utility, since all a distribution is to be tested against test functions At first glance, the concept of a distribution has lim-\mu is empowered to dog to produce inner products can often take operations that are initially defined only\mu, g . However, using this inner product, one on test functions, and duality. A typical example is differentiation. suppose extend them to distributions by one wants to know how to define the derivativea distribution, or in other words how to define\mu\mu^, gof

III. Mathematical Concepts

for any test functiona test function\mu = fg, then we can evaluate this usingand distribution \mu. If \mu is itself integration by parts (recalling that test functions vanishat-1 and 1). \text{We havef}^ , g =-1 1 f^ (x)g(x) dx= −-1 1 f (x)g^ (x) dx = −f , g^ . \text{Note that ifg is a test function}, \text{then so is} g^ . \text{We can therefore generalize this formula to arbitrary distribu}-\text{tions by defining}\mu^, g = −\mu, g^. This is the justification for the differentiation of the Dirac distribution:δ^, g = −δ , g^ = −g^ (0). \text{More formally}, \text{what we have done here is to com} - 0 0 \text{pute the adjoint of the} \text{differentiation} operation (\text{asdefined on the dense space of test functions}). \text{Then we have taken adjoints again to define the} \text{differentiation} \text{operation for general distributions}. \text{This proce}-\text{dure is well}-\text{defined and also works for many other concepts}; \text{for instance}, \text{one can add two distributions}, \text{multiply a distribution by a smooth function}, \text{convolve two distributions}, \text{and compose distributions on both the left and the right with suitably smooth functions}. \text{One can even take Fourier transforms of distributions}.\text{For instance}, \text{the Fourier transform of the Dirac delta}δ \text{is the constant function} 1, \text{and vice versa} (\text{this is essen} - 0 \text{tially the Fourier inversion formula}), \text{while the distribu} - tionδ (x - n) \text{is its own Fourier transform} (\text{this is essentially the Poisson summation formula}). Thus,$n \in ^{Z})^{0}$ the space of distributions is quite a good space to workin, in that it contains a large class of functions (e.g., all measures and integrable functions), and is also closed under a large number of common operations in analy-sis. Because the test functions are dense in the space of distributions, the operations as defined on distributions are usually compatible with those on test func-tions. For instance, iff and g are test functions andf^  = g in the sense of distributions, then f^  = g will also be true in the classical sense. This often allowsone to manipulate distributions as if they were test functions without fear of confusion or inaccuracy. The main operations one has to be careful about are evalua-tion and pointwise multiplication of distributions, both of which are usually not well-defined (e.g., the square of the Dirac delta distribution is not well-defined as a distribution). \text{Another way to view distributions is as the weak limit of test functions}. A \text{sequence of functions converge weakly to a distribution}\mu if f , gfn → \text{is said to}\mu, \text{gn III}.19. \text{Duality for all test functions tion with total integralg}. \text{For instance}, if1 φ = 1, \text{then the test func}-φ \text{is a test func}- \text{tions weakly to the Dirac delta distribution fn}(x) = nφ(nx)-1 \text{can be shown to converge}δ , \text{while the functions derivativef}δn^ (x)\text{of the Dirac delta}. \text{On the other hand},= n2φ^ (nx) \text{converge weakly to the}0 \text{the functionsto zero} (\text{this is a variant of the}0$gn(x) = \cos (nx)φ(x)$ Riemann–\text{lebesgue converge weakly lemma}). \text{Thus weak convergence has some unusual features not present in stronger notions of convergence}, \text{in that severe oscillations can sometimes} “disappear” \text{in the limit}. \text{One advantage of working with distribu}-\text{tions instead of smoother functions is that one often has some compactness in the space of distributions under weak limits} (e.g., \text{by the Banach}–\text{Alaoglu theorem}). Thus, \text{distributions can be thought of as asymp}-\text{totic extremes of behavior of smoother functions}, \text{just as real numbers can be thought of as limits of rational numbers}. \text{while still being closely connected to smoother func} - tions, \text{they have been extremely useful in the study of Because distributions can be easily} \text{differentiated}, \text{partial differential equations} (PDEs), \text{particularly whenthe equations are linear}. \text{For instance}, \text{the general solution to a linear PDE can often be described in termsof its fundamental solution}, \text{which solves the PDE in the sense of distributions}. \text{More generally}, \text{distribution theory} (\text{together with related concepts}, \text{such as that of anot the only}) \text{means to define weak derivative}) \text{gives an important} (\text{though certainly generalized solutions of both linear and nonlinear PDEs}. \text{As the name suggests}, \text{these generalize the concept of smooth} (\text{orsolutions by allowing the formation of singularities}, classical) shocks, \text{and other nonsmooth behavior}. \text{In some casesthe easiest way to construct a smooth solution to a PDE is first to construct a generalized solution and then touse additional arguments to show that the generalized solution is in fact smooth}. III.19 \text{Duality Duality is an important general theme that has manifes}-\text{tations in almost every area of mathematics}. \text{Over and over again}, \text{it turns out that one can associate with agiven mathematical object a related}, “dual” \text{object that helps one to understand the properties of the objectone started with}. \text{Despite the importance of duality in mathematics}, \text{there is no single definition that covers all instances of the phenomenon}. \text{So let us look at a} 187 \text{few examples and at some of the} \text{characteristic} \text{features that they exhibit}. 1 \text{Platonic Solids Suppose you take a cube}, \text{draw points at the centers ofeach of its six faces}, \text{and let those points be the vertices of a new polyhedron}. \text{The polyhedron you get willbe a regular octahedron}. \text{What happens if you repeat the process}? \text{If you draw a point at the center of eachof the eight faces of the octahedron}, \text{you will find that these points are the eight vertices of a cube}. \text{We say thatthe cube and the octahedron are dual to one another}. \text{The same can be done for the other Platonic solids}: \text{the dodecahedron and the icosahedron are dual to one another}, \text{while the dual of a tetrahedron is again a tetrahedron}.\text{The duality just described does more than just split up the five Platonic solids into three groups}: \text{it allows usto associate statements about a solid with statements about its dual}. \text{For instance}, \text{two faces of a dodecahe}-\text{dron are adjacent if they share an edge}, \text{and this is so if and only if the corresponding vertices of the dual icosahedron are linked by an edge}. \text{And for this reason there is also a} \text{correspondence} \text{between edges of the dodecahedron and edges of the icosahedron}. 2 \text{Points and Lines in the Projective Plane There are several equivalent definitions of the projective planethat it is the set of all lines in}[I.3 §6.7](/part - 01/fundamental - definitions). One, \text{which we shall use here}, is R3 \text{that go through the origin}. \text{These lines we call the} “points” \text{of the projec}-\text{tive plane}. \text{In order to visualize this set as a geometrical object and to make its} “points” \text{more point} - like, \text{itis helpful to associate each line through the origin with the pair of points in} R3 \text{at which it intersects the unit sphere}: indeed, \text{one can define the projective plane asthe unit sphere with opposite points identified}. all “points” (\text{that is}, \text{lines through the origin}) \text{that lie insome plane through the origin}. \text{This is associated with} A typical “line” \text{in the projective plane is the set of the great circle in which that plane intersects the unit sphere}, \text{once again with opposite points identified}. \text{points in the projective plane}: \text{each point} P \text{is associated with the line} L \text{that consists of all points orthogonal to There is a natural association between lines and} P, \text{and each line} L \text{is associated with the single point} P \text{that is orthogonal to all points in} L. \text{For example}, if P isthez - axis, \text{then the associated projective line} L \text{is the set of all lines through the origin that lie in thexy} - plane, 188 \text{and vice versa}. \text{This association has the following basic property}: \text{if a point} P \text{belongs to a line} L, \text{then the line associated with} P \text{contains the point associated with} L.\text{This allows us to translate statements about points and lines into logically equivalent statements about lines and points}. \text{For example}, \text{three points are collinear} (\text{that is}, \text{they all lie in a line}) \text{if and only if the corre}-\text{sponding lines are concurrent} (\text{that is}, \text{there is some point that is contained in all of them}). \text{In general}, \text{onceyou have proved a theorem in projective geometry}, \text{you get another}, dual, \text{theorem for free} (\text{unless the dual theorem turns out to be the same as the original one}). 3 Sets and Their Complements Let ple ment X be a set. Ifof A, written A is any subset of Ac, is the set of all elements of X, then the com-X that do not belong toplement of A is clearly A. The complement of the com-A, so there is a kind of dual- ity between sets and their complements.laws are the statements that$(A ∩ B)c =$ De Morgan’s Ac ∪ Bc and(A ∪ B)c = Ac ∩ Bc: they tell us that complement at i on “turns intersections into unions,” and vice versa. Notice that if we apply the first law to Ac and Bc, then we find that(Ac ∩ Bc)c = A ∪ B. Taking complements of both sides of this equality gives us the second law. ing unions and intersections remains true when you interchange them. For example, one useful identity is Because of de Morgan’s laws, any identity involv$A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C)$. Applying this to the complements of the sets and using de Morgan’s laws, itis straightforward to deduce the equally useful identity

$A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C)$. 4 \text{Dual Vector Spaces Letspace}V be a V^*is defined to be the set of allvector space [I.3 §2.3](/part-01/fundamental-definitions), over linear functionals R, say. The dual on$V$: that is, linear maps from V to R. It is not hard to define appropriate notions of addition and scalar mul-tiplication and show that these make$V^{*} \text{into a vector}$ space as well.Suppose that T is a linear map[I.3 §4.2](/part-01/fundamental-definitions) from a vector spacementw* of the dual space V to a vector space W W*, then we can use. If we are given an ele-T andwthat takes* to create an element ofv to the real number V*as follows: it is the map$w^{*}(T v)$. This map, which is denoted byear. The function T*T*is itself a linear map, called thew*, is easily checked to be lin- adjointof$V^{*}$. of T, and it takes elements of W* to elements

III. Mathematical Concepts

object This is a typical feature of duality: a function A to object B very often gives rise to a functionf fromg from the dual of Suppose that T*Bis a surjection. Then ifto the dual of A. v = v^ , we can find$v^{*} \text{such that} v^{*}(v) = v^{*}(v^ )$, and thenw T^*^*w\in^*(v W^*^ ), \text{and therefore such that} T*w*w=*v(T v)*$, \text{so that} = w*T(T v*w*)(v)$. This= implies thattion. We can also prove that if T v = T v^ , which proves that T* is an injection, then T is an injec-T is a surjection. Indeed, if T is not a surjection, then T Va nonzero linear functional is a proper subspace of Ww*, which allows us to findsuch that w*(T v) = 0\text{for every contradicts the injectivity ofv} \in V , \text{and hence such that} T*. \text{If VTand}*w*W=\text{are finite}0, \text{which dimensional}, thenthat T \text{is an injection if and only if}(T*)* = T, \text{so in this case we find}$T* \text{is a surjection}$, \text{and vice versa}. Therefore, \text{we can use duality to convert an existence problem into a uniqueness problem}.\text{This conversion of one kind of problem into a different kind is another} \text{characteristic} \text{and very useful featureof duality}. \text{tion of the dual space may well change}. \text{For instance}, \text{if XIf a vector space has additional structure}, \text{the defini}-\text{is a real} [III.62](/part - 03/normed - spaces - and - banach - spaces), then X*is defined to be the space of allfrom X to Rbanach space, rather than the space of continuous linear functionals all linear func- tionals. This space is also a Banach space: the norm of a continuous linear functional$\sup {|f (x)|}$:$x \in X$, x ⩽ 1. If X is an explicit exam-fis defined to be ple of a Banach space (such as one of the spaces dis-cussed in function spaces [III.29](/part-03/function-spaces)), it can be extremely useful to have an explicit description of the dual space.That is, one would like to find an explicitly described Banach space Y and a way of associating with each nonzero element functionalφdefined ony of Y a nonzero continuous linear X, in such a way that every continuous linear functional is equal to$y \in Y$.y φy \text{for some} and From this perspective, it is more natural to regard Yas having the same status. We can reflect this in$X$ our notation by writingdo this, then we are drawing attention to the fact that$x$, y \text{instead of} φy(x). \text{If we the mapnumber}·x, y, ·, \text{which takes the pair}, \text{is a continuous bilinear map from}(x, y) \text{to the real} X \times Y to R. \text{More generally}, \text{whenever we have two mathematical objectsa function} A andβ: AB, \text{a set} \times B \to SSof “scalars” \text{of some kind}, \text{andthat is a structure}-\text{preserving map in each variable separately}, \text{we can think of the III}.19. \text{Duality elements ofversa}. \text{Functions like} A \text{as elements of the dual of}β \text{are called pairings}. B, \text{and vice} 5 \text{Polar Bodies Let}X \text{be a subset of}[III.37](/part - 03/bayesian - analysis) on Rn \text{and let} Rn. \text{Then the}· , · \text{be the standard polar of} X, \text{inner product denoted} X◦, is the set of all points y \in  Rn such that Xconvex, thenx, y◦ is closed and convex, and that if⩽ 1 for every(X◦)◦ =x X\in . Further more, if X. It is not hard to check that X is closed andn = 3 and X is a Platonic solid centered at the origin, then X◦ is (a multiple of) the dual Platonic solid, and ifball” of a normed space (that is, the set of all points of$X$is the “unit norm at most 1), then$X^{◦}$is (easily identified with) the unit ball of the dual space. 6 Duals of Abelian Groups if homomorphism from G is an Abelian group, then a G to the group character T of all complexon G is a numbers of modulus 1. Two characters can be multi-plied together in an obvious way, and this multiplication makes the set of all characters on Abelian group, called the dual group, ˆG, of the group G into another G. Again, ifimposes an additional continuity condition.G has a topological structure, then one usually An important example is when the group is itself T. It is not hard to show that the continuous homomor-phisms from T to T all have the form ei$θ \to (e^{i})^{n}θ for$ some integer the dual of Tnis (isomorphic to)(which may be negative or zero). Thus, Z. tryagin duality ing between This form of duality between groups is called$G$. Note that there is an easily defined pair-and ˆ$G$: given an element$g \in G \text{and a Pon}-$ character$ψ \in G$ˆ, we defineg, ψ to be ψ(g). functions$G$ˆ Under suitable conditions, this pairing extends toare finite, and defined onf G: and ˆG \to G. For instance, if C and F: ˆ$G G \to and C$, \text{then we can define}|G|-1 f (g)F(ψ)f , F to be the complex number. In general, one obtains a pairing between a complex functions on$g \in^{G} G^{ψ} \in$and a Hilbert space of functions on ˆGˆ hilbert space [III.37](/part-03/bayesian-analysis) of G. duality. Given a function in the Hilbert spaceits This extended pairing leads to another important Fourier transform is the function ˆ$f \in (ZL)^{2}that(T)$, is defined by the formula f (n)ˆ= 21π0 2 π f ((ei)θ)(e-i)nθ dθ. The Fourier transform, which can be defined similarly for functions on other Abelian groups, is immensely

189

useful in many areas of mathematics. (See, for exam-ple, fourier transforms [III.27](/part-03/the-fourier-transform) and representation theory examples, it is[IV.9](/part-04/representation-theory).) By contrast with some of the previous not always easy to translate a statement about a function about its Fourier transform ˆf into an equivalent statementf , but this is what gives the Fourier transform its power: if you wish to under-stand a function fdef in ed on T, then you can explore its properties by looking at both$f$and ˆf . Some proper- ties will follow from facts that are naturally expressedin terms off and others from facts that are naturally expressed in terms of ˆ“doubles one’s mathematical power.”f . Thus, the Fourier transform 7 Homology and Cohomology Let If MX andbe a compact M^  are ann-dimensional i-dimensional submanifold and manifold[I.3 §6.9](/part-01/fundamental-definitions). an(n - i)-dimensional submanifold of X, respectively, and if they are well-behaved and in sufficiently general position, then they will intersect in a finite set ofpoints. If one assigns either 1 or-1 \text{to each of these} points in a natural way that takes account of howand M^  intersect, then the sum of the numbers at the M points is an invariant called the M and M^ . This number turns out to depend only on intersection number of theit defines a map from homology classes H (X)[IV.6 §4](/part-04/algebraic-topology) of\times  H^- (X)M andto Z, where we M^ . Thus, writeis a group homomorphism in each variable separately, Hr (X) for the r th homology group o(fi()n)i X. This map and the resulting pairing leads to a notion of duality called Poincaré duality, and ultimately to the modern theory ofwith some of our other examples, many concepts asso-cohomology, which is dual to homology. As ciated with homology have dual concepts: for exam-ple, in homology one has a boundary map, whereas in cohomology there is adirection). Another example is that a continuous map coboundary map (in the opposite from X to Y gives rise to a homomorphism from the homology groupand also to a homomorphism from the cohomology Hi(X) \text{to the homology group} Hi(Y ), group Hi(Y ) \text{to the cohomology group} Hi(X). 8 Further Examples Discussed in This Book The examples above are not even close to a complete list: even in this book there are several more. For instance, the article oncusses a pairing, and hence a duality, between differential forms [III.16](/part-03/dierential-forms-and-integration) dis-k-forms and integrating the form over the surface.) The article onk-dimensional surfaces. (The pairing is given by

190

distributions rigorous definitions of function-like objects such as the[III.18](/part-03/distributions) shows how to use duality to give Dirac delta function. The article on[IV.16](/part-04/mirror-symmetry) discusses an astonishing (and still largely con-mirror symmetry jectural) duality between and so-called “mirror manifolds.” Often the mirror calabi–yau manifolds [III.6](/part-03/calabiyau-manifolds) manifold is much easier to understand than the origi-nal manifold, so this duality, like the Fourier transform, makes certain calculations possible that would otherwise be unthinkable. And the article ontion theory [IV.9](/part-04/representation-theory) discusses the “Langlands dual” of represent a certain (non-Abelian) groups: a proper understanding of this duality would solve many major open problems. III.20 Dynamical Systems and Chaos From a scientific point of view, a dynamical system is aphysical system, such as a collection of planets or the water in a canal, that changes over time. Typically, the positions and velocities of the parts of such a system at a timeties of those parts just before that time, which meanst depend only on the positions and veloci- that the behavior of the system is governed by a systemof partial differential equations [I.3 §5.3](/part-01/fundamental-definitions). Often, a very simple collection of partial differential equations can lead to very complicated behavior of the physical system. tem is any mathematical object that evolves in time From a mathematical point of view, a dynamical sys according to a precise rule that determines the behaviorof the system at timet from its behavior just before- hand. Sometimes, as above, “just beforehand” refers toa time infinitesimally earlier, which is why calculus is involved. But there is also a vigorous theory of discrete dynamical systems, where the “time”values, and the “time just before$t$” istt-takes integer1. If f is the function that tells us how the system at timeon the system at timet - 1, then the system as a wholet depends can be thought of as the process ofapplyingf over and over again. iterating f: that is, function iterate it enough times. In particular, some of the most As with continuous dynamical systems, a very simplef can lead to very complicated behavior if you interesting dynamical systems, both discrete ones and continuous ones, exhibit an extreme sensitivity to initial conditions, which is known asfor example, of the equations that govern weather. Onechaos. This is true, cannot hope to specify exactly the wind speed at every point on the Earth’s surface (not to mention high above

III. Mathematical Concepts

it), which means that one has to make do with approx-imations. Because the relevant equations are chaotic, the resulting inaccuracies, which may be small to start with, rapidly propagate and overwhelm the system: youcould start with a different, equally good approximation and find that after a fairly short time the systemhad evolved in a completely different way. This is why accurate forecasting is impossible more than a few days in advance.For more about dynamical systems and chaos, see dynamics [IV.14](/part-04/dynamics). III.21 Elliptic Curves Jordan S. Ellenberg An elliptic curve over a field algebraic curve of genus 1 over KK, endowed with a pointcan be defined as an defined over tastes, then an equivalent definition is the following: an K. If this definition is too abstract for your elliptic curve is a curve in the plane determined by anequation of the form y2 + a1 xy + a3 y = x3 + a2 x2 + a4 x + a6. (1) When the characteristic ofform this equation into the simpler form K is not 2, \text{we can trans} - y2 = f (x), for some cubic polynomial tic curve is a rather concrete object. However, this def-f . In this sense, an ellip- inition has given rise to a subject of seemingly inexhaustible mathematical interest, which has provided atremendous fund of ideas, examples, and problems in number theory and algebraic geometry. This is in part because there are many values of “$X$” for which it is the case that “the simplest interesting example of X is an elliptic curve.”For instance, the points of an elliptic curve E with coordinates inwhich we call E(K)K naturally form an Abelian group,. The connected projective vari- eties [III.95](/part-03/varieties) that admit a group law of this kind are calledthe Abelian varieties that are one dimensional. The Abelian varieties; and elliptic curves are just Mordell–Weil theorem tells us that, whenfield and A is an Abelian variety, A(K)Kis actually ais a number finitely generated group; these Abelian groups are much studied but Abelian group, called a Mordell–Weil have retained much of their mystery (see rational points on curves and the mordell conjecture[V.29](/part-05/rational-points-on-curves-and-vi40-ernst-eduard-kummer-18101893)). Even when A is an elliptic curve, in which case we would call itdo not know, though E instead, there is a great deal that wethe birch–swinnerton-dyer conjecture [V.4](/part-05/the-birchswinnerton-dyer-conjecture) offers a conjectural formula for the

III.22. The Euclidean Algorithm and Continued Fractions rank of the groupof rational points on elliptic curves, see E(K). For much more on the topic arithmetic geometry [IV.5](/part-04/arithmetic-geometry). pthat Sinceone can look at the subgroup of elementsp P E(K)= 0. This subgroup is called forms an Abelian group, given any prime E(K)[p]. In par-P such ticular, we can take the algebraic closur\bar{e}look at E(K)[p] ̄ . It turns out that, when KK is aof K and ber field ac ter i st ic not equal to[III.63](/part-03/number-fields) (or, for that matter, any field of char-p), \text{this group is isomorphic tonum}-(Z/p Z)2, \text{no matter what choice of} E \text{we started with}. \text{If the group is the same for all elliptic curves}, \text{why is it interesting}? \text{Because it turns out that the galois group} [V.21](/part - 05/the - insolubility - of - the - quintic) \text{Galaction of Gal}$(K/K) ̄$(K/K) ̄ \text{permutes the seton the group}$(E(Z/p K)[p] ̄ Z$)2 \text{gives rise to}. \text{In fact}, \text{the aa foundational example in the theory of} \text{representation} [III.77](/part - 03/\text{representations}) \text{of the Galois group}. \text{This is Galois} \text{representations}, \text{which has become central to contemporary number theory}. Indeed, \text{the proof oftheorem} [V.10](/part - 05/fermats - last - theorem) \text{by Andrew Wiles is in the end a the} - fermat’s \text{last orem about the Galois} \text{representations} \text{that arise from elliptic curves}. \text{And what Wiles proved about these special Galois} \text{representations} \text{is itself a small special case of the family of conjectures known as the program}, \text{which proposes a thoroughgoing correspon}-\text{Langlands dence between Galois} \text{representations} andforms, \text{which are generalized versions of the classical automorphic analytic functions called modular forms} [III.59](/part - 03/modular - forms). Cates, \text{which we denote}, \text{then the set of points of In another direction}, if E(CE), \text{is a Eis an elliptic curve overwith complex coordin}-\text{complex manifold} [III.88 §3](/part - 03/symplectic - manifolds). \text{It turns out that this manifold can always beexpressed as the quotient of the complex plane by a certain group} \text{transformations} \text{are just translations}: \text{each map sends}Λ of \text{transformations}. \text{What is more}, \text{thesezsion ofto} z + E(c \text{Cfor some complex number}) \text{as a quotient is carried out with the helpc}. (\text{This expres}- \text{of elliptic functions} [V.31](/part - 05/the - riemannroch - theorem).) Each elliptic curve gives rise in this way to a subset—indeed, a subgroup—ofthe complex numbers; the elements of this subgroup are called tion can be regarded as the very beginning ofperiods of the elliptic curve. This construc-Hodge theory, a powerful branch of algebraic geometry with a reputation for extreme difficulty. (Theture, a central question in the theory, is one of the Clay Hodge conjec Institute’s million-dollar-prize problems.)Yet another point of view is presented by the moduli space itself a curve, but not an elliptic one. (In fact, if I am[IV.8](/part-04/moduli-spaces) of elliptic curves, denoted$M1^{\}\\{}}$,\\\\\\\\\\\\\\\\\\\}1. This is completely honest, I should say that$M1\\{}$,\\\\\\\\\\\\\\\\\\}1 \text{is not quite a}}}

191

curve at all—it is an object called, depending on whomyou ask, an orbifold [IV.4 §7](/part-04/algebra) or an algebraic stack— you can think of it as a curve from which someone has removed a few points, folded the points in half or into thirds, and then glued the folded-up points back in. You might find it reassuring to know that even pro-fessionals in the subject find this process rather difficult to visualize.) The curveple” in two ways: it is the simplest$M1^{\}\\{}}$,\\\\\\\\\\\\\\\\\\\\}1}}is a “simplest exam-modular curve, and simultaneously the simplest moduli space of curves. III.22 The Euclidean Algorithm and

Continued Fractions

Keith Ball

1 The Euclidean Algorithm

the fundamental theorem of arithmetic [V.14](/part-05/the-fundamental-theorem-of-arithmetic),

which states that every integer can be factored into primes in a unique way, has been known since antiquity. The usual proof depends upon what is known as the Euclidean algorithm, which constructs the highest common factor (h, say) of two numbers m and n. In doing so, it shows thatam+ bn for some pair of integersh can be written in the forma, b (not necessarily positive). \text{For example}, \text{the highest common factor of} 17 and 7 is 1, \text{and sure enough we can express} 1 \text{as the combination} 1= 5 \times 17 - 12 \times 7. The algorithm works as follows. Assume thatm is larger than quotientq nand a nonnegative remainder and start by dividing m byr nthat is lessto yield a than$n$. \text{Then we hav}(e1)1 m = q1 n + r1. (1)

Now since second quotient and remainder: r1 < n we may divide n by r1 to obtain an = q2 r1 + r2. (2)

Continue in this way, dividingon. The remainders get smaller each time but cannot$r^{1} by r^{2}$, r2 by r3, and so go below zero. So the process must stop at some pointwith a remainder of 0: that is, with a division that comes out exactly. For instance, if$m = 165 and n = 70$, the algorithm generates the sequence of divisions 165$= 2 \times 70 + 25$, (3) 70$= 2 \times 25 + 20$, (4) 25$= 1 \times 20 + 5$, (5)$20$= 4 \times 5 + 0. (6)

192

The process guarantees that the last nonzero remain-der, 5 in this case, is the highest common factor of$m$ andn. On the one hand, the last line shows that 5 is a factor of the previous remainder 20. Now the last-but-one line shows that 5 is also a factor of the remainder 25 that occurred one step earlier, because 25 isexpressed as a combination of 20 and 5. Working back up the algorithm we conclude that 5 is a factor of bothm = 165 and n = 70. So 5 is certainly a common factor of On the other hand, the last-but-one line shows thatm and n. 5 can be written as a combination of 25 and 20 with integer coefficients. Since the previous line shows that 20 can be written as a combination of 70 and 25 we canwrite 5 in terms of 70 and 25: 5$= 25 - 20 = 25 - (70 - 2 \times 25) = 3 \times 25 - 70$. Continuing back up the algorithm we can express 25 in terms of 165 and 70 and conclude that 5$= 3 \times (165 - 2 \times 70) - 70 = 3 \times 165 - 7 \times 70$. of 165 and 70 because any factor of 165 and 70 would automatically be a factor of 3 This shows that 5 is the\times highest165 - 7 common factor\times70: that is, a factor of 5. Along the way we have shown that the high-est common factor can be expressed as a combination of the two original numbersm and n. 2 Continued Fractions for Numbers During the 1500 years following Euclid, it was realizedby mathematicians of the Indian and Arabic schools that the application of the Euclidean algorithm to a pairof integersm and n could be encoded in a formula for the ratiom/n. The equation (1) can be writtenmn = q1 + rn1 = q1 + F1 ,

where$F = n/r^{1}$. Now equation (2) expressesr2 F as F = q2 + r1.

The next step of the algorithm will produce an expres-sion forr /r and so on. If the algorithm stops afterk steps, then we can put these expressions together t(o1)2 get what is called the continued fraction for$m/n$:

$m = q1 + 11$.n q2 +q 3^+ . .

.$+q 1 k$

For example,

16570$= 2 + 2 + 11$.$1$+1

III. Mathematical Concepts

from the ratio 165 ence to the integers 165 and 70. We start by subtract-The continued fraction can be constructed directly/70 = 2.35714 . . . \text{without refer}-$\text{ing from} 2$.35714 . . .the largest whole number we can: namely 2. Now we take the reciprocal of what is left:1$/0$.35714 . . . = 2.$8$. Again we subtract off the largest integer we can, 2, which tells us thatrocal of 0$.8 is 1$.25, so q =$1 \text{and then}$, finally, 1$q2 = 2$. \text{The recip}-/0.25 =$4$, so The mathematician John Wallis, who worked in theq4 = 4 and the continued fraction stops.3 seventeenth century, seems to have been the first to give a systematic account of continued fractions andto recognize that continued-fraction expansions exist for all numbers (not only rational numbers), \text{provided that we allow the continued fraction to have infinitely many levels}. \text{If we start with any positive number}, \text{wecan build its continued fraction in the same way as for the ratio} 2 isπ = 3.14159265.35714. . .. . ., \text{we start by subtracting} 3, then. \text{For example}, \text{if the number take the reciprocal of what is left}: 1$/0$.14159 . . . =7 is 7. Continuing the process we build the continued.06251 . . . . So for π we get that the second quotient fractionπ = 3 + 7 +15+ (11)1. (7)

1$+^{2}9(2^{+1}()^{1}()^{+1})^{}$.}..

The numbers 3, 7, 15, and so on, that appear in the fraction are called the The continued fraction for a real number can be used partial quotients ofπ. to approximate it by rational numbers. If we truncate the continued fraction after several steps, we are left with a finite continued fraction which is a rational num-ber: for example, by truncating the fraction (7), one level down we get the familiar approximation3$+ 1/7 = 22/$7; at the second level we get the approx-$π \approx$ imation 3$+ 1/(7 + 1/15) = 333/106$. \text{The truncations} at different levels thus generate a sequence of rational approximations: the sequence forπ begins$3$, 22/7, 333/106, 355/113, . . . . Whatever positive real number sequence of continued-fraction approximations willx we start with, the approach Indeed, the formal interpretation of the equation (7) isx as we move further down the fraction. precisely that the successive truncations of the fraction approachπ. Naturally, in order to get better approximations to a number fractions—fractions with larger numerator and denom-$x$we need to take more “complicated” inator. The continued-fraction approximations tox are

III.23. The Euler and Navier–Stokes Equations

bestis one of these fractions, then it is impossible to find approximations toxin the following sense: if$p/q$ any fraction has denom in a to rr /s that is closer thans smaller than q. p/q to x and that ing from the continued fraction forx -Moreover, ifp/q cannot be too large relative to the size of thep/q is one of the approximations com-x, then the error denominator$q$; specifically, it is always true that

$x - pq ⩽ q1^{2}$. (8)

This error estimate shows just how special the contin-ued-fraction approximations are: if you pick a denom in at orq without thinking, and then select the numera- torcan guarantee is thatp that makes p/q xclosest tolies betweenx, the only thing you(p - 1/2)/q and(pwhich is much bigger than 1+ 1/2)/q. So the error could be as large as 1/(q2) if q is a large integer./(2 q), can have even smaller error than is guaranteed by (8).For example, the approximation Sometimes a continued-fraction approximation to$π \approx 355/113 \text{that wex}$ get by truncating (7) at the third level is exceptionally accurate, the reason being that the next partial quotient, 292, is rather large. So we are not changing the fraction much by ignoring the tail 1$/(292 + 1/(1 +$. ..)). In this sense, the most difficult number to approximate by fractions is the one with the smallest possible partial quotients, i.e., the one with all its partial quotients equal to 1. This number, 1+ 1 + (11)+1. . , (9). can be easily calculated because the sequence of par-tial quotients is periodic: it repeats itself. If we call the numberrocal of this number is exactly the continued fractionφ$, then φ - 1 is 1/(1 + 1/(1 + . ..))$. The recip-$(9) for$φ. Hence= φ,φ - 1

which in turn implies thatthis quadratic equation areφ(12+-\sqrt{φ5})/=21. The roots of= 1.618 . . . and(1 - \sqrt{5})/2 = −0.618 . . . . Since the number we are try- ing to find is positive, it is the first of these roots: theso-called golden ratio. the positive solution of the equation any other periodic continued fraction represents a root It is quite easy to show that, just as (9) represents$x^{2} - x - 1 = 0$, of a quadratic equation. This fact seems to have been understood already in the sixteenth century. It is quitea lot trickier to prove the converse: that the continued fraction of any quadratic surd is periodic. This was

193

established bycentury and is closely related to the existence of units lagrange [VI.22](/part-06/joseph-louis-lagrange-17361813) during the eighteenth in quadratic number fields [III.63](/part-03/number-fields). 3 \text{Continued Fractions for Functions Several of the most important functions in mathemat}-\text{ics are most easily described using infinite sums}. \text{For example}, \text{the infinite series exponential function} [III.25](/part - 03/the - exponential - and - logarithmic - functions) \text{has the} e$x = 1 + x + x22 + · · · + xnn!$+ · · ·. There are also a number of functions that have sim-ple continued-fraction expansions: continued fractions involving a variable like important continued fractions historically.x. These are probably the most For example, the functionx \to  \tan  x has the contin- ued fraction

$\tan x = 1 - (x^{x})^{2}$, (10)

3$-^{5}^{-x}$. .2.

valid for any value ofples ofπ/2, where the tangent function has a verticalx other than the odd multi- asymptote.Whereas the infinite series of a function can be truncated to provide function, truncation of the continued fraction provides polynomial approximations to the approximations byare ratios of polynomials. For instance, if we truncate rational functions: functions that the fraction for the tangent after one level, then we getthe approximation \tan x \approx 1 - xx2/3 = 3 - 3 xx2. This continued fraction, and the rapidity with which its truncations approach tanx, played the central role in the proof thattwo whole numbers. The proof was found by Johannπis irrational: thatπ is not the ratio of Lambert in the 1760 s. He used the continued fractionto show that ifx is a rational number (other than 0), then tanx is not. But tanπ/4 = 1 (which certainly is rational), so$π/4 \text{cannot be}$. III.23 The Euler and Navier–Stokes

Equations

Charles Fefferman

The Euler and Navier–Stokes equations describe themotion of an idealized fluid. They are important in science and engineering, yet they are very poorly under-stood. They present a major challenge to mathematics.

194

Rtiond To state the equations we work in Euclidean space, withx =d (xequal to 2 or 3. Suppose that, at posi-, . . . , x ) \in  Rd and at time t \in  R, the fluid is moving with a velocity vector(u (x, t), $. . . , u^{1} (x, t))^{d} \in R^{d}$, and the pressure in theu(x$, t) =$ \text{fluid is}1 p(x, t) \ind R. The Euler equation is∂t∂ +j=d 1 uj ∂x∂j ui(x, t) = -∂x∂pi (x, t) (i = 1, . . . , d) (1) for all(x, t); and the Navier–Stokes equation is

$\partial t\partial +^{j}=^{d}^{1}u^{j} \partial x\partial^{j} u^{i}(x$, t)= νd ∂x∂2 2 ui(x, t) - ∂x∂pi (x, t) (i = 1, . . . , d)j=1 j

(2)

for allthe “viscosity” of the fluid.(x, t). Here$, \nu >$0 is a coefficient of friction called In this article we restrict our attention to incompressible fluids, which means that, in addition to requiring that they satisfy (1) or (2), we also demand that div$u ≡^{j}=^{d}^{1} \partial u\partial(x^{j})^{j} = 0 (3)$ for allare nothing but Newton’s law(x, t). The Euler and Navier–Stokes equations F = \text{ma applied to an} infinitesimal portion of the fluid. In fact, the vector\partial t\partial +j=d 1 uj \partial x\partial j u

is easily seen to be the acceleration experienced by amolecule of fluid that finds itself at positionx at time t. entirely from pressure gradients (e.g., if the pressure increases with height, then there is a net force pushing The forces F leading to the Euler equation arise the fluid down). The additional term

$\n(u^{j})^{d}=^{1} \partial x\partia(l^{2}()^{j})^{{}2} u$

in (2) arises from frictional forces.The Navier–Stokes equations agree very well with experiments on real fluids under many and varied circumstances. Since fluids are important, so are the Navier–Stokes equations.The Euler equation is simply the limiting case$\nu =$ 0 of Navier–Stokes. However, as we shall see, solu-tions of the Euler equation behave very differently from solutions of the Navier–Stokes equation, even whenis small.ν

III. Mathematical Concepts

equations (1) and (3), or the Navier–Stokes equations(2) and (3), together with an initial condition We want to understand the solutions of the Euler u(x) = u0(x) \text{for all} x \in Rd, (4) where valued function onu0(x) is a given initial velocity, i.e., a vector-Rd. \text{For consistency with} (3), we assume that div$u^{0}(x) = 0 \text{for all} x \in R^{d}$. Also, to avoid physically unreasonable conditions, suchas infinite energy, we demand that$u^{0}(x)$, as well asu(x, t)enough” asfor each fixed|x| → $\i\text{nf ty}$. We will not specify here exactlyt, should tend to zero “fast what is meant by “fast enough,” but we assume fromnow on that we are dealing only with such rapidly decreasing velocities.A physicist or engineer would want to know how to calculate efficiently and accurately the solution tothe Navier–Stokes equations (2)–(4), \text{and to understand how that solution behaves}. A \text{mathematician asks first whether a solution exists}, and, \text{if so}, \text{whether thereis only one solution}. \text{Although the Euler equation is} 250 \text{years old and the Navier}–\text{Stokes equation well over}100 \text{years old}, \text{there is no consensus among experts as to whether Navier}–\text{Stokes or Euler solutions exist for alltime}, \text{or whether instead they} “\text{break down}” \text{at a finite time}. \text{Definitive answers supported by rigorous proofs seem a long way off}. down” \text{for the Euler and Navier}–\text{Stokes equations}. Equa - tions (1)–(3) \text{refer to the first and second derivatives of Let us state more precisely the problem of} “breaku(x, t)u0(x) in (4) \text{has derivatives}. \text{It is natural to suppose that the initial velocity}\partialαu0(x) = \partial x\partial1 α 1 · · · \partial x\partial d α du0(x) \text{of all orders}, \text{and that these derivatives tend to zero}“\text{fast enough}” as|x| →\infty. We then ask whether the$Navier–\text{Stokes equations} (2)–(4)$, or the Euler equations(1), (3)$, and (4)$, have solutionsu(x, t), p(x, t), defined for allx \in  Rd and t > 0, such that the derivatives\partial x, tα u(x, t) = \partial t\partialα0 \partial x\partial1α1 · · · \partial x\partial dαdu(x, t) and[0, \infty \partial()α)x, t(and tend to zero “fast enough” asp(x, t) of all orders exist for all x|x\in | →\infty Rd, t)$. A \in$ pair solution for the Euler or Navier–Stokes equations. Nou and pwith these properties is called a “smooth” one knows whether such solutions exist (in the three dimensional case). It is known that, for some positive time T = T (u0) > 0 depending on the initial velocity

III.23. The Euler and Navier–Stokes Equations

u0 in (4), there exist smooth solutions u(x, t), p(x, t) to the Euler or Navier–Stokes equations, defined for R$d and t \in [0$, T )$. x \in$ or “2 D Navier–Stokes”), we can takewords, there is no “breakdown” for 2 D Euler or 2 DIn two space dimensions (one speaks of “2 D Euler” T = +\infty; in other Navier–Stokes. In three space dimensions, no one canrule out the possibility that, for some finite$T = T (u^{0})$ as above, there is an Euler or Navier–Stokes solutionu(x, t), p(x, t), which is defined and smooth on $Ω = \\{(x}$, t)\\\\\\\\\\\\\\\\\\\\\\}:$x \in R^{3}$, t \in  [0, T ), such that some derivative is unbounded onΩ. This would imply that there is|∂x$, t^{α} u(x$, t)| or |∂x, tα p(x, t)| no smooth solution past time3 D Navier–Stokes or Euler solution “breaks down” at T . (We say that the timeand/or Navier–Stokes. No one knows what to believe.T.) Perhaps this can actually happen for 3 D Euler Many computer simulations of the 3 D Navier–Stokes and Euler equations have been carried out. Navier–Stokes simulations exhibit no evidence of breakdown, but this may mean only that initial velocities$u^{0} that$ lead to breakdown are exceedingly rare. Solutions of3 D Euler behave very wildly, so that it is hard to decide whether a given numerical study indicates abreakdown. Indeed, it is notoriously hard to perform a reliable numerical simulation of the 3 D Euler equations. solution behaves if one assumes that there is a break-down. For instance, if there is a breakdown at time It is useful to study how a Navier–Stokes or Euler T < \infty  for the 3 D Euler equation, then a theorem of Beale, Kato, and Majda asserts that the “vorticity”

ω(x, t) = curl(u(x, t))= \partial u\partial(x2)3 - \partial u\partial(x3)2, ∂u∂(x3)1 - ∂u∂(x3)1, ∂u∂(x1)2 - ∂u∂(x1)2 (5) \text{grows so large as}t \to  T that the integral T

diverges. This has been used to invalidate some plau-0$\max x \in R)3 |ω(x$, t)| dt sible computer simulations that allegedly indicated abreakdown for 3 D Euler. It is also known that the direction of the vorticity vectorwithx, as tapproaches a finite breakdown timeω(x, t) must vary wildly T . indicates how the fluid is rotating about the pointtime The vector$t$. A small pinwheel placed in the fluid in positionωin (5) has a natural physical meaning: itx atx at time t with its axis of rotation oriented parallel tovelocityω(x, t)|ω(x, t)would be turned by the fluid at an angular|.

195

V. Sverak shows that if there is a breakdown, then the For the 3 D Navier–Stokes equation, a recent result of pressure A promising idea, pioneered by J. Leray in the 1930 s, p(x, t) is unbounded, both above and below. is to study “weak solutions” of the Navier–Stokes equations. The idea is as follows. At first glance, the Navier–Stokes equations (2) and (3) make sense only when u(x, t)one would like the second derivatives of, p(x, t)are sufficiently smooth: for example, u with respect to thethat (2) and (3) are apparently equivalent to conditions xj to exist. However, a formal calculation shows \text{that we shall call} (2) and (3^ ), which make sense even \text{whensee how to derive} (2 u(x, t) and p(x, t)^ ) and (3 are very rough. Let us first), and then we will discuss their use. Fevery smooth functionon The starting point is the observation that a function Rn is equal to zero if and only ifθ. Applying this remark to th(e R)n Fθ dx = 0 for 3 D Navier–Stokes equations (2) and (3) and performing a simple formal computation (an integration by parts), we find that (2) and (3) are equivalent to the following equations: R3\times(0\\{,\\ \infty) - i = 3 1 ui \partialθ\partial ti - i, j3 = 1 uiuj \partial x\partialθi j \text{dx dt} = R 3\times(0,\infty) \nui, j3 = 1 \partial x\partial2 2 j θ\text{i ui} + i = 3 1 \partialθ\partial(xi)i p \text{dx dt} (2}$) and R3$\times(0,\infty)i = 1 ui \partial x\partialφ\text{i dx dt} = 0. (3^ ) \text{More precisely}, \text{given any smooth functionsp}(x, t), equations (2) and (3) hold if and only if (2 u(x, t) and^ ) and (3) are satisfied for arbitrary smooth functions θ\text{outside a compact subset of}1(x, t)$, θ2(x$, t)$, θ3(x$, t)$, and R3 \times φ(x$, t)(0,\infty ). that vanish say that Stokes. Since all the derivatives in (2 We call u θand1$, θp2$, \text{form a}θ3, \text{andweak solution}φ \text{test functions}^ ) and (3 of 3 D Navier–, \text{and we}) \text{are applied to smooth test functions}, equations (2) and (3^ ) \text{make sense even for very rough functions summarize}, \text{we have the following conclusion}.u and p. To A \text{smooth paironly if it is a weak solution}. However, \text{the idea of a weak}(u, p)solves 3 D Navier–\text{Stokes if and solution makes sense even for rough}(u, p). following plan.We hope to use weak solutions, by carrying out the

196

Step (i): Navier–Stokes on all ofprove that suitable weak solutions exist for 3 DR3$\times (0$,\infty ). Step (ii): Navier–Stokes must be smooth.prove that any suitable weak solution of 3 D Step (iii): structed in step (i) is in fact a smooth solution of the conclude that the suitable weak solution con3 D Navier–Stokes equations on all of R3\times (0,\infty ). Here, “suitable” means “\text{not too big}”; \text{we omit the precise definition}. \text{Analogues of the above plan have succeeded for interesting partial differential equations}. \text{But for} 3 DNavier–Stokes, \text{the plan has been only partly carried out}. \text{It has been known for a long time how to construct suitable weak solutions of} 3 D Navier–Stokes, \text{butthe uniqueness of these solutions has not been proved}. \text{Thanks to the work of Sheffer}, \text{of Lin}, \text{and of Caffarelli}, Kohn, \text{and Nirenberg}, \text{it is known that any suitable weak solution to} 3 D Navier–\text{Stokes must be smooth} (i.e., \text{it must possess derivatives of all orders}), \text{outside a set} E ⊂ R3 \times (0,\infty ) \text{of small} [III.17](/part - 03/dimension). In particular, a breakdown, one would have to show that E cannot contain a curve. To rule out fractal dimension E is the empty set. sense, but examples due to Sheffer and Shnirelman For the Euler equation, weak solutions again make show that they can behave very strangely. A two-dimensional fluid that is initially at rest and subject to no outside forces can suddenly start moving in abounded region of space and then return to rest. Such behavior can occur for a weak solution of 2 D Euler. The Navier–Stokes and Euler equations give rise to a number of fundamental problems in addition to the breakdown problem discussed above. We finish this article with one such problem. Suppose that we fix aninitial velocity u0(x)for the 3 D Navier–Stokes or Euler equation. The energy E^0 at time t = 0 is given by E^0 = 12^R^3 |u(x, 0)|^2 dx.

For Navier–Stokes solution with initial velocityν ⩾ 0$, let u^{(}\nu)(x, t) = (u^{(}\nu)^{1}$, u^(ν)2, u(ν)3 )\text{udenote the}0 \text{and with} viscosity We assume thatν. (If νu=(ν)0, then exists for all time, at least when(u(()0){)} is an Euler solution.)ν > 0. The energy for u(ν)(x, t) at time t ⩾ 0 is given$by$ E(ν)(t) = 1(2 R)3 |u(ν)(x, t)|2 dx.

An elementary calculation based on (1)–(3) (we multiply(1) or (2) byu (x), sum over i, integrate over all x \in  R3, i

III. Mathematical Concepts

and integrate by parts) shows that

3\partial u(\nu)2 d dt E(\nu)(t) = −1 2\nu R 3 ij = 1 \partial(xi)j dx. (6) \text{In particular}, \text{for the Euler equation we have}\nu = 0, and (6) shows that the energy is equal to E0, independently of time, as long as the solution exists.Now suppose that\nu is small but nonzero. From (6) it is natural to guess that|(d/dt)E(\nu)(t)| \text{is small when} \nu is small, so that the energy remains almost constant for a long time. However, numerical and physical experi-ments suggest strongly that this is not the case. Instead, it seems that there exists independent of\nu, such that the fluid loses at least half T0 > 0, \text{depending on} u0 \text{but of its initial energy by time}\nu is (\text{provided that} \nu > 0). T0, \text{regard less of how small prove}) \text{this assertion}. \text{We need to understand why a tiny It would be very important if one could prove} (\text{or dis viscosity dissipates a lot of energy}. III.24 \text{Expanders Avi Wigderson} 1 \text{The Basic Definition An expander is a special sort of remarkable properties and many applications}. \text{roughly graph} [III.34] \text{that has speaking}, \text{it is a graph that is very hard to disconnect because every set of vertices in the graph is joined by many edges to its complement}. \text{More precisely}, \text{we saythat a graph withn vertices is a} c-\text{expander if for everymcm}⩽\text{edges betwee}(n1)2 n \text{and every set} S \text{and the complement of} S of m \text{vertices there are at least} S. sparse: \text{in other words}, \text{when This definition is particularly interesting when} G \text{has few edges}. \text{We shall} G \text{is concentrate on the important special case where regular of degreedfor some fixed constantd that is} G \text{is independent of the number that every vertex is joined to exactlynof vertices}: \text{this meansd others}. \text{When Gto its complement is obviously at mostis regular of degree} d, \text{the number of edges fromdm}, \text{so if} c is S \text{some fixed constant} (\text{that is}, \text{not tending to zero withn}), then the number of edges between any set of ver- tices and its complement is within a constant of the largest number possible. As this comment suggests, we are usually interested not in single graphs but in infi-nite families of graphs: we say that an infinite family of d-regular graphs is a family of expanders if there is a constantc-expander.c > 0 such that each graph in the family is a

III.24. Expanders

2 The Existence of Expanders

The first person to prove that expanders exist was Pinkser, who proved that ifn \text{is large and} d ⩾ 3, then almost everyan expander. That is, he proved that there is a con-d-regular graph with n vertices is stant$c >$0 such that for every fixed$d ⩾ 3$, \text{the pro}- portion ofnot expanders tends to zero asd-regular graphs with nntends to infinity.vertices that are This proof was an early example of the probabilistic methodsee that if a[IV.19 §3](/part-04/extremal-and-probabilistic-combinatorics) in combinatorics. It is not hard tod-regular graph is chosen uniformly at ran- dom, then the S is d|S|(n − |expected S|)/n, which is at least number of edges leaving a set(1 d)|S|. Stan- dard “tail estimates” are then used to prove that, forany fixed S, the probability that the number of edges2 leaving value is extremely small: so small that if we add up the Sis significantly different from its expected probabilities for all sets, then even the sum is small.So with high probability all sets S have at least c|S| edges to their complement. (In one respect this descrip-tion is misleading: it is not a straightforward matter to discuss probabilities of events concerning random ddently chosen. However, Bollobás has defined an equiv--regular graphs because the edges are not in de pen a le nt model for random regular graphs that allows them to be handled.)Note that this proof does not give us an explicit description of any expander: it merely proves thatthey exist in abundance. This is a drawback to the proof, because, as we shall see later, there are applications for expanders that depend on some kind ofexplicit description, or at least on an efficient method of producing expanders. But what exactly is an “explicit description” or an “efficient method”? There are many possible answers to this question, of which we shall discuss two. The first is to demand that there is an algorithm that can list, for any integer edges of ad-regular c-expander with aroundn, all the vertices andn vertices (we could be flexible about this and ask for the num-ber of vertices to be between$n and n^{2}$, say) in a time that is polynomial inity [IV.20 §2](/part-04/computational-complexity) for a discussion of polynomial-time algo-n. (See computational complex- rithms.) Descriptions of this kind are sometimes called “mildly explicit.” the following graph. Its vertices are all 01 sequencesof length To get an idea of what is “mild” about this, considerk, and two such sequences are joined by an edge if they differ in exactly one place. This graph issometimes called the discrete cube ink dimensions. It 197 has 2 k vertices, so the time taken to list all the ver- tices and edges will be huge compared withever, for many purposes we do not actually need suchk. How- a list: what matters is that there is a concise way of representing each vertex, and an efficient algorithm for listing the (representations of the) neighbors of any given vertex. Here the 01 sequence itself is a very con-cise representation, and given such a sequenceσ it is very easy to list, in a time that is polynomial inrather than 2 k, the k sequences that can be obtained byk altering described in this way (so that listing the neighbors ofσin one place. Graphs that can be efficiently a vertex takes a time that is polynomial in the logarithm explicit of the number of vertices) are called. strongly The quest for explicitly constructed expanders has been the source of some beautiful mathematics, whichhas often used ideas from fields such as number theory and algebra. The first explicit expander was discovered by Margulis. We give his construction and another one; we stress that although these constructions are very simple to describe, it is rather less easy to prove thatthey really are expanders. for every integer Z Margulis’s construction gives an 8-regular graphis the set of all integers modm. The vertex set ism. The neighbors of Z^m \times  Z^m, where G^m the vertex(x$, y^{m} - x)$,(x$, y)(x + yare + 1(x, y)+, y, y)(x - y, (x + 1-, y)y, y)$, (x$, y, (x, y + x++x)1)$,,(x, y - x + 1) (all operations are mod m). Margulis’s proof thattation theory Gm is an expander was based on[IV.9](/part-04/representation-theory) and did not provide any specific re pre sen bound on the expansion constant later derived such a bound us in gc harmonic analy-. Gabber and Galil sis explicit.[IV.11](/part-04/harmonic-analysis). Note that this family of graphs is strongly 3-regular graph withset is Another construction provides, for each prime Z , and a vertex px vertices. This time the vertexis connected to x + 1, x p-, a1, anddefine the inverse of 0 to be 0). The proof that these(x-1)p (where this is the inverse of x mod p, and we graphs are expanders depends on a deep result in num-ber theory, called the Selberg 3/16 theorem. \text{This family} \text{is only mildly explicit}, \text{since we are at present unable togenerate large primes} \text{deterministical} ly. \text{itly constructing expanders were algebraic}. However, \text{in Until recently}, \text{the only known methods for explic}2002 Reingold, Vadhan, \text{and Wigderson introduced theso}-\text{called zigzag product of graphs}, \text{and used it to give a combinatorial}, \text{iterative construction of expanders}. 198 3 \text{Expanders and Eigenvalues The condition that a graph should be ainvolves all subsets of the vertices}. \text{Since there are expo} - c-\text{expander nentially many subsets}, \text{it would seem on the face ofit that checking whether a graph is ac}-\text{expander is an exponentially long task}. And, indeed, \text{this problem turns out to be co}-\text{np complete} [[IV.20 §§3, 4]](/part - 04/computational - complexity). However, we shall now describe a closely related property that can be checked in polynomial time, and which is in some ways more natural. A Given a graphis the n \times  n matrix where G with n vertices, its Auvis defined to be 1 ifadjacency matrix uand symmetric, and therefore hasis joined to v and 0 otherwise. This matrix is realn real eigenvalues [I.3 §4.3](/part-01/fundamental-definitions)thatλ ⩾λ1λ, λ2⩾, . . . , λ· · ·n⩾, which we name in such a wayλ . Moreover, eigenvectors [I.3 §4.3](/part-01/fundamental-definitions) with distinct eigenvalues are orthogonal.1 2$n$ of useful information aboutthis, let us briefly consider how It turns out that these eigenvalues encode a great deal G. But before we come to A acts as a linear map. If we are given a function G, then Af is the function whose value atf, defined on the vertices ofu is the sum of immediately that iff (v) over all neighbors G is d-regular andv of u. From this we seef is the function that is 1 at every vertex, thend at every vertex. In other words, a constant function Af is the function that is is an eigenvector of A with eigenvalue d. It is also not hard to see that this is the largest possible eigenvalue$λ^{1}$, and that if the graph is connected, then the second largest eigenvalueλ2 will be strictly less than d. ity properties of the graph is considerably deeper than In fact, the relationship between$λ2 \text{and connectiv}-$ this: roughly speaking, the further awaythe bigger the expansion parameterc of the graph.λ2 is from d, More precisely, it can be shown that1(d - λ ) and 2 d(d - λ ). From this it follows thatc lies between an infinite family ofexpanders if and only if there is some constant2 2 d-regular graphs is a family of2 a > 0 such that the spectral gapsd - λ2 \text{are at least a for} every graph in the family. One of the many reasons these bounds onc are important is that although, as we have remarked, it is hard to test whether a graph is acomputed in polynomial time. So we can at least obtainc-expander, its second largest eigenvalue can be estimates for how good the expansion properties of agraph are. Another important parameter of ad-regular graph Gfromis the largest absolute value of any eigenvalue apartλ1; this parameter is denoted byλ(G). If λ(G) is

III. Mathematical Concepts

small, thend-regular graph. For example, let G behaves in many respects like a random A and B be two dis- joint sets of vertices. If G were random, a small calcu- lation shows that we would expect the numberof edges from A to B to be about d|A| |B|/n. It can be E(A, B) shown that, for any two disjoint sets in anyd-regular graphby at most G, E(A, B)λ(G)will differ from this expected amount|A| |B|. Therefore, if λ(G) is a small fraction ofd, then between any two reasonably large setswe expect. This shows that graphs for which A and B we get roughly the number of edges thatλ(G) is small “behave like random graphs.” regular graphs. Alon and Boppana proved that it wasalways at least 2 It is natural to ask how small\sqrt{d} - 1 - g(n) for a certain functionλ(G) can be in d-gthat almost allthat tends to zero asd-regular graphsn increases. Friedman proved G with n vertices haveλ(G)a typical⩽ 2\sqrt{dd}-regular graph comes very close to match-- 1 + h(n), where h(n) tends to zero, so ing the best possible bound fora tour de force. Even more remarkably, it is possibleλ(G). \text{The proof was to match the lower bound withthe famous Ramanujan graphs of Lubotzky}, Philips, \text{explicit constructions}: \text{and Sarnak}, and, independently, Margulis. \text{They con} - structed, \text{for eachd such that} d - 1 \text{is a prime power}, \text{a family ofd} - \text{regular graphs} G with λ(G) = 2 \sqrt{d} - 1. 4 \text{Applications of Expanders Perhaps the most obvious use for expanders is in communication networks}. \text{The fact that expanders are highly connected means that such a network is highly}“\text{fault tolerant},” \text{in the sense that one cannot cut off part of the network without destroying a large numberof individual communication lines}. \text{Further desirable properties of such a network}, \text{such as a small diameter}, \text{follow from an analysis of random walks on expanders}. \text{a path} A \text{random walk} v0, v1, . . . , vof lengthm, where eachm on avdi -regular graphis a randomly cho-G is sen neighbor ofused to model many phenomena, and one of the ques-(vi)-1. Random walks on graphs can be tions one frequently asks about a random walk is how rapidly it “mixes.” That is, how large doesm have to be before the probability thatthe same for all vertices$v$?$v^{m} = v \text{is approximately}$ it is not hard to show thatwords, the If we let pt ran sit i on matrixk(v) be the probability thatpk T+1 of the random walk,= (d-1 Apv()k)k=. In otherv, then which tells you how the distribution after depends on the distribution after$k$ steps, iskd+-1 steps1 times

III.25. The Exponential and Logarithmic Functions the adjacency matrix value is 1, and ifλ(G) is small then all other eigenvalues A. Therefore, its largest eigen- are small. bility distribution we can write Suppose that this is the case, and letp as a linear combination[III.71](/part-03/probability-distributions) on the vertices ofp be anyu G, where proba-. Thenuis appliedi is an eigenvector ofk times, then the new distribution will be T with eigenvalue (di()-1)i\lambda i. If T rapidly to zero, except that it equals 1 when In other words, after a short time, the “nonconstanti(d - 1\lambda i)kui. If λ(G) is small, then (d-1\lambda i)ki tends= 1. part” of distribution.p goes to zero and we are left with the uniform property is at the heart of some of the applications of expanders. For example, suppose that Thus, random walks on expanders mix rapidly. This V is a large set, we wish to estimate quickly and accurately the aver-f is a function from V to the interval [0,1], and age of$v^{1}$, v2, . . . , vf . A natural idea is to choose a random sampleof points in V and calculate the average kp en de nt ly, then it is not too hard to prove that thi(s-1)k i=1 f ((vk)i). If k is large and the vi are chosen inde- sample average will almost certainly be close to the true average: the probability that they differ by more thanis at most e$-^{2}^{k}$. it requires a source of randomness. In theoretical com-This idea is very simple, but actually implementing puter science, randomness is regarded as a resource, and it is desirable to use less of it if one can. The above procedure needed about logdomness for eachv , so k\log (|V |) bits in all. Can we(|V |) bits of ran-i

do better? Ajtai, Komlós, and Szemerédi showed thatthe answer is yes: big time! What one does is associate instead of choosing V with the vertices of an explicit expander. Then, v1$, v2$, . . . , v independently, one chooses them to be the vertices of a random walk inthis expanding graph, starting at a random pointk v$of$\log V(|. The randomness needed for this is far smaller: V |) bits for v and log(d) bits for each further v1, making loglarge andd(|is a fixed constant, this is a big saving: we V |) +1 k\log (d) bits in all. Since V is veryi essentially pay only for the first sample point.But is this sample any good? Clearly there is a heavy dependence between thethat nothing is lost in accuracy: again, the probabil-$v^{i}$. However, it can be shown ity that the estimate differs from the true mean bymore than is at most e$-^{2}^{k}$. Thus, there are no costs attached to the big saving in randomness. expanders, which include both practical applications This is just one of a huge number of applications of

199

and applications in pure mathematics. For instance, they were used by Gromov to give counterexamples to certain variants of the famous ture [IV.15 §4.4](/part-04/operator-algebras). \text{And certain bipartite graphs called baum}–\text{connes conjec}“\text{lossless expanders}” \text{have been used to produce linear codes with efficient decodings}. (\text{See mission of information} [VII.6](/part - 07/reliable - transmission - of - information) \text{for a description ofreliable transwhat this means}.) III.25 \text{The Exponential and Logarithmic Functions} 1 \text{Exponentiation} \text{The following is a very well}-\text{known mathematical se} - quence: 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024,. . .. \text{Each term in this sequence is twice the term before}, so, \text{for instance}, 128, \text{the seventh term in the sequence}, \text{is equal to} 2 \times 2 \times 2 \times 2 \times 2 \times 2 \times 2. \text{Since repeated multipli}- \text{cations of this kind occur through out mathematics}, \text{itis useful to have a less cumbersome notation for them}, so 2 \times 2 \times 2 \times 2 \times 2 \times 2 \times 2 \text{is normally written as} 27, \text{which we read as} “2 \text{to the power} 7” \text{or just} “2 \text{to the} 7.”\text{More generally}, \text{ifa is any real number and} m \text{is any positive integer}, \text{thenam stands for a} \t\text{imes a} \times · · · \t\text{imes a}, \text{where there arecalled} “\text{a to the mm a},” \text{and numbers of the forms in the product}. \text{This product isam are called the powers ofa}. \text{The process of raising a number to a power is known asnent} \text{exponentiation}.) A \text{fundamental fact about} \text{exponentiation} \text{is the}. (\text{The numberm is called the expo}- \text{following identity}:$am + n = am · an$\text{This says that} \text{exponentiation} “\text{turns addition into mul} - tiplication.” \text{It is easy to see why this identity must be true if one looks at a small example and temporarily reverts to the old}, \text{cumbersome notation}. \text{For instance}, 27 = 2 \times 2 \times 2 \times 2 \times 2 \times 2 \times 2= (2 \times 2 \times 2) \times (2 \times 2 \times 2 \times 2)= 23 \times 24. \text{Suppose now that we are asked to evaluate} 23$/2$. \text{At first sight}, \text{the question seems misconceived}: \text{an essen}-\text{tial part of the definition of} 2 m \text{that has just been given was that ply ing one} - and - a - half 2 s \text{together does not make sense}.m \text{was a positive integer}. \text{The idea of multi} - However, \text{mathematicians} \text{like to generalize}, \text{and even ifwe cannot immediately make sense of} 2 m \text{except when} 200 \text{minventing a meaning for it for a wider class of numbers}.\text{is a positive integer}, \text{there is nothing to stop us The more natural we make our} \text{generalization}, \text{the more interesting and useful it is likely to be}. \text{And theway we make it natural is to ensure that at all costs we keep the property of} “\text{turning addition into} \text{multiplication}.” This, \text{it turns out}, \text{leaves us with only one sensi}-\text{ble choice for what} 23/2 \text{should be}. \text{If the fundamental property is to be preserved}, \text{then we must have} 23$/2 · 23/2 = 23/2 \sqrt + 3/2 = 23 = 8$. Therefore, 23/2 \text{has to be} ± 8. \text{It turns out to be con}- \text{venient to take} 2 be$\sqrt{8}$.3 / 2 \text{to be positive}$, \text{so we define} 23$/2 to A \text{similar argument shows that} 20 \text{should be defined to be} 1: \text{if we wish to keep the fundamental property}$, then 2$= 21 = (21)+0 = 21 · 20 = 2 · 20. \text{Dividing both sides by} 2 \text{gives the answer} 20= 1. What we are doing with these kinds of arguments is solving awhere the unknown is a function. So that we can see this functional equation, that is, an equation more clearly, let us write$f (t) for 2t$. The information we are given is the fundamental propertyf (t)f (u) together with one value, f (1) = f (t2, to get us+ u) = started. From this we wish to deduce as much as we canaboutf . we have placed on It is a nice exercise to show that the two conditionsf determine the value of f at every rational number, at least iftive. For instance, to show thatf is assumed to be posi-f (0) should be 1, we note that$f (0)f (1) = f (\sqrt{1})$, and we have already shown that similar spirit to these arguments, and the conclusionf (3/2) must be 8. The rest of the proof is in a is thatf (p/q) must be the qth root of 2 p. More gener- ally, the only sensible definition ofof$a^{p}$. ap/q is the qth root functional equation, but we have made sense of We have now extracted everything we can from the$a^{t} only$ iftion whentis a rational number. Can we give a sensible defini-$t$is irrational? For example, what would be the most natural definition of 2 equation alone does not determine what 2$\sqrt^{2}$? Since the functional\sqrt2 should be, the way to answer a question like this is to look for some natural additional property thatthat would, together with the functional equation, spec-f might have ifyf uniquely. It turns out that there are two obvious choices, both of which work. The first is thatbe an increasing function: that is, ifs is less thanf shouldt, then

III. Mathematical Concepts

f (s)that fis less thanis continu ousf (t). Alternatively, one can assume[I.3 §5.2](/part-01/fundamental-definitions). \text{used to work out} 2 \text{directly but to obtain better and better Let us see how the first property can in principle be}\sqrt2. \text{The idea is not to calculate itestimates}. \text{For instance}, since 1\text{us that} 2\sqrt2 \text{should lie between} 2.4 < \sqrt{2} < 1.5 \text{the order property tells}7/5 and 23/2, \text{and in gen}-$\text{eral that if}2$ p/q and 2 r /sp/q <. \text{It can be shown that if two rational num}-\sqrt{2} < r /s then 2\sqrt2 \text{should lie between bersp}/q and r /s \text{are very close to each other}$, then 2 p/q$ and 2 r /s are also close. It follows that as we choose frac-\text{tionsthe resulting numbers} 2 p/q and r /s \text{that are closer and closer together}, sop/q and 2 r /s \text{converge to some limit}, \text{and this limit we call} 2\sqrt2. 2 The Exponential Function One of the hallmarks of a truly important concept in mathematics is that it can be defined in many different but equivalent ways. The exponential function \exp most basic way to think of it, though for most purposes(x)very definitely has this property. Perhaps the not the best, is that exp(x) = ex, where e \text{is a number whose decimal expansion begins} 2 \text{we focus on this number}? \text{One property that singles it}.7182818. \text{Why do} \text{out is that if we differentiate the function expthen we obtain} e xagain—and e is the only number for$(x) = e^{x}$, which that is true. Indeed, this leads to a second way ofdefining the exponential function: it is the only solution of the differential equationf^ (x) = f (x)that satisfies the initial conditionf (0) = 1. chosen in textbooks, is as the limit of a power series: A third way to define exp(x), \text{and one that is often}\exp (x) = 1 + x + x2!2$+ x3!3$+ · · ·, known as the Taylor series of exp(x). It is not immedi- ately obvious that the right-hand side of this definition gives us some number raised to the powerx, which is why we are using the notation expex. However, with a bit of work one can verify that it(x) rather than yields the basic properties exp$(x + y) = \exp (x) \exp (y)$,\exp (0) = 1$, and (d/dx) \exp (x) = \exp (x)$. There is yet another way to define the exponential function, and this one comes much closer to telling uswhat it really means. Suppose you wish to invest some money for ten years and are given the following choice: either you can add 100% to your investment (that is, double it) at the end of the ten years, or each year you can take whatever you have and increase it by 10%.Which would you prefer?

III.25. The Exponential and Logarithmic Functions The second is the better investment because in the second case the interest isyou start with 100, then after a year you will have 110 compounded: for instance, if and after two years you will have $121$. \text{The increase of}11 in the second year breaks down as 10% interest on the original 100 plus a further dollar, which is 10% interest on the interest earned in the first year. Underthe second scheme, the amount of money you end up with is $100 timesby 1$.1. The approximate value of(1.1)10, since each year it multiplies(1.1)10 is 2.5937, so you will get almost $260 \text{instead of}$200. Instead of multiplying your investment by 1 times, you would multiply it by 1 What if you compounded your interest monthly?1 120 times. By the101 ten end of ten years your 100 would have been multiplied by(1 +1 )120, which is approximately 2120 .707. If you compounded it daily, you could increase this to approx-120 imately 2.718, which is suspiciously close to e. In fact, e can be defined as the limit, asthe number$(1 +^{1} )^{n}$. ntends to infinity, of does tend to a limit. For any fixed powerof It is not instantly obvious that this expression really$(1 + 1 )m \text{as nn}$ tends to infinity is 1, while for anym, the limit fixed comes to$n$, \text{the limit asn} (1 + 1 )n, the increase in the power just com-mtends to infinity is\infty . When it pensates for the decrease in the number 1 get a limit between 2 and 3. Ifn x is any real number, then+1 n and we(to be exp1 +x n)n (x)also converges to a limit, and this we define. Here is a sketch of an argument that shows that if we define exp property that we need if our definition is to be a good(x) in this way, then we obtain the main one, namely exp$(x) \exp (y) = \exp (x + y)$. Let us take$1$+ nx^n 1 + yn^n,$\text{which equals} 1$+ xn + yn + xyn^2^n. \text{Now the ratio of} 1 y/n is smaller than 1+ x/n+ xy/n+ y/n^2, and+ xy/n(1 +^2 xy/nto 1 +^2 x/n)^n can+ be shown to converge to 1 (as here the increase inis not enough to compensate for the rapid decrease in$nxy/n^{2})$. Therefore, for large n the number we have is$\text{very close to} 1$+ x +n y^n. Lettingntend to infinity, we deduce the result.

201

3 Extending the Definition to Complex Numbers

If we think of exp(x) as ex, then the idea of generalizing the definition to complex numbers seems hopeless: our intuition tells us nothing, the functional equation does not help, and we cannot use continuity or order rela-tions to determine it for us. However, both the power series and the compound-interest definitions can be generalized easily. Ifz is a complex number, then the most usual definition of exp(z) is$1$+ z + z2!2$+ z$3!3$+ · · ·$.$Settingz = iθ$, for a real number θ, and splitting the resulting expression into its real and imaginary parts, we obtain 1- θ2!2$+ θ$4!4$+ · · · + i θ - θ$3!3$+ θ$5!5− · · · , which, using the power-series expansions for cosand sin(θ), tells us that exp(iθ) = \cos (θ) + i sin(θ)(θ), the formula for the point with argumentθ on the unit circle in the complex plane. In particular, if we takeθ = π, we obtain the famous formula (ei)π = −1 (since\cos (π) = −1 and sin(π) = 0).

This formula is so striking that one feels that it ought to hold for a good reason, rather than being a merefact that one notices after carrying out some formal algebraic manipulations. And indeed there is a good reason. To see it, let us return to the compound-interest idea and define exp(z) to be the limit of (1 + z/n)n as nw here tends to infinity. Let us concentrate just on the casez = iπ: why should(1 + iπ/n)n \text{be close to} - 1 when To answer this, let us think geometrically. What is$n$is very large? the effect on a complex number of multiplying it by1$+ iπ/n$? On the Argand diagram this number is very close to 1 and vertically above it. Because the vertical line through 1 is tangent to the circle, this means that the number is very close indeed to a number that lies on the circle and has argumentof a number on the circle is the length of the circular$π/n (\text{since the argument}$ arc from 1 to that number, and in this case the circular arc is almost straight). Therefore, \text{\text{\text{\text{multiplication}}} by} 1+iπ/n is very well approximated by rotation through an angle ofπ, which is the same as multiplication byπ/n. Doing this n times results in a rotation by-1. The same argument can be used to justify the formula exp\cos (θ) + \text{i sin}(θ). (iθ) = of the exponential function is the exponential function.Continuing in this vein, let us see why the derivative

202

We know already that exp(z + w) = \exp (z) \exp (w), so the derivative of exp atzero of exp(z)(\exp (w) -z1)/wis the limit as. It is therefore enoughw tends to to show that exp(w) - 1 is very close to w when w is small. To get a good idea of expa large n \text{and consider} (1 + w/n)(w)n. \text{It is not hard towe should take prove that this is indeed close to} 1 + w, \text{but here is an} \text{informal argument instead}. \text{Suppose that you have abank account that offers a tiny rate of interest over a year}, say 0 \text{could compound this interest monthly}? \text{The answer is}.5%. \text{How much better would you do if you not very much}: \text{if the total amount of interest is verysmall}, \text{then the interest on the interest is negligible}. This, \text{in essence}, \text{is why}1 + w when w \text{is small}. (1 + w/n)n \text{is approximately function yet further}. \text{The main ingredients one needsare addition}, \text{multiplication}, \text{and the possibility of lim}-\text{One can extend the definition of the exponential iting arguments}. So, \text{for example}, \text{ifbanach algebra} [III.12](/part - 03/c--algebras)A, \text{then expx is an element of a}(x) \text{makes sense}. (Here, \text{the power series definition is the easiest}, \text{thoughnot necessarily the most enlightening}.) 4 \text{The Logarithm Function Natural logarithms}, \text{like exponentials}, \text{can be defined inmany ways}. \text{Here are three}. (i) \text{The function log is the inverse of the function exp}. \text{That is}, \text{ift is a positive real number}, \text{then the statement statementt} = \exp u (u)= .\log (t) \text{is equivalent to the} (ii) \text{Lett be a positive real number}. Then\log (t) =1 t dxx . (iii) \text{If This defines log}|x| < 1 \text{then log}(t)(1 for 0 + x) =< t <x - 1 22. Ifx2 +(t1)3 x⩾32 then− · · ·.\log (t)\text{can be defined as}-\log (1/t). \text{tion is a functional equation that is the reverse of the functional equation for exp}, \text{namely log The most important feature of the logarithmic func}-(st) = \log (s) +\log plication}, \text{log turns} \text{multiplication} \text{into addition}. A more(t). \text{That is}, \text{whereas exp turns addition into multi}- \text{formal way of putting this is that addition}, and R , \text{the set of positive real numbers}, R \text{forms a group under forms a group under} \text{multiplication}. \text{The function expis an isomorphism from} + R to R , \text{and log}, \text{its inverse}, \text{is an isomorphism from groups have the same structure}, \text{and the exponential} R + to R. Thus, \text{in a sense the two}+ \text{and logarithmic functions demonstrate this}. III. \text{Mathematical Concepts must equal log}\e\text{xp Let us use the first definition of log to see why log}(b). \text{Then log}(s)(s)+=\log a}(t), log. Write(t) = bs, and= \exp (a) and (st)t =\log (st) = \log (\exp (a) \exp (b))= \log (\exp (a + b))= a + b. \text{The result follows}.\text{In general}, \text{the properties of log closely follow those of exp}. However, \text{there is one very important differ} - ence, \text{which is a complication that arises when one tries to extend log to the complex numbers}. \text{At first it seems quite easy}: \text{every complex number written asr} (ei)θ \text{for some nonnegative real numberz can ber and sometively}). Ifzθ=(\text{the modulus and argument ofr} (ei)θ \text{then log}(z)$, \text{one might think}$, shouldz, respec- \text{be log}(r ) + iθ (\text{using the functional equation for log and the fact that log inverts exp}). The problem withthis is thatθ is not uniquely determined. For instance, what is logwe could, perversely, say that 1(1)? Normally we would like to say 0, but= e2π\text{i and claim that} \log (1) = 2πi.

to define the logarithmic function on the entire com-plex plane, even if 0, a number that does not have a Because of this difficulty, there is no single best way logarithm however you look at it, is removed. One con-vention is to writez = r eiθ with r > 0 and 0 ⩽ θ < 2π, which can be done in exactly one way, and\log (z) to be log(r ) + iθ. However, this function is not then define continuous: as you cross the positive real axis, the argument jumps by 2π and the logarithm jumps by$2$πRemarkably, this difficulty, far from being a blowi. to mathematics, is an entirely positive phenomenon that lies behind several remarkable theorems in complex analysis, such as Cauchy’s residue theorem, which allows one to evaluate very general path integrals. III.26 The Fast Fourier Transform If$f$: R\to  R is a periodic function with period 1, then one can obtain a great deal of useful information about$f$by calculating its Fourier coefficients (see the fourier transform This is true for both theoretical and practical reasons,[III.27](/part-03/the-fourier-transform) for a discussion of why). and because of the latter it is highly desirable to havea good way of computing Fourier coefficients quickly. A method for doing this was discovered by Cooley and Tukey in 1965 (though it turned out that Gauss had anticipated them over 150 years earlier).

III.26. The Fast Fourier Transform

formula The rth Fourier coefficient of1 f is given by thef (r )ˆ=0 f (x)(e-2()π){i}r x dx.

If we do not have an explicit formula for the integral(as would be the case, for instance, iff were derived from some physical signal rather than a mathematical formula), then we will want to approximate this integral numerically, and a natural way to do that is to$-discretiz(e^{1}()^{N})^{-1}$ it: that is, turn it into a sum of the form-2 π i r n/NNlating andn=0 f (n/N)r is not too big, then this should be a goode . If f is not too wildly oscil- approximation. The sum above will be unchanged if we add a multiple ofoff at points of the form N to r , so we now care only about the valuesn/N. Moreover, the period- icity off tells us that adding a multiple of N to n also makes no difference. So we can regard both belonging to the group Z of integers mod Nn(seeandmod-r as ular arithmetic to one that reflects this. Given a function[III.58](/part-03/modular-arithmetic)). Let us change our notation N gdefined on Zthe function ˆNwe define theg, also defined ondiscrete Fourier transform Z , which is given byofg to be N

the formula

g(r )ˆ$= N^{-1} g(n)ω^{-r} n$, (1)n \in  Z)N

where we are writinge-2 π i r n/N . Note that the sum overω for (e2()π){i}/Nn , so thatcould be regardedω-r n = \text{as a sum from} 0 to N -1 just as above; the other notational change is that we have writtenf (n/N). g(n) instead of as multiplying a column vector (corresponding to the function The discrete Fourier transform can be thought ofg) by an N \times  N matrix (with entries N-1ω-r n for eachabout Nr2 and arithmetical operations. The fast Fouriern). Therefore it can be calculated using transform arises from the observation that the sum in (1) has symmetry properties that allow it to be calcu-lated much more efficiently. This is most easily seen whenshall look at the case N is a power of 2, and to make it even easier we N = 8. The sums to be evaluated are then g(0) + ω-r g(1) + ω-2 r g(2) + · · · + ω-7 rg(7) \text{for each}r between 0 and 7. Now a sum like this can be rewritten as g(0) + ω-2 rg(2) + ω-4 r g(4) + ω-6 rg(6)+ ω-r (g(1) + ω-2 rg(3) + ω-4 r g(5) + ω-6 r g(7)), 203 \text{which is interesting because}$g(0) + ω-2 r g(2) + ω-4 r g(4) + ω-6 r g(6) and$ g(1) + ω-2 r g(3) + ω-4 r g(5) + ω-6 r g(7) \text{are themselves values of discrete Fourier transforms}.\text{For instance}$, \text{if we set}$ h(n) = g(2 n) for 0 ⩽ n ⩽ 3, and write equals$h(0ψ) +forψ^{-}ω^{r}^{2}h(=1)e^{2}+^{π}ψ^{i}^{/}^{4}^{-}$, then the first expression2$r h(2) + ψ^{-3}^{r}h(3)$. If we think ofthe formula for ˆhas being defined onh(r )$. Z^{4}$, then this is precisely A similar remark applies to the second expression, so if we can calculate the discrete Fourier transforms of the “even part” of$g$and the “odd part” ofg, then it will be very straightforward to obtain each value of the Fourier transform ofgitself: it will be a linear combination of values of the transforms of the two parts ofg. Thus, if N is even and we write F(N) for the number of operations needed to calculate the discrete fourier transform of a function defined on Z , we obtain a

$N$

recurrence of the form

$F(N) = 2F(N/2) + CN$.

The interpretation of this is that in order to work outthe N values of the transform of a function on Z , it is enough to work out two such transforms for functionson Z and work out N \text{linear combinations}, \text{each of}N which takes a constant number of steps.If NN/\text{is a power of} 2, \text{then we can iterate this}:2 F(N/2) \text{will be at most} 2 F(N/4) + CN/2, \text{and so on}. \text{It is not hard to show as a result thatfor some constant} C, \text{a considerable improvement on} F(N) \text{is at most CN} \log NCN}2. If N \text{is not a power of} 2, \text{then the above argu}- \text{ment does not work}, \text{but there are modifications ofthe method that do}, \text{and that lead to similar efficiency gains}. (Indeed, \text{this is true for the Fourier transform on an arbitrary finite Abelian group}.)\text{Once we can calculate Fourier transforms efficiently}, \text{there are other calculations that immediately become easy as well}. A \text{simple example is the inverse Fourier transform}, \text{which has a formula very similar to that of the Fourier transform and can therefore be calcu}-\text{lated in a similar way}. \text{Another calculation that becomes easy is the defined as follows}. \text{if convolution a} =\text{of two sequences}, \text{which is}(a , a , a , . . . , a ) and b =(\text{blution is the sequence}0, b1, b2, . . . , bn) \text{are two sequences}, \text{then their convo} - c = (c0 , c1, c2, . . . , cm ), where each This sequence is denoted bycris defined to bea0(br)0 a+1 *a1 b2 b. One of the mos(tr)-1 + · · · +m +n arb0. important properties of Fourier transforms is that they

204

“convert convolutions into multiplication.” That is, ifwe find a suitable way of regardinga and b as func- tions onfunction Zr N\to , then the Fourier transform ofa(r )ˆb(r )ˆ . Therefore, to work outa*ab*\text{is theb we} can work out ˆr , and take the inverse Fourier transform of the result.aand ˆb, multiply them together for each All stages of this calculation are quick, so calculating convolutions is quick.This immediately leads to a quick way of multiplying the two polynomials$b$ + b x+· · ·+b xntogether, since the coefficients of$a^{0} + a^{1}x + · · · + a^{m}x^{m} and$ the product are given by the sequencethe0 a1 are between 0 and 9, it is a quick process to evalu-n c = a* b. If alli

ate the product polynomial atx = 10 (\text{since none of the} coefficient sc will have many digits), \text{so we also haver a method of multiplying twothat is far faster than long} \text{multiplication}. \text{These aren}-\text{digit integers together two of the huge number of applications of the fast Fourier transform}. A \text{more direct source of applications occurs in engineering}, \text{where one frequently wishes toanalyze a signal by looking at its Fourier transform}. A \text{very surprising application is totion} [III.74](/part - 03/quantum - computation): \text{a famous result of Peter Shor is that one quantum computacan use a quantum computer to factorize large integers very quickly}; \text{this algorithm depends in an essential way on the fast Fourier transform}, \text{but uses the power ofquantum computing in an almost miraculous way to divide the} N \log N \text{steps into} N \text{lots of log} N \text{steps that can be carried out} “\text{in parallel}.” III.27 \text{The Fourier Transform Terence Tao Letf be a function from} R to R. Typically, \text{there is not much that one can say about tions have useful symmetry properties}. \text{For instance}, f , \text{but certain func}-\text{fis calledis called odd even if} f (if - f (x)-x)= −=f (x)f (x)\text{for everyfor everyx}. Further - x, \text{and it more}, \text{every functionf can be written as a superposition of an even part}, \text{the functionf} (x)fe=, \text{and an odd part}, x3 + 3 x2 + 3 x + 1 \text{is neither evenfo}. \text{For instance}, \text{nor odd}, \text{but it can be written as}$f (x) = 3 x2 + 1 and f (x) = x3 fe+(x)3 x+$. \text{For a generalf}o(x), where functionby the formulasef , the decomposition is unique and is givenofe(x) =1 2 (f (x) + f (-x))

and

$fo (x) =1 2 (f (x) - f (-x))$.

III. Mathematical Concepts

and odd functions? A useful way to regard them is asfollows. We have a group of two transformations of the What are the symmetry properties enjoyed by even real line: one is the identity mapι:$x \to x \text{and the}$ other is the reflectionρ: x → −x. Now any transfor- mationtion of the functions defined on the real line: given aφ of the real line gives rise to a transforma- functiong(x) = f (φ(x))f , the transformed function is the function. In the case at hand, if φ = ι then the transformed function is justit isf (-x). If f is either even or odd, then both thef (x)$, \text{while if} φ = ρ then$ transformed functions areinal functionf . In particular, when scalar multiplesφ = ρ, the trans-of the orig- formed function ismultiple is 1) and-f (x)f (x)whenwhenff is even (so the scalaris odd (so the scalar multiple is-1). a very simple prototype of the general notion of a The procedure just described can be thought of as Fourier transform. Very broadly speaking, a fourier transform is a systematic way to decompose “generic” functions into a superposition of “symmetric” func-tions. These symmetric functions are usually quite explicitly defined: for instance, one of the most important examples is a decomposition into themetric functions [III.92](/part-03/trigonometric-functions) sin(nx) and cos(nx)trigono-. They are also often related to physical concepts such as fre-quency or energy. The symmetry will usually be associated with a group [I.3 §2.1](/part-01/fundamental-definitions)G, which is usually Abe- lian. (In the case considered above, it is the two-element group.) Indeed, the Fourier transform is a fundamental tool in the study of groups, and more precisely in the representation theory [IV.9](/part-04/representation-theory) of groups, which concerns different ways in which a group can be regarded as a group of symmetries. It is also related to topics inlinear algebra, such as the representation of a vector as linear combinations of anor as linear combinations of orthonormal basis eigenvectors [I.3 §4.3](/part-01/fundamental-definitions) of[III.37](/part-03/bayesian-analysis), a matrix or linear operator [III.50](/part-03/linear-operators-and-their-properties). integer posing functions from For a more complicated example, let us fix a positive$n$and let us define a systematic way of decom-C to C, that is, complex-valued functions defined on the complex plane. Iffunction andj is an integer between 0 and fn -is such a1, then we say that low ing property. Letf is a harmonic of orderω = (e2()π){i}/n, so thatj if it has the fol-ω is a primi- tive positive power ofnth root of 1 (meaning thatω gives 1). Thenωn = f (ωz)1 \text{but no smaller}= ωjf (z) \text{for everywhen} j = z0 we recover the definition of an even func-\in  C. Notice that if n = 2, then ω = −1, so tion and when j =1 we recover the definition of an odd

III.27. The Fourier Transform

function. In fact, inspired by this, we can give a gen-eral formula for a decomposition off into harmonics, which again turns out to be unique. If we define n-1 fj(z) = n1 k = 0 f (ωkz)ω-jk,

then it is a simple exercise to prove that

$f (z) =^{n}^{-1}f (z)j$

for everyz (use the fact thatj=0 ω-jk = n if k = 0 j$and 0 otherwise)$, and thatfj(ωz) = ωjfj(z) for everyzics. The group associated with this Fourier transform. Thus, f can be decomposed as a sum of harmon- is the multiplicative group of the1, ω$, . . . , ω^{n}^{-1}$, or the cyclic group of ordernth roots of unityn. The rootωj is associated with the rotation of the complex plane \text{through an angle of} 2πj/n. complex-valued function defined on the unit circle{z}Now let us consider infinite groups. Let$\in C$:$|z| = 1$. To avoid technical issues we shallf be a T = assume thatf is smooth—that is, it is infinitely differentiable. Now iff (z) = czn for some integerf is a function of the simple formn and some constantc That is, if, then f will have rotational symmetry of orderω = (e2()π){i}/n again, then f (ωz) = f (z) forn. all complex numbers should come as no surprise that an arbitrary smoothz. After our earlier examples, it function such rotationally symmetric functions. Indeed, one canf can be expressed as a superposition of write

$f (z) =^{n}=−$\infty$\i\text{nf ty} f (n)z$ˆn,

where the numbers ˆf (n), called the Fourier coefficients off at the frequencies n, are given by the formulaf (n)ˆ$= 21π^{0}^{2}^{π} f ((e^{i})^{θ})(e^{-i})^{n}θ dθ$. This formula can be thought of as the limiting case\infty  of the previous decomposition, restricted to the unitn \to circle. It can also be regarded as a generalization of the Taylor series expansion of a holomorphic function [I.3 §5.6](/part-01/fundamental-definitions). If${z \in C}$:|z| ⩽f 1 is holomorphic on the closed unit disk, then one can writef (z) =^n\infty=0 a^nz^n,

where the Taylor coefficient an is given by the formulaan = 21π(i|()z){|}=1 f (z)(zn)+1 dz.

205

In general, there are very strong links between fourier analysis and complex analysis. zero very quickly and it is easy to show that the fourier series Iffis smooth, then its Fourier coefficients decay to$\i\text{nf ty} f (n)z$ˆn converges. The issue becomes more subtle ifmerely continuous). Then one must be careful to spec-$n=−$\infty f is not smooth (for instance, if it is ify the precise sense in which the series converges.In fact, a significant portion of harmonic analysis [IV.11](/part-04/harmonic-analysis) is devoted to questions of this kind, and to developing tools for answering them. sion of Fourier analysis is the circle groupthat we can think of the number e The group of symmetries associated with this ver-iθ both as a point in T. (Notice the circle and as a rotation through an angle ofthe circle can be identified with its own group of rota-θ. Thus, tional symmetries.) But there is a second group that isimportant here as well, namely the additive group Z of all integers. If we take two of our basic symmetric func-tions,$z^{m} and z^{n}$, and multiply them together, then we obtain the function$zm^{+}n$, so the map n \to  zn is an iso- morphism from multiplication. The group Z to the set of all these functions under Z is known as the Pontryagin dual of T. related areas of harmonic analysis, the most important Fourier transform is defined on the Euclidean space In the theory of partial differential equations and in Rd . Among all functionsbe “basic” are the plane waves$f$: R$d \to Cf (x)$, the ones considered to= c e^2^π^i^x^·^ξ, whereξξ \in  R^d is a vector (known as the frequency of the plane wave), x · ξ is the dot product between the positionx and the frequency ξ, and c is a complex numberξ

(whose magnitude is the Notice that sets of the form amplitude H = {\text{of the plane wave})}.x:$x · ξ = \l\text{ambda are}$ (hyper)planes orthogonal tovalue off (x) is constant. Moreover, the value taken byξ, and on each such set the\lambda f This explains the name “plane waves.” It turns out thaton H\lambda is always equal to the value taken on (Hλ()+2){π}. if a function rapidly decreasing as$f$is sufficiently “nice” (e.g., smooth andx gets large), then it can be rep- resented uniquely as the superposition of plane waves, where a “superposition” is now interpreted as an integral rather than a summation. More precisely, we havethe formulas1 f (x) =R d f (ξ)$ˆ e2$πi x · ξ dξ, ferently, \text{with factors such as} 2 places. \text{These notational differences have some minor benefits and}1. \text{In some texts}, \text{the Fourier transform is defined slightly dif}-π and - 1 \text{being moved to other drawbacks}, \text{but they are all equivalent to each other}$. 206 where f (ξ)ˆ$=R d f (x)(e-2()π){i}x · ξ dx.

The function ˆoff , and the second formula is known as thef (ξ) is known as the Fourier transform Fourier inversion formula determine the Fourier-transformed function from the. These two formulas show how to original function and vice versa. One can view the quan-tity ˆf (ξ) as the extent to which the function f contains a component that oscillates at frequencyξ. As it turns out, there is no difficulty in justifying the convergence of these integrals whenfis sufficiently nice, though the issue again becomes more subtle for functions thatare somewhat rough or slowly decaying. In this case, the underlying group is the Euclidean group Rd (which can also be thought of as the group of translations); note that both the position variabled-dimension alx and the frequency variable also the Pontryagin dual group in this setting.$ξ \text{are contained in} R^{d}$, so2 Rd is understanding various linear operations on functions, such as, for instance, the Laplacian on One major application of the Fourier transform lies in Rd. Given a func- tion$f$: Rd \to  C, its Laplacian Δfis defined by the formula

Δf (x) =j=d 1 ∂∂x2(fj)2,

where we think of the vectorx in coordinate form, x =(xreal variables. To avoid technicalities let us consider1, . . . , xd), \text{and of} f \text{as a function} f (x1, . . . , xd) of d \text{only those functions that are smooth enough for theabove formula to make sense without any difficulty}. \text{function wave such as In general}, \text{there is no obvious relationship between af and its Laplacianf} (x) = (e2()π){i}x ·\Deltaξf, \text{there is a very simple}. \text{But when} f \text{is a plane relationship}:\Delta(e2()π){i}x · ξ = −4π2|ξ|2(e2()π){i}x · ξ. That is, the effect of the Laplacian on the plane wavee2πi x · ξ is to multiply it by the scalar -4π2|ξ|2. In other words, the plane wave is an eigenfunction the Laplacian\Delta, \text{with eigenvalue} - 4π2|ξ|2. (More gen-3 for erally, plane waves will be eigenfunctions for any lin-ear operation that commutes with translations.) Therefore, the Laplacian, when viewed through the lens of the not want to use this dot product, the Pontryagin dual would insteadbe2. This is because of our reliance on the dot product; if one did(R d)*, the dual vector space t(o R)d. But this subtlety is not too important in most applications.3. Strictly speaking, this is a generalized eigenfunction, as plane waves are not square-integrable on Rd.

III. Mathematical Concepts

Fourier transform, is very simple: the Fourier transform lets one write an arbitrary function as a superposition of plane waves, and the Laplacian has a very simple effect on each plane wave. To be explicit about it,\Delta f (x) = \Delt(a R)d f (ξ)$ˆ e2$πi x · ξ dξ=R d f (ξ)ˆ$\Delta(e^{2}()^{π})^{{}i}^{x}^{·}^{ξ} dξ=^{R}^{d}(-4π^{2}|ξ|^{2})f (ξ)$ˆ e2$π^{i}^{x}^{·}^{ξ} dξ$,

which gives us a formula for the Laplacian of a gen-eral function. Here we have interchanged the Laplacian Δwith an integral; this can be rigorously justified for suitably nice This formula representsf , but we omit the details.Δf as a superposition of plane waves. But any such representation is unique, and the Fourier inversion formula tells us that

$\Delta f (x) =^{R}^{d} \Delta f (ξ)(e^{2}()^{π})^{{}i}^{x}^{·}^{ξ} dξ$.

Therefore,

$\Delta f (ξ) = (-4π^{2}|ξ|^{2})f (ξ)$,ˆ

a fact that can also be derived directly from the definition of the Fourier transform using integration byparts. This identity shows that the Fourier transform diagonalizes Laplacian, when viewed using the Fourier transform, isthe Laplacian: the operation of taking the nothing more than multiplication of a function the multiplier$-4π^{2}|ξ|^{2}$. The quantity -4π2|ξ|2 F(ξ)can beby interpreted as the energy level associated4 with the frequencyas a Fourier multiplierξ. In other words, the Laplacian can be viewed, meaning that to calculate the Laplacian you take the Fourier transform, multiply bythe multiplier, and then take the inverse Fourier transform again. This viewpoint allows one to manipulate the Laplacian very easily. For instance, we can iterate the above formula to compute higher powers of the Laplacian: $\Delta^{n}f (ξ) = (-4π^{2}|ξ|^{2})^{n}f (ξ)$ˆ for$n = 0$, 1, 2, . . . . Indeed, we are now in a position to develop more gen-eral functions of the Laplacian. For instance, we can take a square root as follows: $-\Delta f (ξ) = 2π|ξ|f (ξ)$.ˆ This leads to the theory of fractional differential oper-ators (which are in turn a special case of pseudo differential operators), as well as the more general theory to make the energies positive.4. When taking this view, it is customary to replaceΔ by -Δ in order

III.27. The Fourier Transform

ofstarts with a given operator (such as the Laplacian) and functional calculus [IV.15 §3.1](/part-04/operator-algebras), in which one then studies various functions of that operator, suchas square roots, exponentials, inverses, and so forth. As the above discussion shows, the Fourier transform can be used to develop a number of interesting oper-ations, which have particular importance in the theory of differential equations. To analyze these operations effectively, one needs various estimates on the Fourier transform. For instance, it is often important to knowhow the size of a functionf , as measured by some norm, relates to the size of its Fourier transform, asmeasured by a possibly different norm. For a further discussion of this point, see function spaces [III.29](/part-03/function-spaces). One particularly important and striking estimate of thistype is the Plancherel identity, which shows that the actually equal Rd to the|f (x)|L2 L2 d-norm of a Fourier transform is-norm of the original function.x =R d |f (ξ)ˆ|2 dξ, The Fourier transform is therefore a unitary operation, so one can view the frequency-space representation of2 a function as being in some sense a “rotation” of the physical-space representation. transform and associated operators is a major compo-nent of harmonic analysis. A variant of the Plancherel Developing further estimates related to the Fourier identity is the convolution formula: This formula allows one to analyze the R d f (y)g(x - y) dy =R d f (ξ)ˆg(ξ)$ˆ convolutione2$πi x^·^ξ dξ.f^* g(x) =R d f (y)g(x - y) dy

of two functions forms; in particular, if the Fourier coefficients off and g in terms of their Fourier trans-f org are small, then we expect the convolution f* g to be small as well. This relationship means that the fourier transform controls certain correlations of a function with itself and with other functions, which makes the Fourier transform an important tool in understanding the randomness and uniform distribution proper-ties of various objects in probability theory, harmonic analysis, and number theory. For instance, one can pur-sue the above ideas to establish the central limit theorem, which asserts that the sum of many independent random variables will eventually resemble a gaussian distribution ods to establish[III.71 §5](/part-03/probability-distributions); one can even use such meth-vinogradov’s theorem [V.27](/part-05/problems-and-results-in-vi36-peter-gustav-lejeune-dirichlet-18051859), \text{that every sufficiently large odd number is the sum of three primes}. 207 \text{above set of ideas}. \text{For instance}, \text{one can replace the Laplacian by a more general operator and the plane There are many directions in which to generalize the waves by} (generalized) \text{eigenfunctions} \text{of that operator}. \text{This leads to the subject ofand functional calculus}; \text{one can also study the alge}-\text{spectral theory} [III.86](/part - 03/the - spectrum) \text{bra of Fourier multipliers} (\text{and of convolution}) \text{more abstractly}, \text{which leads to the theory of}$C*$[IV.15 §3](/part - 04/operator - algebras). \text{One can also go beyond the theory of lin}-\text{ear operators and study bilinear}, multilinear, \text{or even}-\text{algebras fully nonlinear operators}. \text{This leads in particular tothe theory of paraproducts}, \text{which are} \text{generalizations} \text{of the pointwise product operation}(f (x), g(x)) \tof g(x)\text{In another direction}, \text{one can replace Euclidean spacethat are of importance in differential equations}. \text{Rd by a more general group}, \text{in which case the notion of a plane wave is replaced by the notion of aacter} (\text{if the group is Abelian}) \text{or a} \text{representation} char-(\text{if the group is non} - Abelian). \text{There are other variants ofthe Fourier transform}, \text{such as the Laplace transform or the Mellin transform} (\text{for more about other trans} - forms, \text{see the article transforms} [III.91](/part - 03/transforms)), \text{which are very similar algebraically to the Fourier transform and play similar roles} (\text{for instance}, \text{the Laplace transform isalso useful in analyzing differential equations}). \text{We have already seen that Fourier transforms are connected to Taylor series}; \text{there is also a connection to some other important series expansions}, \text{notably Dirichlet series}, \text{as well as expansions of functions in terms of polynomials} [III.85](/part - 03/special - functions) \text{such as orthogonal polynomials special or The Fourier transform decomposes a function ex}-\text{spherical harmonics} [III.87](/part - 03/spherical - harmonics). \text{actly into many components}, \text{each of which has a precise frequency}. \text{In some applications it is more usefulto adopt a} “fuzzier” approach, \text{in which a function is decomposed into fewer components but each compo}-\text{nent has a range of frequencies rather than consisting purely of a single frequency}. Such \text{decompositions} \text{can have the advantage of being less constrained by the uncertainty principle}, \text{which asserts that it is impossible for both a function and its Fourier transform to be concentrated in very small regions of Rd}. \text{This leads to some variants of the Fourier transform}, \text{such as wavelet transforms to a number of problems in applied and computational}[VII.3](/part - 07/wavelets - and - applications), which are better suited mathematics, and also to certain questions in harmonic analysis and differential equations. The uncertainty principle, being fundamental to quantum mechanics, also connects the Fourier transform to mathematical physics, and in particular to the connections between

208

classical and quantum physics, which can be studied rigorously using the methods of geometric quantization and microlocal analysis. III.28 Fuchsian Groups

Jeremy Gray

One of the most basic objects in geometry is thea surface that has the shape of the surface of a bagel.torus: If you want to construct one, you can do so by tak-ing a square and gluing opposite edges together. When you glue the top and bottom edges together you havea cylinder, and when you glue the other two edges together, which have now become circles, you obtain your torus. A more mathematical way of making a torus is as follows. We start with the usualand the square in it with vertices at(x$, y)(0\text{coordinate plane}$, 0), (1, 0), (1,1),$\text{andates satisfy} 0$(0, 1), which consists of the points whose coordin-⩽ x ⩽ 1, 0 ⩽ y ⩽ 1. This square can be moved around horizontally and vertically. If we shift itm units horizontally and n units vertically, where m andthe points whose coordinates satisfyn are integers, we get the square that consists ofm ⩽ x ⩽ m + 1, n ⩽ y ⩽ n+1. As m and n run through all the integers, we see that the copies of the square cover the whole plane, with four squares coming together at each point with integer coordinates. The plane is said to beor tessellated (from the Latin word for a marble chip intiled a mosaic), and it is easy to see that you can color the squares alternately black and white and get an infinite checkerboard pattern.To make the torus we “identify” points. We say that the points point in a certain new figure if(x, y) and (x^ , y^ ) correspond to the samex - x^  and y - y^  are both integers. To see what the new figure looks like, we observe that any point in the plane corresponds to a point inside, or on the edge of, our original square.Moreover, the point(x, y) corresponds to exactly one point inside the square provided that neitheris an integer. So our new space looks a lot like our origi-x nor y nal square. But what about the points They correspond to the same point in our new space, as(1 4,0) and (1 4, 1)? \text{do any corresponding pairs of points on the upper andlower edges of our square}. \text{So those edges are identified in our new space}. \text{By a similar argument}, \text{so too are the left and right edges}. \text{The result is that}, \text{after points are identified according to our rule}, \text{we obtain the torus}. \text{figures on it just by drawing them in the original square}; \text{If we make the torus in this way}, \text{we can draw small III}. \text{Mathematical Concepts lengths in the square will then correspond exactly tolengths on the torus}. \text{This is how old}-\text{fashioned printing on a drum works}: \text{an inked figure on a cylinder isrolled over the paper to make exact copies of the figure}. Thus, \text{as far as small figures are concerned}, \text{the geom}-\text{etry of the torus is exactly like Euclidean geometry}. \text{In mathematical language we say that the geometry on thetorus is induced from the geometry on the plane}, \text{and therefore that it isit is different}, \text{because one can draw curves on the torus locally Euclidean}. Globally, \text{of course}, \text{that cannot be shrunk to a point}, \text{whereas one cannot do so on the plane}. \text{the bulk of the work for us}. \text{In this case the group is Notice}, too, \text{that we have brought in a group to do the set of all pairswith}(m, n) + (m^ , n(m, n)^ )\text{defined to bewherem and}(mn+\text{are integers}, m^ , n + n^ ). \text{class of surfaces that are closed} (\text{they have no bound}-\text{The torus and the sphere are but two of an infinite ary}) \text{and compact} (\text{they do not in any sense go off toinfinity}). \text{Other examples include the two}-\text{holed torus}, \text{and more generally thegenus} 2, 3, 4, . . . ). To create these in a similar way, wen-holed torus (the surfaces of need Fuchsian groups. It is natural to expect that we can get other surfaces by using polygons with more than four sides. Itturns out that if you use a polygon with eight sides, for example a regular octagon, and glue sides 1 and 3 together, 2 and 4 together, 5 and 7 together, and 6 and 8 together, you get the two-holed torus. How can we usea group to achieve the same result, as we did with the torus? For that we need a way of fitting lots of copies of the octagon together so that they overlap only along edges. The problem is that one cannot tile the plane with octagons: the angles of an octagon are 135◦, and that is far too big because we need eight octagons to fit together at each vertex. The way forward here is to use hyperbolic geometry can also work with our bare hands. Take the unit disk[I.3 §6.6](/part-01/fundamental-definitions) instead of Euclidean geometry. But we in the complex plane, D$= {z}$:$|z| ⩽ 1$. Take the group of what are calledare maps of the form$z$Möbius transformations$\to (az + b)/(cz + d)$. It is a, which routine calculation to show that these maps send circles and straight lines to circles and straight lines (theymix the two types up, sometimes sending a circle to a straight line and vice versa) and that they map anglesto equal angles, just like the more familiar Euclidean rotations. If we now select just those Möbius transfor-mations that map D to itself, then we have a group that

III.28. Fuchsian Groups

we shall callgroup.G. Indeed, we very nearly have a Fuchsian the square played in the Euclidean plane. Our group$G$We need to find a shape that will play the role thathas the property that it maps diameters of D and arcs of circles perpendicular to the boundary ofdiameters of D and arcs of circles perpendicular to D to the boundary of D, so we let these play the role of straight lines and use eight of them as the edges ofa (non-Euclidean) octagon. We find that we can do this in many ways, so we pick one with the highest degreeof symmetry to make things easy for ourselves. That is, we draw a “regular octagon” centered on the centerof the disk D. This still leaves us with some choice: the bigger the octagon, the smaller its angles. So we drawthe octagon with angles ofπ/4, \text{which allows eight of} them to cluster at each vertex, and then we can fit them together as we want. If we identify points that lie in corresponding places in different copies of the polygon, then the resulting space is a riemann surface [III.79](/part-03/riemann-surfaces) of genus 2.A Fuchsian group is a subgroup of the group$G$ (of Möbius transformations that map D to itself) that moves some polygon around “en bloc” and thereby tilesthe disk. Just as with the torus, we have a notion of equivalent points (ones that are in the corresponding place in different tiles) and when we identify equivalent points we get the space that we would also have obtained by identifying the edges of the polygon in pairs, which is the space we wanted.All this can be described in the language of hyperbolic geometry. Thea riemannian metric disk model[I.3 §6.10](/part-01/fundamental-definitions) onis defined by means of D, the differential of which is given by d$s = 1|− |dz|z|^{2}$. The elements of Gmove figures around in D in a way that preserves hyperbolic distances. It follows that the geometry on the surface that we obtain by identifying points in the manner just described is locally hyperbolic It turns out that if we carry out the above construc-, just as that of the torus was locally Euclidean. tion starting with a regular 4 then we obtain a Riemann surface of genus$n$-sided figure (with$n$. \text{But math} - n > 2), ematicians can do much more. If you go back to theplane and start not with a square but with a rectangle, or still more generally a parallelogram, it is rea-sonably easy to see that the same construction can be carried out. Indeed, if you just watch the original con-struction from an appropriate angle, instead of from

209

vertically above the plane, then the square will turn intoany parallelogram you choose (possibly enlarged or contracted). When you use a parallelogram, you again obtain a torus, but it differs from the original one in thesame way that the square and the parallelogram differ: angles are distorted. It is a not entirely trivial exerciseto show that the only angle-preserving maps from one parallelogram to another are similarities (uniform scaling by the same amount in two, and therefore all, direc-tions). So the resulting tori have a different sense of what angles are: that is, they have different structures. conformal The same happens in the hyperbolic disk. If one picks a 4 whose edges come in pairs of equal length, and onen-sided polygon (its sides are parts of geodesics) finds a group that moves this polygon around en blocand matches the edges exactly, then a Riemann surface is once again obtained, but if the polygons are not conformally equivalent, then neither are the cor-responding surfaces; they have the same genus, n, but different conformal structures. We can even go further and allow some of the vertices of the polygon to lie on the boundary of the disk, in which case the corresponding sides of the polygon are infinitely long with respect to the hyperbolic metric. The space we then construct is a “punctured” Riemann surface, and again mathematicians can vary its conformal structure. The fundamental importance of Fuchsian groups derives from thethat all but the simplest Riemann surfaces arise from uniformization theorem, which says some Fuchsian group in the fashion described above.This includes every Riemann surface of genus greater than 1, and those of genus 1 with at least one puncture, with any possible conformal structure.The name Fuchsian group was given to these groups bythe course of work on the hypergeometric equation andpoincaré [VI.61](/part-06/jules-henri-poincar-18541912) in 1881, who discovered them in related differential equations, which had been inspired by the work of the German mathematician Lazarus Fuchs. klein [VI.57] protested to him that a better procedure might have been to name them after Schwarz, and Poincaré was willing to agree once he read the relevant paper by Schwarz, but by then Fuchs had given his approval to the name. When Klein protested too much(in Poincaré’s view), Poincaré \text{publicly gave the name Kleinian groups arise in the study of conformal} \text{transformations} \text{of theto the analogous class of groups that three}-\text{dimensional unit ball}. \text{The names have stuck ever since}, \text{but the study of Kleinian groups is much more difficult and neither Poincar}é \text{nor Klein could do much} 210 \text{with the concept}. However, \text{the idea that every riemann surface might arise from either the sphere}, \text{the Euclidean plane}, \text{or the hyperbolic plane was something theyboth came to conjecture}. \text{Rigorous proofs of this statement}, the \text{uniformization} theorem, \text{were to be givenonly in} 1907, \text{by Poincar}é \text{and Koebe independently}. lows. A \text{subgroup The formal definition of a Fuchsian group is as fol}- Hof the group of all Möbius transformations is said to actpact set K in the disk ddis continuously the sets h(K) andif, for every com-K are disjoint except for finitely manyh \in H. A \text{Fuchsian group is a} subgroup that acts discontinuously on the disk Hof the group of all Möbius transformations D. III.29 Function Spaces

Terence Tao

1 What Is a Function Space?

When one works with real or complex numbers, thereis a natural notion of the magnitude of a numberx, namely its modulusof magnitude to define a distance|x|. One can also use this notion|x - y| between two numbers which pairs of numbers are close and which ones arex and y and thereby say in a quantitative way far apart. when one deals with objects with more degrees offreedom. Consider for instance the problem of deter-The situation becomes more complicated, however, mining the “magnitude” of a three-dimensional rect-angular box. There are several candidates for such a magnitude: length, width, height, volume, surface area, diameter (the length of a long diagonal), eccentricity, and so forth. Unfortunately, these magnitudes donot give equivalent comparisons: for example, box A may be longer and have a greater volume than box B, but box B may be wider and have a greater surface area. Because of this, one abandons the idea that there should be only one notion of “magnitude” for boxes, and instead accepts that there is a multiplicity of such notions and that they can all be useful: for some appli-cations one may wish to distinguish the large-volume boxes from the small-volume boxes, while in others onemay wish to distinguish the eccentric boxes from the round boxes. Of course, there are several relationships between the different notions of magnitude (e.g., the isoperimetric inequality an upper limit on the possible volume if one knows the[IV.26] allows one to place surface area), so the situation is not as disorganized asit may at first appear.

III. Mathematical Concepts

and range. (A good case to have in mind is functions$f$ Now let us turn to functions with a fixed domain:[-1,1] \to  R from the interval [-1, 1] to the real line R.) These objects have infinitely many degrees of freedom, so it should not be surprising that there are now infinitely many distinct notions of “magnitude,” which all provide different answers to the question “how large is a given function tion “how close together are two functions$f$?” (or to the closely related ques-f and g?”). In some cases, certain functions may have infinite mag-nitude by one measure and finite magnitude by another (similarly, a pair of functions may be very close by one measure and very far apart by another). Again, this situation may seem chaotic, but it simply reflects thefact that functions have many distinct characteristics— some are tall, some are broad, some are smooth, someare oscillatory, and so forth—and that, depending on the application at hand, one may need to give more weight to one of these characteristics than to others. In analysis, these characteristics are embodied in a vari-ety of standard function spaces and their associated norms qualitatively and quantitatively., which are available to describe functions both Xdomain and range). A majority (but certainly not all), the elements of which are functions (with some fixed Formally, a function space is a normed space [III.62](/part-03/normed-spaces-and-banach-spaces) of the standard function spaces considered in analysis are not just normed spaces but also banach spaces [III.62](/part-03/normed-spaces-and-banach-spaces). The normf X of a function f in X is the func- tion space’s way of measuring how largemon, though not universal, for the norm to be definedf is. It is com- by a simple formula and for the spacecisely of those functionsf for which the resulting def-X to consist pre- initionfact that a function$f$ Xmakes sense and is finite. Thus, the meref belongs to a function space X can already convey some qualitative information about that function. For example, it may imply some regularity,1 decay, boundedness, or integrability on the function The actual value of the normf makes this informa-f . tion quantitative. It may tell usmuch decay it has, by which constant how X regularit is bounded, orf is, how how large its integral is. 2 Examples of Function Spaces We now present a sample of commonly used function spaces. For simplicity we shall consider only spaces of functions from[-1,1] to R. \text{considered to be}.1. \text{The more smoothly a function varies}, \text{the more} “regular” \text{it is III}.29. \text{Function Spaces} 2.1 C0[-1, 1] \text{This space consists of all}[I.3 §5.2](/part - 01/fundamental - definitions) from[-1,1] to R, \text{and is sometimes denoted continuous functions} C[-1,1]. \text{Continuous functions are regular enough to allow one to avoid many of the technical subtleties associated with very rough functions}. \text{Continuous func}-\text{tions on a compact} [III.9](/part - 03/compactness - and-\text{compactication}) \text{interval such as}[-1, 1] are bounded, so the most natural norm to place on this space is theis the largest possible value ofsupremum norm, denoted|f (x)|. (Formally, it isf \infty , which defined to be sup tinuous functions on\\{|f (x)[-|1},\\: 1 x] \i\text{nthe two definitions are}[-1, 1], \text{but for con} - equivalent.) \text{form convergence}: \text{a sequence form ly to The supremum norm is the norm associated with uni} - f \text{if and only if} f f - 1, ff2, . . .\text{tends to} 0 \text{asconverges uni} - n tends toerty that one can multiply functions together as well as\infty. \text{The space} C0[-1 n,1] \text{has the useful prop}-\i\text{nfty adding them}. \text{This makes it a basic example of aalgebra}. Banach 2.2 C1[-1, 1] \text{This is a space that has a more restricted member}-\text{ship than} C0[-1, 1]: \text{not only must a function}f in C1[-1, 1] \text{be continuous but it must also have a deriva}- \text{tive that is continuous}. \text{The supremum norm here isno longer a natural one}, \text{because a sequence of continuously} \text{differentiable} \text{functions can converge in thisnorm to a non} \text{differentiable} function. Instead, \text{the right norm here is theto be}$f + f^ C1-$.norm (f C()1()[){ - 1}\\\{,\\\}1 ], which is defined a function trolling the latter would be unsatisfactory, since it Notice that the\infty and the size of its derivative. (Merely con-\infty C1-norm measures both the size of would give constant functions a norm of zero.) Thusit is a norm that forces a greater degree of regularity than the supremum norm. One can similarly definethe space$C^{2}[-1$,1]of twice continuously differentiable functions, and so forth, all the way up to thespace$C \i\text{nf ty} [-1$,1]of infinitely differentiable functions. (There are also “fractional” versions of these spaces, such as$(C^{0})^{\}\\{}}$,\\\\\\\\\\\\\\\\\\\\}α[-1, 1], \text{the space of} α}}-Hölder continuous functions. We will not discuss these variants here.)

2.3 The Lebesgue Spaces Lp[-1, 1]

The supremum norm simultaneous control on the size off \infty  mentioned earlier gives|f (x)| for all x \in[-1, 1]. However, this means that if there is a tiny set

211

oflarge, even if a typical value ofx for which |f (x)| is very large, then|f (x)| is much smaller.f \infty  is very It is sometimes more advantageous to work with normsthat are less influenced by the values of a function on small sets. The Lp-norm\sum  of a function f isfp =-1 1 |f (x)|p d(x1)/p.

This is defined for 1 The function space L⩽p[p <-1,\infty 1]and for any measurable is the class of measurablef . functions for which the above norm is finite. The normf \infty  of a measurable function f is its essential supre-$mum$|f (x): roughly speaking this means the largest value of| if you ignore sets of measure zero. It turns out to be the limit of the normsity. The space L\infty [-1, 1] consists of those me a sur a bl efp as ptends to infin functionsf for which f \inftyis finite. While the$L \i\text{nfty norm}$ is concerned solely with the “height” of a function, the Lp norms are instead concerned with a combination of the “height” and “width” of a function. LThis space is exceptionally rich in symmetries: there2 Particularly important among these norms is the-norm, since L2[-1, 1] is a hilbert space [III.37](/part-03/bayesian-analysis). \text{is a wide variety of invertible linear maps unitary} \text{transformations} \text{Tdefined on} L2[-1, 1] \text{such that}, \text{that is}, T f2 = f2 \text{for every function} f \in L2[-1, 1].$2$.4 \text{The Sobolev Spaces} Wk, p[-1, 1]

The Lebesgue norms control, to some extent, the heightand width of a function, but say nothing about regularity; there is no reason why a function in Lp should be differentiable or even continuous. To incorporate such information one often turns to the Sobolev norms (f W)k, (p[)-1,1], \text{defined for} 1$⩽ p ⩽ \i\text{nfty and} k ⩾ 0 by(f W)k$, p[ - 1^,1] = j = k 0 ddjx(fj)p. \text{The Sobolev space} Wk, p[-1,1] is the space of functions for which this norm is finite. Thus, a function lies in Wk, p[-1, 1]\text{if it and its firstk derivatives all belong to Lp}[-1, 1]. \text{There is one subtlety}: \text{we do not requiref to beweaker sense ofktimes} \text{differentiable} \text{in the usual sense}, \text{but in the distributions} [III.18](/part - 03/distributions). For instance, the function$f$ (x) = |x|is not differentiable at zero, but it does have a natural weak derivative: the functionf^ (x) which is -1 when x < 0 and +1 when x > 0. This function lies in L\infty [-1,1] (since the set {0} has measure zero, we do not need to specify therefore f \text{lies in} (W1),\infty [-1,1] (which turns out to bef^ (0)), and the space of Lipschitz-continuous functions). We need

212

to consider these generalized differentiable functions because without them the space Wk, p[-1,1] would not be complete.Sobolev norms are particularly natural and useful in the analytical study of partial differential equations and mathematical physics. For instance, the W1\\\{}},\\2 norm \text{can be interpreted as} (\text{the square root of}) an “energy”\text{associated with a function}. 3 \text{Properties of Function Spaces There are many ways in which knowledge of the struc}-\text{ture of function spaces can assist in the study of functions}. \text{For instance}, \text{if one has a good basis for the function space}, \text{so that every function in the space isa} (\text{possibly infinite}) \text{linear combination of basis elements}, \text{and one has some quantitative estimates onhow this linear combination converges to the original function}, \text{then this allows one to represent that function efficiently in terms of a number of coefficients}, \text{and also allows one to approximate that func}-\text{tion by smoother functions}. \text{For instance}, \text{one basic result about} L2[-1, 1] \text{is the Plancherel theorem}, \text{which asserts}, \text{among other things}, \text{that there are numbers}(a )\i\text{nfty such thatnn}=−\inftyf - n=−N N aneπ\text{i nx}2 \to 0 as N → \infty.

This shows that any function in approximated to any desired accuracy in L2[-1, 1]L2\text{can beby a} \text{trigonometric polynomial form}$N a eπ\text{i nx}$. \text{The number}: that is, an expression of thea is the nth Fourier coefficient n=−f (n)Nˆn of f . It is given by the formulanf (n)ˆ$= 12^{-}1 1 f (x)(e^{-})^{π}\text{i nx dx}$. tions eare in fact an One can regard this result as saying that the func-πi nx form a very good basis for orthonormal basis: \text{they have norm} 1 and L2[-1, 1]. (They the inner product of two different ones is always zero.)Another very basic fact about function spaces is that certain function spaces embed into others, sothat a function from one space automatically also belongs to other spaces. Further more, there is oftensome inequality that gives an upper bound for one norm in terms of another. For instance, a function in ahigh-regularity space such as$C1[-1$,1] automatically belongs to a low-regularity space such as$C0[-1$,1], and a function in a high-integrability space such as L\infty [-1, 1] automatically belongs to a low-integrability space such as L1[-1,1]. (This statement is no longer

III. Mathematical Concepts

true if one replaces the interval ni te measure, such as the real line$[-1R$,.) \text{These inclusions}1]by a set of inficannot be reversed; however, one does have the Sobolev embedding theorem la ri ty for integrability. This result tells us that spaces, which allows one to “trade” reguwith lots of regularity but low integrability can beembedded into spaces with low regularity but high integrability. A sample estimate of this type is

$f \i\text{nf ty} ⩽ (f W)1^{\}\\{}}$,\\\\\\\\\\\\\\\\\\\\}(1[)-1\\\\\\\\\\\\\\\\\\\\{,\\\\\\\\\\\\\\\\\\\\}1]}}}},

which tells us that if the integrals of$|f (x)| and |f^ (x)|$ are both finite, thenfar stronger integrability condition than the finitenessf must be bounded (which is a of Another very useful concept is that of$f1)$. duality [III.19](/part - 03/duality). Given a function spacedual space$X^{*}$, which is formally defined as the class$X$, one can define the of allcisely all maps continuous linear functionalsω:$X \to R (or ω$: X \to on CX, if the function, or more pre- space is complex valued) that are linear and continuous with respect to the norm of X . For example, it turns out that every linear functionalω on the space Lp [-1, 1] is of the form

$ω(f ) =^{-1}^{1} f (x)g(x) dx$

for some functiong in Lq[-1,1], where q is the dual$or1$/pconjugate exponent+ 1/q = 1. of p, defined by the equation One can sometimes analyze functions in a function space by looking instead at how the linear function-als in the dual space act on those functions. Similarly, one can often analyze a continuous linear operator$T$: X \to  Y from one function space to another by first considering the adjoint operator$T^{*}$:$Y^{*} \to X^{*}$, defined for all linear functionals T*ω be the functional on Xdefined by the formulaω:$Y \to R \text{by letting} T^{*}ω(x) = ω(T x)$.

We mention one more important fact about function spaces, which is that certain function spaces“interpolate” between two other function spaces$X^{0} \text{and XXspaces}^{1}$. For example, there is a natural sense in which the Lp[-1, 1] with 1 < p < \infty“lie between” the spaces L1[-1, 1] and L\infty [-1,1]. The precise definition of interpolation is too technical for this article, but its usefulness lies in the fact that the “extreme” spaces$X0$ andmediate” spaces$X^{1}$are often easier to deal with than the “inter-X. For this reason, it is sometimes possible to prove difficult results aboutmuch easier results about$X^{0} and X^{1}$and “interpolat-X by proving ing” between them. For instance, it can be used to give

III.31. The Gamma Function

a short proof ofing statement. Let 1 Young’s inequality⩽ p, q, r ⩽ \infty  , which is the follow-satisfy the equation 1$L/pq(R+)$, respectively, and let1/q = 1/r + 1, let f fand^*ggbe thebelong to convolution Lp(R)ofandf$and$\sum  g: that is,$f^{*} g(x) =^{−}$\infty$\i\text{nf ty} f (y)g(x - y) dy$. Then \infty |f* g(x)|r d(x1)/r−$\i\text{nf ty}$⩽ \sum−$\i\text{nf ty}$\infty |f (x)|p d(x1)/p \sum−$\i\text{nf ty}$\infty |g(x)|q d(x1)/q. Interpolation is useful here because the inequality iseasy to prove in the extreme cases when$p = 1$, whenq = 1, \text{or when} r = $\i\text{nf ty}$. It is much harder to prove this result without the help of interpolation theory. III.30 Galois Groups Given a polynomial function cients, the splitting field of$f$is defined to be the small-$f$with rational co ef fie stand all the roots offield [I.3 §2.2](/part-01/fundamental-definitions) that contains all rational numbersf . The Galois group of f is the group of allfield. Each such automorphism permutes the roots of automorphisms [I.3 §4.1](/part-01/fundamental-definitions) of the splittingf , so the Galois group can be thought of as a subset of the group of all structure and properties of the Galois group are closely permutations [III.68](/part-03/permutation-groups) of these roots. The connected with the solubility of the polynomial: in par-ticular, the Galois group can be used to show that not all polynomials aremeans of a formula that involves the usual arithmetic solvable by radicals (that is, solvable by operations together with the extraction of roots). This theorem, spectacular as it is, is by no means the only application of Galois groups: they play a central role in modern algebraic number theory.For more details, see the insolubility of the quintic [V.21](/part-05/the-insolubility-of-the-quintic) and algebraic numbers [IV.1 §20](/part-04/number-theory). III.31 The Gamma Function

Ben Green

Ifthe number 1 n is a positive integer, then its\times  2 × · · · × n: that is, the product of all factorial, written n!, \text{is positive integers up to factorials are} 1, 2, 6, 24, 120, 720, 5040, and 40 320. n. For example, the first eight (The exclamation mark was introduced by Christian Kramp 200 years ago as a convenience to the printer: it is perhaps also intended to convey some alarm atthe rapidity with which n! grows. An obsolete notation, which can still be found in some twentieth-century texts, is$n$.) From this definition, it might appear to be

213

impossible to make sense of the idea of the factorial ofa number that is not a positive integer, but, as it turns out, it is not just possible to do so, but also extremely useful. agrees with the factorial function at positive integer values, but that makes sense for any real number, and The gamma function, writtenΓ , is a function that even for any complex number. Actually, for various rea-sons it is natural to define$Γ \text{so that} Γ (n) = (n - 1)$! for n = 2, 3, . . . . Let us start by writing\inftyΓ (s) =0 (xs)-1 e-x dx, (1)

without paying too much attention to whether the inte-gral converges. If we integrate by parts, then we find that Γ (s) = [-(xs)-1 e-x ]\infty0 +0 \infty (s - 1)(xs)-2 e-x dx. (2)$As$ xtends to infinity,(xs)-1 e-x tends to zero, and ifsxsis, for example, a real number greater than 1, then-1 = 0 when x = 0. Therefore, for such s, we can ignore the first term in the above expression. But thesecond one is simply the formula for$Γ (s - 1)$, so we have shown that$Γ (s) = (s - 1)Γ (s - 1)$, which is just what we need if we want to think oflike$(s - 1)$!.Γ (s) as something It is not hard to show that the integral is in fact convergent whenever real part of$s$) is positive. Moreover, it defines as is a complex number and Re(s)holo-(the morphic function real part ofs is negative, the integral does not converge[I.3 §5.6](/part-01/fundamental-definitions) in that region. When the at all, and so the formula (1) cannot be used to definethe gamma function in its entirety. However, we can instead use the property the definition. For example, when$Γ (s) = (s --11)Γ (s< Re - 1(s)) to⩽extend0$, we know that the definition does not work directly, but itdoes work fors + 1, since Re(s + 1) > 0. We would likeΓ (sto be+1Γ (s) to equal+ 1)/s. Once we have done this, we can turnsΓ (s), so it makes sense to defineΓ (s) our attention to values of$s with - 2 < Re(s) ⩽ -1$, and so on. example), we have divided by zero. This is perfectly permissible, however, if all we require of The reader may object that in definingΓ Γ (\text{is that it}0) (for should befunctions are allowed to take the “value”meromorphic [V.31](/part-05/the-riemannroch-theorem), \text{because meromorphic}\infty . Indeed, \text{it is} \text{not hard to see thatpoles at} 0,-1, -2, . . .Γ ., \text{as we have defined it}, \text{has simple ful properties of}\c\text{os There are in fact many functions that share the use}-(2π(s + 1)) \text{for any}Γ . (\text{For instance}, \text{because coss}, \text{and cos}(2πn) = 1 \text{for every}(2πs) =$214 \text{integer the property}$ n, \text{the function} F(s) = (s - F(s)1)F(s=-Γ (s)1) and\cos F(n)(2πs)= (\text{nalso has} - 1)!.) Nevertheless, \text{for a variety of reasons}, \text{the function}Γ , \text{as we have defined it}, \text{is the most natural meromorphic extension of the factorial function}. \text{The most persuasive reason is the fact that it arises so often in natural contexts}, \text{but it is also}, \text{in a certain sense}, \text{the smoothest interpolation of the factorial function to all positive real values}. \text{In fact}, if$f$:(0, \infty ) \to (0, \infty ) \text{is such thatf} (xf = Γ+. 1) = xf (x)$, f (1) = 1$, \text{and log} f \text{is convex}, \text{then such asfamous result There are many interesting formulas involving}Γ (s)Γ (Γ (1 - 1 )s)= =\sqrt{ππ}/, \text{which is essentially equiva}-\sin (πs). There is also theΓ , lent to the fact that the area under the “normal distri-bution curve”h(x)2 = (1/\sqrt{2π})(e-x()2()/){2} is 1 (this can be seen by making the substitution$x = u^{2}/2 in (1))$. A very important result concerning product expansion, which states thatΓ is the WeierstrassΓ (z)1 = zeγzn\infty=1 1 + nz e-z/n for all complexz, where γis Euler’s constant: $γ =^{n} \lim^{→}$\infty$1 + 12 + · · · + n1 - \log n$. This formula makes it clear thatΓ never vanishes, and that it has simple poles at 0 and the negative integers. Why is the gamma function important? A simple reason is that it occurs frequently in many parts of mathe-matics, but one can still ask why this should be so. One reason is thatform of the unarguably natural functionΓ$, \text{as defined in} (1)$, is the Mellin trans-$f (x) = e^{-x}$. The Mellin transform is a type of[III.27](/part - 03/the - fourier - transform), but it is defined for functions on the group fourier transform $(R^{+}$, \times ) rather than (R,+) (which is the habitat of the most familiar type of Fourier transform). For this reason, lytic number theoryΓ is often seen in number theory, particularly[IV.2](/part-04/number-theory), where multiplicative lyana- defined functions are often studied by taking fourier transforms. text is in the functional equation for the One appearance ofΓ in a number-theoretical con-riemann zeta function [IV.2 §3](/part-04/number-theory), namely,

$Ξ(s) = Ξ(1 - s)$,

where

$Ξ(s) = Γ (s/2)π^{-s}/^{2}ζ(s)$. (3)

III. Mathematical Concepts

Thetionζ function has a well-known product representa-ζ(s) = (1 - p-s)-1,

where the product is over primes and the representa-tion is valid for Re$(s) > 1$. \text{The extra factorp} Γ (s/2)π-s/2 in (3) may be regarded as coming from the “prime atinfinity” (a term which may be rigorously defined). the gamma function: it provides a rather accurate esti-Stirling’s formula is a very useful tool in dealing with mate forrough (but often useful) approximation forΓ (z) in terms of simpler functions. A veryn! is$(n/e)^{n}$, which tells us that log(n!$) \text{is about} n(\log n - 1)$. Stir- ling’s formula is a sharper version of this crude esti-mate. Letδ > 0 and suppose that z is a complex num- ber that has modulus at least 1 and argument between-π + δ and π - δ. (This second condition keeps z away from the negative real axis, where the poles are.) Then Stirling’s formula states that $\log Γ (z) = (z -^{1}^{2}) \log z - z +^{1}^{2} log 2π + E$, where the error E is at most C(δ)/|z|. Here, C(δ) stands for a certain positive real number that dependsonδ. (The smaller you make δ, the larger you have to make exponentially as Im C(δ).) Using this, one may confirm thatz → $\i\text{nf ty}$ in any fixed vertical strip inΓ decays the complex plane. In fact, if$α < σ < β$, then|Γ (σ + it)| ⩽ C(α, β)|t(|β)-1(e-()π){|}t | / 2 for all$|t| > 1$, \text{uniformly in} σ . III.32 Generating Functions Suppose that you have defined a combinatorial struc-ture, and for each nonnegative integern you wish to understand how many examples of this structure thereare of sizen. If a denotes this number, then the object that you are trying to analyze is the sequence na then this may be a very hard problem, but one can0$, a1$, a2$, a3$, . . . . If the structure is quite complicated, sometimes make it easier by considering a different object, the generating function of the sequence, which contains the same information.To define this function, one simply regards the sequence series. That is, the generating function an as the sequence of coefficients in a powerf of the se- quence is given by the formula $f (x) = a0 + a1x + a2x2 + a3x3 + · · ·$. The reason this can be useful is that one can some-times derive a succinct expression forf and analyze it

III.35. Hamiltonians

without reference to the individual numbers example, one important generating function has the$an$. For formulaf (x) = (1 - \sqrt{1} - 4 x)/2 x. In such cases, one can deduce properties of the sequence from properties off , rather than the other way round.a0, a1$, a2$, . . . and algebraic combinatorics forms For more on generating functions, see[III.91](/part-03/transforms). [IV.18](/part - 04/enumerative - and - algebraic - combinatorics) \text{and enumerative trans III}.33 \text{Genus The genus is a topological invariant of surfaces}: \text{that is}, \text{a quantity associated with a surface that does notchange when the surface is continuously deformed}. \text{Roughly speaking}, \text{it corresponds to the number ofholes of that surface}, \text{so a sphere has genus} 0, \text{a torus has genus} 1, \text{a pretzel shape} (\text{that is}, \text{the surface of a blown}-\text{up figure eight}) \text{has genus} 2, \text{and so on}. \text{If one triangulates an orientable surface and counts the vertices}, edges, \text{and faces in the triangulation}, \text{denoting their numbers by} V , E, and F, respectively, \text{then the Euler} \text{characteristic} \text{is defined to be}$V - E + F$. \text{It can be} \text{shown that i fact er i st ic}, thengχ\text{is the genus and} = 2 - 2 g. See [I.4 §2.2](/part - 01/general - goals) \text{for a fuller}χ \text{is the Euler char} - discussion.A \text{famous result of poincar}é [VI.61](/part - 06/jules - henri - poincar - 18541912) \text{states that for every nonnegative integerg there is precisely one ori}- \text{entable surface of genusbe defined for nonorientable surfaces}, \text{where a similarg}. (Moreover, \text{genus can also result holds}.) \text{Seefor more about this theorem}.\text{differential topology} [IV.7 §2.3](/part - 04/dierential - topology) \text{One can associate an orientable surface}, \text{and therefore a genus}, \text{with a smooth algebraic curve}. \text{Antic curve} [III.21](/part - 03/elliptic - curves) \text{can be defined as a smooth curve of el lip genus} 1. \text{See details}. \text{algebraic geometry} [IV.4 §10](/part - 04/algebra) \text{for more III}.34 Graphs A \text{graph is one of the simplest of all mathematical struc} - tures: \text{it consists of some elements called vertices} (\text{of which there are usually just finitely many}), \text{some pairsof which are deemed to be} “joined” or “adjacent.” \text{It is customary to represent the vertices by points in a planeand to join adjacent points by a line}. \text{The line is referred to as anized is irrelevant}: \text{all that is important is whether or notedge} (\text{though how the line is drawn or visualtwo points are joined}). \text{resented by a graph}: \text{we can use vertices to represent For example}, \text{the rail network of a country can be rep} - 215 \text{the stations}, \text{and we can join two vertices if they repre}-\text{sent consecutive stations along some railroad}. \text{Another example is provided by the Internet}: \text{the vertices are allthe world}’s computers, \text{and two are adjacent if there is a direct link between them}.\text{Many questions in graph theory take the form of asking what some structural property of a graph can tellyou about its other properties}. \text{For example}, \text{suppose that we are trying to find a graph withdoes not contain a triangle} (\text{defined to be a set of threen vertices that vertices that are mutually joined}). How many edges canthe graph have? Clearly 1 n2 is possible, at least if n is even, since one can then divide up thetwo equal classes and join all vertices in one class to4 n vertices into all vertices in the other. But can there be more edgesthan that? graphs. Letn such that every graph with Here is another example of a typical question aboutk be a positive integer. Must there exist ann vertices always contains either vertices no two of which are joined to each other? Thisk vertices that are all joined to each other or k question is quite easy forbut already fork = 4 it is not obvious that such ank = 3 (where n =$6 suffices)$, n exists.For more on these problems (the first is the founding problem of “extremal graph theory,” while the sec-ond is the founding problem of “Ramsey theory”) and on the study of graphs in general, see probabilistic combinatorics [IV.19](/part-04/extremal-and-probabilistic-combinatorics).extremal and III.35 Hamiltonians

Terence Tao

At first glance, the many theories and equations ofmodern physics exhibit a bewildering diversity: for instance, compare classical mechanics with quantum mechanics, or nonrelativistic physics with relativistic physics, or particle physics with statistical mechanics.However, there are strong unifying themes connecting all of these theories. One of these is the remarkable fact that in all of them the evolution of a physical system over time (as well as the steady states of that sys-tem) is largely controlled by a single object, the hamiltonian as describing the total energy of any given state in thatof that system, which can often be interpreted system. Roughly speaking, each physical phenomenon(e.g., ele ct ro magnetism, atomic bonding, particles in a potential well, etc.) may correspond to a single hamiltonian tum, statistical, etc.) corresponds to a different way H, while each type of mechanics (classical, quan-

216

of using that Hamiltonian to describe a physical sys-tem. For instance, in classical physics, the Hamiltonian is a function(q, p) \to  H(q, p) of the positions q and momentap of the system, which then evolve according to Hamilton’s equations: ddqt = ∂H∂p , ddpt = − ∂H∂q . In (nonrelativistic) quantum mechanics, the Hamilto-nian H becomes a linear operator [III.50](/part-03/linear-operators-and-their-properties) (which is often a formal combination of the position operatorsq and momentum operators p), \text{and the wave func} - tionschrö\text{dinger equation}ψ \text{of the system then evolves according to}[III.83](/part - 03/the - schrdinger - equation): \text{the i dd} t ψ = Hψ. \text{In statistical mechanics}, \text{the Hamiltonian} H \text{is a func}- \text{tion of the microscopic state} (\text{orand the probability that a system at a given tempera} - microstate) \text{of a system}, turee - H/k TT . \text{And so on and so forth}.\text{will lie in a given microstate is proportional to with their counterparts in physics}, \text{and so it is not sur}-\text{Many fields of mathematics are closely intertwined prising that the concept of a Hamiltonian also appearsin pure mathematics}. \text{For instance}, \text{motivated by classical physics}, Hamiltonians (\text{as well as} \text{generalizations} \text{of Hamiltonians}, \text{such as moment maps}) \text{play a major role in dynamical systems}, \text{differential equations}, \text{Liegroup theory}, \text{and symplectic geometry}. \text{Motivated by quantum mechanics}, Hamiltonians (\text{as well as gener} - alizations, \text{such as observables or pseudo}-\text{differential operators bras}, \text{spectral theory}, \text{representation} theory, differen-) \text{are similarly prominent in operator algetial equations}, \text{and microlocal analysis}. \text{and mathematics}, \text{Hamiltonians are useful for build}-\text{Because of their presence in so many areas of physics ing bridges between seemingly unrelated fields}: \text{for instance}, \text{between classical mechanics and quantum mechanics}, \text{or between symplectic mechanics and oper}-\text{ator algebras}. \text{The properties of a given Hamiltonian often reveal much about the physical or mathematical objects associated with that Hamiltonian}. \text{For example}, \text{the symmetries of a Hamiltonian often induce corre}-\text{sponding symmetries in objects described using that Hamiltonian}. \text{While not every interesting feature of a mathematical or physical object can be read off directly from its Hamiltonian}, \text{this concept is still fundamental to understanding the properties and behavior of such objects}. III. \text{Mathematical Concepts mirror symmetry tic manifolds See also vertex operator algebras}[III.88 §2.1](/part - 03/symplectic - manifolds).[[IV.16 §§2.1.3, 2.2.1]](/part - 04/mirror - symmetry), and[IV.17 §2.1](/part - 04/vertex - operator - algebras), \text{symplec III}.36 \text{The Heat Equation Igor Rodnianski The heat equation was first proposed by fourier} [VI.25](/part - 06/jean - baptiste - joseph - fourier - 17681830) \text{as a mathematical description of the trans}-\text{fer of heat in solid bodies}. \text{Its influence has subsequently been felt in many corners of mathematics}: \text{it provides explanations for such disparate phenomena as the formation of ice} (\text{thetheory of} \text{incompressible} \text{viscous fluids} (\text{the Stefan problem navier}–), \text{the stokes equation shortening}, \text{and the harmonic}-\text{map heat flow prob}-[III.23](/part - 03/the - euler - and - navierstokes - equations)), \text{geometric flows} (e.g., \text{curve lem}), \text{porous media} (\text{the brownian motion Hele}-\text{Shaw problem}[IV.24](/part - 04/stochastic - processes), \text{liquid filtration in}), \text{index theorems} (e.g., \text{the Gauss}–Bonnet–\text{Chern formula}), \text{the price of stock options} (\text{theand the topology of three}-\text{dimensional manifolds} (black–\text{scholes formula} [VII.9 §2](/part - 07/the - mathematics - of - money)), \text{the poincar}é \text{conjecture the heat equation could have been predicted at its birth}:[V.25](/part - 05/the - poincar - conjecture)). \text{But the bright future of after all}, \text{another small event that accompanied it wasthe creation of fourier analysis} [III.27](/part - 03/the - fourier - transform). nuity principle. The change in the quantity of heata small volume The propagation of heat is based on a simple conti-ΔV over a small interval of time Δut inis approximately

CD ∂u∂t ΔtΔV ,

where Dis its density; but it is also given by the amount C is the heat capacity of the substance and of heat entering and exiting throughΔV , which is approximately

 K\Delta(t\partial()\Delta){V} \partial u\partial n,

whereunit normal to the boundary of K is the heat conductivity constant andΔV . n is the dividing through byto zero, we find that the evolution of the amount of heat Thus, setting the values of all physical constants to 1,Δt and ΔV, and letting them tend (that is, the temperature) in a three-dimensional solidΩ is governed by the following classical heat equation, where$x = (x$, y, z)u(t, x:) is the temperature at time t at the point∂u(t, x) - \Delta u(t, x) = 0. (1)\partial t HereΔ = ∂x∂2 2 + ∂y∂2 2 + ∂z∂2 2

III.36. The Heat Equation

is the three-dimensional Laplacian; the diameter ofΔV tends to zero of the quantityΔu is the limit as$1$∂u.ΔV^∂^ΔV ∂n

To determine ple ment ed by theu(t, initial distri but io nx), equation (1) needs to be com-u (x) = u(0, x) and example, for a solid unit cube boundary conditions on the solid interface C \text{with surface main} - 0 ∂Ω. For tained at zero temperature, the heat equation is considered as a problem with Dirichlet boundary conditions and, as was proposed by Fourier, u(t, x) can be found by the method of separation of variables by expandingu (x) \text{into its Fourier seriesu}0(x, y, z) =k, m, l\infty=0 Ckml \sin (πkx)\times  \sin (πmy) \sin (πlz), which leads to the solution u(t$, x, y, z) =^{k}$, m, l\infty=0 e^-^π2^((k2)+m\time(s2)+l 2^)t Ckml \sin (πkx)\sin (πmy) \sin (πlz).

This simple example already illuminates a fundamen-tal property of the heat equation: the tendency of its solutions to converge to an equilibrium state. In thiscase it reflects a physically intuitive fact that the te mp er at ureu*(x) = u(t, C x. ) converges to the constant distribution to the choice of thewhich the normal derivative of Propagation of heat in an insulated body corresponds000 Neumann boundary conditions, inu (normal, that is, to the boundary constructed in a similar fashion.∂Ω) is set to vanish. Its solutions can be nected with the heat equation is that the trigonometric functions are The reason that Fourier analysis is intimately con-eigenfunctions [I.3 §4.3](/part-01/fundamental-definitions) of the Laplacian. A variety of more general heat equations can beobtained if one replaces the Laplacian by a more general linear, tonianself-adjoint[III.35](/part-03/hamiltonians)H with a discrete set of eigenvalues[III.50 §3.2](/part-03/linear-operators-and-their-properties), nonnegative hamil\lambda n \text{and corresponding \text{eigenfunctions}} ψn. That is, one considers the heat flow\partial u + Hu = 0.\partial t

The solutione-t H u , where eu(t)-t His given by the formulais the heat semigroup generatedu(t) = by H, which also takes the more explicit form0 u(t, x) =n\infty = 0(e-)\lambda n t Cnψn(x).

217

Here the coefficient su relative to H: that is, they are the coefficients that Cn\text{are the Fourier coefficients of arise when we write tence of such a decomposition follows from the}0 u0 \text{as a sum} \inftyn = 0 Cnψn. (\text{The exis} - spec- \text{tral theorema similar way}, \text{heat flows can also be generated by self}-[III.50 §3.4](/part - 03/linear - operators - and - their - properties) \text{for self}-\text{adjoint operators}. \text{In adjoint operators with a continuous spectrum}.) \text{In par} - ticular, \text{the asymptotic behavior ofu}(t, x) as t → +\infty is completely determined by the spectrum of Although explicit, representations like this do not H . provide very good quantitative descriptions of the behavior of the heat equation. To obtain such descriptions one has to abandon the idea of constructing solu-tions explicitly and look instead for principles and methods that apply to general classes of solutions while also being sufficiently robust to be useful in the analysis of more complicated heat equations.The first methods of this type are called energy identities heat equation by a certain quantity, which may depend. To derive an energy identity, one multiplies the on the given solution, and integrates by parts. The simplest two identities of this type are thetotal heat of an insulated body, conservation of d

u(t, x) dx = 0,$d$ tΩ

and the energy identity,

$tΩ u^{2}(t$, x)dx + (20)Ω |∇u(s, x=)|2 dxud2(s0, x) dx. The second identity already captures a fundamental smoothing property of the heat equation: since all threeΩ integrands are nonnegative and the first and third integrals are finite, the average of the mean-square gradientofuis finite, even if the initial mean-square gradient is infinite, and it even decreases to zero withaway from the boundary ofΩ an arbitrary amount oft. In fact, smoothing takes place, and not just on average but atevery time$t > 0$. tion is the The second fundamental principle of the heat equa-global maximum principle $x \in^{Ω}$,\ma(x0()⩽){t}⩽ T u(t$,⩽x\max ) u(0, x)$, \max u(t, x)$, x\in\partialΩ$,0⩽t⩽T

which tells us the familiar fact that the hottest spot inthe body, over all time, is either on its boundary or in the initial distribution. tion in Finally, the diffusive properties of the heat equa-Rn are captured by the Harnack inequality for

218

nonnegative solutionsu. It tells us thatu(tu(t2,$, xx2)) ⩾ t(t1)n/2e^{−}(|x()2)-x 1^{|}2^{/}4^{(}(t2()-t)1^{)} \text{whenat time}$ t2 t> ttakes a certain value, then the temperatur(e1)1. This tells us that if the temperature a(t1)2 x1$at$ x2 at time1 t2 cannot be too much smaller. This form of the Harnack inequality features a very important object in the study of the heat equation, called the heat kernel: p(t$, x, y) = (4πt)1n/2 e^{−}|x^{-}y^{|}2^{/}4 t$. One of its many uses is that it allows one to construct solutions of the heat equation in the whole of space (that is, in R$n) \text{from initial data} u^{0}$, by the formulau(t, x) =R n p(t, x, y)u0(y)dy.

It also shows that after a timet \text{initial point dis}-\sqrt turbances become distributed in a ball of radius around the point of the original disturbance. This sort$t$ of relation between spatial scales and timescales is the characteristic parabolic scaling of the heat equation. mately connected with the diffusion process of Brown-ian motion. In fact, the mathematical description of As was shown by Einstein, the heat equation is inti Brownian motion is in terms of a random process B with transitional probability densities given by thet

heat kernel motion Bx starting atp(t, x, y). For thex, the functionn-dimensional Browniantu(t, x) = E[u0(\sqrt{2 B}t x )]

computed with the help of expectation valuecisely the solution of the heat equation in Rn with initial E is pre- data beneficial relationship between the theory of the heat u0(x). This connection is the start of a mutually equation and probability. Among the most profitable applications of this relationship is the Feynman–Kac formula u(t$, x) = E \exp -^{0}^{t} V (\sqrt{2B}^{x}^{s} )ds u^{0}(\sqrt{2B}^{t}^{x})$, which connects Brownian motion with solutions of theheat equation

∂u(t$, x) - \Delta u(t, x) + V (x)u(t, x) = 0\partial t$

with initial data$u^{0}(x)$.

tion described above are remarkably robust, in the The three fundamental principles of the heat equasense that they, or weaker versions of them, hold evenfor very general variants of the classical equation. For

III. Mathematical Concepts

instance, they can be applied to the question of the continuity of solutions of the heat equation $\partial t\partial u -^{i}$, jn=1 ∂x∂i aij(x)∂x∂j u = 0, where all that is assumed of the coefficients they are bounded and that they satisfy the$aellipticity^{i}j \text{is that}$ condition$λ|ξ|^{2} ⩽^{i}$, j aijξiξj ⩽ Λ|ξ|2. One can even look at the equations in “nondivergence form”: $\partial t\partial u -^{i}$, jn=1 aij (x)∂x∂i ∂x∂j u = 0. Here, the connection between the heat equation and the corresponding stochastic diffusion process turns out tobe particularly helpful. This analysis has led to beautiful applications in theand in fully nonlinear problems.calculus of variations [III.94](/part-03/variational-methods) onate analogue of the Laplacian for a manifold The same principles also hold for the heat equations riemannian manifolds [I.3 §6.10](/part-01/fundamental-definitions). \text{The appropri} - M \text{is the Laplace}–\text{Beltrami operator for} M is \Delta M, \text{and the heat equation}\partial\partial t u - \Delta M u = 0. \text{If the Riemannian metric is}\D\text{elta takes the form} g, \text{then in local coordinates} M\Delta M = \det 1 g(x)n \partial x\partial i gij (x) \det g(x)\partial x\partial j.i$, j = 1$\text{In this case}, \text{a version of the Harnack inequality holdsfor the heat equation on a manifold that has ricci curvature heat equations on manifolds is in part motivated by}[III.78](/part - 03/ricci - flow) \text{bounded from below}. \text{Interest in the nonlinear geometric flows and attempts to understand their long}-\text{term behavior}. \text{One of the earliest geometric flows was the harmonic map flow} \partial which describes a deformation of the map between two compact Riemannian manifolds$\partial t Φ - \Delt(a N)M Φ = 0, M andΦ(t, N·)$. The operators tructed by projectingΔN M is a nonlinear Laplacian that is con-Δ onto the tangent space of N. This is a gradient flow associated with the energy$ME[U] = 12^{M} |d U(|^{2})^{N}$; it measures the stretching of the map N. Under the assumption that the sectional curvature U between M and ofmap heat flow is regular and converges, as N is nonpositive, it can be shown that the harmonict → +\infty, to a harmonic map between M and N, which is a critical

III.37. Hilbert Spaces

point of the energy functional is used to establish the existence of harmonic maps E[U]. This heat equation and to construct a continuous deformation of a givenmapΦ(0, ·) \text{to a harmonic map} Φ(+$\i\text{nf ty}$, ·). The curva- ture assumption on the target manifold ble for the crucial monotonicity properties of the har-N is responsi- monic map heat flow, which come to light through theuse of the energy estimates. mation principle of this kind appears in the three-dimensional An even more spectacular application of a defor-ricci flow [III.78](/part-03/ricci-flow)

∂

This is aricsg (t)quasilinear on a given manifold∂t gheat evolution of a family of met-ij = −2 Ricij(g).M. In this case the flow is not necessarily regular; nonetheless, it can beextended as a flow with “surgeries” in such a way that$ij$ the structure of the surgeries and the long-term behav-ior of the flow can be precisely analyzed. This analysis shows in particular that any three-dimensional sim-ply connected manifold is diffeomorphic to a three dimensional sphere, which gives the proof of the Poincaré conjecture. important in the analysis oftems The long-term behavior of the heat equation is alsoand associated biological phenomena. This was reaction–diffusion sys suggested already in the work ofhis attempt to understand morphogenesis turing [VI.94](/part-06/alan-turing-19121954) in(the formation of in homogeneous patterns such as animal-coat patterns from a nearly homogeneous initial state) by means of exponential instabilities in the reaction–diffusion equations $\partial u = \mu\Delta u + f (u$, v)$, \partial v = \nu\Delta v + g(u$, v). the heat equation, and in particular the tendency of its solutions to converge to an equilibrium, or alternatively These examples emphasize the long-term behavior of∂t ∂t to develop exponential instabilities. However, it turnsout that the short-term behavior of the heat equation on a manifold tion with the geometry and topology of M is of the utmost importance in connec-M. This connec- tion is twofold: first, one seeks to establish a relation-ship between the spectrum ofΔ and the geometry of Mbehavior to prove; second, one can use an analysis of the short-termindex theorems M . The former aspect, in the context of planar domains, is captured by Marc Kac’s well-known question, “Can one hear the shape of a drum?” For manifolds it begins with the$\i\text{nfty Weyl formula}$ e$-^{t}λ^{i} = (4πt)1^{n}/^{2} (Vol(M) + O(t))i = 0$

219

astrace of the heat kernel oft tends to 0. The left-hand side of the identity is theΔ . That is, M\infty

where equationp(t, x, y)i=∂u/∂t0 e-t\lambda i-=is such that any solution of the heatΔtr e(u-t)Δ=M =0 with M p(t, x, x)u(0, x) d=x, u (x) is given by the expression$M^{0}u(t$, x) =M p(t, x, y)u0(y) dy.

The right-hand side of the Weyl identity reflects theshort-term asymptotics of the heat kernelp(t, x, y). orems can be viewed as a refinement of both sides of The heat-flow approach to the proof of the index thethe Weyl identity. The trace on the left-hand side isreplaced by a more complicated “super-trace,” while the right-hand side involves full asymptotics of the heat kernel, which requires one to understand subtle cancelations. The simplest example of this kind is the Gauss–Bonnet formula

$χ(M) = 2π^{M} R$,

which connects the Euler characteristic of a two-dimen-sional manifold M and the integral of its scalar curva- ture. The Euler characteristic combination of traces of the heat flows associated withχ(M) arises from a linear the Hodge Laplacian(d + d*)2 \text{restricted to the space} of exterior differential 0-forms, 1-forms, and 2-forms.A proof of a general atiyah–singer index theorem [V.2](/part-05/the-atiyahsinger-index-theorem) involves heat flows associated with an operator given by the square of a Dirac operator. III.37 Hilbert Spaces The theory ofmaps [I.3 §4.2](/part-01/fundamental-definitions) underpins a large part of mathematics.vector spaces [I.3 §2.3](/part-01/fundamental-definitions) and linear However, angles cannot be defined using vector space concepts alone, since linear maps do not in general pre-serve angles. An inner product space can be thought of as a vector space with just enough extra structure for the notion of angle to make sense. space is the standard scalar product defined onspace of all real sequences of length The simplest example of an inner product on a vector$n$, \text{as follows}. If Rn, thev sequences, then their scalar product, denoted= (v1,. . . , vn) and w = (w1, . . . , wn) are two suchv, w , is the sumthe scalar product of$v^{1}w^{1} + v^{2}w(3^{2}$,2+ · · · +$,-1) andvnw(1n$,4. (\text{For example},,4) is 3 \times 1 + 2 \times 4 + (-1) \times 4 = 7.) 220 \text{the following two}.\text{Among the properties that the scalar product has are} (i) \text{It is linear in each variable separately}. \text{That is},$\lambda u + \mu v, w = \lambda u, w + \mu v, w$ \text{for any three} \text{vectors and similar lyu}, v, andu, \l\text{ambda vw} +\text{and any two scalars}\mu w = \lambda u, v + \mu\lambda u, wand \mu. , (ii) \text{The scalar product itself is always a nonnegative real number}, \text{and isv}, v \text{of any vector} v \text{with zero only ifv is zero}. \text{In a general vector space}, \text{any function vectorsv and} w \text{that has these two properties is calledv}, w \text{of pairs of an inner product}, \text{and a vector space with an inner prod}-\text{uct is called an inner product space}. \text{If the vector space has complex scalars}, \text{then instead of} (i) \text{one must use the following modification}. (i) \text{For any three vectors} u, v, and w \text{and any two scalars and}$u$, \lambda v\l\text{ambda and}+\mu\mu w, \lambda u =+\mu v,$\bar{w}\lambda u$, v = +λ\m\bar{u}$u$, wu, w+. \text{That is},\mu v, w , the inner product isvariable. conjugate-linear in the second inw The reason this has anything to do with angles is that Rworks out as the length of2 and R3 the scalar product of two vectorsv times the length ofv andw times the cosine of the angle between them. In particu-lar, since a vectorv makes an angle of zero with itself, v, v This gives us a natural way tois the square of the length ofdefinev.length and angle in an inner product space. The length, orvectorv , denoted v , is v, v . Given two vectors norm, of av andthat it lies between 0 and$w$, the angle between them is defined by the factπ (or 180◦) and its cosine isv, w / v\sum w. Once length has been defined, we can also talk about distance: the distancev and wis the length of their difference, ord(v, w) betweenv - w . This definition of distance satisfies the axioms for ametric space [III.56](/part-03/metric-spaces). From the notion of angle, we can say what it is forother: this simply means thatv and w to be orthogonal to eachv, w = 0. beyond their ability to represent the geometry of two-and three-dimensional space. Where they really come The usefulness of inner product spaces goes far into their own is if they are infinite dimensional. Then itbecomes convenient if they satisfy the additional property ofend of [III.62](/part-03/normed-spaces-and-banach-spaces). A complete inner product space is called completeness, which is briefly discussed at the a Hilbert space Two important examples of Hilbert spaces are the. following.

III. Mathematical Concepts

(i) tion of2 is the natural infinite-dimensional generaliza-Rn with the standard scalar product. It that the infinite sumis the set of all sequences converges. The inner product of|a1|2 + |(aa1$, a2(|2)2(a$, a+ |1$, a3 a$, . . . ()3)2|, a2 + · · ·3, . . . )such and(which can be shown to converge by the$(b1$, b2, b3, . . . ) \text{is a}1 b1 + a2 b2 + a3 cauchy–$b3 + · · ·$ (ii) \text{schwarz inequality} L2[0, 2π] is the set of all functions[V.19](/part-05/inequalities)). f\text{defined on the interval and} 2π, \text{such that the integral}[0, 2π] \text{of all real numbers between} (02)π |f (x)|2 \text{dx makes sense and is finite}. \text{The inner product oftwo functions} f and g in L [0,2π]is defined to be0 2π f (x)g(x) dx. (For technical reasons, this defi-2 nition is not quite accurate, as a nonzero function0 can have norm zero, but this problem can easilybe dealt with.) analysis. Aform cos The second of these examples is central to Fourier(mx)trigonometric functionor sin(nx). The inner product of anyis a function of the two different trigonometric functions is zero, so they are all orthogonal. Even more importantly, the trigono-metric functions serve as a coordinate system for the spacecan be represented as an (infinite) linear combination L2[0,2π], in that every function f in the space of trigonometric functions. This allows Hilbert spacesto model sound waves: if the functionf represents a sound wave, then the trigonometric functions are thepure tones that are its constituent parts. trate a very important general phenomenon in thetheory of Hilbert spaces: that every Hilbert space has These properties of trigonometric functions illusan orthonormal basis. This means a set of vectors$ei$

with the following three properties:

$• e = 1 \text{for every i}$;

$i• • \text{every vectore}^{i}$, ej = 0 wheneverv in the space can be expressed as ai = j; and convergent sum of the form$i λ^{i}e^{i}$. The trigonometric functions do not quite form an orthonormal basis of$L [0$,2π] \text{but suitable multiples} of them do. There are many contexts besides fourier analysis where one can obtain useful information about2 a vector by decomposing it in terms of a given orthonor-mal basis, and many general facts that can be deduced from the existence of such bases.Hilbert spaces (with complex scalars) are also central to quantum mechanics. The vectors of a hilbert space can be used to represent possible states of a

III.40. The Ideal Class Group

quantum mechanical system, and observable featuresof that system correspond to certain linear maps. For this and other reasons, the study of linear operators mathematics: see[III.50](/part-03/linear-operators-and-their-properties) on Hilbert spaces is a major branch ofoperator algebras [IV.15](/part-04/operator-algebras). III.38 Homology and Cohomology Ifciate with it a sequence of groups X is a topological space [III.90](/part-03/topological-spaces), then one can asso-Hn(X, R), where R \text{is a commutative ring} [III.81 §1](/part - 03/rings - ideals - and - modules) \text{such as} Z or C. \text{These groups}, \text{the homology groups of} X(with coefficients incontain a great deal of information about$R$), are a powerful invariant: powerful because they X but are nevertheless easy to compute, at least compared withsome other invariants. The closely related cohomology groups Hn(X, R) are more useful still because they can be made into a ring: to oversimplify slightly, an ele-ment of the cohomology group$H^{n}(X) \text{is an}$ lence classsionn. (Of course, for this to make true sense[I.2 §2.3](/part-01/language-and-grammar)[Y ] of a subspace Y of codimen-Xequiva-should be a fairly nice space such as a Then, if[Y ] and [Z] \text{belong to} Hn(X, R)manifold and H[I.3 §6.9](/part-01/fundamental-definitions).)m(X, R), respectively, their product is[Y ∩Z]. Since Y ∩ Z“typically” has codimension[Y ∩Z] belongs to (Hn)+mn(X, R)+ m. Homology and cohom-, the equivalence class ology groups are described in more detail intopology [IV.6](/part-04/algebraic-topology). algebraic become far more general than the above discussion suggests, and are no longer tied to topological spaces: The concepts of homology and cohomology have for instance, the notion of group cohomology is of great importance in algebra. Even within topology, there are many different homology and cohomology theories. In1945, Eilenberg and Steenrod devised a small number of axioms that greatly clarified the area: a homology theory is any association of groups with topological spaces that satisfies these axioms, and the fundamental properties of homology theories follow from theaxioms. III.39 Homotopy Groups Ifa path that begins and ends at the same point; or, more X is a topological space [III.90](/part-03/topological-spaces), then a loop in X is formally, a continuous function$f (0) = f (1)$. The point where the path begins and endsf:[0$,1] \to X \text{such that}$ is called thepoint, they are called base point homotopic. If two loops have the same baseif one can be continuously deformed to the other, with all the intermediate

221

paths living inbase point. For example, if X and beginning and ending at the given X is the plane R2, then any two paths that begin and end at(0$, 0) \text{are homotopic}$, whereas ifwhether or not two paths (that begin and end at some X is the plane with the origin removed, then other point) are homotopic depends on whether or notthey go around the origin the same number of times. Homotopy is an equivalence relation [I.2 §2.3](/part-01/language-and-grammar), and the equivalence classes of paths with base pointform the fundamental group of X, relative to x, whichx is denoted bynot depend onπ1 x(X, x)and we can write. If X is connected, then this doesπ (X) instead. The group operation is “concatenation”: given two paths1 that begin and end atbined path that goes along one and then the other, and x, their “product” \text{is the comthe product of equivalence classes is then defined tobe the equivalence class of the product}. \text{This group is a very important invariant} (\text{see for instance geometric and combinatorial group theorythe first in a sequence of higher}-\text{dimensional homotopy}[IV.10 §7](/part - 04/geometric - and - combinatorial - group - theory)); \text{it is groups}, \text{which are described in} [[IV.6 §§2, 3]](/part - 04/algebraic - topology). algebraic topology III.40 The Ideal Class Group the fundamental theorem of arithmetic asserts that every positive integer can be written in[V.14](/part-05/the-fundamental-theorem-of-arithmetic) exactly one way (apart from reordering) as a product ofprimes. Analogous theorems are true in other contexts as well: for example, there is a unique factorization the-orem for polynomials, and another one for Gaussian integers, that is, numbers of the form$a + \text{ib where a}$ andb are integers. ated “ring of integers” does not have the unique-factor-ization property. For example, in the However, for most number fields [III.63](/part-03/number-fields), \text{the associ} - ring [III.81 §1](/part - 03/rings - ideals - and - modules) \text{of numbers of the formone can factorize} 6 \text{either as} 2 a + b\sqrt{-5} with \times 3 \text{or asa and}(1 + b\sqrt{integers},-5)(1 -\sqrt - 5). \text{unique factorization fails}. \text{Given any ring of integers ofa number field}, \text{one can define a} \text{multiplicative} \text{structure The ideal class group is a way of measuring how badly on its set of ideals} [III.81 §2](/part - 03/rings - ideals - and - modules), \text{for which unique factorization holds}. \text{The elements of the ring itself corre}-\text{spond to so} - called “\text{principal ideals},” \text{so if every ideal is principal}, \text{then unique factorization holds for the ring}.\text{If there are nonprincipal ideals}, \text{then one can define a natural equivalence relation} [I.2 §2.3](/part - 01/language - and - grammar) \text{on them in such a way that the equivalence classes}, \text{which arecalled ideal classes}, \text{form a group} [I.3 §2.1](/part - 01/fundamental - definitions). \text{This group} 222 \text{is the ideal class group}. \text{All principal ideals belong tothe class that forms the identity of this group}, \text{so the larger and more complex the ideal group is}, \text{the further the ring is from having the unique}-\text{factorization property}. \text{For more details}, \text{see algebraic numbers} [IV.1](/part - 04/number - theory), and in particular section 7. III.41 Irrational and Transcendental

Numbers

Ben Green

An irrational number is one that cannot be written as a/boccurring numbers, such aswith both a and b integers. A great many naturally\sqrt{2}, e, and π, are irrational. The following proof that\sqrt{2} is irrational is one of the best-known arguments in all of mathematics. Suppose that\sqrt{2} = a/b; since common factors can be canceled, we may assume thatwe have$a^{2} = 2b^{2}$, which means thata and bhave no common factor;$\text{amust be even}$; write2$c2 = ab = 2$, \text{and hence}2 c; \text{but then} 4 bmust be even too; this, how-$c^{2} = 2b^{2}$, which implies that ever, is contrary to our assumption that coprime.a and b were that ask whether certain specific numbers are rationalor not. For example, There are several famous conjectures in mathematicsπ + e and πe are not known to be irrational, and neither is Euler’s constant: $γ =^{n} \lim^{→}$\infty$1 + 12 + · · · + n1 - \log n \approx 0$.577215 . . . . It is known that$ζ(3) = 1 + 2^{-3} + 3^{-3}+· · · \text{is irrational}$. Almost certainly, as well. However, although it has been shown thatζ(5), ζ(7), ζ(9), . . . are all irrational infinitely many of these numbers are irrational, nospecific one is known to be. A classic proof is that of the irrationality of e. If

$\i\text{nf ty}$

e$=j$!

$j = 0$

were equal top/q, then we would have\inftyp(q - 1)!$=^{j} = 0 qj$!!.

The left-hand side and the terms of the sum withj ⩽ q are all integers. Therefore the quantity $qj$!!$= q 1 + 1 + (q + 1)(q1 + 2) + · · ·(j^{⩾}()^{q})^{{} + 1}$

is also an integer. But it is not hard to show that this quantity lies strictly between 0 and 1, a contradiction.

III. Mathematical Concepts

have absolute value at least one, is surprisingly pow-erful in the theory of irrational and transcendental The principle used here, that a nonzero integer must numbers.Some numbers are more irrational than others. In a sense, the most irrational number isgolden ratio, because the best rational approximations$τ =^{1}^{2}(1 + \sqrt{5})$, the to it, which are ratios of consecutive Fibonacci numbers, approach it rather slowly. There is also a very elegant proof thatτ is irrational. This is based on the observation that theinto a square of side 1 and a 1τ \times  1 rectangle/τ \times R1 rectangle. Ifmay be dividedτ were rational, then we would be able to create a rectangle with integer sides that was similar tothis we could remove a square, and we would be left R. From with a smaller rectangle with integer sides that would still be similar to R. We could continue this process ad infinitum, which is clearly impossible. braic equation with integer coefficients. Thus, A transcendental, that is to say, is not the root of a polynomial number is one which is not\sqrt{2} is not tran-alge- scendental, \text{since it solves}7$+ \sqrt{17}$. x2 - 2 = 0, \text{and neither is} question was answered bywho showed that various numbers were transcenden-Are there, in fact, any transcendental numbers? this liouville [VI.39](/part-06/joseph-liouville-18091882) in 1844, tal, of which

$κ = 10 - n^{!}n^{⩾}1 = 0$.1100010000000000000000010 . . .

is a well-known example. This is not algebraic, becauseit can be approximated by rationals more accurately than any algebraic number can. For example, the rational approximation 110 001 indeed toκ, but its denominator is not particularly/1 000 000 is very close large.Liouville showed that ifα is a root of a polynomial of degree$n$, thenα - aq > q Cn

for all integer spending onα. In words, a and q αand for some constant cannot be too well approxi-C de- mated by rationals. Roth later proved that the exponentn here can actually be replaced by 2 + ε for any ε > 0. (For more on these topics, seeand roth’s theorem [V.22](/part-05/liouvilles-theorem-and-roths-theorem).) liouville’s theorem A completely different approach to the existence of transcendental numbers was discovered by[VI.54](/part-06/georg-cantor-18451918) thirty years later. He proved that the set ofcantor

III.43. Jordan Normal Form

algebraic numbers isroughly speaking, that they may be listed in order.countable [III.11](/part-03/countable-and-uncountable-sets), which means, More precisely, there is a surjective map from N, the set of natural numbers, to the set of algebraic num-bers. By contrast, the real numbers R are not countable. Cantor’s famous proof of this uses a diagonalization argument to show that any listing of all the real num-bers must be incomplete. There must, therefore, be real numbers that are not algebraic. cific number is transcendental. For instance, it is byno means the case that all transcendental numbers are It is generally rather difficult to prove that a spevery well approximated by rationals; this merely pro-vides a useful sufficient condition. There are other ways to establish that numbers are transcendental. Both e andthatπ|eare known to be transcendental, and it is known- a/b| > C(ε)/(b2()+){ε} for all ε > 0, so e is not all that well approximated by rationals. Since always a rational multiple ofπ2 m, it follows that theζ(2 m) is numbers The modern theory of transcendental numbers con-ζ(2), ζ(4), . . . are all transcendental. tains a wealth of beautiful results. An early one isthe Gel’fond–Schneider theorem, which says that$α^{β}$ is transcendental ifalgebraic but not rational. In particular,α ≠ 0,1 is algebraic, and if\sqrt{2}\sqrt2 is tran-β is scendental. There is also thewhich states that ifx , x are two linearly independent six-exponentials theorem, complex numbers, and if independent complex numbers, then at least one of the1 2$y^{1}$, y2, y3 are three linearly six numbers e$(x^{1}()^{y})^{1}$, (ex()1()y)2$, (ex()1()y)3$, (ex()2()y)1$, (ex()2)y 2$, (ex)2 y 3 is transcendental. Related to this is the (as yet unsolved) four-exponentials conjecture early independent complex numbers, and if: ifx1 and x2 are two lin-y and y are linearly independent, then at least one of the four1 2 exponentials e$(x^{1}()^{y})^{1}$, (ex()1()y)2$, (ex()2)y 1$, (ex)2 y 2 is transcendental. III.42 The Ising Model The Ising model is one of the fundamental models of statistical physics. It was originally designed as a model for the behavior of a ferromagnetic material when it is heated up, but it has since been used to model manyother phenomena. be the set of all pairs of integers with absolute value The following is a special case of the model. Let Gn

223

at mosteach pointn. Ax in configuration G a numberis a way of assigning toσ , which equals 1 or-1. The points represent atoms an(dn)x σ (x) represents whether configuration$x$has “spin up” or “spin down.” With eachσwe associate an “energy”E(σ ), which equalsof neighboring points$- σ^{x}σ^{y}$, where the sum is taken over all pairsx and y. Thus, the energy is high if many points have different signs from some of their neighbors, and low ifof points with the same sign.Gn is divided into large clusters is proportional to enumber that represents temperature. The probability Each configuration is assigned a probability, which-E(σ )/T . Here, T \text{is a positive real} of a given configuration is therefore higher when it hassmall energy, so there is a tendency for a typical configuration to have clusters of points with the same sign.However, as the temperature T increases, this clus- tering effect becomes smaller since the probabilities become more equal.The two-dimensional Ising model with zero potential is the limit of this model asmore detailed discussion of the general model and ofntends to infinity. For a the phase transition associated with it, see probabilistic models of critical phenomena [IV.25 §5]. III.43 Jordan Normal Form Suppose that you are presented with an$n \times n \text{real or}$ complex stand it. You might ask how it behaves as amatrix [I.3 §4.2](/part-01/fundamental-definitions)A and would like to under-linear map [I.3 §4.2](/part-01/fundamental-definitions) on Rn or C^n, or you might wish to know what the powers oftions is not particularly easy, but for some matrices it A are. In general, answering these ques- is very easy. For example, ifis, one whose nonzero entries all lie on the diagonal), A is a diagonal matrix (that then both questions can be answered immediately: ifx \text{is a vector in} Rn or Cn, then Ax will be the vector obtained by multiplying each entry ofsponding diagonal element of A, and to computex by the corre-Am you just raise each diagonal entry to the power So, given a linear map T (from Rn to Rn or fromm. Cn to C n), \text{it is very nice if we can find a basis with respect to whichthen we feel that we} “understand” \text{the linear map}. Say-\text{Thas a diagonal matrix}; \text{if this can be done}, \text{ing that such a basis exists is the same as saying thatthere is a basis consisting of eigenvectors} [I.3 §4.3](/part - 01/fundamental - definitions): \text{a linear map is called} \text{diagonalizable} \text{if it has such a basis}. \text{Of course}, \text{we may apply the same terminology to a matrix} (\text{since a matrix} A \text{determines a linear map on} R n or Cn, by mapping x to Ax). So a matrix is also

224

called diagonalizable if it has a basis of eigenvectors, or equivalently if there is an invertible matrix P such that P-1 AP \text{is diagonal}. \text{answer is no for uninteresting reasons}, \text{since there neednot even be any eigenvectors}: \text{for example}, \text{a rotation in Is every matrix} \text{diagonalizable}? \text{Over the reals}, \text{the the plane clearly has no eigenvectors}. \text{So let us restrict our attention to matrices and linear maps over the complex numbers}.\text{If we have a matrix} A, \text{then its} \text{characteristic} polyno - mial, \text{namely det}(A - t I), \text{certainly has a root}, \text{by the fundamental theorem of algebraa root}, \text{then standard facts from linear algebra tell us}[V.13](/part - 05/the - fundamental - theorem - of - algebra). If\l\text{ambda is such that} A - \lambda I \text{is singular}, \text{and therefore that there is a vector Ax} = \l\text{ambda xx} . \text{So we do have at least one eigenvector}. Unfor-\text{such that} (A - \lambda I)x = 0, \text{or equivalently that tunately}, however, \text{there need not be enough eigenvec}-\text{tors to form a basis}. \text{For example}, \text{consider the linear mapmatrix of this map} (\text{with respect to the obvious basis})T \text{that sends} (1,0) to (0, 1) and (0, 1) to (0,0). The isseeing why not is the following. The characteristic poly-$(^{0} 0^{1} 0 )$. This matrix is not diagonalizable. One way of nomial turns out to be An easy computation reveals that if$t^{2}$, of which the only root is 0.Ax = 0 then x has to be a multiple ofearly independent eigenvectors. A rather more elegant(0, 1), so we cannot find two linmethod of proof is to observe that T2 \text{is the zero matrix} (since it maps each of(1,0) and (0,1) to (0, 0)), so that ifhave to be zero (since any nonzero diagonal matrix has T were diagonalizable, then its diagonal matrix would a nonzero square), and therefore the zero matrix, which it is not.T would have to be that nilpotent The same argument shows that Ak ) must fail to be diagonalizable, unless= 0 for some k (such matrices are calledany matrix A such A is itself the zero matrix. This applies, for example, to anymatrix that has all of its nonzero entries below the main diagonal. matrix“nearly” an eigenvector, since we do have What, then, Tabove? In a sense, one feels thatcan we say about our non diagonalizable$T^{2}((11$,,00)) is=(0,0). So what happens if we extend our point of view by allowing such vectors? One would say that a vec-torx is a generalized eigenvector of T, with eigen- valueλ, if some power of T - \lambda maps x to zero. For instance, in our example above the vector generalized eigenvector with eigenvalue 0. And, just as(1, 0) \text{is a} we have an “eigenspace” associated with each eigenvalue eigenvalueλ(defined to be the space of all eigenvectors withλ), we also have a “generalized eigenspace,”

III. Mathematical Concepts

which consists of all generalized eigenvectors with eigenvalueλ. composing the vector space (it is natural to hope that one could decompose the vec-Diagonalizing a matrix corresponds exactly to de-Cn) into eigenspaces. So tor space into generalized eigenspaces for And this turns out to be true. The way of breaking upany matrix. the space is callednow describe in more detail.Jordan normal form, which we shall simplest situation in which we get a generalized eigen-Let us pause for a moment and ask: what is the very vector? It would surely be the obvious generalization of the above example ton dimensions. In other words, we have a linear mapso on, untile- is sent to T that sendse , withe1 e toitself mapped toe2, e2 to e3, and zero. This corresponds to the matrix$n⎛1 n n ⎞⎜⎜⎜01 00 00 · · ·· · · 00 00⎟⎟⎟⎜⎜⎜0$.. 1.. 0.. · · · 0.. 0.. ⎟⎟⎟ .⎜⎝ . . . . .. . . ⎟⎠

0 0 0· · · 1 0

Although this matrix is not diagonalizable, its behavioris at least very easy to understand. sum of matrices that are easily understood in the way The Jordan normal form of a matrix will be a diagonal that this one is. Of course, we have to consider eigen-values other than zero: accordingly, we define a block to be any matrix of the form⎛ ⎞⎜⎜⎜λ1 λ0 00 · · ·· · · 00 00⎟⎟⎟⎜⎜⎜0.. 1.. λ.. · · · 0.. 0.. ⎟⎟⎟ .⎜⎝ . . . . .. . . ⎟⎠

0 0 0· · · 1 \lambda Note that this matrixthe matrix above, so that A, with(A-\lambda I\lambda I)subtracted, is precise lyn is indeed zero. Thus, a block represents a linear map that is indeed easy to understand, and all its vectors are generalized eigenvectors with the same eigenvalue. The Jordan normal form theorem tells us that every matrix can be decomposed into such blocks: that is, a matrix is in jordan normal form if it is of the form

$⎛B 0 · · · 0 ⎞⎜⎜⎜ 01 B2 · · · 0 ⎟⎟⎟⎜⎜⎝$... ... . .. ... ⎟⎟⎠ .

0 0· · · Bk

Here, theand the 0 s represent submatrices of the matrix with Biare blocks, which can have different sizes,

III.44. Knot Polynomials

sizes depending on the block sizes. Note that a blockof size 1 simply consists of an eigenvector. Once a matrix A is put into Jordan normal form, we have broken up the space into subspaces on which itis easy to understand the action of A. For example, suppose that⎛A \text{is the matrix} ⎞⎜⎜⎜41 04 00 00 00 00 00⎟⎟⎟⎜⎜⎜0 1 4 0 0 0 0⎟⎟⎟⎜⎜⎜0 0 0 4 0 0 0⎟⎟⎟ ,⎜⎜⎜0 0 0 1 4 0 0⎟⎟⎟⎝0 0 0 0 0 2 0⎠

0 0 0 0 0 1 2

which is made out of three blocks, of sizes 3, 2, and 2.Then we can instantly read off a great deal of information about Its algebraic multiplicity (its multiplicity as a root of the A. For instance, consider the eigenvalue 4. characteristic polynomial) is 5, since it is the sum of thesizes of all the blocks with eigenvalue 4, while its geometric multiplicity (the dimension of its eigenspace) is 2, since it is theblock we only have one actual eigenvector). \text{And even number of such blocks} (\text{because in each the minimal polynomial of the matrix} (\text{the smallest}-\text{degree polynomial} P (t) \text{such that} P (A) = 0) \text{is easy} \text{to write down}. \text{The minimal polynomial of each blockcan be written down instantly}: \text{if the block has size} k and generalized eigenvalueλ$, \text{then it is} (t - λ)^{k}$. The minimal polynomial of the whole matrix is then the“lowest common multiple” of the polynomials for the individual blocks. For the matrix above, we get(t-4)2, and (t-2)2 for the three blocks, so the minimal(t -4)3, polynomial of the whole matrix is$(t - 4)^{3}(t - 2)^{2}$. There are some generalizations of Jordan normal form, away from the context of linear maps acting onvector spaces. For example, there is an analogue of the theorem that applies to Abelian groups, which turnsout to be the statement that every finite Abelian group can be decomposed as a direct product of cyclic groups. III.44 Knot Polynomials W. B. R. Lickorish 1 Knots and Links Aclosed (in other words, it stops where it began) andknot is a curve in three-dimensional space that is never meets itself along its way. A link is several such curves, all disjoint from one another, which are called

225

theknots and links are the following: components of the link. Some simple examples of unknot trefoil figure eight unlink Hopf link Whitehead link be moved continuously, never breaking the “string,” to Two knots are equivalent or “the same” if one can become the other.movement. For example, the following knots are the Isotopy is the technical term for such same: whether two knots are the same. Two knots may appearto be very different but how does one The first problem in knot theory is how to decide prove that they are different? In classical geometry two triangles arethe same (or congruent) if one can be moved rigidly on to the other. Numbers that measure side-lengths and angles are assigned to each triangle to help determine whether this is the case. Similarly, mathematical entities calledand links in such a way that if two links have differ-invariants can be associated with knots ent invariants, then they cannot be the same link. many invariants relate to the geometry or topology of the complement of a link in three-dimensional space. the fundamental group [IV.6 §2](/part-04/algebraic-topology) of this complement is an excellent invariant, but algebraic techniques are then needed to distinguish the groups. The polynomial of J. W. Alexander (published in 1926) is a link invari-ant derived from distinguishing such groups. Although rooted in polynomial has long been known to satisfy a skein rela-algebraic topology [IV.6](/part-04/algebraic-topology), the Alexander tion (see below). The HOMFLY polynomial of 1984 generalizes the Alexander polynomial and can be based onthe simple combinatorics of skein theory alone.

1.1 The HOMFLY Polynomial

Suppose that links are oriented so that directions, indicated by arrows, are given to all components. To each oriented link L is assigned its HOMFLY polynomial

226

P (L)ables, a polynomial with integer coefficients in two vari-v and z (allowing both positive and negative powers ofv and z). The polynomials are such that P (unknot) = 1 (1)

and there is a linear skein relation v - 1 P (L+) - v P (L-) = z P (L0). (2)

This means that equation (2) holds whenever three links have identical diagrams except near one crossing where they are as follows L+ L- L0,

then this equation holds.This turns out to be good notation, although one could in principle usex and y in place of v-1 and -v. Although Alexander’s polynomial satisfied a particular instance of (2), it took almost sixty years and the discovery of the Jones polynomial for it to be realized that this general linear relation can be used. Note that there are two possible types of crossing in a diagram of an ori-ented link. A crossing is positive if, when approaching the crossing along the under-passing arc in the direc-tion of the arrow, the other directed arc is seen to cross over from left to right. If the over-passing arc crosses from right to left, the crossing is negative. When interpreting the skein relation at a crossing of a linkvital that L be regarded as L+ if the crossing is positive L, it is and as L- \text{if it is negative}. not at all obvious, is that it is possible to assign such polynomials to oriented links in a coherent fashion, The theorem that underpins this theory, which is uniquely, independent of any choice of a link’s diagram.A proof of this is given in Lickorish (1997).

1.2 HOMFLY Calculations

In a diagram of a knot it is always possible to change some of the crossings, from over to under, to achieve a diagram of the unknot. Links can be undone similarly. Using this, the polynomial of any link can be calculated from the above equations, though the length of the calculation is exponential in the number of crossings. the following is a calculation of P (trefoil). Firstly, consider the following instance of the skein relation:

$v^{-1P} ( ) - v P ( ) = z P ( )$.

Substituting the polynomial 1 for the polynomials of the two unknots, this shows that the HOMFLY polyno-mial of the two-component unlink is$z - 1(v - 1 - v)$. A

III. Mathematical Concepts

second usage of the skein relation is

$v^{-1P} - v P = z P$.

Substituting the previous answer for the unlink shows that the HOMFLY polynomial of the Hopf link is equal to$z^{-1}(v^{-3} - v^{-1}) - zv^{-1}$. Finally, consider the following instance of the skein relation:

$v^{-1P} - v P = z P$.

Substitution of the polynomial already calculated forthe Hopf link and of course the value 1 for the unknot shows that P (trefoil) = −v-4 + 2 v-2 + z2 v-2. A similar calculation shows that $P (\text{figure eight}) = v^{2} - 1 + v^{-2} - z^{2}$. The trefoil and the figure eight thus have different poly-nomials; this proves they are different knots. Experimentally, if a trefoil is actually made from a necklace(using the clasp to join the ends together) it is indeed found to be impossible to move it to the configuration of a figure eight knot. Note that the polynomial of a knot is not dependent on the choice of its orientation(but this is not so for links). ing every crossing in a diagram of the knot from anover-crossing to an under-crossing and vice versa (con-Reflecting a knot in a mirror is equivalent to changsider the plane of the diagram to be the mirror). the polynomial of the reflection is always the same as that of the original knotmust be replaced by one ofexcept that every occurrence of$-v^{-1}$. Thus the trefoil andv its reflection, , have polynomials $-v^{-}4 + 2v^{-}2 + z2v^{-}2 and - v4 + 2v2 + z2v2$. As these polynomials are not the same, the trefoil andits reflection are different knots. 2 Other Polynomial Invariants The HOMFLY polynomial was inspired by the discov-ery in 1984 of the polynomial of V. F. R. Jones. For an oriented linkone variablet (together with L, the Jones polynomialt-1). \text{It is obtained from} V (L) \text{has just} P (L) \text{by substituting} v = t and z = (t1()/){2} - (t - 1()/){2}, where III.46. \text{The Leech Lattice} t1^/2 is just a formal square root of t. The Alexan- der polynomial is obtained by the substitution$z = (t^{-1}()^{/})^{{}2} - (t^{1}()^{/})^{{}2}$. This latter polynomial is well under-v = 1, stood in terms of topology, by way of the fundamental group, covering spaces, and homology theory, and can be calculated by various methods involving determinants. It was J. H. Conway who, in discussing in 1969 his normalized version of the Alexander polynomial (the polynomial in one variable$v =$1 into the HOMFLY polynomial), first develop edz obtained by substituting the theory of skein relations.There is one more polynomial (due to L. H. Kauffman) based on a linear skein relation. The relation involves four links with unoriented diagrams differingas follows: . There are examples of pairs of knots that the Kauffman polynomial but not the HOMFLY polynomial can distin-guish and vice versa; some pairs are not distinguished by any of these polynomials.

2.1 Application to Alternating Knots

For the Jones polynomial there is a particularly simple formulation, by means of “Kauffman’s bracket polyno-mial,” that leads to an easy proof that the Jones (but not the HOMFLY) polynomial is coherently defined. this approach has been used to give the first rigorous confirmation of P. G. Tait’s (1898) highly believable pro-posal that a reduced alternating diagram of a knot has the minimal number of crossings for any diagram ofthat knot. Here “alternating” means that in going along the knot the crossings go: ... over, under, over, under, over, ... . Not every knot has such a diagram. “Reduced” means that there are, adjacent to each crossing, four distinct regions of the diagram’s planar complement. Thus, for example, any nontrivial reduced alternating diagram is not a diagram of the unknot. Also, the figure eight knot certainly has no diagram with only three crossings.

2.2 Physics

Unlike that of Alexander, the HOMFLY polynomial hasno known interpretation in terms of classical algebraic topology. It can, however, be reformulated as a col-lection of state sums, summing over certain labelings of a knot diagram. This recalls ideas from statistical mechanics; an elementary account is given in Kauffman

227

(1991). An amplification of the whole HOMFLY poly-nomial theory leads into a version of conformal field theory called topological quantum field theory.

Further Reading

Kauffman, L. H. 1991.Scientific. Knots and Physics. Singapore: World Lickorish, W. B. R. 1997.Graduate Texts in Mathematics, volume 175. New York: An Introduction to Knot Theory. Tait, P. G. 1898. On knots. In Springer.pp. 273–347. Cambridge: Cambridge University Press.Scientific Papers, volume I, III.45 K-Theory Kants of a-theory concerns one of the most important invari-topological space [III.90](/part-03/topological-spaces) X , a pair of groups called the K-groups of X. To form the group K0(X) one takes all (equivalence classes of) vector bundles on X, and uses the direct sum as the group operation. Thisleads not to a group but to a semigroup. However, from the semigroup one can easily construct a group in thesame way that one constructs Z out of N: by taking equivalence classes of expressions of the forma - b. Ifof defining a groupi is a positive integer, then there is a natural way K-i(X): it is closely related to the group theorem K0\text{says that}(Si \times X). The very important K^i(X) depends only on the parity of Bott periodicity i and, so there are in fact just two distinct K^1(X). See[IV.6 §6](/part - 04/algebraic - topology) \text{for more} K - groups, K0(X) \text{algebraic topology details}.If X \text{is a topological space such as a compact mani} - fold, \text{then one can associate with it the} C* - algebra C(X)\text{of all continuous functions from} X to C. \text{It turns out to be possible to define thebra in such a way that it applies to algebras that are not} K-\text{groups in terms of this alge}- \text{of the form} C(X). \text{In particular}, \text{it applies to algebras where} \text{multiplication} \text{is not commutative}. \text{For instance}, K-\text{theory provides important invariants of} C*-algebras. \text{See operator algebras} [IV.15 §4.4](/part - 04/operator - algebras).

Lagrange Multipliers

See optimization and lagrange

multipliers [III.64](/part-03/optimization-and-lagrange-multipliers)

III.46 The Leech Lattice

To define a lattice in Rd one chooses d linearly inde- pendent vectors$v^{1}$, . . . , vd and takes all combinations
