# Some Fundamental Mathematical Definitions

the first way. Sometimes, actual elimination is not pos-sible, but one feels it could be done in principle. For instance, the sentence “For every real number either positive, negative, or zero” is a bit like puttingx, x is together infinitely many sentences such as “t is either positive, negative, or zero,” one for each real number none of which involves a variable.t, 4 Levels of Formality It is a surprising fact that a small number of set-theoretic concepts and logical terms can be used to providea precise language that is versatile enough to express all the statements of ordinary
mathematics. There are some technicalities to sort out, but even these can oftenbe avoided if one allows not just sets but also numbers as basic objects. However, if you look at a well-written mathematics paper, then much of it will be written not in symbolic language peppered with sym-bols such as∀ and ∃, but in what appears to be ordi- nary English.
(Some papers are written in other lan-guages, particularly French, but English has established itself as the international language of mathematics.)How can mathematicians be confident that this ordinary English does not lead to confusion, ambiguity, and even in correctness? careful compromise between fully colloquial English, The answer is that the language typically used is a which would indeed run the risk of being unacceptably imprecise, and fully formal symbolism, which would be a nightmare to read.
The ideal is to write in as friendly and approachable a way as possible, while making sure that the reader (who, one assumes, has plenty of experience and training in how to read mathematics) can seeeasily how what one writes could be made more formal if it became important to do so. And sometimes it does become important: when an argument is difficultto grasp it may be that the only way to convince oneself that it is correct is to rewrite it more formally. of the principle of mathematical induction, which un-derlies many proofs:
Consider, for example, the following reformulation (15) Every nonempty set of positive integers has a least element. If we wish to translate this into a more formal lan-guage we need to strip it of words and phrases such as “nonempty” and “has.” But this is easily done. To saythat a set A of positive integers is nonempty is simply

I. Introduction

to say that there is a positive integer that belongs to This can be stated symbolically: A. (16)$∃n \in N n \in A$. What does it mean to say that It means that there exists an element$A$has a least element?x of A such that every elementx itself. This formulation is again ready to be translatedy of A is either greater than x or equal tointo symbols: (17)$∃x \in A ∀y \in A (y > x) ∨ (y = x)$. Statement (15) says that (16) implies (17) for every setof positive integers. Thus, it can be written symbolically$A$ as follows: (18)$∀A ⊂ N[(∃n \in N n \in A)⇒ (∃x \in A ∀y \in A (y > x) ∨ (y = x))]$.

Here we have two very different modes of presenta-tion of the same mathematical fact. Obviously (15) is much easier to understand than (18). But if, for exam-ple, one is concerned with the foundations of mathematics, or wishes to write a computer program that checks the correctness of proofs, then it is better to work with a greatly pared-down grammar and vocabu-lary, and then (18) has the advantage. In practice, there are many different levels of formality, and mathemati-cians are adept at switching between them.
It is this that makes it possible to feel completely confident inthe correctness of a mathematical argument even when it isalso this that allows mistakes to slip through the netnot presented in the manner of (18)—though it is from time to time. I.3 Some Fundamental Mathematical

Definitions

The concepts discussed in this article occur through out so much of modern mathematics that it would be in appropriate to discuss them in part III—they are too basic. Many later articles will assume at least some acquaintance with these concepts, so if you have not met them, then reading this article will help you to understand significantly more of the book. 1 The Main Number Systems Almost always, the first mathematical concept that achild is exposed to is the idea of numbers, and numbers retain a central place in mathematics at all levels.

I.3. Some Fundamental Mathematical Definitions

However, it is not as easy as one might think to say what the word “number” means: the more mathemat-ics one learns, the more uses of this word one comes to know, and the more sophisticated one’s concept ofnumber becomes. This individual development parallels a historical development that took many centuries(see from numbers to number systems [II.1](/part-02/from-numbers-to-number-systems)). regarded not individually but as parts of larger wholes, The modern view of numbers is that they are best called number systems are the arithmetical operations—such number systems;
the distinguishing features of as addition, multiplication, subtraction, division, and extraction of roots—that can be performed on them. This view of numbers is very fruitful and provides a springboard into abstract algebra. The rest of this sec-tion gives a brief description of the five main number systems. 1.1 The Natural Numbers The natural numbers, otherwise known as the positive integers dr en: 1, 2, 3, 4, and so on. It is the natural numbers, are the numbers familiar even to young chilthat we use for the very basic mathematical purposeof counting.
The set of all natural numbers is usually denoted N. (Some mathematicians prefer to include 0 as a natural number as well: for instance, this is theusual convention in logic and set theory. Both conventions are to be found in this book, but it should alwaysbe clear which one is being used.) constitute a formal definition, but it does suggest the Of course, the phrase “1, 2, 3, 4, and so on” does not following basic picture of the natural numbers, one thatwe tend to take for granted. (i) Given any natural numbern there is another, n + 1, that comes next—known as the successor ofn.
(ii) A list that starts with 1 and follows each numberby its successor will include every natural number exactly once and nothing else. This picture is encapsulated by the peano axioms [III.67](/part - 03/the - peano - axioms). Given two natural numbersm and n one can add them together or multiply them, obtaining in each casea new natural number. By contrast, subtraction and division are not always possible. If we want to give meaning to expressions such as 8$- 13 or5$, then we must work in a larger number system.

1.2 The Integers

The natural numbers are not the only whole numbers, since they do not include zero or negative numbers, both of which are indispensable to mathematics. One of the first reasons for introducing zero was that itis needed for the normal decimal notation of positive integers—how else could one conveniently write 1005? However, it is now thought of as much more than justa convenience, and the property that makes it significant is that it is anthat adding zero to any number leaves that number additive identity, which means unchanged.
And while it is not particularly interesting to do to a number something that has no effect, the property itself is interesting and distinguishes zero from all other numbers. An immediate illustration ofthis is that it allows us to think about negative numbers: if-nnis that when you add it tois a positive integer, then the defining property ofn you get zero. unthinkingly assume that numbers are for counting and find negative numbers objectionable because the Somebody with little mathematical experience may answer to a question beginning “How many” is never negative.
However, simple counting is not the only use for numbers, and there are many situations that are naturally modeled by a number system that includes both positive and negative numbers. For example, negative numbers are sometimes used for the amount ofmoney in a bank account, for temperature (in degrees Celsius or Fahrenheit), and for altitude compared withsea level. is usually denoted meaning “numbers”). Within this system, subtraction The set of all integers—positive, negative, and zero—Z (for the German word “Zahlen,” is always possible: that is, ifso ism - n. m and n are integers, then

1.3 The Rational Numbers

So far we have considered only whole numbers. If we form all possible fractions as well, then we obtain the rational numbers. The set of all rational numbers is denoted Q (for “quotients”). One of the main uses of numbers besides counting is measurement ones that can vary continuously, such as length, weight,, and most quantities that we measure are temperature, and velocity. For these, whole numbers are inadequate. bers is that they form a number system in which division is always possible—except by zero. This fact, A more theoretical justification for the rational num-

together with some basic properties of the arithmetical operations, means that Q is a field. What fields are and why they are important will be explained in more detail later (section 2.2).

1.4 The Real Numbers

A famous discovery of the ancient Greeks, often attrib-uted, despite very inadequate evidence, to the school ofnot a rational number. That is, there is no fraction pythagoras [VI.1](/part-06/pythagoras-ca), was that the square root of 2 is p/qsuch that(p/q)2 = 2. The Pythagorean theorem about right-angled triangles (which was probably known at least a thousand years before Pythagoras) tells us thatif a square has sides of length 1, then the length of its diagonal iscannot be measured by rational numbers.$\sqrt{2}$.
Consequently, there are lengths that for extending our number system still further. How - ever, such a conclusion can be resisted: after all, we This argument seems to give strong practical reasons cannot make any measurements with infinite precision, so in practice we round off to a certain number of decimal places, and as soon as we have done so we have presented our measurement as a rational number. (This point is discussed more fully in[IV.21](/part - 04/numerical - analysis).) numerical analysis beyond the rational numbers are irresistible.
If wewant to solve polynomial equations, take Nevertheless, the theoretical arguments for going logarithms [III.25 §4](/part - 03/the - exponential - and - logarithmic - functions), do trigonometry, or work with theian distribution [III.71 §5](/part - 03/probability - distributions), to give just four exam-gaussples from an almost endless list, then irrational num-bers will appear every where we look. They are not used directly for the purposes of measurement, but they areneeded if we want to reason theoretically about the physical world by describing it mathematically.
This necessarily involves a certain amount of idealization: it is far more convenient to say that the length of the diagonal of a unit square iswhat would be observed, and with what degree of cer-. qrt{2} than it is to talk about tainty, if one tried to measure this length as accurately as possible. all numbers with a finite or infinite decimal expansion. In the latter case, they are defined not directly but by The real numbers can be thought of as the set of a process of successive approximation.
For example, the squares of the numbers 1, 1.4, 1.41, 1.414, 1.4142, 1.41421, enough along the sequence, which is what we mean by. . . , get as close as you like to 2, if you go far saying that the square root of 2 is the infinite decimal1.41421 . . .. I. Introduction abstract view of The set of all real numbers is denoted R is that it is an extension of the R. A more rational number system to a larger field, and in fact theonly one possible in which processes of the above kind always give rise to numbers that themselves belongto R.
the idea of limits (of successive approximations), a true appreciation of the real number system depends on an Because real numbers are intimately connected with understanding of mathematical analysis, which will bediscussed in section 5.

1.5 The Complex Numbers

Many polynomial equations, such as the equationx2 =$2$, do not have rational solutions but can be solved in R. However, there are many other equations that cannotbe solved even in R. The simplest example is the equationx2 = −1, which has no real solution since the square of any real number is positive or zero. In order to get around this problem, mathematicians introducea symbol, i, which they treat as a number, and they simply stipulate that i2 is to be regarded as equal to-1. The numbers of the form complex number systema+bi, where, denoteda and C, is the set of allb are real num- bers.
To add or multiply complex numbers, one treats ias a variable (likex, say), but any occurrences of i2 are replaced by-1. Thus,(a + bi) + (c + di) = (a + c) + (b + d)i and (a + bi)(c + di) = ac + bci + adi + bdi2= (ac - bd) + (bc + ad)i. There are several remarkable points to note about this definition. First, despite its apparently artificial nature, it does not lead to any in consistency. Secondly, although complex numbers do not directly count or measure anything, they are immensely useful.
Thirdly, and perhaps most surprisingly, even though the number i was introduced to help us solve just one equation, it in fact allows us to solve tions. This is the famous fundamental theorem ofall polynomial equa algebra [V.13](/part - 05/the - fundamental - theorem - of - algebra). One explanation for the utility of complex numbers is that they provide a concise way to talk about many aspects of geometry, via Argand diagrams. These represent complex numbers as points in the plane, thenumbera+bi corresponding to the point with coordin - ates(a, b).
If r = . qrt{a}2 + b2 and θ = . an - 1(b/a), then I.3. Some Fundamental Mathematical Definitions aplying a complex number= r . os θ and b = r . in zθ. It turns out that multi-= x + yi by a + bi cor- responds to the following geometrical process. First, you associatez with the point (x, y) in the plane. Next, you multiply this point byr , obtaining the point(r x, r y)clockwise about the origin through an angle of. Finally, you rotate this new point counter-θ. In other words, the effect on the complex plane of multi-plication bya + bi is to dilate it by r and then rotate it$by$θ.
In particular, if a2 + b2 = 1, then multiplying bya + bi corresponds to rotating by θ.

good as Cartesian coordinates for representing com-plex numbers: an alternative way to write For this reason, polar coordinates are at least asa + bi is r (ei)θ, which tells us that the number has distance the origin and is positioned at an angleθ around fromr from the positive part of the real axis (in a counter clockwise direction). Ifz = r (ei)θ with r > 0, then r is called the modulus ofz. (Since adding 2 of z, denoted byπ to θ|zdoes not change e|, and θ is the argumen(ti)θ, it isusually understood that 0-π ⩽ θ < π.) One final useful definition:
if⩽ θ < 2π, or sometimes thatz = x + iy is a complex number, then itste. ar{n}z, is the number x - yi. It is easy to check that complex conjugate$, writ - z$. ar{z} = x2 + y2 = |z|2.

2 Four Important Algebraic Structures

In the previous section it was emphasized that num-bers are best thought of not as individual objects but as members of number systems. A number system consists of some objects (numbers) together with opera-tions (such as addition and multiplication) that can be performed on those objects. As such, it is an exampleof an algebraic structure. However, there are many very important algebraic structures that are not number systems, and a few of them will be introduced here.

2.1 Groups

Ifis a way of moving S is a geometrical shape, then a S in such a way that the distances rigid motion of S between the points of Sare not changed—squeezing and stretching are not allowed. A rigid motion is ametry of S if, after it is completed, S looks the same assym- it did before it moved. For example, iftriangle, then rotating S through 120 S◦ about its centeris an equilateral is a symmetry; so is reflecting through one of the vertices of SS and the midpoint of theabout a line that passes opposite side.
to itself such that the distance between any two points More formally, a symmetry of S is a function f from Sx transformed pointsand y of S is the same as the distance between thef (x) and f (y). ematical structure, then a symmetry of This idea can be hugely generalized: if S Sis any math-is a func- tion fromis a geometrical shape, then the mathematical struc - S to itself that preserves its structure. If S ture that should be preserved is the distance between any two of its points.
But there are many other mathematical structures that a function may be asked topreserve, most notably algebraic structures of the kind that will soon be discussed. It is fruitful to draw ananalogy with the geometrical situation and regard any structure-preserving function as a sort of symmetry. Because of its extreme generality, symmetry is an all pervasive concept within mathematics; and wherever symmetries appear, structures known as groups follow close behind.
To explain what these are and whythey appear, let us return to the example of an equilateral triangle, which has, as it turns out, six possible symmetries. lateral triangle with vertices A, B, and C and suppose Why is this? Well, letf be a symmetry of an equi- for convenience that this triangle has sides of length 1.Thenf (A), f (B), and f (C) must be three points of the triangle and the distances between these points mustall be 1. It follows thatf (A), f (B), and f (C) are dis- tinct vertices of the triangle, since the furthest apart anythe two points are distinct vertices.
Sotwo points can be is 1 and this happens only whenf (A), f (B), andf (number of possible orders of A, B, and C is 6. It is not C) are the vertices A, B, and C in some order. But the hard to show that, once we have chosenf (C), the rest of what f does is completely determined.f (A), f (B), and (For example, if X is the midpoint of A and C, thenmust be the midpoint off (A) and f (C) since there isf (X) no other point at distance 12 fromf (A) and f (C).) Let us refer to these symmetries by writing down in order what happens to the vertices A, B, and C.
So, for instance, the symmetry ACB is the one that leaves the vertex A fixed and exchanges B and C, which is achievedby reflecting the triangle in the line that joins A to the midpoint of B and C. There are three reflections likethis: ACB, CBA, and BAC. There are also two rotations: BCA and CAB.
Finally, there is the “trivial” symmetry, ABC, which leaves all points where they were originally.(The “trivial” symmetry is useful in much the same way as zero is useful for the algebra of integer addition.) groups is that any two symmetries can be What makes these and other sets of symmetries into composed, meaning that one symmetry followed by another pro-duces a third (since if two operations both preserve a structure then their combination clearly does too). For example, if we follow the reflection BAC by the reflec-tion ACB, then we obtain the rotation CAB.
To work this out, one can either draw a picture or use the following kind of reasoning: the first symmetry takes Ato B and the second takes B to C, so the combination takes A to C, and similarly B goes to A, and C to B. Notice that the order in which we perform the sym-metries matters: if we had started with the reflection ACB and then done the reflection BAC, then we would have obtained the rotation BCA.
(If you try to see this bydrawing a picture, it is important to think of A, B, and C as labels that stay where they are rather than moving with the triangle—they mark positions that the vertices can occupy.) own right, and of composition as an algebraic oper-We can think of symmetries as “objects” in their ation, a bit like addition or multiplication for num - bers. The operation has the following useful properties: it is associative, the trivial symmetry is an identity element[I.2 §2.4](/part - 01/language - and - grammar).
(For example, the inverse of a reflection is, and every symmetry has an inverse itself, since doing the same reflection twice leaves the triangle where it started.) More generally, any set witha binary operation that has these properties is called a group. It is not part of the definition of a group that the binary operation should be commutative, since, aswe have just seen, if one is composing two symmetries then it often makes a difference which one goes first.
However, if it is commutative then the group is called Abelian, after the Norwegian mathematician niels henrik abel [VI.33](/part - 06/niels - henrik - abel - 18021829). The number systems Z, Q, R, and C all form Abelian groups with the operation of addition, or under addition, as one usually says. If you remove zero from Q, R, and C, then they form Abelian groups under multiplication, but Z does not because of a lack of inverses: the reciprocal of an integer is not usually aninteger. Further examples of groups will be given later in this section.
2.2 Fields Although several number systems form groups, toregard them merely as groups is to ignore a great deal of their algebraic structure. In particular, whereas a group has just one binary operation, the standard I. Introduction number systems have two, namely addition and multi - plication (from which further ones, such as subtraction and division, can be derived). The formal definition ofa field is quite long: it is a set with two binary operations and there are several axioms that these opera-tions must satisfy. Fortunately, there is an easy way to remember these axioms.
You just write down all thebasic properties you can think of that are satisfied by addition and multiplication in the number systems R, and C. Q, multiplication are commutative and associative, andboth have identity elements (0 for addition and 1 for These properties are as follows. Both addition and multiplication). Every element - x and a multiplicative inverse 1 x has an additive inverse/x (except that 0 does not have a multiplicative inverse). It is the existenceof these inverses that allows us to define subtraction and division:$x · (1/y)$.
x - y means x + (-y) and x/y means tiplication satisfy individually. However, a very general rule when defining mathematical structures is that if That covers all the properties that addition and mula definition splits into parts, then the definition as a whole will not be interesting Here our two parts are addition and multiplication, andunless those parts interact. the properties mentioned so far do not relate them inany way. But one final property, known as the distributive law, does this, and thereby gives fields their special character.
This is the rule that tells us how to multiply out brackets: x(y+z) = xy+xz for any three numbersx, Having listed these properties, one may then view they , and z. whole situation abstractly by regarding the properties as axioms and saying that a field is any set with twobinary operations that satisfy all those axioms. However, when one works in a field, one usually thinks ofthe axioms not as a list of statements but rather as a general license to do all the algebraic manipulations that one can do when talking about rational, real, and complex numbers.
find a mathematical structure that satisfies them, andit is indeed the case that fields are harder to come by Clearly, the more axioms one has, the harder it is to than groups. For this reason, the best way to under-stand fields is probably to concentrate on examples. In addition toas fundamental, namely Q, R, and CF, one other field stands out, which is the set of integers modulo a primetion also defined modulop, with addition and multiplica-pp(see modular arithmetic [III.58](/part-03/modular-arithmetic)).

I.3. Some Fundamental Mathematical Definitions

much the existence of these basic examples as the fact What makes fields interesting, however, is not so that there is an important process ofallows one to build new fields out of old ones. The idea extension that is to start with a field F, find a polynomial P that has no roots in F, and “adjoin” a new element to F with the stipulation that it is a root ofextended field F, which consists of everything that one P. This produces an can produce from this root and from elements of F using addition and multiplication. process:
in the fieldhas no root, so we adjoined the element i and let We have already seen an important example of this R, the polynomial P (x) = x2 C + be1 the field of all combinations of the form a + bi. in which again the equation If we do so, then we obtain a new field, which, like We can apply exactly the same process to the field$x^{2} + 1 = 0 \text{has no solution}$.FC3,, consists of all combinations of the form$a + bi$, but nowanew field has nine elements. Another example is theandb belong to F3.
Since F3 has three elements, this fielda + b Q . qrt(2, where now . qrt{2}), which consists of all numbers of the forma and b are rational numbers. A slightly more complicated example isa root of the polynomial$x^{3} - x - 1$. A typical element Q(γ), where γ is of this field has the form$a + bγ + cγ^{2}$, with a, b, and c rational. If one is doing arithmetic ineverγ3 appears, it can be replaced by Q(γ)γ +, then when-1 (becauseγ3 - γ - 1 = 0), just as i2 can be replaced by -1 in the complex numbers.
For more on why field extensions are interesting, see the discussion of automorphisms in section 4.1. A second very significant justification for introducing fields is that they can be used to form vector spaces, and it is to these that we now turn.

2.3 Vector Spaces

One of the most convenient ways to represent pointsin a plane that stretches out to infinity in all directions is to use Cartesian coordinates. One chooses an originand two directions X and Y , usually at right angles to each other. Then the pair of numbers the point you reach in the plane if you go a distance(a, b) stands fora in directiona is a negative number such as X and a distance b in direction-2, this is interpreted Y (where if as going a distance+2 in the opposite direction to X, and similarly forb). Another way of saying the same thing is this.
Let$x$ and respectively, so their Cartesian coordinates arey stand for the unit vectors in directions X and(1, Y0), andlinear combination(0,1). Then every point in the plane is a so-calledax + by of the basis vectors x andyit as. To interpret the expressiona(1, 0) + b(0,1). Then a atimes the unit vectorx + by, first rewrite ((10,, b)0) isand when you add(a,0) and b times the unit vector(a, 0) and (0, b) coordinate(0,1) is by coordinate you get the vector Here is another situation where linear combinations(a, b). appear.
Suppose you are presented with the differential equation(d2 y/dx2) + y = 0, and happen to know (or notice) that solutions. Then you can easily check thaty = . in x and y = . os x are two possibley = a. in x + b . os x is a solution for any pair of numbers a and b. That is, any linear combination of the existing solutions. in x and cos x is another solution. It turns out that all solutions are of this form, so we can regard sin$\cos x$ as “basis vectors” for the “space” of solutions ofx and the differential equation. through out mathematics.
To give one more example, an arbitrary polynomial of degree 3 has the form Linear combinations occur in many many contexts ax3 + bx2 + cx + d, which is a linear combination of the four basic polynomials 1,$x$, x2, and x3. the notion of linear combination makes sense. The objects that belong to the vector space are usually A vector space is a mathematical structure in which called example and are thinking of them as concrete objects vectors, unless we are talking about a specific such as polynomials or solutions of a differential equa-tion.
Slightly more formally, a vector space is a set$V$ such that, given any two vectors ments of V ) and any two real numbersv andawand(that is, ele-b, we can form the linear combination$av + bw$. of two different kinds, the vectors numbers Notice that this linear combination involves objectsa and b. The latter are known asv andscalarsw and the. The operation of forming linear combinations can be bro-ken up into two constituent parts: addition and scalar multiplication.
To form the combination$av + bw$, first multiply the vectorsb, obtaining the vectorsv andav wandby the scalarsbw, and then adda and these resulting vectors to obtain the full combination$av + bw$. tain natural rules. Addition of vectors must be commu-tative and associative, with an identity (the The definition of linear combination must obey cer-zero vector ) and an inverse for eachv (written -v). Scalar multipli- cation must obey a sort of associative law, namely that a(bd is tr i but i ve laws: v) and (ab)v (aare always equal.
We also need two + b)v = av + bv and a(v + w) =av + aw for any scalars a and b and any vectors v$and$ w. Another context in which linear combinations arise, one that lies at the heart of the usefulness of vector spaces, is the solution of simultaneous equations. Suppose one is presented with the two equations 36 andx - y = 7. The usual way to solve such a pair ofx + 2 y = equations is to try to eliminate eitheran appropriate multiple of one of the equations to thex or y by adding other: that is, by taking a certain linear combination of the equations.
In this case, we can eliminatey by adding twice the second equation to the first, obtain-ing the equation 5 x = 20, which tells us that x = 4 and hence thaty = −3. Why were we allowed to combine equations like this? Well, let us write L1 and R1 for the left- and right-hand sides of the first equation, and sim - ilarly L2 and R2 for the second. If, for some particular choice ofthen clearlyx and L + y2, it is true that L = R + 2 R L, as the two sides of1 = R1 and L2 = R2, this equation are merely giving different names to the1 2 1 2 same numbers. tors Given a vector space$v1$, v2, . . .
, vnwith the following property: every V , a basis is a collection of vec- vector inlinear combination V can be written in exactly one way as aa v + a v + · · · + a v . There are two ways in which this can fail: there may be avector that cannot be written as a linear combination1 1 2 2 nn ofso expressed, but in more than one way. If every vec-$v^{1}$, v2, . . . , vn or there may be a vector that can be tor is a linear combination then we say that the vectors combination in more than one way then we say that$v^{1}$, v2, . . . , vn span V , and if no vector is a linear they arev , v , . . .
, in depend en tv are independent if the only way of writ-. An equivalent definition is that ing the zero vector astaking1 2 a =^na = · · · =aa^1 v^1=+0.a^2 v^2 + · · · + a^nv^n is by The number of elements in a basis is called the1 2 n dimen- sionnot be two bases of different sizes, but it turns outof V . It is not immediately obvious that there could that there cannot, so the concept of dimension makes sense. For the plane, the vectorsx and ydefined earlier formed a basis, so the plane, as one would hope, has dimension 2.
If we were to take more than two vectors, then they would no longer be independent: for example, if we take the vectors(1,2), (1,3)$, and(tion 83$,1), then we can write(1, 2)-5(1, 3)-(3, 1()0. (To work this out one must,0) as the linear combina- solve some simultaneous equations—this is typical of calculations in vector spaces.)

I. Introduction

space of all sequences bers. To add this to a sequence The most obviousn-dimensional vector space is the(x1, . . . , x(yn), . . . , yof n )real num-one sim- ply forms the sequenceto multiply it by a scalar(xc1 one forms the sequence+ y1, . . . , (x1()n)n+yn) and(cxthe plane with its usual coordinate system is1, . . . , cxn). This vector space is denoted Rn R. Thus,2 and three-dimensional space is R3. in a basis to be finite. A vector space that does not havea finite basis is called It is not in fact necessary for the number of vectors infinite dimensional. This is not an exotic property:
many of the most important vec-tor spaces, particularly spaces where the “vectors” are functions, are infinite dimensional. There is one final remark to make about scalars. They were defined earlier as real numbers that one uses tomake linear combinations of vectors. But it turns out that the calculations one does with scalars, in particular solving simultaneous equations, can all be done in amore general context. What matters is that they should belong to a field, so Q, R, and C can all be used as systems of scalars, as indeed can more general fields.
Ifthe scalars for a vector space Vcome from a field F, then one says that V is a vector space over F. This gen- eral ization is important and useful: see, for example, algebraic numbers [IV.1 §17](/part-04/number-theory).

2.4 Rings

Another algebraic structure that is very important isa ring. Rings are not quite as central to mathematics as groups, fields, or vector spaces, so a proper discus-sion of them will be deferred to rings, ideals, and modules [III.81](/part-03/rings-ideals-and-modules). However, roughly speaking, a ring is an algebraic structure that has most, but not necessar-ily all, of the properties of a field. In particular, the requirements of the multiplicative operation are less strict. The most important relaxation is that nonzero elements of a ring are not required to have multiplicative inverses;
but sometimes multiplication is not even required to be commutative. If it is, then the ring itself is said to be commutative—a typical example of a com-mutative ring is the set Z of all integers. Another is the set of all polynomials with coefficients in somefield F. 3 Creating New Structures Out of Old Ones An important first step in understanding the definition of some mathematical structure is to have a supply ofexamples. Without examples, a definition is dry and

I.3. Some Fundamental Mathematical Definitions

abstract. With them, one begins to have a feeling forthe structure that its definition alone cannot usually provide. to answer basic questions. If you have a general state-ment about structures of a given type and want to know One reason for this is that it makes it much easier whether it is true, then it is very helpful if you can testit in a wide range of particular cases. If it passes all the tests, then you have some evidence in favor of the statement. If you are lucky, you may even be able to seewhy it is true;
alternatively, you may find that the statement is true for each example you try, but always for reasons that depend on particular features of the exam-ple you are examining. Then you will know that you should try to avoid these features if you want to find a counterexample. If youthe general statement is false, but it may still happendo find a counterexample, then that a modification to the statement is true and useful. In that case, the counterexample will help you to findan appropriate modification. how does one find them?
There are two completely dif-The moral, then, is that examples are important. So ferent approaches. One is to build them from scratch. For example, one might define a group G to be the group of all symmetries of an icosahedron. Another, which is the main topic of this section, is to take some examples that have already been constructed and build new ones out of them. For instance, the group Z2, which consists of all pairs of integers tion defined by the obvious rule(x, y)(x, y)+, with addi-(x^ , y^ ) =(x + x^ , y + y^ ), is a “product” of two copies of the group Z.
As we shall see, this notion of product is very general and can be applied in many other contexts. Butfirst let us look at an even more basic method of finding new examples.

3.1 Substructures

As we saw earlier, the set C of all complex numbers, with the operations of addition and multiplication, forms one of the most basic examples of a field. It also contains manyselves form fields. Take, for example, the set subfields: that is, subsets that them-Q(i) of all complex numbers of the formb are rational.
This is a subset ofa +Cband is also a field.i for whicha and To show this, one must prove that Q(i) is closed under addition, multiplication, and the taking of inverses. That is, ifz and w are elements of Q(i), then z + wandzw must be as well, as must -z and 1/z (this last requirement applying only when z = 0). Axioms such as the commutativity and associativity of addition and multiplication are then true in Q(i) for the simple reason that they are true in the larger set C. Even though Q(i) is contained in C, it is a more inter- esting field in some important ways. But how can thisbe?
Surely, one might think, an object cannot become more moment’s further thought shows that it certainly can: interesting when most of it is taken away. But a for example, the set of all prime numbers contains fas-cinating mysteries of a kind that one does not expect to encounter in the set of all positive integers. As for fields, tells us that every polynomial equation has a solution the fundamental theorem of algebra [V.13](/part - 05/the - fundamental - theorem - of - algebra) in C. This is very definitely not true in Q(i).
So in Q(i), and in many other fields of a similar kind, we can askwhich polynomial equations have solutions. This turns out to be a deep and important question that simply does not arise in the larger field C. ture, a substructure of In general, given an example X is a subset X of an algebraic struc - Y that has rel- evant closure properties. For instance, groups have subgroups, vector spaces have subspaces, rings have subrings (and also property defining the substructure ideals [III.81](/part - 03/rings - ideals - and - modules)), and so on.
If the Yis a sufficiently interesting one, thenent from X and may therefore be a useful addition to Ymay well be significantly differone’s stock of examples. ing substructures abound in analysis and geometry aswell. For example, the plane This discussion has focused on algebra, but interest - R2 is not a particularly interesting set, but it has subsets, such as the mandelbrot setstill far from fully understood.[IV.14 §2.8](/part - 04/dynamics), to give just one example, that are

3.2 Products

Let G and H be two groups. The product group G . imes  H has as its elements all pairs of the formthatg belongs to G and h belongs to H. This definition(g, h) such shows how to build the elements of G . imes H out of the elements of G and the elements of H. But to define a group we need to do more: we are given binary oper-ations on G and H and we must use them to build a binary operation on G, let us write g1 g2 for the result of applying G . imes H. If g1 and g2 are elements of G’s binary operation to them, as is customary, and let us do the same forwe can define on the pairs, namely H.
Then there is an obvious binary operation(g1$, h1)(g2$, h2) = (g1 g2$, h1h2)$.

That is, one applies the binary operation fromfirst coordinate and the binary operation from HG to theto the second. ilar way. Ifments of One can form products of vector spaces in a very sim-VV. imes and W Ware all pairs of the formare two vector spaces, then the ele-(v, w) withvare defined by the formulasin V and w in W. Addition and scalar multiplication(v1, w1) + (v2$, w2) = (v1 + v2$, w1 + w2) and λ(v$, w) = (\lambda v, \lambda w)$.

The dimension of the resulting space is the sum of the dimensions of V and W . (It is actually more usual to denote this space by V ⊕W and call it the direct sum of VIt is not always possible to define product structures and W . Nevertheless, it is a product construction.) in this simple way. For example, if F and Fare two fields, we might be tempted to define a “product field”F. imes F^ using the formulas(x1, y1) + (x2$, y2) = (x1 + x2$, y1 + y2) and $(x1$, y1)(x2$, y2) = (x1x2$, y1 y2). However, this definition does not give us a field.
Most of the axioms hold, including the existence of additive and multiplicative identities—they are(0,0) and (1,1), respectively—but the nonzero element have a multiplicative inverse, since the product of(1,0) does not(1,0) and Occasionally we can define more complicated binary(x, y) is (x, 0), which can never equal (1,1). operations that do make the set instance, if F$= F = R$, then we can define addition as F. imes F^into a field. For above but define multiplication in a less obvious wayas follows: $(x^{1}$, y1)(x2$, y2) = (x1x2 - y1y2$, x1 y2 + x2 y1).
Then we obtain C, the field of complex numbers, since the pairber$x + (x$, y)iy. However, this is not a product field in thecan be identified with the complex num general sense we are discussing. Returning to groups, what we defined earlier was the direct product more complicated products of groups, which can beof G and H. However, there are other, used to give a much richer supply of examples. To illus-trate this, let us consider the dihedral group D , which is the group of all symmetries of a square, of which4 there are eight.
If we lettions and T for a counter clockwise quarter turn, then Rstand for one of the reflec-

I. Introduction

every symmetry can be written in the form Ti Rj, wherei is 0, 1, 2, or 3 and j is 0 or 1. (Geometrically, this says that you can produce any symmetry by either rotat-ing through a multiple of 90◦or reflecting and then rotating.) a product of the group rotations, with the group This suggests that we might be able to regard I, T , T{I, R2}}, T, consisting of the iden - 3, consisting of four D4 as tity Iand the reflection R. We could even write (Ti, Rj) instead ofinstance,(T R)(T R)Ti Rj. However, we have to be careful. Fordoes not equal T2 R2 = T2 but I.
The correct rule for multiplication can be deduced fromthe fact that RT R = T - 1 (which in geometrical terms is saying that if you reflect the square, rotate it counter-clockwise through 90◦, and reflect back, then the result is a clockwise rotation through 90◦). It turns out to be(Ti, Rj)(Ti^ , Rj^ ) = (T(i+)( - 1()j)i^ , (Rj)+j^ ). For example, the product of(T-2 R)2, which equals T2. (T $, R) with (T3$, R) is This is a simple example of a “semidirect product” of two groups.
In general, given two groupsmay be several interesting ways of defining a binary G and H, there operation on the set of pairs(g, h), and therefore several potentially interesting new groups. 3.3 Quotients Let us write Q[x] for the set of all polynomials in the variablesions like 2 xwith rational coefficients: that is, expres - x4 - 3 x + 6. Any two such polynomials can be added, subtracted, or multiplied together andthe result will be another polynomial.
This makes2 Q[x] into a commutative ring, but not a field, because if youdivide one polynomial by another then the result is not (necessarily) a polynomial. We will now convert Q[x]into a field in what may at first seem a rather strange way: by regarding the poly - nomial x3 - x -1 as “equivalent” to the zero polynomial. To put this another way, whenever a polynomial involvesx3 we will allow ourselves to replace x3 byx+1, and we will regard the new polynomial that results as equivalent to the old one. For example, writing “∼” for “is equivalent to”:
x5 = x3 x2 ∼ (x + 1)x2 = x3 + x2∼ x + 1 + x2 = x2 + x + 1.

Notice that in this way we can convert any polynomial into one of degree at most 2, since whenever the degreeis higher, you can reduce it by taking out x3 from the I.3. Some Fundamental Mathematical Definitions

term of highest degree and replacing it byx + 1, just as we did above. Notice also that whenever we do such a replacement, the difference between the old polynomial and the newone is a multiple of x3 - x - 1. For example, when we replacedx3 x2 by (x + 1)x2 the difference was(x3 - x - 1)x2. Therefore, what our process amounts to is this: two polynomials are equivalent if and only if their difference is a multiple of the polynomial$x3 - x - 1$.
Now the reason Q[x]was not a field was that nonconstant polynomials do not have multiplicative inverses. For example, it is obvious that one cannot multiply$x2$ by a polynomial and obtain the polynomial 1. However, we can obtain a polynomial that is equivalent to 1 if we multiply by 1$+ x - x2$. Indeed, the product of the two$is$ x2 + x3 - x4 ∼ x2 + x + 1 - (x + 1)x = 1. It turns out thatto zero (that is, are not multiples ofall polynomials that are not equivalent$x^{3} - x - 1) \text{have mul}-$ tiplicative inverses in this generalized sense.
(To find aninverse for a polynomial P one applies the generalized euclid algorithm such that$P Q + R(x^{3}$[III.22] to find polynomials-x-1) = 1. The reason we obtain Q and R 1 on the right-hand side is that factorized in Q[x] and P is not a multiple ofx3 - x - 1 cannot bex3 -x -1, so their highest common factor is 1. The inverse ofis then Q.) P After all, the product ofwas merely equivalent to 1. This is where the notion In what sense does this mean that we have a field?$x2 and 1 + x - x2$was not 1: it of quotients comes in.
We simply decide that when two polynomials are equivalent, we will regard them asequal, and we denote the resulting mathematical structure by Q$[x]/(x3 - x - 1)$. This structure turns out to be a field, and it turns out to be important as the smallest field that contains Q and also has a root of the polynomial$X^{3} - X -$1. What is this root? It is simplynow thinking of polynomials in two different ways: asx.
This is a slightly subtle point because we are elements of Q[x]/(x3 - x - 1) (at least when equiv- alent ones are regarded as equal), and also as func-tions defined on Q$[x]/(x^{3} - x - 1)$. So the polyno- mial X3 - X - 1 is not the zero polynomial, since for example it takes the value 5 whenx6 - x2 - 1 ∼ (x + 1)2 - x2 - 1 ∼ 2 Xx=when2 and the value X = x2. discussion of the field cuss i on of the field You may have noticed a strong similarity between the Q(γ)Q[x]/(xat the end of section 2.2. And3 - x - 1) and the dis- indeed, this is no coincidence: they are two different

ways of describing the same field. However, thinking ofthe field as Q[x]/(x3 - x - 1)brings significant advantages, as it converts questions about a mysterious setof complex numbers into more approachable questions about polynomials. What does it mean to “regard two mathematical objects as equal” when they are not equal? A formal answer to this question uses the notion of equivalence relations and equivalence classes (discussed inlanguage and grammar of mathematics [I.2 §2.3](/part-01/language-and-grammar)):
the one says that the elements of Q$[x]/(x^{3} - x - 1) \text{are not}$ in fact polynomials butmials. However, to understand the notion of a quotient equivalence classes of polynoit is much easier to look at an example with which weare all familiar, namely the set Q of rational numbers. If we are trying to explain carefully what a rational number is, then we may start by saying that a typical rational number has the forma/b, where a and b are integers and rational numbers to be the set of all such expressions,$b$is not 0. And it is possible to define the set of with the rules

$ab + dc = adbd + bc$

and

$\text{ab dc} = bdac$.

However, there is one very important further remarkwe must make, which is that we do not regard all such expressions as different: for example, posed to be the same rational number. So we define two12 and 36 are sup expressions we regard equivalent expressions as denoting the sameab an(dc)d to be equivalent if ad = bc and number. Notice that the expressions can be genuinely different, but we think of them as denoting the same object. If we do this, then we must be careful whenever we define functions and binary operations.
For example, suppose we tried to define a binary operation “◦” on Q by the natural-looking formula$a c a + c$ This definition turns out to have a very serious flaw. Tosee why, let us apply it to the fractions$b \circ d = b + d$.1 and1. Then it gives us the answer equivalent fraction 3 and apply the formula again. This25. Now let us replace2 123 by the time it gives us the answer although the formula defines a perfectly good binary6 49, which is different. Thus, operation on the set ofdoes not make any sense as a binary operation on the expressions of the form$ab$, it set of rational numbers.

equivalent objects in then you get equivalent objects out. For example, when defining addition and multipli-In general, it is essential to check that if you put cation for the fieldthat if P and Pdiffer by a multiple of Q[x]/(x3 - x - 1), one must checkx3 - x - 1, and Qso doand PQ+^  Qalso differ by a multiple ofand P^  + Q^ , and so do P Qx3 and- x P-^ Q1, then^ . This is an easy exercise. that of asubgroup of An important example of a quotient construction isquotient group G, then it is natural to try to do what we did.
If G is a group and H is a for polynomials and define$g^{-1g}$(the obvious notion of the “difference” betweeng1 and g2 to be equivalent ifgelemen(t1)1 and2 gg2) belongs tois easily seen to be the set of all elements H. The equivalence class of angh such that h \in  H, which is usually written g H. (It is called a There is a natural candidate for a binary operation left coset of$H$.)*on the set of all left cosets:$g^{1}H^{*} g^{2}H = g^{1}g^{2}H$.
In other words, given two left cosets, pick elementsandg2 from each, form the product g1 g2, and take theg1 left cosetthat if you pick different elements from the originalg1 g2 H . Once again, it is important to check cosets, then you will still get the cosetout that this is not always the case: one needs the addi-$g^{1}g^{2}H$. It turns tional assumption thatmeans that ifh is any element of H is a normal subgroup H, then ghg, which-1 is an element ofof the formghg H-for every element1 are called conjugatesg of of G. Elementsh;
thus, a normal subgroup is a subgroup that is “closed under conjugation.” forms a group under the binary operation just defined. If H is a normal subgroup, then the set of left cosets This group is writtenof G by H. One can regard G/H and is called the quotient G as a product of H and G/Huct), so if you understand both(though it may be a somewhat complicated prod-H and G/H, then for many purposes you understand G.
Therefore, groups Gitself and the subgroup that consists of just the iden-that do not have normal subgroups (other than G tity element) have a special role, a bit like the role ofprime numbers in number theory. They are called simple groups. (See the classification of finite simple groups Why is the word “quotient” used? Well, a quotient is[V.7](/part-05/the-classication-of-finite-simple-groups).) normally what you get when you divide one numberby another, so to understand the analogy let us think about dividing 21 by 3.
We can think of this as dividing up twenty-one objects into sets of three objects each and asking how many sets we get. This can be

I. Introduction

described in terms of equivalence as follows. Let us calltwo objects equivalent if they belong to the same one of the seven sets. Then there can be at most seven inequiv-alent objects. So when we regard equivalent objects as the same, we “divide out by the equivalence,” obtaininga “quotient set” that has seven elements. definition of the mathematical shape known as athat is, the shape of the surface of a doughnut (of the A rather different use of quotients leads to an elegant torus: kind that has a hole).
We start with the plane, define two points(x, y) and (x^ , y^ ) to be equivalent R2, and ifx - x^  and y -y^  are both integers. Suppose that we regard any two equivalent points as the same and that we start at a pointthe point(x + 1, y)(x, y). This point is “the same” asand move right until we reach(x, y), since the difference isthe entire plane has been wrapped around a vertical(1, 0). Therefore, it is as though cylinder of circumference 1 and we have gone around this cylinder once.
If we now apply the same argumentto they - coordinate, noting that (x, y)is always “the same” point as(x, y + 1), then we find that this cylinder is itself “folded around” so that if you go “upwards” bya distance of 1 then you get back to where you started. But that is what a torus is: a cylinder that is folded backinto itself. (This is not the only way of defining a torus, however. For example, it can be defined as the productof two circles.) Many other important objects in modern geometry are defined using quotients.
It often happens that theobject one starts with is extremely big, but that at the same time the equivalence relation is very generous, inthe sense that it is easy for one object to be equivalent to another. In that case the number of “genuinely distinct” objects can be quite small. This is a rather looseway of talking, since it is not really the number of distinct objects that is interesting so much as the complex-ity of the set of these objects.
It might be better to say that one often starts with a hopelessly large and complicated structure but “divides out most of the mess”and ends up with a quotient object that has a structure that is simple enough to be manageable while still con-veying important information. Good examples of this are the fundamental group [IV.6 §2](/part - 04/algebraic - topology) and the homology and cohomology group sical space;
an even better example is the notion of a[IV.6 §4](/part - 04/algebraic - topology) of a to pol og moduli space Many people find the idea of a quotient somewhat[IV.8](/part - 04/moduli - spaces). difficult to grasp, but it is of major importance through out mathematics, which is why it has been discussed atsome length here. I.3. Some Fundamental Mathematical Definitions 4 Functions between Algebraic Structures One rule with almost no exceptions is that mathematical structures are not studied in isolation:
as well asthe structures themselves one looks at certain functions defined on those structures. In this section we shall seewhich functions are worth considering, and why. (For a discussion of functions in general, see the language and grammar of mathematics [I.2 §2.2](/part - 01/language - and - grammar).)

4.1 Homomorphisms, Isomorphisms, and

Automorphisms

If X and Y are two examples of a particular mathemat- ical structure, such as a group, field, or vector space, then, as was suggested in the discussion of symmetry in section 2.1, there is a class of functions fromto Y of particular interest, namely the functions that X “preserve the structure.” Roughly speaking, a functionf:
X \to  Y is said to preserve the structure of X if, given any relationship between elements ofexpressed in terms of that structure, there is a corre-X that is sponding relationship between the images of those elements that is expressed in terms of the structure of For example, if X and Y are groups and a, b, and c are Y. elements of X such that ab = c, then, if f is to preserve the algebraic structure ofin Y.
(Here, as is usual, we are using the same notation X , f (a)f (b) must equal f (c) for the binary operations that makeas is normally used for multiplication.) Similarly, if X and Y groups X andwrite using the standard notation for addition and mul-Yare fields, with binary operations that we shall tiplication, then a functioning only if$f (a) + f (b) = ff (c)$: X whenever\to  Y will be interest-a + b = c$and$ f (a)f (b) = f (c) whenever ab = c. For vector spaces, the functions of interest are ones that preserve linear combinations:
if V and W are vector spaces, thenf (av + bw) should always equal af (v) + bf (w). A function that preserves structure is called a homomorphism mathematical structures often have their own names:, though homomorphisms of particular for example, a homomorphism of vector spaces iscalled a linear map. There are some useful properties that a homomorphism may have if we are lucky. To see why further properties can be desirable, consider the following example. Let X and Y be groups and let f:$X \to Y \text{be the}$ function that takes every element ofelemente of Y.
Then, according to the definition above, X to the identityf preserves the structure of X, since whenever ab = c, we have$f (a)f (b) = ee = e = f (c)$. However, it seems

more accurate to say thatture. One can make this idea more precise: althoughf has collapsed the struc-f (a)f (b) = f (c) whenever ab = c, the converse does not holdf (c) without: it is perfectly possible forab equaling c, and indeed that happensf (a)f (b) to equal in the example just given. An isomorphism between two structures X and Y is a homomorphismg: Y \to  X that is also a homomorphism. For mostf: X \to  Y that has an inverse algebraic structures, if automatically a homomorphism;
in such cases we canf has an inverse g, then g is simply say that an isomorphism is a homomorphism that is also aone correspondence between bijection [I.2 §2.2](/part-01/language-and-grammar). That is, X and Y that preservesf is a one-to- structure.1 less interesting: it is a simple exercise to show thatevery homomorphism If X and Yare fields, then these considerations are f: X \to  Y that is not identically zero is automatically an isomorphism between its imagef (X), that is, the set of all values taken by X and the function out being lost. (The proof depends on the fact that thef .
So structure cannot be collapsed with- zero in In general, if there is an isomorphism between two Y has no multiplicative inverse.) algebraic structures to be isomorphic (coming from the Greek words for X and Y , then X and Y are said “same” and “shape”). Loosely, the word “isomorphic”means “the same in all essential respects,” where what counts as essential is precisely the algebraic structure. What is absolutely not essential is the nature of the objects that have the structure:
for example, one group might consist of certain complex numbers, another of integers modulo a primea geometrical figure, and they could all turn out to bep, and a third of rotations of isomorphic. The idea that two mathematical construc-tions can have very different constituent parts and yet in a deeper sense be “the same” is one of the most important in mathematics. isomorphism fromprising that An automorphism X is isomorphic to itself, one might ask Xof an algebraic structureto itself. Since it is hardly sur-X is an what the point is of automorphisms.
The answer is that automorphisms are precisely the algebraic symmetries groups, u,1. Let us see how this claim is proved for groups. Ifv, andfw: Xare elements of\to  Y is a homomorphism with inverse Y with uv = w, then we must show thatg: XY and\to  XY, andareg(u)g(v)Since f and=gg(w)are inverse functions,. To do this, let a =f (a)g(u)=, bu,=f (b)g(v)=, andv, andd =f (d)g(w)=.whom om or phism. But then. Now let c = ab. Then f (c)w ==uvf (d)= f (a)f (b)$, \text{which implies that} = f (c)$, sincec = df(justis a apply the functionus that$g(u)g(v) =gg(w)to f (c)$, as we needed to show.and f (d)).
Therefore ab = d, which tells

alluded to in our discussion of groups. An automor-phism of X is a function from X to itself that preserves the structure (which now comes in the form of state-ments like ab = c). The composition of two automor- phisms is clearly a third, and as a result the automor-phisms of a structure X form a group.
Although the individual automorphisms may not be of much inter - est, the group certainly is, as it often encapsulates what one really wants to know about a structure complicated to analyze directly. X that is too To illustrate, let us take the example of Q(A spectacular example of this is when. qrt{2}) \to Q(. qrt{2}) is an automorphism$, \text{then QX}(\sqrt{f} ($ is a field.2)1. If) =f1.: (This follows easily from the fact that 1 is the only mul-tiplicative identity.) It follows thatf (2) = f (1 + 1) =f (can show that1) + f (1) =f (n)1 + =1 n= for every positive integer2.
Continuing like this, wen. Thenf (-n)f (n)= −f (n)+ f (-= −n)n=. Finally, f (n + (f (p/q)-n)) ==f (f (p)/f (q)0) = 0, so = p/q when p and q are integers with q = 0. So f takes every rational number to itself. What can we say about$f (\sqrt{2})? Well,$ f (. qrt{2})f (. qrt{2}) = f (. qrt{2} · . qrt{2}) = f (2) = 2, but this implies only thatf (. qrt{2}) is . qrt{2} or -. qrt{2}. It turns out that both choices are possible:
one automorphism is the “trivial” one,$f (a + b \sqrt{2}) = a + b \sqrt{2}$, and the other is the more interesting one, This observation demonstrates that there is no alge-$f (a + b \sqrt{2}) = a - b \sqrt{2}$. braic difference between the two square roots; in thissense, the field Q(. qrt{2}) does not know which square root of 2 is positive and which negative.
These two automor-phisms form a group, which is isomorphic to the group consisting of the elements±1 under multiplication, or the group of integers modulo 2, or the group of symmetries of an isosceles triangle that is not equilateral, or. . . . The list is endless. field extensions are called component of the proof of The automorphism groups associated with certain Galois groupsthe insolubility of the, and are a vital quintic number theory[V.21](/part - 05/the - insolubility - of - the - quintic), as well as large parts of[IV.1](/part - 04/number - theory).
algebraic phismnel An important concept associated with a homomor-. This is defined to be the set of all elementsφ between algebraic structures is that of ax ofker - X such thatmeans the additive identity ifφ(x) is the identity element of X and Y are structures Y (where this that involve both additive and multiplicative binary operations). The kernel of a homomorphism tends to be a substructure of X with interesting properties. For instance, if homomorphism from G and K are groups, then the kernel of a G to K is a normal subgroup of I. Introduction Gthe;
and conversely, ifquotient map, which takes each element H is a normal subgroup ofg Gto the, then left cosettient groupg HG/H, is a homomorphism fromwith kernel H. Similarly, the kernel of G to the quo- any ring homomorphism is an ideal [III.81](/part - 03/rings - ideals - and - modules), and every idealfrom RI in a ringto R/I. (This quotient construction is discussed Ris the kernel of a “quotient map” in more detail in rings, ideals, and modules [III.81](/part - 03/rings - ideals - and - modules).)

4.2 Linear Maps and Matrices

Homomorphisms between vector spaces have a dis-tinctive geometrical property: they send straight lines to straight lines. For this reason they are calledear maps, as was mentioned in the previous subsec-lintion. From a more algebraic point of view, the structure that linear maps preserve is that of linear combi-nations: a functionf from one vector space to another is a linear map iff (au + bv) = af (u) + bf (v) for every pair of vectorsu, v \in  V and every pair of scalars a assertion thatand b.
From this one can deduce the more generalf (a v + · · · + a v ) is always equal toa1 f (v1) + · · · + (a1)nf (1 vn). n n to Suppose that we wish to define a linear map from$W$. How much information do we need to provide? In$V$ order to see what sort of answer is required, let us beginwith a similar but slightly easier question: how much information is needed to specify a point in space? The answer is that, once one has devised a sensible coordi-nate system, three numbers will suffice.
If the point is not too far from Earth’s surface then one might wishto use its latitude, its longitude, and its height above sea level, for instance. Can a linear map from V to W similarly be specified by just a few numbers? dimensional. Suppose that W The answer is that it can, at least ifhas a basis w , . . . , w , and that V has a basisf V:$Vandv \to^{1}$, . . . , WW is the lin-are finitevn, that ear map we would like to specify. Since every vector in V can be written in the for(m1)m a v +· · ·+a v and sincef (aanf (1 v(v1)n+· · ·+), once we decide whatanvn) is always equal to1 f (1 v1), .
. . , f ((a1)nf (nv(vn)1))+· · ·+are we have specifiedf completely. But each vector f (v ) isj

a linear combination of the basis vectors that is, it can be written in the form w1, . . . , wm: f (vj) = (a1)jw1 + · · · + amj wm. Thus, to specify an individual the scalarsa , . . . , a . Since there aref (vj) ne edsn different vec-m numbers, torsbersv(aj)ij, the linear map is determined by the, wher(e1)j i runs from 1 tomj m and j from 1 tomn num-n.

I.3. Some Fundamental Mathematical Definitions

These numbers can be written in an array, as follows:⎛ ⎞||| aa1121 aa1222 · · ·· · · a(a1()2()n)n |||||(... ... . .. ... ⎟⎟⎠ .(am)1 (am)2 · · · amn

An array like this is called anote that a different choice of basis vectors formatrix. It is important to V and Wof the matrix ofwould lead to a different matrix, so one often talksf relative to a given pair of bases (a basis for Now suppose that V and a basis forf is a linear map from W). V to W and thatthe linear map fromg is a linear map from U to WUobtained by doing firstto V . Then f g stands forg, thenbases off . If the matrices of U , V , and W , aref Aandandg B, relative to certain, then what is the matrix off g?
To work it out, one takes a basis vector$u$ of combination U and applies to it the functionb v +· · ·+b v of the basis vectors ofg, obtaining a lineark Vf . To this linear combination one applies the function, obtaining a rather complicated linear combinatio(n1()k()1)nkn of linear combinations of the basis vectorsof$W$. w1, . . . , wm rowa Pursuing this idea, one can calculate that the entry inbi and column+· · ·+a b j . This matrixof the matrix P Pis called theof f g is aproduc(ti)1(b1)j + of definition then you will find it hard to grasp, but thei2 A2 andj B and is writteninnj AB.
If you have not seen this main point to remember is that there is a way of calcu-lating the matrix forf g from the matrices A and B of f an dt i pl ic at i on of this kind is associative but not commuta-g, and that this matrix is denoted AB. Matrix mul- tive. That is, not necessarily the same as A(BC) is always equal to BA. The associativity fol-(AB)C but AB is lows from the fact that composition of the underlying linear maps is associative:
if A, B, and C are the matrices$of$ f , g, and h, respectively, then A(BC) is the matrix of the linear map “dothe matrix of the linear map “doh-then-g, thenh, thenf” andg-then-(AB)Cf,” andis these are the same linear map. Let us now confine our attention to automorphisms from a vector space$f$:$V$ \to Vthat can be inverted; that is, for which there V to itself. These are linear maps exists a linear mapgf (v) = v for every vectorg: V v\to in VV . These we can thinksuch that f g(v) = of as “symmetries” of the vector spacethey form a group under composition.
If VV, and as suchis n dimen- sional and the scalars come from the field group is called GL(F). The letters “G” and “L” stand for F, then this “general” and “linear”; some of the most important and$n$

difficult problems in mathematics arise when one triesto understand the structure of the general linear groups (and related groups) for certain interesting fields F (see representation theory While matrices are very useful, many interesting [[IV.9 §§5,6]](/part-04/representation-theory)). linear maps are between infinite-dimensional vector spaces, and we close this section with two examples for the reader who is familiar with elementary calcu-lus.
(There will be a brief discussion of calculus later in this article.) For the first, lettions from R to R that can be differentiated and let V be the set of all func-W be the set of all functions from R to R. These can be made into vector spaces in a simple way: ifare functions, then their sum is the function hf defined an dg by the formulah(x) = f (x) + g(x), and if a is a real number thenmulak(x) = af (x)af is the function.
(So, for example, we could regard kd ef in ed by the forthe polynomial the functionsx2 x,2 x+, and the constant function 1.) Then3 x + 2 as a linear combination of differentiation is a linear map (from derivative(af + bg)^  is af^  + bg^ . This is clearer if we V to W ), since the write DD(af +fbg)for the derivative of= a Df + b Dg. f: then we are saying that vector space of functions, and let variables. (The functions involved have to have certain A second example uses integration.
Letu be a function of V be another two properties for the definition to work, but let us ignore the technicalities.) Then we can define a linear mapon the space V by the formula T(T f )(x) = u(x, y)f (y) dy.

Definitions like this one can be hard to take in, because they involve holding in one’s mind three different levels of complexity. At the bottom we have real numbers, denoted byx and y. In the middle are functions like f , uinto real numbers. At the top is another function,, and T f , which turn real numbers (or pairs of them)T , but the “objects” that it transforms are themselves func-tions: it turns a function likefinto a different functionto think of a function as a single, elementary “thing”T f. This is just one example where it is important rather than as a process of transformation.
(See the dis-cussion of functions in the language and grammar of mathematics help to clarify the definition is that there is a very close[I.2 §2.2](/part-01/language-and-grammar).) Another remark that may analogy between the role of the two-variable functionu(x, y) and the role of a matrix a (which can itself be thought of as a function of the two integer vari-$ij$ ab les kernels i and(which should not be confused with kernels ofj). Functions like u are sometimes called

homomorphisms). For more about linear maps between infinite-dimensional spaces, see operator algebras [IV.15](/part-04/operator-algebras) and linear operators [III.50](/part-03/linear-operators-and-their-properties).

4.3 Eigenvalues and Eigenvectors

Let V be a vector space and let S: V \to V be a lin-ear map from nonzero vector Vv into itself. An V such that eigenvector Sv is proportional toof S is av; that is, Sv = . ambda v for some scalar λ. The scalar in question is called the This simple pair of definitions is extraordinarily impor-eigenvalue corresponding tov. tant: it is hard to think of any branch of mathemat-ics where eigenvectors and eigenvalues do not have a major part to play. But what is so interesting about being proportional to v?
A rather vague answer is that$Sv$ in many cases the eigenvectors and eigenvalues associ-ated with a linear map contain all the information one needs about the map, and in a very convenient form. Another answer is that linear maps occur in many dif-ferent contexts, and questions that arise in those contexts often turn out to be questions about eigenvec-tors and eigenvalues, as the following two examples illustrate. First, imagine that you are given a linear map$T$ from a vector spacewhat happens if you perform the map repeatedly.
One V to itself and want to understand approach would be to pick a basis of corresponding matrix A of T, and calculate the pow-V , work out the ers ofthe calculation will be messy and uninformative, and it A by matrix multiplication. The trouble is that does not really give much insight into the linear map. special basis, consisting only of eigenvectors, and inthat case understanding the powers of However, it often happens that one can pick a very T becomes easy. Indeed, suppose that the basis vectors areand that eachvi is an eigenvector with correspondingv1$, v2$, . . .
, vn eigenvalue everyi. If w. ambda i. That is, suppose thatis any vector in V , then there is exactly T (vi) = . ambda ivi for one way of writing it in the formand then$a1v1 + · · · + anvn$, T (w) = λ1 a1 v1 + · · · + . ambda nanvn. Roughly speaking, this says thatw in direction v by a factor of T. ambda stretches the part of. But now it is easy to say what happens if we applyi Tinot just once but m times tow. The result will be Tm(w) = . ambda m 1 a1 v1 + · · · + . ambda m n anvn.
In other words, now the amount by which we stretch inthe$v \text{direction is} λ^{m}$, and that is all there is to it.ii

I. Introduction

over and over again? There are many reasons: one fairly Why should one be interested in doing linear maps convincing one is that this sort of calculation is exactly what Google does in order to put Web sites into a useful order. Details can be found in the mathematics of algorithm design [VII.5](/part-07/the-mathematics-of-algorithm-design). erty of the The second example concerns the interesting prop-exponential function [III.25](/part - 03/the - exponential - and - logarithmic - functions) ex: that its derivative is the same function. In other words, if$f (x) = ex$, then f^ (x) = f (x).
Now differentiation, as we saw earlier, can be thought of as a linear map, and iff^ (x) = f (x) then this map leaves the func- tiontor with eigenvalue 1. More generally, iff unchanged, which says that f is an eigenvec-g(x) = e. ambda x, then g^ (x) = . ambda e. ambda x = . ambda g(x), so g is an eigenvector of the differentiation map, with eigenvalueλ. Many linear differential equations can be thought of as asking for eigenvectors of linear maps defined using differentiation.
(Differentiation and differential equations will be discussed in the next section.) 5 Basic Concepts of Mathematical Analysis Mathematics took a huge leap forward in sophistication with the invention of calculus, and the notion that one can specify a mathematical object indirectly by meansof better and better approximations. These ideas form the basis of a broad area of mathematics known as analysis reader who is unfamiliar with them.
However, it will not, and the purpose of this section is to help the be possible to do full justice to the subject, and what is written here will be hard to understand without at leastsome prior knowledge of calculus.

5.1 Limits

In our discussion of real numbers (section 1.4) there was a brief discussion of the square root of 2. Howdo we know that 2 has a square root? One answer is the one given there: that we can calculate its decimal expansion. If we are asked to be more precise, we may well end up saying something like this. The real numbers 1, 1.4, 1.41, 1.414, 1.4142, 1.41421,. . . , which have terminating decimal expansions (and are therefore rational), approach another real number$x =$ 1.4142135. . . .
We cannot actually write down x prop- erly because it has an infinite decimal expansion but wecan at least explain how its digits are defined: for example, the third digit after the decimal point is a 4 because1.414 is the largest multiple of 0.001 that squares to

I.3. Some Fundamental Mathematical Definitions

less than 2. It follows that the squares of the origi-nal numbers, 1, 1.96, 1.9881, 1.999396, 1.99996164, 1 entitled to say that.9\,999\,899\,241, . . . , approach 2, and this is why we arex2 = 2. of a curve drawn on a piece of paper, and that we Suppose that we are asked to determine the length are given a ruler to help us. We face a problem: theruler is straight and the curve is not. One way of tackling the problem is as follows. First, draw a few points P, P , P , . . . , P along the curve, with P at one end and Pto P0 n at the other.
Next, measure the distance from (P1)1, the distance from (P2()n)1 to P2, and so on up to (P0()n)0. Finally, add all these distances up. The result will not be an exactly correct answer, but if there are enough points, spaced reasonably evenly, and if the curve does not wiggle too much, then our procedure will give us agood notion of the “approximate length” of the curve. Moreover, it gives us a way tothe “exact length”:
suppose that, as we take more anddefine what we mean by more points, we find that the approximate lengths, in the sense just defined, approach some numberwe say thatl is the length of the curve. l. Then reach by means of better and better approximations. In both these examples there is a number that we I used the word “approach” in both cases, but this israther vague, and it is important to make it precise. Let ait mean to say that these numbers approach a specified1, a2, a3, . . . be a sequence of real numbers. What does real number l? mind.
The first is the sequence the numbers in this sequence approach 2, since each The following two examples are worth bearing in12,2 3 ,3 4,4 5, . . . . In a sense, one is closer to 2 than the one before, but it is clear that this is not what we mean. What matters is not somuch that we get closer and closer, but that we get arbitrarily closethis stronger sense is the obvious “limit,” 1., and the only number that is approached in 1, A second sequence illustrates this in a different way:0,1 2 ,0,1 3, 0,1 4, 0, . . . .
Here, we would like to say that the numbers approach 0, even though it is not true thateach one is closer than the one before. Nevertheless, it is true that eventually the sequence gets as close as youlike to 0 and remains at least that close. matical notion of a This last phrase serves as a definition of the mathe - limit : the limit of the sequence of numbers gets as close as you like to$a1$, a2$, a3$, . . . is l if eventually the sequencel and remains that close.
However, in order to meet the standards of precision demanded by mathematics, we need to know how to translate English words like “eventually” into mathe - matics, and for this we need quantifiers [I.2 §3.2](/part - 01/language - and - grammar). Supposeδ is a positive number (which one usually imagines as small). Let us say that|a -l|, the difference betweena andan isl, is less thanδ-close to lδif. What would it mean to say that eventually the sequence getsn δ-close to land stays there?
It means that from$n$ some point onwards, all thewhat is the meaning of “from some point onwards”?an are δ-close to l. And It is that there is some number tion) with the property thata is Nδ(the point in ques--close to l from N onwards—that is, for everynnthat is greater than or equal to$N$. In symbols:

$∃N ∀n ⩾ N a^{n} is δ-\text{close to} l$.

It remains to capture the idea of “as close as you like.” What this means is that the above sentence is true foranyδyou might wish to specify. In symbols:

$∀δ > 0 ∃N ∀n ⩾ N a^{n} is δ-\text{close to} l$.

Finally, let us stop using the nonstandard phrase “close”:$δ-∀δ > 0 ∃N ∀n ⩾ N |a^{n} - l| < δ$.

This sentence is not particularly easy to understand. Unfortunately (and interestingly in the light of the discussion in [I.2 §4](/part-01/language-and-grammar)), using a less symbolic language doesnot necessarily make things much easier: “Whatever positive that for all bigger numbersδ you choose, there is some numbernthe difference between N suchan and l is less than δ.” just to real numbers.
If you have any collection of math-ematical objects and can say what you mean by the dis-The notion of limit applies much more generally than tance between any two of those objects, then you cantalk of a sequence of those objects having a limit. Two objects are now called them is less thanδ, rather than the difference. (Theδ-close if the distance between idea of distance is discussed further in[III.56](/part-03/metric-spaces).) For example, a sequence of points in space canmetric spaces have a limit, as can a sequence of functions.
(In thesecond case it is less obvious how to define distance— there are many natural ways to do it.) A further example comes in the theory of fractals (see dynamics [IV.14](/part - 04/dynamics)): the very complicated shapes that appear there are best defined as limits of simpler ones. a1 Two other ways of saying “the limit of the sequence$, a^{2}$, . . . is l” are “an converges to l” and “an tends to l.” One sometimes says that this happens asn tends

to infinity ver ge nt. If. Any sequence that has a limit is calleda converges to l then one often writescon-nan \to  l.

5.2 Continuity

Suppose you want to know the approximate value ofπ2. Perhaps the easiest thing to do is to press a π button on a calculator, which displays 3 then anx2 button, after which it displays 9.1415927, and.8696044. Of course, one knows that the calculator has not actu-ally squaredπ: instead it has squared the number 3 used a few more digits of.1415927. (If it is a good one, then it may have secretlyπ without displaying them, but not infinitely many.) Why does it not matter thatthe calculator has squared the wrong number? of explanation:
how do we know that if A first answer is that it was only anπ2 that was required. But that is not quite a comp let ex approximate is a good approx-value imation toπ then x2 is a good approximation to π2? Here is how one might show this. Ifimation toπ, then we can write xx=is a good approx-π + δ for some very small numberx2 = π2 + 2δπ + δ2δ. Since(which could be negative). Thenδ is small$, \text{so is} 2δπ + δ^{2}$,$so$ x^2 is indeed a good approximation to π^2. function that takes a numberous What makes the above reasoning work is that the.
Roughly speaking, this means that if two numbersx to its square is continu- are close, then so are their squares. To be more precise about this, let us return to the calculation of$π^{2}$, and imagine that we wish to work it out to a much greater accuracy—so that the first hundred digits after the decimal point are correct, for example.
A calculator will not be much help, but what we mightdo is find a list of the digits ofπ (on the Internet you can find sites that tell you at least the first fifty million), use this to define a new imation toπ, and then calculate the newx that is a much better approx-x2 by getting a computer to do the necessary long multiplication. How close toπ do we need x to be for x2 to be within10-100 of π2? To answer this, we can use our earlier argument. Let$x = π+δ again$. Then x2-π2 = 2δπ+δ2, and an easy calculation shows that this has modulus less than 10 - 100 if δ has modulus less than 10-101.
So we will be all right if we take the first 101 digits ofafter the decimal point.π mate ofprepared to make More generally,π2 to be, we can achieve this accuracy if we are however xa sufficiently good approximation accurate we wish our estitoπ. In mathematical parlance, the function f (x) = x2 is continuous atπ. I. Introduction ment “|x Let us try to say this more symbolically. The state - 2 - π(x2)2|=< π2. To capture the phrase “however accu-to within an accuracy of ” means that rate,” we need this to be true for every positive should start by saying∀ > 0.
Now let us think about, so we the words “if we are prepared to makegood approximation toπ.” The thought behind themxa sufficiently is that there is someδ > 0 for which the approxima- tion is guaranteed to be accurate to withinasx is within δ of π. That is, there exists aas longδ > 0 such that if|x2 - π2| < |. Putting everything together, we end upx - π| < δ then it is guaranteed that with the following symbolic sentence:$∀ > 0 ∃δ > 0 (|x - π| < δ ⇒ |x2 - π2| < )$. To put that in words:
“Given any positive number there is a positive numberδ such that if |x - π| is less thanaδ that worked whenδ then |x2 - π2| is less thanwas chosen to be 10.” Earlier, we found-100: it was 10 - 101.x2 What we have just shown is that the functionis continuous at the point x = π. Now let us gener - f (x) = alize this idea: letreal number. We say thatf be any function and letf is continuous at aaifbe any∀ > 0 ∃δ > 0 (|x - a| < δ ⇒ |f (x) - f (a)| < ).
This says that however accurate an estimate foryou wishf (x) to be, you can achieve this accuracy iff (a) you are prepared to makexa sufficiently good approximation toit is continuous at everya. The functiona. Roughly speaking, what thisf is said to be continuous if means is thatout certain kinds of very rapid oscillations that would$f$has no “sudden jumps.” (It also rules also make accurate estimates difficult.)As with limits, the idea of continuity applies in much more general contexts, and for the same reason.
Letf be a function from a set X to a set Y , and sup- pose that we have two notions of distance, one for ele-ments of X and the other for elements of Y. Using the expressiond(x, a) to denote the distance between x andis continuous ata, and similarly fora if d(f (x), f (a)), one says that f∀ > 0 ∃δ > 0 (d(x, a) < δ ⇒ d(f (x), f (a)) < ) and that X.
In other words, we replace differences such asf is continuous if it is continuous at every|xa-ain| by distances such as Like homomorphisms (which are discussed in sec-d(x, a).$tion 4$.1 above), continuous functions can be regardedas preserving a certain sort of structure. It can be shown that a functionf is continuous if and only if, whenever I.3. Some Fundamental Mathematical Definitions aous functions are functions that preserve the structuren \to  x, we also have f (an) \to  f (x). That is, continu- provided by convergent sequences and their limits.

5.3 Differentiation

The derivative of a functions ented as a number that measures the rate of change off at a value a is usually pre-f (x) as x passes through a. The purpose of this sec- tion is to promote a slightly different way of regardingit, one that is more general and that opens the door to much of modern mathematics. This is the idea of differentiation as linear approximation.
Intuitively speaking, to say thatf^ (a) = m is to say that if one looks through a very powerful microscope at the graph off in a tiny region that includes the pointa straight line of gradient(a, f (a)), then what one sees is almost exactlym. In other words, in a sufficiently small neighborhood of the pointf is approximately linear. We can even write down aa, the function formula for the linear functiong that approximates f:

$g(x) = f (a) + m(x - a)$.

This is the equation of the straight line of gradient that passes through the point(a, f (a)). Another waym of writing it, which is a little clearer, is

$g(a + h) = f (a) + mh$,

and to say thathood ofa is to say thatg approximate sf (a+h) isf approximately in a small neighbor-equal$to$ f (a) + mh when h is small. not jump suddenly, then, whenwill be close to One must be a little careful here: after all, iff (a) and mh will be small, soh is small, f (aff (a+doesh)+h) is approximately equal to f (a) + mh. This line of reasoning seems to work regard less of the value ofm, and yet we wanted there to be something special aboutthe choice$m = f (a)$.
What singles out that particular value is thatso close that the differencef (a+h) is not just close to(h) = f (a+f (a)h)-f (a)+mh-, butmh is small compared withh. That is, (h)/h \to  0 as h \to

0. (This is a slightly more general notion of limit thanthe one discussed in section 5.1. It means that you can make enough.)(h)/h as small as you like if you make h small notion of a linear map is much more general than sim-ply a function from The reason these ideas can be generalized is that the R to R of the form$g(x) = mx + c$. Many functions that arise naturally in mathematics— and also in science, engineering, economics, and manyother areas—are functions of several variables, and can

therefore be regarded as functions defined on a vec-tor space of dimension greater than 1. As soon as we look at them this way, we can ask ourselves whether, in a small neighborhood of a point, they can be approxi-mated by linear maps. It is very useful if they can: a general function can behave in very complicated ways, butif it can be approximated by a linear function, then at least in small regions ofior is much easier to understand.
In this situation onen-dimensional space its behav- can use the machinery of linear algebra and matrices, which leads to calculations that are feasible, especially if one has the help of a computer. Imagine, for instance, a meteorologist interested in how the direction and speed of the wind change asone looks at different parts of some three-dimensional region above Earth’s surface. Wind behaves in compli-cated, chaotic ways, but to get some sort of handle on this behavior one can describe it as follows.
To eachpoint(x, y, z) in the region (think of x and y as hori- zontal coordinates andciate a vector(u, v, w) zre presenting the velocity of theas a vertical one) one can asso- wind at that point: the velocity in thexu-,, yv, and-, andwz-directions.are the components of choosing three small numbersat Now let us change the point$(x + h$, y + k, z + l). At this new point, we would(x, y, z)h, k, andvery slightly byl and looking expect the wind vector to be slightly different as well, so let us write it$(u + p$, v + q, w + r ).
How does the small change small change(p, q, r )(h, k, l) in the wind vector depend on thein the position vector? Provided the wind is not too turbulent andh, k, and l are small enough, we expect the dependence to be roughly linear: that is how nature seems to work. In other words, we expect there to be some linear mapis roughly T (h, k, l) when h, k, and Tlsuch thatare small. Notice(p, q, r ) that each ofso nine numbers will be needed in order to specify thisp, q, and r depends on each of h, k, and l, linear map.
In fact, we can express it in matrix form:⎛ ⎞ ⎛ ⎞ ⎛ ⎞⎜⎜⎝pq⎟⎟⎠ = ⎜⎜⎝aa1121 aa1222 aa1323⎟⎟⎠ ⎜⎜⎝hk⎟⎟⎠ .r a31 a32 a33 l

The matrix entries cies. For example, if a xij and express individual dependen - zare held fixed, then we are settingh = l = 0, from which it follows that the rate of change ofu as just y varies is given by the entryapoint12. That is,(x, y, z)a12. is the partial derivative ∂u/∂y at the the conceptual point of view it is easier to use vector This tells us how to calculate the matrix, but from

notation. Write(h, k, l), and p forx for(p, q, r )(x, y, z). Then what we are saying is, u(x) for (u, v, w), h for that

p = T (h) + (h)

for some vector native ly, we can write(h) that is small relative to h. Alter-u(x + h) = u(x) + T (h) + (h),

a formula that is closely analogous to our earlier for-mulag(x + h) = g(x) + mh + (h). This tells us that if we add a small vectorh to x, then u(x) will change by roughly More generally, let T (h). u be a function from Rn to Rm. Thenuis defined to be differentiable at a pointx \in  Rn if there is a linear map T: R$n \to R^{m} \text{such that}$, once again, the formula

$u(x + h) = u(x) + T (h) + (h) holds$, with(h) small relative to h. The linear map T is the An important special case of this is when derivative ofu at x. m = 1. Iffof: f Ratn \to x is a linear map from Ris differentiable at Rxn, then the derivative to R. The matrix of T. abla f (x)is a row vector of lengthand referred to as then, which is often denoted gradient of f at x. This vector points in the direction in whichf increases most rapidly and its magnitude is the rate of change in that direction.

5.4 Partial Differential Equations

Partial differential equations are of immense impor-tance in physics, and have inspired a vast amount of mathematical research. Three basic examples will bediscussed here, as an introduction to more advanced articles later in the volume (see, in particular, differential equations [IV.12](/part-04/analysis)). partial gests, describes the way the distribution of heat in aphysical medium changes with time: The first is the heat equation, which, as its name sug. artial T. artial t = κ . artial \1 artialx2 T2 + . artial \1 artialy2 T2 + . artial \1 artialz2 T2.
Here, perature at the point T (x, y, z, t)is a function that specifies the tem-(x, y, z) at time t. stand the symbols that make it up, but quite anotherto see what it really means. However, it is important to It is one thing to read an equation like this and underdo so, since of the many expressions one could write down that involve partial derivatives, only a minority are of much significance, and these tend to be the ones I. Introduction that have interesting interpretations. So let us try tointerpret the expressions involved in the heat equation.
rate of change of the temperature the spatial coordinates The left-hand side,. artial T /. artial tx, y, is quite simple. It is the, and zare kept fixed and T (x, y, z, t) whent varies. In other words, it tells us how fast the point(x, y, z)would we expect this to depend on? Well, heat takesis heating up or cooling down at timet.
What time to travel through a medium, so although the tem-perature at some distant point(x, y^ , z^ ) will even- tually affect the temperature at temperature is changing right now(x, y, z)(that is, at time, the way thet) will be affected only by the temperatures of points very close tohood of(x, y, z)(x, y, z):
if points in the immediate neighbor-are hotter, on average, than(x, y, z) itself, then we expect the temperature at increasing, and if they are colder then we expect it to(x, y, z) to be be decreasing. The expression in brackets on the right-hand side appears so often that it has its own shorthand. Thesymbol. elta, defined by . elta f = . artial \1 artialx2 f2 + . artial y. artial2 f2 + . artial \1 artialz2 f2, is known as the Laplacian. What information does. elta f give us about a function f? The answer is that it captures the idea in the last paragraph:
it tells us how thevalue off at (x, y, z) compares with the average value ofcisely, with the limit of the average value in a neigh-f in a small neighborhood of (x, y, z), or, more pre- borhood ofshrinks to zero.(x, y, z) as the size of that neighborhood This is not immediately obvious from the formula, but the following (not wholly rigorous) argument inone dimension gives a clue about why second derivatives should be involved. Letreal numbers to real numbers.
Then to obtain a goodf be a function that takes approximation to the second derivative ofx, one can look at the expression (f^ (x)-ff^ (xat a point-h))/h for some smallh. (If one substitutes -h for h in the above expression, one obtains the more usual formula, but this one is more convenient here.) The der iv at iv esf^ (x) and f^ (x - h) can themselves be approximated by(f (x+h)-f (x))/h and (f (x)-f (x-h))/h, respec- tively, and if we substitute these approximations into the earlier expression, then we obtain h1 f (x + h)h - f (x) - f (x) - f (xh - h), which equalsthe top of this last
fraction by 2, we obtain(f (x + h)-2 f (x)+f (x - h))/h1(f (x2. Dividing + h)+ I.3. Some Fundamental Mathematical Definitions f (x - h)) - f (x): that is, the difference between the value of surrounding pointsf at x and the average value ofx + h and x - h. f at the two the idea we want—a comparison between the value atx In other words, the second derivative conveys justand the average value near x. It is worth noting that iff is linear, then the average of f (x - h) and f (x + h) will be equal tof (x), which fits with the familiar fact that the second derivative of a linear functionf is zero.
to divide the difference it is not automatically tiny, so with the second deriva-Just as, when defining the first derivative, we havef (x + h) - f (x) by h so that tive it is appropriate to divide by$h^{2}$. (This is appropri- ate, since, whereas the first derivative concerns linear approximations, the second derivative concerns quadratic tionfones:
the best quadratic approximation for a func-near a value$x is f (x + h) \approx f (x) + hf (x) +$ 12$h2f (x)$, an approximation that one can check is exact iff was a quadratic function to start with.) show that ifvalue of It is possible to pursue thoughts of this kind andΔf fatis a function of three variables then the(x, y, z) does indeed tell us how the value off at (x, y, z) compares with the average values ofthe number 3 here—the ideas can easily be generalize df at points nearby.
(There is nothing special about to functions of any number of variables.) All that is leftto discuss in the heat equation is the parameterκ. This measures the conductivity of the medium. Ifκ is small, then the medium does not conduct heat very well andΔThas less of an effect on the rate of change of the temperature; if it is large then heat is conducted betterand the effect is greater. equation A second equation of great importance is the,Δf = 0.
Intuitively speaking, this says of a Laplace function equal to the average value at the immediately surround-f that its value at a point (x, y, z) is always ing points. Ifthis says that the second derivative off is a function of just one variablef is zero, whichx, implies thatf is of the form ax + b. However, for two or more variables, a function has more flexibility—itcan lie above the tangent lines in some directions and below it in others.
As a result, one can impose a varietyof boundary conditions on f(that is, specifications of the valuesand there is a much wider and more interesting classf takes on the boundaries of certain regions), of solutions. In its one-dimensional formulation it describes the A third fundamental equation is the wave equation. motion of a vibrating string that connects two points

A and B. Suppose that the height of the string at dis-tancex from A and at time t is written h(x, t). Then the wave equation says that

$v1^{2} \partial 1artialt^{2}h^{2} = \partial 1artialx^{2}h^{2}$.Ignoring the constant 1/v2 for a moment, the left-hand side of this equation represents the acceleration (in avertical direction) of the piece of string at distance$x$ from A. This should be proportional to the force actingon it. What will govern this force? Well, suppose for a moment that the portion of string containing absolutely straight. Then the pull of the string on thex were left ofand the net force would be zero.
So, once again, whatx would exactly cancel out the pull on the right matters is how the height atage height on either side: if the string lies above thex compares with the aver- tangent line atand if it lies below, then there will be a downwards one.x, then there will be an upwards force, This is why the second derivative appears on the right-hand side once again. How much force results from this second derivative depends on factors such as the den-sity and tautness of the string, which is where the constant comes in.
Sinceh and x are both distances$, v^{2}$ has dimensions of(distance/time)2, which means th a tv propagation of the wave.represents a speed, which is, in fact, the speed of wave equation, which is, as one might now expect, Similar considerations yield the three-dimensional  v12 . artial \1 artialt2 h2 = . artial \1 artialx2 h2 + . artial y. artial2 h2 + . artial \1 artialz2 h2,$or$, more concisely$, 1\partial2h= \Delta h$.v2 ∂t2

One can be more concise still and write this equationas 2 h = 0, where2 h is shorthand forΔh - v12 ∂∂t2 h2.

The operation 2 is called the d’Alembertian, after d’alembert wave equation.[VI.20](/part-06/jean-le-rond-dalembert-17171783), who was the first to formulate the

5.5 Integration

Suppose that a car drives down a long straight road forone minute, and that you are told where it starts and what its speed is during that minute. How can you workout how far it has gone? If it travels at the same speed for the whole minute then the problem is very simple indeed—for example, if that speed is thirty miles per

hour then we can divide by sixty and see that it hasgone half a mile—but the problem becomes more interesting if the speed varies. Then, instead of trying to give an exact answer, one can use the following technique to approximate it. First, write down the speed of the car at the beginning of each of the sixty seconds that it is trav-eling. Next, for each of those seconds, do a simple calculation to see how far the car would have gone during that second if the speed had remained exactly as it wasat the beginning of the second. Finally, add up all these distances.
Since one second is a short time, the speedwill not change very much during any one second, so this procedure gives quite an accurate answer. Moreover, if you are not satisfied with this accuracy, thenyou can improve it by using intervals that are shorter than a second. If you have done a first course in calculus, then you may well have solved such problems in a completely different way.
In a typical question, one is given anexplicit formula for the speed at time t—something like $at + u$, for example—and in order to work out how far the car has gone one “integrates” this function to obtainthe formula 1 at2 + ut for the distance traveled at time ten ti at i on: to find the integral of a function. Here, integration simply means the opposite of differ-2 fis to find a functiong such that g^ (t) = f (t). This makes sense, because ifspeed, theng(t)f (t)is the distance traveled andis indeed the rate of change off (t)g(t)is the. integration.
To see why not, consider the following question: what is the distance traveled if the speed at However, anti differentiation is not the definition of timet is (e-t)2? It is known that there is no nice function (which means, roughly speaking, a function built up out of standard ones such as polynomials, exponentials, logarithms, and trigonometric functions) with e$- {}^{t2} as$ its derivative, yet the question still makes good senseand has a definite answer.
(It is possible that you have heard of a functionΦ(t)that differentiates to e. qrt . qr(t-t()2()/){2}, from which it follows thate$- {}^{t2}$. However, this does not remove the difficulty, since$Φ(t 2)/$2 differentiates to Φ(t)is defined as the integral of e-t 2 / 2.) where anti differentiation runs into difficulties, we must In order to define integration in situations like this fall back on messy approximations of the kind dis-cussed earlier. A formal definition along such lines was given bytury.
To see what Riemann’s basic idea is, and to see riemann [VI.49] in the mid nineteenth cenalso that integration, like differentiation, is a procedure that can usefully be applied to functions of more thanone variable, let us look at another physical problem.

I. Introduction

wish to calculate its mass from its density. Suppose alsothat this density is not constant but varies rather irreg-Suppose that you have a lump of impure rock and ularly through the rock. Perhaps there are even holes inside, so that the density is zero in places. What shouldyou do? the rock in a cuboid. For each point cuboid there is then an associated density Riemann’s approach would be this. First, you enclose(x, y, z)d(x, y, z)in this (which will be zero ifinside a hole). Second, you divide the cuboid into a large(x, y, z) lies outside the rock or number of smaller cuboids.
Third, in each of the small cuboids you look for the point of lowest density (if any point in the cuboid is not in the rock, then this density will be zero) and the point of highest density. Letone of the small cuboids and suppose that the lowest C be and highest densities inthat the volume of C is VC. Then the mass of the part ofare a and b, respectively, and the rock that lies in C must lie between a V and b V. Fourth, add up all the numbersin this way, and then add up all the numbersa V that are obtainedb V.
If the totals aremass of rock has to lie between$M^{1} and M^{2}$, respectively, then the total M and M . Finally, repeat this calculation for subdivisions into smaller and smaller cuboids. As you do this, the resulting numbers1 2 Mand you will have better and better approximations to1 and M2 will become closer and closer to each other, the mass of the rock. would be to divide the minute up into small intervals and look at the minimum and maximum speeds during Similarly, his approach to the problem about the car those intervals.
For each interval, this would give hima pair of numbersa and b for which he could say that the car had traveled a distance of at leastb. Adding up these sets of numbers, he could then saya and at most that over the full minute the car must have traveled adistance of at least D (the sum of the as) and at most D2 (the sum of the bs).1

sity/speed) defined on a set (the cuboid/a minute oftime) and in a certain sense we wanted to work out the With both these problems we had a function (den“total amount” of the function. We did so by dividing the set into small parts and doing simple calculations in those parts to obtain approximations to this amount from below and above. This process is what is known as (Riemann)mon: if S is the set and integration. The following notation is com-f is the function, then the total amount off in S, known as the integral, is writtenf (x) dx. Here, x denotes a typical element of S. If, S

as in the density example, the elements of S are points

I.3. Some Fundamental Mathematical Definitions

(x, y, z), then vector notation such as f (x) dx can S

be used, though often it is not and the reader is left to deduce from the context that an ordinary “a vector rather than a real number.$x$” denotes anti differentiation, but a famous theorem, known as We have been at pains to distinguish integration from the fundamental theorem of calculus two procedures do, in fact, give the same answer, at, asserts that the least when the function in question has certain continuity properties that all “sensible” functions have. So it isusually legitimate to regard integration as the opposite of differentiation.
More precisely, ifx f (t) dt for somef is continuous anda, then F can F(x)is defined to be be differentiated andgrate a continuous function and differentiate it again,$F^{a} (x) = f (x)$. That is, if you inte- you get back to where you started. Going the other way around, ifthen$x f (t)F \text{dhas a continuous derivativet} = F(x) - F(a)$. This almost says that iff and a < x, you differentiate a F and then integrate it again, you get back tonumbera F. Actually, you have to choose an arbitrary and what you get is the function F with the constant F(a) subtracted.
To get an idea of the sort of exceptions that arise if one does not assume continuity, consider the so-called Heaviside step function H(x), which is 0 when x < 0 and 1 whenx ⩾ 0. This function has a jump at 0 and is therefore not continuous. The integral function is 0 whenx < 0 and x when x ⩾J(x)0, and forof this almost all values of$x \text{we have} J (x) = H(x)$. However, the gradient of differentiable there and one cannot say that J suddenly changes at 0, so JJ^ is not(0) =H(0) = 1.

5.6 Holomorphic Functions

One of the jewels in the crown of mathematics isplex analysis, which is the study of differentiable func-comtions that take complex numbers to complex numbers. Functions of this kind are called holomorphic. functions, since the definition of a derivative in this context is no different from the definition for functions At first, there seems to be nothing special about such of a real variable: iff^ (z) at a complex numberf is a function then the derivative zis defined to be the limit ash tends to zero of (f (z + h) - f (z))/h.
However, if we look at this definition in a slightly different way (onethat we saw in section 5.3), we find that it is not altogether easy for a complex function to be differentiable. Recall from that section that differentiation meansear approximation. In the case of a complex function, lin-

this means that we would like to approximate it by func-tions of the formg(w) = . ambda w + \mu, where . ambda and \mu are complex numbers. (The approximation near g(w) = f (z) + f^ (z)(w - z), which gives . ambda z=will bef^ (z) and\mu = f (z) - zf^ (z).) Let us regard this situation geometrically. If$λ = 0$ then the effect of multiplying byby some factorr and to rotate it by some angle. ambda is to expand θz. This means that many transformations of the planethat we would ordinarily consider to be linear, such as reflections, shears, or stretches, are ruled out.
Weneed two real numbers to specifyλ (whether we write it in the forma + bi or r (ei)θ), but to specify a gen- eral linear transformation of the plane takes four (see the discussion of matrices in section 4.2). This reduc-tion in the number of degrees of freedom is expressed by a pair of differential equations called the Riemann equations. Instead of writingf (z) let us write Cauchyu(xand imaginary parts of+ iy) + iv(x + iy)z, whereand u(xx+andiy) yandare the realv(x + iy) are the real and imaginary parts of f (x + iy).
Then the linear approximation to⎛ f near z⎞ has the matrix⎜⎜⎜ ∂u∂x ∂u∂y ⎟⎟⎟ .⎝ ∂v ∂v ⎠∂x ∂y

The matrix of an expansion and rotation always has theform( a b ), from which we deduce that-b a∂u∂x = ∂y∂v and ∂u∂y = −∂v∂x .

These are the Cauchy–Riemann equations. One conse-quence of these equations is that . artial \1 artialx2 u2 + . artial y. artial2 u2 = . artial x. artial y. artial2 v - . artial y. artial x. artial2 v = 0. (It is not obvious that the necessary conditions hold for the symmetry of the mixed partial derivatives, butwhenf is holomorphic they do.) Therefore, u sat- isfies the Laplace equation (which was discussed insection 5.4).
A similar argument shows thatv does as well. These facts begin to suggest that complex differentiabili ty is a much stronger condition than real differen-tiability and that we should expect holomorphic functions to have interesting properties. For the remainderof this subsection, let us look at a few of the remarkable properties that they do indeed have. culus (discussed in the previous subsection). Suppose that The first is related to the fundamental theorem of cal-F is a holomorphic function and that we are given

its derivative numberu. How can we re con struc tf and the value of F(u)Ffor some complex? An approximate method is as follows. Letw be another complex num- ber and let us try to work outof pointsz , z , . . . , z with z F(w)= . We take a sequenceu and z = w, and with the differences all small. We can then approximate0 1|(zn)1 - z0|,|0 z2 - z F(z1|, . . . , n)|z-n F(z- zn)-by1|(zequal(si)+1 -F(zzi)f (z) -i)F(z. It follows that), is approximated by the sum of F(w)i-+1 F(u), whichi all themany small errors, it is not obvious that this approx-((zi()+n)1 - zi)f ((z0)i).
(Since we have added together imation is a good one, but it turns out that it is.) Wecan imagine a numberz that starts at u and follows a pathsteps of P toδzw=by jumping from onez+ - z . In the limit aszi to another in smallngoes to infinity and the steps integral, which is denotedδ(zi)1 go to zero we obtain a so-calledi f (z) dz. path P

The above argument has the consequence that if the pathpath integral P begins and ends at the same pointf (z) dz is zero. Equivalently, if twou, then the P

pathssame endpoint P1 and P2 whave the same starting point, then the path integrals u f (z)and thedz andvalue PF(w)2 f (z)-d F(u)z are the same, since they both give the. P 1 big assumption that$F$. Cauchy’s theorem says that the same conclusion is Of course, in order to establish this, we made thef was the derivative of a function true iff is holomorphic. That is, rather than requiringff to be the derivative of another function, it asks foritself to have a derivative. If that is the case, then any path integral ofbegins and ends.
What is more, these path integra lsf depends only on where the path can be used to define a function Fthat differentiates toan antiderivative.f , so a function with a derivative automatically has on the whole of everything remains true if we restrict attention to a It is not necessary for the function C for Cauchy’s theorem to be valid:$f$to be defined simply connected domain[III.90](/part-03/topological-spaces) with no holes in it. If there are holes, then, which means an open set two path integrals may differ if the paths go aroundthe holes in different ways.
Thus, path integrals have a close connection with the topology of subsets of the plane, an observation that has many ramifications through out modern geometry. For more on topology, see section 6.4 of this article and[IV.6](/part-04/algebraic-topology). algebraic topology A very surprising fact, which can be deduced from Cauchy’s theorem, is that ifbe differentiated twice. (This is completely untrue off is holomorphic then it can

I. Introduction

real-valued functions: consider, for example, the func-tion$f where f (x) = 0 when x < 0 and f (x) = x^{2}$ whenx ⩾ 0.) It follows that f^  is holomorphic, so it too can be differentiated twice. Continuing, one finds thatfor complex functions differentiabili ty implies infinitefcan be differentiated any number of times. Thus, differentiabili ty.
(This property is what is used to estab-lish the symmetry, and even the existence, of the mixed partial derivatives mentioned earlier.)A closely related fact is that wherever a holomorphic function is defined it can be expanded in a power series. That is, iffis defined and differentiable every where on an open disk of radiusby a formula of the form R about w, then it will be givenf (z) =n. nfty=0 an(z - w)n,

valid every where in that disk. This is called the expansion off . Taylor tions, one that shows just how “rigid” they are, is thattheir entire behavior is determined just by what they Another fundamental property of holomorphic funcdo in a small region. That is, ifphic and they take the same values in some tiny disk, f and g are holomor- then they must take the same values every where. This remarkable fact allows a process oftion.
If it is difficult to define a holomorphic function analytic continua$f$ply define it in some small region and say that else-every where you want it defined, then you can simwhere it takes the only possible values that are consis-tent with the ones that you have just specified.
This is how the famous riemann zeta function [IV.2 §3](/part-04/number-theory) is conventionally defined. Finally, we mention a theorem of liouville [VI.39](/part-06/joseph-liouville-18091882), which states that ifon the whole complex plane, and iffis a holomorphic function definedf is bounded (that is, if there is some constant C such that |f (z)| ⩽ C for every complex number Once again, this is obviously false for real functions.z), then f must be constant. For example, the function sinbining boundedness with very good behavior:
it can be(x)has no difficulty com expanded in a power series that converges every where.(However, if you use the power series to define an extension of the function sinthe function you obtain is unbounded, as Liouville’s(x) to the complex plane, then theorem predicts.) 6 What Is Geometry? It is not easy to do justice to geometry in this arti-cle because the fundamental concepts of the subject

I.3. Some Fundamental Mathematical Definitions

are either too simple to need explaining—for exam-ple, there is no need to say here what a circle, line, or plane is—or sufficiently advanced that they are bet-ter discussed in parts III and IV of the book. However, if you have not met the advanced concepts and haveno idea what modern geometry is like, then you will get much more out of this book if you understand two basic ideas: the relationship between geometry and symmetry, and the notion of a manifold. These ideas will occupy us for the rest of the article.

6.1 Geometry and Symmetry Groups

Broadly speaking, geometry is the part of mathemat-ics that involves the sort of language that one would conventionally regard as geometrical, with words suchas “point,” “line,” “plane,” “space,” “curve,” “sphere,” “cube,” “distance,” and “angle” playing a prominent role. However, there is a more sophisticated view, first advocated by klein [VI.57], that regards transformations the above list one should add words like “reflection,”as the true subject matter of geometry.
So, to “rotation,” “translation,” “stretch,” “shear,” and “projection,” together with slightly more nebulous con-cepts such as “angle-preserving map” or “continuous deformation.” hand in hand with groups, and for this reason there is As was discussed in section 2.1, transformations go an intimate connection between geometry and group theory. Indeed, given any group of transformations, there is a corresponding notion of geometry, in whichone studies the phenomena that are unaffected by transformations in that group.
In particular, two shapes are regarded asother by means of one of the transformations in the equivalent if one can be turned into the group. Different groups will of course lead to differ-ent notions of equivalence, and for this reason mathematicians frequently talk about geometries, rather than about a single monolithic subject called geometry. this subsection contains brief descriptions of some of the most important geometries and their associated groupsof transformations.

6.2 Euclidean Geometry

Euclidean geometry is what most people would think of as “ordinary” geometry, and, not surprisingly given itsname, it includes the basic theorems of Greek geometry that were the staple of geometers for over two millennia. For example, the theorem that the three

angles of a triangle add up to 180◦ belongs to Euclidean geometry. To understand Euclidean geometry from a transformation al viewpoint, we need to say how many dimen-sions we are working in, and we must of course specify a group of transformations. The appropriate groupis the group of rigid transformations. These can be thought of in two different ways. One is that they arethe transformations of the plane, or of space, or more generally of Rn for some n, that preserve distance.
That is, and T yis a rigid transformation if, given any two points, the distance between T x and T y is always thex same as the distance between greater than 3, distance is defined in a way that natu-x and y. (In dimensions rally generalizes the Pythagorean formula. Seespaces [III.56](/part-03/metric-spaces) for more details.) metric It turns out that every such transformation can be realized as a combination of rotations, reflections, and translations, and this gives us a more concrete way to think about the group.
Euclidean geometry, in other words, is the study of concepts that do not change when you rotate, reflect, or translate, and these include points, lines, planes, circles, spheres, distance, angle, length, area, and volume. The rotations of Rn form an important group, theas SO(n). The larger special orthogonal group orthogonal group O(n) includes, known reflections as well. (It is not quite obvious how to definea “rotation” ofn-dimensional space, but it is not too hard to do. An orthogonal map of Rn is a linear map T that preserves distances, in the sense that always the same asd(x, y).
It is a rotationd(T x, T y)if its deter-is minant determinant of a distance-preserving map is[III.15](/part - 03/determinants) is 1. The only other possibility for the - 1. Maps with determinant - 1 are like reflections in that they turn space “inside out.”) 6.3 Affine Geometry There are many linear maps besides rotations and reflections. What happens if we enlarge our group from SOble?
For a transformation to be part of a group it must(n) or O(n) to include as many of them as possi- begroup to look at is the group gl invertible and not all linear maps are, so the natural(R) of all invertible lin - ear transformations ofsection 4.2. These maps all leave the origin fixed, but if R n, a group that we first met in$n$ we want we can incorporate translations and consider a larger group that consists of all transformations ofthe formx \to  T x + b, where bis a fixed vector and T is an invertible linear map. The resulting geometry iscalled affine geometry.

preserve neither distance nor angle, so these are not Since linear maps include stretches and shears, they concepts of affine geometry. However, points, lines, and planes remain as points, lines, and planes after an invertible linear map and a translation, so these concepts do belong to affine geometry. Another affine con-cept is that of two lines being parallel. (That is, although angles in general are not preserved by linear maps, angles of zero are.) This means that although there is nosuch thing as a square or a rectangle in affine geometry, one can still talk about a parallelogram.
Similarly, one cannot talk of circles but one can talk of ellipses, sincea linear map transformation of an ellipse is another ellipse (provided that one regards a circle as a special kind of ellipse).

6.4 Topology

The idea that the geometry associated with a groupof transformations “studies the concepts that are preserved by all the transformations” can be made more precise using the notion of[I.2 §2.3](/part-01/language-and-grammar). Indeed, let G be a group of transformations equivalence relations of Rn. We might think of an n-dimensional “shape” as being a subset$S of R^{n}$, but if we are doing G-geometry, then we do not want to distinguish between a setany other set we can obtain from it using a transforma-S and tion in G.
So in that case we say that the two shapes arelent in Euclidean geometry if and only if they are con-equivalent. For example, two shapes are equ iv a gr uent in the usual sense, whereas in two-dimensional affine geometry all parallelograms are equivalent, asare all ellipses. One can think of the basic objects of G-geometry as equivalence classes of shapes rather than the shapes themselves.
arises when we use a particularly generous notion of equivalence, saying that two shapes are equivalent, or Topology can be thought of as the geometry that homeomorphic be “continuously deformed” into the other. For exam-, to use the technical term, if each can ple, a sphere and a cube are equivalent in this sense, as figure 1 illustrates. tions, it is quite hard to prove that two shapes are equivalent in this sense.
For example, it may seem obvi-Because there are very many continuous deforma-not ous that a sphere (this means the surface of a ball rather than the solid ball) cannot be continuously deformed into a torus (the shape of the surface of a doughnut of the kind that has a hole in it), since they are fundamen-tally different shapes—one has a “hole” and the other

does not. However, it is not easy to turn this intuition into a rigorous argument. For more on this kind of problem, see invariants [I.4 §2.2](/part-01/general-goals), algebraic topology [IV.6](/part-04/algebraic-topology), and differential topology [IV.7](/part-04/dierential-topology).

6.5 Spherical Geometry

We have been steadily relaxing our requirements for two shapes to be equivalent, by allowing more andmore transformations. Now let us tighten up again and look atlonger Rsphericaln but the geometry. Here the universe is non-dimensional sphere Sn, which is defined to be the surface of the(n + 1)-dimensional ball of radius 1, or, to put it more algebraically, theset of all points(x , x , . . . , x ) in Rn + 1 such thatxthree-dimensional ball is two dimensional, so this se(t2)1 + (x2)2 + · · · + (x2)n 1 + 1 2 = 1. Just as the surface of an + 1 isn dimensional.
We shall discuss the case n = 2 here, but it is easy to generalize the discussion tolargern. The appropriate group of transformations is SO(3): the group that consists of all rotations about axesthat go through the origin. (One could allow reflections as well and take Osphere S2, and that is how we regard them in spherical(3).) These are symmetries of the geometry, rather than as transformations of the wholeof R3. Among the concepts that make sense in spherical geometry are line, distance, and angle.
It may seem oddto talk about a line if one is confined to the surface of a ball, but a “spherical line” is not a line in the usual sense. Rather, it is a subset of S2 obtained by intersect- ing S2 with a plane through the origin. This produces a great circle, that is, a circle of radius 1, which is as large as it can be given that it lives inside a sphere ofradius 1. of as some sort of line is that the shortest path between any two points The reason that a great circle deserves to be thoughtx and y in S2 will always be along a great circle, provided that the path is confined to$S^{2}$.
This is a very natural restriction to make, since we are regarding$S^{2}$as our “universe.” It is also a restriction of some practical relevance, since the shortest sensible route between two distant points on Earth’s surface will

I.3. Some Fundamental Mathematical Definitions

not be the straight-line route that burrows hundreds ofmiles under ground. The distance between two pointsx and yis defined to be the length of the shortest path fromlies entirely in$S^{2}$. (If x and y are opposite each other, x to y that then there are infinitely many shortest paths, all of length about theπ, so the distance between angle between two spherical lines? Well, thex and y is π.) How lines are intersections of S2 with two planes, so one can define it to be the angle between these two planes in the Euclidean sense.
A more aesthetically pleasing wayto view this, because it does not involve ideas external to the sphere, is to notice that if you look at a very small region about one of the two points where two spherical lines cross, then that portion of the sphere will be almost flat, and the lines almost straight. So you can define the angle to be the usual angle between the“limiting” straight lines inside the “limiting” plane. in several interesting ways. For example, the angles ofa spherical triangle always add up to Spherical geometry differs from Euclidean geometry more than 180◦.
Indeed, if you take as the vertices the North Pole, a pointon the equator, and a second point a quarter of the way around the equator from the first, then you obtain atriangle with three right angles. The smaller a triangle, the flatter it becomes, and so the closer the sum of itsangles comes to 180◦. There is a beautiful theorem that gives a precise expression to this: if we switch to radi-ans, and if we have a spherical triangle with anglesα,β, and γ, then its area is α + β + γ - π.
(For example, this formula tells us that the triangle with three anglesof 1π has area1 π, which indeed it does as the sur- face area of a ball of radius 1 is 42 2π and this triangle occupies one-eighth of the surface.)

6.6 Hyperbolic Geometry

So far, the idea of defining geometries with reference to sets of transformations may look like nothing more than a useful way to view the subject, a unified approach to what would otherwise be rather different looking aspects. However, when it comes to hyperbolic geometry, the transformation al approach becomes indispensable, for reasons that will be explained in a moment. bolic geometry is called PSLlinear group The group of transformations that produces hyper-in two dimensions. One way to present this2(R), the projective special group is as follows.
Thethe set of all matrices(a bspecial linear group) with SL2[III.15](/part - 03/determinants)(R) isc d determinant ad - bc equal to 1. (These form a group because the product of two matrices with determinant 1 again has determinant 1.) To make this “projective,” one then regards each matrixthe matrices(3 - 1 )Aandas equivalent(-3 1 ) are equivalent.to - A: for example, interpret it as a group of transformations of some two-dimensional set of points. Once we have done this, we To get from this group to the geometry one must first-5 (25)-2 have what is called abolic geometry.
The subtlety is that there is no single model of two-dimensional hyper model of hyperbolic geometry that is clearly the most natural in the way that the sphere is the most natural model of spherical geometry. (One might think that the sphere was theetry, but this is not in fact the case.
For example, thereonly sensible model of spherical geomis a natural way of associating with each rotation ofa transformation of R2 with a “point at infinity” added, R3 so the extended plane can be used as a model of spherical geometry.) The three most commonly used modelsof hyperbolic geometry are called the half-plane model, the disk model, and the hyperboloid model. The half-plane model is the one most directly associated with the group PSLthe upper half-plane of the complex numbers2(R). The set in question is C, that is, the set of all complex numbers$y > 0$.
Given a matrix (a b ), the corresponding trans-z = x + iy such that formation is the one that takes the point(az + b)/(cz + d). (Notice that if we replacec d z to the pointa, b, c, and formation.) The conditiond by their negatives, then we get the same trans - ad - bc = 1 can be used to show that the transformed point will still lie in theupper half - plane, and also that the transformation can be inverted. tancesate” the geometry.
If we are to have a notion of distance What this does not yet do is tell us anything about, and it is here that we need the group to “gener - disdof transformations, then it is important that the trans-that is sensible from the perspective of our group formations should preserve it. That is, ifthe transformations andz and w are two points in the T is one of upper half - plane, thenthe same asd(z, w). It turns out that there is es sent i all yd(T (z), T (w)) should always be only one definition of distance that has this property, and that is the sense in which the group defines the geometry.
(One could of course multiply all distances by some constant factor such as 3, but this would belike measuring distances in feet instead of yards, rather than a genuine difference in the geometry.) odd. For example, a typical This distance has some properties that at first seem hyperbolic line takes the form of a semicircular arc with endpoints on the realaxis. However, it is semicircular only from the point of view of the Euclidean geometry of C: from a hyperbolic perspective it would be just as odd to regard a Euclid-ean straight line as straight.
The reason for the discrepancy is that hyperbolic distances become larger andlarger, relative to Euclidean ones, the closer you get to the real axis. To get from a pointz to another point w, it is therefore shorter to take a “detour” away from thereal axis, and the best detour turns out to be along an arc of the circle that goes through real axis at right angles.
(Ifz and wzare on the same ver - and w and cuts the tical line, then one obtains a “degenerate circle,” namely that vertical line.) These facts are no more paradoxical than the fact that a flat map of the world involves distortions of spherical geometry, making Greenland verylarge, for example. The half-plane model is like a “map” of a geometric structure, the hyperbolic plane, that in reality has a very different shape. One of the most famous properties of two-dimensional hyperbolic geometry is that it provides a geom-etry in which Euclid’s parallel postulate fails to hold.
That is, it is possible to have a hyperbolic line L, a pointbolic lines through xnot on the line, and two different hyper - x, neither of which meets L. All the other axioms of Euclidean geometry are, when suitably interpreted, true of hyperbolic geometry as well. It follows that the parallel postulate cannot be deduced from those axioms.
This discovery, associ-ated with gauss [VI.26](/part - 06/carl - friedrich - gauss - 17771855), bolyai [VI.34], and lobachevskii mathematicians for over two thousand years.[VI.31](/part - 06/nicolai - ivanovich - lobachevskii - 17921856), solved a problem that had bothered Another property complements the result about the angle sums of spherical and Euclidean triangles. Thereis a natural notion of hyperbolic area, and the area of a hyperbolic triangle with anglesβ - γ.
Thus, in the hyperbolic planeα, βα, and+ β +γ γisis alwaysπ - α - less thanπ, and it almost equals π when the triangle is very small. These properties of angle sums reflect thefact that the sphere has positive curvature [III.13](/part - 03/curvature), the Euclidean plane is “flat,” and the hyperbolic plane has negative curvature. The disk model, conceived in a famous moment of inspiration bya bus, takes as its set of points the poincaré [VI.61](/part - 06/jules - henri - poincar - 18541912) as he was getting intoopen unit disk in C, that is, the setulus less than 1.
This time, a typical transformation D of all complex numbers with mod- takes the following form. One takes a real numberθ, and a complex numbereachz in D to the point e(ai)θfrom inside(z - a)/(1 - Daz) ̄, and sends. It is not I. Introduction Figure 2 A tessellation of the hyperbolic disk. completely obvious that these transformations form a group, and still less that the group is isomorphic to PSL(R). However, it turns out that the function that takes upper half-plane and vice versa.
This shows that the2 z to -(iz + 1)/(z + i) maps the unit disk to the two models give the same geometry and can be used to transfer results from one to the other. As with the half-plane model, distances become larger, relative to Euclidean distances, as you approach the boundary of the disk: from a hyperbolic perspective, the diameter of the disk is infinite and it does not really have a boundary. Figure 2 shows a tessellation of the disk by shapes that are congruent in the sense that any one can be turned into any other by means ofa transformation from the group.
Thus, even though they do not look identical, within hyperbolic geometry they all have the same size and shape. Straight linesin the disk model are either arcs of (Euclidean) circles that meet the unit circle at right angles, or segments of(Euclidean) straight lines that pass through the center of the disk. the geometry is called hyperbolic. This time the set isthe hyperboloid consisting of all points The hyperboloid model is the model that explains why(x$, y, z) \in R^{3}$ such that$z > 0 and x^{2} + y^{2} + 1 = z^{2}$.
This is the hyper- boloid of revolution about thex2+1 = z2 in the plane y = 0. A general transform at io nz-axis of the hyperbola in the group is a sort of “rotation” of the hyperboloid, and can be built up from genuine rotations about thez- axis, and “hyperbolic rotations” of thexz-plane, which have matrices of the form coshθ sinh θ.

sinhθ cosh θ

Just as an ordinary rotation preserves the unit circle, one of these hyperbolic rotations preserves the hyperbola$x^{2} + 1 = z^{2}$, moving points around inside it. Again, it is not quite obvious that this gives the same group

I.3. Some Fundamental Mathematical Definitions

of transformations, but it does, and the hyperboloid model is equivalent to the other two.

6.7 Projective Geometry

Projective geometry is regarded by many as an old-fash-ioned subject, and it is no longer taught in schools, but it still has an important role to play in modern mathe-matics. We shall concentrate here on the real projective planeber of dimensions and with scalars in any field. This, but projective geometry is possible in any nummakes it particularly useful to algebraic geometers. The first is that the set of points is the ordinary plane, together with a “line at infinity.” The group of transfor-Here are two ways of regarding the projective plane.
mations consists of functions known as understand what a projection is, imagine two planes Pp ro je ct i ons. To and Pin space, and a point x that is not in either of them. We can “project” P onto Pas follows. If a is a point in P, then its imageline joiningx to a meets Pφ(a)^ . (If this line is parallel to Pis the point where the^ , thenφ(a)is a point on the line at infinity of P.) Thus, if you are atthen its image under the projectionx and a picture is drawn on the plane P,φ will be the picture drawn on Pthat to you looks exactly the same.
In fact, however, it will have been distorted, so the transforma-tionφhas made a difference to the shape. To turnφ into a transformation of P itself, one can follow it by arigid transformation that moves Pback to where P is. Such projections clearly do not preserve distances, but they do preserve other interesting concepts, suchas points, lines, quantities known as cross-ratios, and, most famously, conic sections. A conic section is the intersection of a plane with a cone, and it can be a circle, an ellipse, a parabola, or a hyperbola.
From the point of view of projective geometry, these are all the same kind of object (just as, in affine geometry, one can talk about ellipses but there is no special ellipse called a circle). set of all lines in A second view of the projective plane is that it is the R3 that go through the origin. Since a line is determined by the two points where it intersects the unit sphere, one can regard this set as a sphere, but with the significant difference that regarded as the same—because they correspond to the opposite points are same line. jective plane is obtained as follows.
Take any invertible linear map, and apply it to Under this view, a typical transformation of the pro-R3. This takes lines through the origin to lines through the origin, and can there-fore be thought of as a function from the projective

plane to itself. If one invertible linear map is a multipleof another, then they will have the same effect on all lines, so the resulting group of transformations is like GL(R), except that all nonzero multiples of any given matrix are regarded as equivalent. This group is calledthe3 projective special linear group PSL(R), and it is the three-dimensional equivalent of PSLhave already met. Since PSL(R) is bigger than PS(L3)2(R), which we(R), the projective plane comes with a richer set of transfor-mations than the hyperbolic plane, which is why fewer3 2 geometrical properties are preserved.
(For example, we have seen that there is a useful notion of hyperbolic distance, but there is no obvious notion of projective distance.)

6.8 Lorentz Geometry

This is a geometry used in the theory of special rel-ativity to model four-dimensional spacetime, otherwise known asbetween it and four-dimensional Euclidean geometry is Minkowski space. The main difference that, instead of the usual notion of distance between two points(t, x, y, z) and (t^ , x^ , y^ , z^ ), one considers the quantity -(t - t)2 + (x - x)2 + (y - y)2 + (z - z)2, which would be the square of the Euclidean distance were it not for the all-important minus sign before (t - t)2.
This reflects the fact that space and time are significantly different (though intertwined).A Lorentz transformation is a linear map from R4 to R4 that preserves these “generalized distances.” Letting(-t, x, y, z)g be the linear map that sendsand letting G be the corresponding matrix(t, x, y, z) to (which has-1,1,1,1 down the diagonal and 0 every- where else), we can define a Lorentz transformation abstractly as one whose matrix$ΛsatisfiesΛ^{T}GΛ = G$, where I is the 4 . imes  4 identity matrix and ΛT is the trans- pose ofdefined byΛ.
(The B =transpose A .) of a matrix A is the matrix Bx(z2)2 A point+< y0. If2 +(t, x, y, z)z-ij2 t2>+0, andjix2 +is said to beytimelike2 + z2 =ifspacelike0, then the point-t2 + x2 if+-y(t2)2 ++ lies in theof Lorentzian geometry because they are preserved bylight cone. All these are genuine concepts Lorentz transformations. tance tothe study of Lorentzian geometry is also of fundamental impor-general Lorentzian manifolds relativity, which can be thought of as. These are closely related to Riemannian manifolds, which are discussed

in section 6.10. For a discussion of general relativ-ity, see general relativity and the einstein equations [IV.13](/part-04/general-relativity-and-the-einstein-equations). 6.9 Manifolds and Differential Geometry To somebody who has not been taught otherwise, it is natural to think that Earth is flat, or rather that it con-sists of a flat surface on top of which there are buildings, mountains, and so on. However, we now know that it is in fact more like a sphere, appearing to be flat only because it is so large. There are various kinds of evidence for this.
One is that if you stand on a cliff by the sea then you can see a definite horizon, not too faraway, over which ships disappear. This would be hard to explain if Earth were genuinely flat. Another is that if you travel far enough in what feels like a straight linethen you eventually get back to where you started. A third is that if you travel along a triangular route and the triangle is a large one, then you will be able to detect that its three angles add up to more than 180◦.
best models that of the universe is three-dimensional Euclidean geometry, or what one might think of as “nor-It is also very natural to believe that the geometry that mal” geometry. However, this could be just as much ofa mistake as believing that two-dimensional Euclidean geometry is the best model for Earth’s surface.
Indeed, one can immediately improve on it by considering Lorentzian geometry as a model of spacetime, but even if there were no theory of special relativity, our astronomical observations would give us no particular reason to suppose that Euclidean geometry wasthe best model for the universe. Why should we be so sure that we would not obtain a better model by tak-ing the three-dimensional surface of a very large fourdimensional ball? This might feel like “normal” space injust the way that the surface of Earth feels like a “normal” plane unless you travel large distances.
Perhaps if you traveled far enough in a rocket without changing your course then you would end up where you started. one just associates with each point in space a triple of It is easy to describe “normal” space mathematically: coordinates describe a huge “spherical” space? It is slightly harder,(x, y, z) in the usual way. How might we but not much: one can give each point four coordinates (x, y, z, w)isfy the equation but add the condition that these must sat - x2 + y2 + z2 + w2 = R2 for some fixed Rthat we think of as the “radius” of the universe.
This describes the three-dimensional surface ofa four-dimensional ball of radius R in just the same

I. Introduction

way that the equation$x^{2} + y^{2} + z^{2} = R^{2} \text{describes the}$ two-dimensional surface of a three-dimensional ball ofradius R. to rely on the rather implausible idea that the uni-A possible objection to this approach is that it seems verse lives in some larger unobserved four-dimensional space. However, this objection can be answered. The object we have just defined, the 3-sphere$S3$, can also be described in what is known as anis, without reference to some surrounding space. the intrinsic way:
that easiest way to see this is to discuss the 2-sphere first, in order to draw an analogy. Let us therefore imagine a planet covered with calm water. If you drop a large rock into the water at the North Pole, a wave will propagate out in a circle of everincreasing radius. (At any one moment, it will be a circle of constant latitude.) In due course, however, this circle will reach the equator, after which it will start to shrink, until eventually the whole wave reaches the South Poleat once, in a sudden burst of energy.
space—it could, for example, be a light wave caused Now imagine setting off a three-dimensional wave in by the switching on of a bright light. The front ofthis wave would now be not a circle but an everexpanding spherical surface. It is logically possible thatthis surface could expand until it became very large and then contract again, not by shrinking back to where itstarted, but by turning itself inside out, so to speak, and shrinking to another point on the opposite sideof the universe.
(Notice that in the two-dimensional example, what you want to call the inside of the cir-cle changes when the circle passes the equator.) With a bit of effort, one can visualize this possibility, and there is no need to appeal to the existence of a fourth dimension in order to do so. More to the point, this account can be turned into a mathematically coher-ent and genuinely three-dimensional description of the 3-sphere. A different and more general approach is to use what is called anmal, everyday sense) consists of a number of flat pages, atlas.
An atlas of the world (in the nor together with an indication of theirhow parts of some pages correspond to parts of others.overlaps: that is, of Now, although such an atlas is mapping out an exter-nal object that lives in a three-dimensional universe, the spherical geometry of Earth’s surface can be readoff from the atlas alone. It may be much less convenient to do this but it is possible: rotations, for exam-ple, might be described by saying that such-and-such a

I.3. Some Fundamental Mathematical Definitions

part of page 17 moved to a similar but slightly distorted part of page 24, and so on. Not only is this possible, but one can define a surface by means of two-dimensional atlases. For example, there is a mathematically neat “atlas” of the 2-sphere that consists of just two pages, both of them circular. One is a map of the Northern Hemisphere plus a little bit of the Southern Hemisphere near the equator (to provide a small overlap) and the other is a map of the Southern Hemisphere with a bit of the Northern Hemisphere.
Because these maps are flat, they necessarily involve some distortion, but one can specify what this distortion is. dimensions. A “page” now becomes a portion of three-dimensional space. The technical term is not “page” but The idea of an atlas can easily be generalized to three “chart,” and a three-dimensional atlas is a collection ofcharts, again with specifications of which parts of one chart correspond to which parts of another. A possible atlas of the 3-sphere, generalizing the simple atlas of the 2-sphere just discussed, consists of two solid three-dimensional balls.
There is a correspondence between points toward the edge of one of these balls and points toward the edge of the other, and this can be used todescribe the geometry: as you travel toward the edge of one ball you find yourself in the overlapping region, so you are also in the other ball. As you go further, you are off the map as far as the first ball is concerned, but the second ball has by that stage taken over. The 2-sphere and the 3-sphere are basic examples of manifoldsin this section are the torus and the projective plane..
Other examples that we have already met Informally, ad-dimensional manifold, or d-manifold, is any geometrical objectpointx in M is surrounded by what feels like a portion M with the property that every ofparts of a sphere, torus, or projective plane are veryd-dimensional Euclidean space. So, because small close to planar, they are all 2-manifolds, though when the dimension is two the word(However, it is important to remember that a “surface”surface is more usual. need not be the surface3-sphere is a 3-manifold.
of anything.) Similarly, the The formal definition of a manifold uses the idea of atlases: indeed, one says that the atlasfold. This is a typical mathematician’s use of the wordis a mani“is,” and it should not be confused with the normaluse. In practice, it is unusual to think of a manifold as a collection of charts with rules for how parts of them correspond, but the definition in terms of chartsand atlases turns out to be the most convenient when

one wishes to reason about manifolds in general rather than discussing specific examples. For the purposes of this book, it may be better to think of ain the “extrinsic” way that we first thought aboutd-manifold the 3-sphere: as ain some higher-dimensional space. Indeed, there is a$d$-dimensional “hypersurface” living famous theorem of Nash that states that all manifolds arise in this way. Note, however, that it is not always easy to find a simple formula for defining such a hypersurface.
For example, while the 2-sphere is described bythe simple formulax2+y2+z2 = 1 and the torus by the slightly more complicated and more artificial formula(r - 2)2 + z2 = 1, where r is shorthand for x2 + y2, it is not easy to come up with a formula that describes atwo-holed torus. Even the usual torus is far more easily described using quotients, as we did in section 3.3.
Quo-tients can also be used to define a two-holed torus (see fuchsian groups fide nt that the result is a manifold is that every point[III.28](/part-03/fuchsian-groups)), and the reason one is conhas a small neighborhood that looks like a small part ofthe Euclidean plane.
In general, ad-dimensional man- ifold can be thought of as any construction that givesrise to an object that is “locally like Euclidean space of ddimensions.” calculus is possible for functions defined on them. Roughly speaking, if An extremely important feature of manifolds is that M is a manifold and f is a function from M to R, then to see whether fis differentiable at a point representation of it), and regardx in Myou first find a chart that contains fas a function definedx (or a on the chart instead.
Since the chart is a portion of the$d$ - dimensional Euclidean space Rdand we can differentiate functions defined on such sets, the notion of differentiabili ty now makes sense forthis definition to work for the manifold, it is importantf . Of course, for that ifanswer will be the same for both. This is guaranteedx belongs to two overlapping charts, then the if the function that gives the correspondence between the overlapping parts (known as ais itself differentiable.
Manifolds with this property are transition function) called transition functions are continuous but not necessar-differentiable manifolds: manifolds for which the ily differentiable are called topological manifolds. The availability of calculus makes the theory of differen-tiable manifolds very different from that of topological manifolds. The above ideas generalize easily from real-valued functions to functions from M^ , where M^  is another manifold. However, it is eas-M to Rd, or from M to ier to judge whether a function defined on a manifold

is differentiable than it is to say what the derivative is. The derivative at some pointx of a function from Rn to Rm is a linear map, and so is the derivative of a function defined on a manifold. However, the domain of the lin-ear map is not the manifold itself, which is not usually a vector space, but rather the so-called tangent space at the pointx in question. see For more details on this and on manifolds in general, differential topology [IV.7](/part-04/dierential-topology).

6.10 Riemannian Metrics

Suppose you are given two points P and Q on a sphere. How do you determine the distance between them? The answer depends on how the sphere is defined. If it isthe set of all points(x, y, z) such that x2 + y2 + z2 = 1 then P and Q are points in R3. One can therefore use the Pythagorean theorem to calculate the distance between them. For example, the distance between the points(1,0,0) and (0,1,0) is . qrt{2}. the line segment PQ ?
This segment does not lie in thesphere itself, so to use it as a means of defining length However, do we really want to measure the length of does not sit at all well with the idea of a manifold asan intrinsically defined object. Fortunately, as we saw earlier in the discussion of spherical geometry, there is another natural definition that avoids this problem: wecan define the distance between P and Q as the length of the shortest path from P to Q that lies entirely withinthe sphere. Now let us suppose that we wish to talk more generally about distances between points in manifolds.
If the manifold is presented to us as a hypersurface in some bigger space, then we can use lengths of shortest paths as we did in the sphere. But suppose that the mani-fold is presented differently and all we have is a way of demonstrating that every point is contained in a chart— that is, has a neighborhood that can be associated witha portion ofd-dimensional Euclidean space.
(For the purposes of this discussion, nothing is lost if one takesd to be 2 through out, in which case there is a corre- spondence between the neighborhood and a portion ofthe plane.) One idea is to define the distance between the two points to be the distance between the corresponding points in the chart, but this raises at least three problems. at might belong to different charts. This, however, isnot too much of a problem, since all we actually need The first is that the points P and Q that we are looking to do is calculate lengths of paths, and that can be done I.
Introduction provided we have a way of defining distances between points that are very close together, in which case we can find a single chart that contains them both. The second problem, which is much more serious, is that for any one manifold there are many ways ofchoosing the charts, so this idea does not lead to a single notion of distance for the manifold. Worse still, evenif one fixes one set of charts, these charts will overlap, and it may not be possible to make the notions ofdistance compatible where the overlap occurs. The third problem is related to the second.
The surface of a sphere is curved, whereas the charts of anyatlas (in either the everyday or the mathematical sense) are flat. Therefore, the distances in the charts cannot correspond exactly to the lengths of shortest paths in the sphere itself. The single most important moral to draw from the above problems is that if we wish to define a notion ofdistance for a given manifold, we have a great deal of choice about how to do so. Very roughly, a riemannian metric is a way of making such a choice. tion of distance (the precise definition can be foundin [III.56](/part - 03/metric - spaces)).
A Riemannian metric is a way of determining A little less roughly, a metric means a sensible no infinitesimal distances. These infinitesimal distances can be used to calculate lengths of paths, and then the distance between two points can be defined as the length of the shortest path between them. To see howthis is done, let us first think about lengths of paths in the ordinary Euclidean plane. Suppose that belongs to a path and$(x +δx$, y +δy) is another point(x, y) on the path, very close tobetween the two points isδx(x, y)2 + δy. Then the distance2.
To calculate the length of a sufficiently smooth path, one can choose alarge number of points along the path, each one very close to the next, and add up their distances. This givesa good approximation, and one can make it better and better by taking more and more points. In practice, it is easier to work out the length using calculus. A path itself can be thought of as a moving point(x(t), y(t)) that starts when t = 0 and ends when approximate lyt = 1. Ifx(t)δt+is very small, thenx^ (t)δt and y(t +δt)x(tis approxi-+ δt) is matelyy(t)+y^ (t)δt.
Therefore, the distance between(x(t)$, y(t))mately δt xand (t)2 (x(t + y (t)+2δt)$, y(t, by the Pythagorean theo-+ δt)) is approxi- rem. Therefore, letting all the infinitesimal distances along the path, we obtainδt go to zero and integrating the formula x^ (t)2 + y^ (t)2 dt I.4. The General Goals of Mathematical Research for the length of the path. Notice that if we writex^ (t) and y^ (t) as dx/dt and dy/dt, then we can rewritex^ (t)2 + y^ (t)2 dt as dx2 + dy2, which is the infinitesimal version of the expressionδx2 + δy2 that we had earlier.
We have just defined a Rieman-nian metric, which is usually denoted by d$x^{2} + dy^{2}$. This can be thought of as the square of the distance between the point(x, y)and the infinitesimally close point(x + dx, y + dy). If we want to, we can now prove that the shortest path between two points line, which will tell us that the distance between them$(x^{0}$, y0) and (x1, y1) is a straight isin variational methods(x1 - x0)2 + (y1 - y0)2[III.94](/part-03/variational-methods).) However, since we.
(A proof can be found could have just used this formula to begin with, this example does not really illustrate what is distinctive about Riemannian metrics. To do that, let us give a more precise definition of the disk model for hyper-bolic geometry, which was discussed in section 6.6. There it was stated that distances become larger, rela-tive to Euclidean distances, as one approaches the edge of the disk.
A more precise definition is that theunit disk is the set of all points(x, y) such that openx2 +ygiven by the expression2 < 1 and that the Riemannian metric on this disk is(dx2 +dy2)/(1 -x2-y2). This is how we(x, y) anddefine(x + dthe square of the distance betweenx, y + dy).
Equivalently, the length of a path metric is defined as(x(t), y(t)) with respect to this Riemannian$1$ x^ (t)^2 + y^ (t)^2$d$ t.$1$- x(t)^2 - y(t)^2 the plane is an expression of the form More generally, a Riemannian metric on a portion of E(x, y)dx2 + 2 F(x, y) dx dy + G(x, y) dy2 that is used to calculate infinitesimal distances andhence lengths of paths. (In the disk model we took E(x, y) and G(x, y) to be 1/(1 - x2 -y2) and F(x, y) to be 0.) It is important for these distances to bepositive, which will turn out to be the case provided that E(x, y)G(x, y) - F(x, y)2 is always positive.
One also needs the functions E, F, and G to satisfy certain smoothness conditions. dimensions. Insion of the form This definition generalizes straightforward ly to moren dimensions we must use an expres-n Fij (x1, . . . , xn) dxi dxj.i, j = 1

to specify the squared distance between the points(x , . . . , x ) and (x + dx , . . . , x + dx ). The num - bers1 Fij((xn)1, . . . , xn)1 form an1 n . imes nnmatrix that dependsn on the point symmetric and positive definite: that is,(x1, . . . , xn). This matrix is required to be Fij(x1, . . . , xn) should always equalthat determines the squared distance should always be Fji(x1, . . . , xn), and the expression positive. It should also depend smoothly on the point(x , . . . , x ).
Finally, now that we know how to define many differ-1 nent Riemannian metrics on portions of Euclidean space, we have many potential ways to define metrics on the charts that we use to define a manifold. A riemannian metric on a manifold is a way of choosing compatible Riemannian metrics on the charts, where “compatible” means that wherever two charts overlap the distances should be the same. As mentioned earlier, once one has done this, one can define the distance between twopoints to be the length of a shortest path between them.
sible to define many other concepts, such as angles Given a Riemannian metric on a manifold, it is posand volumes. It is also possible to define the impor-tant concept of curvature, which is discussed in ricci flow geodesic[III.78](/part - 03/ricci - flow). Another important definition is that of a, which is the analogue for Riemannian geometry of a straight line in Euclidean geometry. A curve Cis a geodesic if, given any two points P and Q on C that are sufficiently close, the shortest path from P to Q ispart of C.
For example, the geodesics on the sphere are the great circles. As should be clear by now from the above discussion, on any given manifold there is a multitude of possi-ble Riemannian metrics. A major theme in Riemannian geometry is to choose one that is “best” in some way. For example, on the sphere, if we take the obvious definition of the length of a path, then the resulting metricis particularly symmetric, and this is a highly desirable property. In particular, with this Riemannian metricthe curvature of the sphere is the same every where.
More generally, one searches for extra conditions toimpose on Riemannian metrics. Ideally, these conditions should be strong enough that there is just one Riemannian metric that satisfies them, or at least that the family of such metrics should be very small. I.4 The General Goals of Mathematical Research The previous article introduced many concepts that appear through out mathematics. This one discusses what mathematicians do with those concepts, and thesorts of questions they ask about them.
1 Solving Equations As we have seen in earlier articles, mathematics is fullof objects and structures (of a mathematical kind), but they do not simply sit there for our contemplation: we also like tober, there will be contexts in which we want to dou-do things to them. For example, given a numble it, or square it, or work out its reciprocal; givena suitable function, we may wish to differentiate it; given a geometrical shape, we may wish to transform it; and so on. Transformations like these give rise to a never-ending source of interesting problems.
If we have defined some mathematical process, then a rather obvious mathematical project is to invent techniques for car-rying it out. This leads to what one might call direct questions about the process. However, there is also adeeper set of inverse questions, which take the following form. Suppose you are told what process has been carried out and what answer it has produced. Can you then work out what the mathematical object was thatthe process was applied to? For example, suppose I tell you that I have just taken a number and squared it, and that the result was 9.
Can you tell me the original number? In this case the answer is more or less yes: it must have been 3, except that if negative numbers are al-lowed, then another solution is-3. we have been examining the equation If we want to talk more formally, then we say that$x^{2} = 9$, and have discovered that there are two solutions. This example raises three issues that appear again and again. ••Does a given equation have any solutions?If so, does it have exactly one solution? • What is the set in which solutions are required to live? The first two concerns are known as thethe uniqueness of solutions.
The third does not seem existence and particularly interesting in the case of the equation$x^{2} =$ 9, but in more complicated cases, such as partial differential equations, it can be a subtle and important question. function ment of the form To use more abstract language, suppose that[I.2 §2.2](/part-01/language-and-grammar) and that we are faced with a state-f (x) = y. The direct question is tof is a work outy given what x is. The inverse question is

I. Introduction

to work out solving the equation$x \text{given whatf} (x) =yy$is: this would be called. Not surprisingly, questions about the solutions of an equation of this formare closely related to questions about the invertibility of the functionx and y can be very much more general objects thanf , which were discussed in [I.2](/part-01/language-and-grammar). Because numbers, the notion of solving equations is itself very general, and for that reason it is central to mathematics. 1.1 Linear Equations The very first equations a schoolchild meets will typi-cally be ones like 2 x + 3 = 17.
To solve simple equations like this, one treatsx as an unknown number that obeys the usual rules of arithmetic. By exploiting these rulesone can transform the equation into something much simpler: subtracting 3 from both sides we learn that2 x = 14, and dividing both sides of this new equation by 2 we then discover thatx = 7. If we are very careful, we will notice that all we have shown is thatsome numberx such that 2 x + 3 = 17 then xif must bethere is 7. What we have not shown is that there is any such So strictly speaking there is a further step of checkingx.$that 2$. imes 7 + 3 = 17.
This will obviously be true here, but the corresponding assertion is not always true for more complicated equations so this final step can beimportant. The equation 2 x + 3 =17 is called “linear” because the functionby 2 and add 3) is a linear one, in the sense that its graphf we have performed on x (to multiply it is a straight line. As we have just seen, linear equa-tions involving a single unknownx are easy to solve, but matters become considerably more sophisticated when one starts to deal with more than one unknown.
Let us look at a typical example of an equation in two unknowns, the equation 3 x + 2 y = 14. This equation has many solutions: for any choice ofx = (14 - 2 y)/3 and you have a pair (x, y)y you can setthat sat- isfies the equation. To make it harder, one can take asecond equation as well, 5 x + 3 y = 22, say, and try to solve the two equations out, there is just one solution, namely simultaneous lyx. Then, it turns = 2 and y = 4.
Typically, two linear equations in two unknowns have exactly one solution, just as these two do, which is easy to see if one thinks about the situation geometrically. An equation of the formax + by = c is the equation of a straight line in thexy - plane. Two lines normally meet in a single point, the exceptions being when theyare identical, in which case they meet in infinitely many points, or parallel but not identical, in which case theydo not meet at all. I.4.
The General Goals of Mathematical Research can be conceptually simpler to think of them as one If one has several equations in several unknowns, it equation in one unknown. This sounds impossible, butit is perfectly possible if the new unknown is allowed to be a more complicated object. For example, the two equations 3 x + 2 y = 14 and 5 x + 3 y = 22 can be rewrit- ten as the following single equation involving matrices and vectors:
3 2$\sum x = 14. 5 3$ y 22 If we letumn vector, and A stand for the matrix, b for the known one, then this equa-x for the unknown col- tion becomes simply Ax = b, which looks much less complicated, even if in fact all we have done is hidden the complication behind our notation. There is more to this process, however, than sweeping dirt under the carpet. While the simpler notation conceals many of the specific details of the problem, it also reveals very clearly what would otherwise be obscured:
that we have a linear map from R2 to R2 and we want to know which vectorsx, if any, map to the vector ta neo us equations, this reformulation does not makeb. When faced with a particular set of simul- much difference—the calculations we have to do arethe same—but when we wish to reason more generally, either directly about simultaneous equations or about other problems where they arise, it is much easier to think about a matrix equation with a single unknown vector than about a collection of simultaneous equations in several unknown numbers.
This phenomenon occurs through out mathematics and is a major reason for the study of high-dimensional spaces.

1.2 Polynomial Equations

We have just discussed the generalization of linear equations from one variable to several variables. Another direction in which one can generalize them is tothink of linear functions as polynomials of degree 1 and consider functions of higher degree. At school, for example, one learns how to solve quadratic equations, such asx2 - 7 x + 12 = 0. More generally, a polynomial equation is one of the form anxn + (an()-1 x()n)-1 + · · · + a2 x2 + a1 x + a0 = 0. for which the equation is true (or, better still, all such values).
This may seem an obvious thing to say until To solve such an equation means to find a value of$x$ one considers a very simple example such as the equa-tionx2 - 2 = 0, or equivalently x2 = 2. The solution to

this is, of course, defined to be the positive number that squares to 2, butx = ±. qrt{2}. What, though, is . qrt2? It is it does not seem to be much of a “solution” to the equa - tionx2 = 2 to say that x is plus or minus the positive number that squares to 2. Neither does it seem entirely satisfactory to say that$x = 1$.4142135 . . ., since this is just the beginning of a calculation that never finishes and does not result in any discernible pattern. example.
One is that what matters about an equationis often the There are two lessons that can be drawn from this existence and properties of solutions and not so much whether one can find a formula for them. Although we do not appear to learn anything when we are told that the solutions to the equation$x = ±\sqrt{2}$, this assertion does contain within it a factx2 = 2 are that is not wholly obvious: that the number 2 has asquare root.
This is usually presented as a consequence of the intermediate value theorem (or another result of a similar nature), which states that ifreal-valued function andf (a) and f (b)f is a continuous lie on either side of 0, then somewhere betweenbe ac such that f (c) = 0. This result can be applieda and b there must to the functionf (2) = 2. Therefore, there is somef (x) = x2 - 2, sincex between 1 and 2 f (1) = −1 and such thatx2-2 = 0, that is, x2 = 2.
For many purposes, the mere existence of this defining properties of being positive and squaring to 2.x is enough, together with its bers have positive square roots. But the picture changes when we try to solve more complicated quadratic equa-A similar argument tells us that all positive real numtions. Then we have two choices. Consider, for exam-ple, the equationx2 - 6 x + 7 = 0. We could note thatx2 - 6 x + 7 is -1 when x = 4 and 2 when x = 5 and deduce from the intermediate value theorem that the equation has some solution between 4 and 5.
However, we do not learn as much from this as if we complete thesquare, rewritingx2 - 6 x + 7 as (x - 3)2 - 2. This allows us to rewrite the equation astwo solutions$x = 3 ± \sqrt{2}$. We have already established(x-3)^2 = 2, which has the thatwe have a solution of. qrt{2} exists and lies between 1 and 2, so not only dox2 - 6 x + 7 = 0 that lies between 4 and 5, but we can see that it is closely related to, indeed built out of, the solution to the equation$x^{2} = 2$.
This demonstrates a second important aspect of equa-tion solving, which is that in many instances the explicit solubility of an equation is agiven a solution to the equation relativex2 = 2, we do not neednotion. If we are anysolve the more complicated equation new input from the intermediate value theorem to$x^{2} - 6x + 7 =$0: all we need is some algebra. The solution,$x = 3±\sqrt{2}$, is

given by an explicit expression, but inside that expres-sion we have$\sqrt{2}$, which is not defined by means of an explicit formula but as a real number, with certain properties, that we can prove to exist. Solving polynomial equations of higher degree is markedly more difficult than solving quadratics, andraises fascinating questions.
In particular, there are complicated formulas for the solutions of cubic and quartic equations, but the problem of finding corresponding formulas for quintic and higher-degree equa-tions became one of the most famous unsolved problems in mathematics, until abel [VI.33](/part-06/niels-henrik-abel-18021829) and galois [VI.41](/part-06/variste-galois-18111832) showed that it could not be done. For more details about these matters see the insolubility of the quintic nomial equations see[V.21](/part-05/the-insolubility-of-the-quintic).
For another article related to poly-the fundamental theorem of algebra [V.13](/part-05/the-fundamental-theorem-of-algebra).

1.3 Polynomial Equations in Several Variables

Suppose that we are faced with an equation such as x3 + y3 + z3 = 3 x2 y + 3 y2 z + 6 xyz. We can see straight away that there will be many solu - tions: if you fixx and y , then the equation is a cubic polynomial inz, and all cubics have at least one (real) solution. Therefore, for every choice ofis somez such that the triple (x, y, z) is a solution ofx and y there the above equation. cubic equation is rather complicated, a precise speci-fication of the set of all triples Because the formula for the solution of a general(x, y, z) that solve the equation may not be very enlightening.
However, one can learn a lot by regarding this solution set as a geo-metric object—a two-dimensional surface in space, to be precise—and asking One might, for instance, wish to understand roughly qualitative questions about it. what shape it is. Questions of this kind can be made precise using the language and concepts of topology [I.3 §6.4](/part - 01/fundamental - definitions). simultaneous solutions to several polynomial equa - tions. Understanding the solution sets of such systems One can of course generalize further and consider of equations is the province of[IV.4](/part - 04/algebra).
algebraic geometry

1.4 Diophantine Equations

As has been mentioned, the answer to the question of whether a particular equation has a solution varies according to where the solution is allowed to be. The

I. Introduction

equationx2 + 3 = 0 has no solution if x is required to be real, but in the complex numbers it has the two solutions$x = ±i \sqrt{3}$. The equation x^2 + y^2 = 11 has infinitely many solutions if we are looking forin the real numbers, but none if they have to be integers.x and y the name given to an equation if one is looking for integer solutions. The most famous Diophantine equa-This last example is a typical Diophantine equation, tion is the Fermat equation$x^{n} + y^{n} = z^{n}$, which is now known, thanks to Andrew Wiles, to have no pos-itive integer solutions ifn is greater than 2.
(See fer- mat’s last theoremx2 + y2 = z2 has infinitely many solutions.) A great[V.10](/part-05/fermats-last-theorem). By contrast, the equation deal of modern concerned with Diophantine equations, either directly algebraic number theory [IV.1](/part-04/number-theory) is or indirectly. As with equations in the real and com-plex numbers, it is often fruitful to study the structure of sets of solutions to Diophantine equations: this investigation belongs to the area known asgeometry [IV.5](/part-04/arithmetic-geometry). arithmetic they tend to be extremely difficult.
It is therefore nat-ural to wonder whether there could be a systematic A notable feature of Diophantine equations is that approach to them. This question was the tenth in afamous list of problems asked by hilbert [VI.63](/part-06/david-hilbert-18621943) in

1900. It was not until 1970 that Yuri Matiyasevitch, building on work by Martin Davis, Julia Robinson, and Hilary Putnam, proved that the answer was no. (This is discussed further inproblem [V.20](/part-05/the-insolubility-of-the-halting-problem).) the insolubility of the halting bymake precise the notion of a “systematic approach,”An important step in the solution was taken in 1936, church [VI.89](/part-06/alonzo-church-19031995) and turing [VI.94](/part-06/alan-turing-19121954).
This was to by formalizing (in two different ways) the notion ofan algorithm (see algorithms [II.4 §3](/part-02/algorithms) and computational complexity this in the pre-computer age, but now we can restate[IV.20 §1](/part-04/computational-complexity)). It was not easy to do the solution of Hilbert’s tenth problem as follows: there is no computer program that can take as its input any Diophantine equation, and without fail print “YES” if it has a solution and “NO” otherwise. What does this tell us about Diophantine equations?
We can no longer dream of a final theory that will encompass them all, so instead we are forced to restrict our attention to individual equations or special classesof equations, continually developing different methods for solving them. This would make them uninteresting after the first few, were it not for the fact that specific Diophantine equations have remarkable links with very general questions in other parts of mathematics. For

I.4. The General Goals of Mathematical Research example, equations of the form y2 = f (x), where f (x) is a cubic polynomial inx, may look rather special, but in fact the central to modern number theory, including the proof elliptic curves [III.21](/part - 03/elliptic - curves) that they define are of Fermat’s last theorem. Of course, Fermat’s last theo-rem is itself a Diophantine equation, but its study has led to major developments in other parts of number theory. The correct moral to draw is perhaps this:
solv-ing a particular Diophantine equation is fascinating and worthwhile if, as is often the case, the result is morethan a mere addition to the list of equations that have been solved. 1.5 Differential Equations So far, we have looked at equations where the unknown is either a number or a point in(that is, a sequence ofn numbers). In order to generaten-dimensional space these equations, we took various combinations of thebasic arithmetical operations and applied them to our unknowns. equations, the first “ordinary” and the second “partial”:
Here, for comparison, are two well-known differential d2$x + k^{2}x = 0$,∂T∂t = κdt∂∂(x2)2 T2 + ∂∂y2 T2 + ∂∂z2 T2. The first is the equation for simple harmonic motion, which has the general solutionx(t) = A . in  kt +Bdiscussed in. os  kt; the second is the heat equation, which wassome fundamental mathematical definitions [I.3 §5.4](/part-01/fundamental-definitions). jump in sophistication. One is that the unknowns are functions For many reasons, differential equations represent a, which are much more complicated objects than numbers orn-dimensional points.
(For example, the first equation above asks what function the property that if you differentiate it twice then youx of t has get - k2 times the original function.) A second is that the basic operations one performs on functions include differentiation and integration, which are considerably less “basic” than addition and multiplication.
A third isthat differential equations that can be solved in “closed form,” that is, by means of a formula for the unknown functionf , are the exception rather than the rule, even when the equations are natural and important. Consider again the first equation above. Suppose that, given a function(d2 f /dt2) + k2 f . Thenf , we writeφ is a linear map, in the senseφ(f ) for the function thatφ(f + g) = φ(f ) + φ(g) and φ(af ) = aφ(f ) for any constant tion can be regarded as something like a matrix equa-$a$.
This means that the differential equation, but generalized to infinitely many dimensions. The heat equation has the same property: if we define ψ(T ) to be. artial T. artial t - κ . artial \1 artialx2 T2 + . artial \1 artialy2 T2 + . artial \1 artialz2 T2, thentions are calledψis another linear map. Such differential equa - linear , and the link with linear algebra makes them markedly easier to solve. (A very useful tool for this is the fourier transform [III.27](/part - 03/the - fourier - transform).) cannot be solved in closed form?
Then the focus shifts What about the more typical equations, the ones that once again toward establishing whether or not solu-tions exist, and if so what properties they have. As with polynomial equations, this can depend on what you count as an allowable solution. Sometimes we are in the position we were in with the equationx2 = 2: it is not too hard to prove that solutions exist and all that is left to do is name them. A simple example is the equationdy/dx = (e - x)2. In a certain sense, this cannot be solved:
it can be shown that there is no function built out of polynomials, exponentials[III.92](/part - 03/trigonometric - functions) that differentiates to e[III.25](/part - 03/the - exponential - and - logarithmic - functions), and trigonomet--x 2. How- ric functions ever, in another sense the equation is easy to solve— all you have to do is integrate the function eresulting function (when divided by. qrt{2π}) is the - x 2. Thenor- mal distribution [III.71 §5](/part - 03/probability - distributions) function.
The normal distribution is of fundamental importance in probability, so the function is given a name,Φ. a formula for a solution, even if one allows oneself to In most situations, there is no hope of writing down integrate “known” functions. A famous example is theso-called three-body problem [V.33](/part - 05/the - three - body - problem): given three bodies moving in space and attracted to each other by gravitational forces, how will they continue to move? Using Newton’s laws, one can write down some differential equations that describe this situation.
newton [VI.14](/part - 06/isaac - newton - 16421727) solved the corresponding equations for two bodies, and thereby explained why planets move in elliptical orbits around the Sun, but for three or more bodies they proved very hard indeed to solve. It is now knownthat there was a good reason for this: the equations can lead to chaotic behavior. (See dynamics [IV.14](/part - 04/dynamics) for more about chaos.) However, this opens up a new andvery interesting avenue of research into questions of chaos and stability.
Sometimes there are ways of proving that solutions exist even if they cannot be easily specified. Then one may ask not for precise formulas, but for general descriptions. For example, if the equation has a time dependence (as, for instance, the heat equation andwave equations have), one can ask whether solutions tend to decay over time, or blow up, or remain roughly the same.
These more qualitative questions concern what is known as techniques for answering some of them even when aasymptotic behavior, and there are solution is not given by a tidy formula. As with Diophantine equations, there are some special and important classes of partial differential equations, including nonlinear ones, that exactly. This gives rise to a very different style ofcan be solved research: again one is interested in properties of solu - tions, but now these properties may be more algebraic in nature, in the sense that exact formulas will playa more important role.
See linear and nonlinear waves and solitons [III.49](/part - 03/linear - and - nonlinear - waves - and - solitons). 2 Classifying If one is trying to understand a new mathematical struc - ture, such as a group [I.3 §2.1](/part - 01/fundamental - definitions) or a manifold [I.3 §6.9](/part - 01/fundamental - definitions), one of the first tasks is to come up with a good supply of examples. Sometimes examples are very easy to find, in which case there may be a bewildering array of them that cannot be put into any sort of order.
Often, how-ever, the conditions that an example must satisfy are quite stringent, and then it may be possible to come upwith something like an infinite list that includes every single one. For example, it can be shown that anytor space [I.3 §2.3](/part-01/fundamental-definitions) of dimension$n$over a field F is iso-vecmorphic to Fn. This means that just one positive inte- ger, this case our “list” will ben, is enough to determine the space completely. In{0}, F$, F^{2}$, F3, F4, . . . .
In such a situation we say that we have a mathematical structure in question.classification of the sify a mathematical structure then we have a new wayof proving results about that structure: instead of de-Classifications are very useful because if we can clasducing a result from the axioms that the structure isrequired to satisfy, we can simply check that it holds for every example on the list, confident in the knowledge that we have thereby proved it in general. Thisis not always easier than the more abstract, axiomatic approach, but it certainly is sometimes.
Indeed, thereare several results proved using classifications that nobody knows how to prove in any other way. More gen-erally, the more examples you know of a mathematical structure, the easier it is to think about that structure—testing hypotheses, finding counterexamples, and so

I. Introduction

on. If you knowfor some purposes your understanding is complete.all the examples of the structure, then

2.1 Identifying Building Blocks and Families

There are two situations that typically lead to inter-esting classification theorems. The boundary between them is somewhat blurred, but the distinction is clear enough to be worth making, so we shall discuss them separately in this subsection and the next. As an example of the first kind of situation, let us look at objects called polygons, polyhedra, and their higher-dimensional gen-regular polytopes. Polytopes are eral iz at i ons.
The regular polygons are those for which all sides have the same length and all angles are equal, and the regular polyhedra are those for which all faces are congruent regular polygons and every vertex hasthe same number of edges coming out of it. More generally, a higher-dimensional polytope is regular if it is as symmetrical as possible, though the precise definition of this is somewhat complicated. (Here, in three dimensions, is a definition that turns out to be equivalent tothe one just given but easier to generalize.
A flag is a triple(v, e, f ) where v is a vertex of the polyhedron, e is an edge containing polyhedron is regular if for any two flagsv , and f is a face containing(v, e, f ) eand. A(vtakes^ , e^ v, fto^ ) vthere is a symmetry of the polyhedron that^ , e to e^ , and f to f^ .) dimensions: for everyone regular It is easy to see what the regular polygons are in twok-gon and that is all there is. In three dimen-k greater than 2 there is exactly sions, the regular polyhedra are the famous solids, that is, the tetrahedron, the cube, the octahe-Platonic dron, the dodecahedron, and the icosahedron.
It is not too hard to see that there cannot be any more regu-lar polyhedra, since there must be at least three faces meeting at each vertex, and the angles at that vertex must add up to less than 360◦. This constraint means that the only possibilities for the faces at a vertex arethree, four, or five triangles, three squares, or three pentagons. These give the tetrahedron, the octahedron, the icosahedron, the cube, and the dodecahedron, respectively. have natural higher-dimensional analogues.
For exam-ple, if you take Some of the polygons and polyhedra just definedn + 1 points in Rn all at the same dis- tance from one another, then they form the verticesof a regular simplex, which is an equilateral triangle or regular tetrahedron whenn = 2 or 3. The set of all points$(x^{1}$, x2, . . . , xn) with 0 ⩽ xi ⩽ 1 for every i

I.4. The General Goals of Mathematical Research forms thecube. The octahedron can be defined as the set of alln-dimensional analogue of a unit square or points(x, y, z) in R3 such that |x| + |y | + |z| ⩽ 1, and the analogue of this inpoints(x , x , . . . , x ) such thatn dimensions is the set of all|x | + · · · + |x | ⩽ 1. hedron would lead to infinite families of regular poly-topes, and it turns out that they do not. In fact, apart It is not obvious how the dodecahedron and icosa-1 2(n1)n from three more examples in four dimensions, theabove polytopes constitute a complete list.
These three examples are quite remarkable. One of them has 120“three-dimensional faces,” each of which is a regular dodecahedron. It has a so-called dual, which has 600 regular tetrahedra as its “faces.” The third example can be described in terms of coordinates: its vertices are the sixteen points of the form(±1,±1, ±1,±1), together with the eight points(±2, 0, 0, 0), (0, ±2,0,0),(0,0,±2, 0)$, and (0$,0,0,±2).

is significantly harder to prove than the result sketched The theorem that these are all the regular polytopes above for three dimensions. The complete list was obtained by Schäfli in the mid nineteenth century; the first proof that there are no others was given by Donald Coxeter in 1969. mensions three and higher fall into three families—the We therefore know that the regular polytopes in di nand the octahedron—together with five “exceptional”-dimensional versions of the tetrahedron, the cube, examples—the dodecahedron, the icosahedron, and thethree four-dimensional polytopes just described.
This situation is typical of many classification theorems. The exceptional examples, often called “sporadic,” tend tohave a very high degree of symmetry—it is almost as if we have no right to expect this degree of symmetryto be possible, but just occasionally by a happy chance it is. The families and sporadic examples that occur indifferent classification results are often closely related, and this can be a sign of deep connections between areas that do not at first appear to be connected at all.
matical structures of a given kind, one identifies a cer - Sometimes, instead of trying to classify all mathetain class of “basic” structures out of which all theothers can be built in a simple way. A good analogy for this is the set of primes, out of which all other integers can be built as products. Finite groups, for example, are all “products” of certain basic groups thatare called simple. the classification of finite simple groups [V.7](/part - 05/the - classication - of - finite - simple - groups), one of the most famous theorems of twentieth-century mathematics, is discussed in part V.
also For more on this style of classification theorem, seelie theory [III.48](/part - 03/lie - theory). 2.2 Equivalence, Nonequivalence, and Invariants There are many situations in mathematics where two objects are, strictly speaking, different, but where we are not interested in the difference. In such situations we want to regard the objects as “essentially the same,”or “equivalent.” Equivalence of this kind is expressed formally by the notion of an[I.2 §2.3](/part - 01/language - and - grammar).
equivalence relation essentially the same if one is a continuous deforma-tion of the other, as we saw in [I.3 §6.4](/part - 01/fundamental - definitions). As pointed out For example, a topologist regards two shapes as there, a sphere is the same as a cube in this sense, andone can also see that the surface of a doughnut, that is, a torus, is essentially the same as the surface of ateacup.
(To turn the teacup into a doughnut, let the handle expand while the cup part is gradually swallowed upinto it.) It is equally obvious, intuitively speaking, that a sphere is not essentially the same as a torus, but this is much harder to prove. Why should nonequivalence be harder to prove than equivalence? The answer is that in order to show thattwo objects are equivalent, all one has to do is find a single transformation that demonstrates this equivalence. However, to show that two objects are not equivalent, one must somehow consider tions and show that not one of them works.
How canall possible transform a one rule out the existence of some wildly complicated continuous deformation that is impossible to visualize but happens, remarkably, to turn a sphere into a torus? are examples of Here is a sketch of a proof. The sphere and the torus compact orientable surfaces, which means, roughly speaking, two-dimensional shapes that occupy a finite portion of space and have no boundary. Given any such surface, one can find an equivalent sur-face that is built out of triangles and is topologically the same.
Here is a famous theorem of euler [VI.19](/part - 06/leonhard - euler - 17071783). Leta sphere, and suppose that it has P be a polyhedron that is topologically the same as V vertices, E edges, and F faces. Then V - E + F = 2. For example, ifvertices, thirty edges, and twenty faces, and 12 P is an icosahedron, then it has twelve - 30 + 20 is indeed equal to 2.For this theorem, it is not in fact important that the triangles are flat: we can draw them on the original sphere, except that now they are spherical triangles.
Itis just as easy to count vertices, edges, and faces when we do this, and the theorem is still valid. A network oftriangles drawn on a sphere is called a triangulation of the sphere. Euler’s theorem tells us that V - E + F = 2 regard less of what triangulation of the sphere we take. Moreover, the formula is still valid if the surface we triangulate is not a sphere but another shape that is topologically equivalent to the sphere, since triangulations can be continuously deformed without More generally, one can triangulate V , E, orany F surface, and changing. evaluate V - E + F.
The result is called the Euler charac- teristicwe need the following fact, which is a generalization ofof that surface. For this definition to make sense, Euler’s theorem (and which is not much harder to prove than the original result). (i) Although a surface can be triangulated in manyways, the quantity V - E + F will be the same for all triangulations. If we continuously deform the surface and continuously deform one of its triangulations at the sametime, we can deduce that the Euler characteristic of the new surface is the same as that of the old one.
Inother words, fact (i) above has the following interesting consequence. (ii) If two surfaces are continuous deformations of eachother, then they have the same Euler characteristic. This gives us a potential method for showing that sur-faces are not equivalent: if they have different Euler characteristics then we know from the above that they are not continuous deformations of each other.
The Euler characteristic of the torus turns out to be 0 (as one can show by calculating V - E + F for any triangu- lation), and that completes the proof that the sphere and the torus are not equivalent. The Euler characteristic is an example of an invariant the set of all objects of the kind one is studying, with. This means a functionφ, the domain of which is the property that ifthen$φ(X) = φ(Y )$. To show that X and Y are equivalent objects, X is not equivalent$to$φ(X)Y, it is enough to find an invariant andφ(Y )are different.
Sometimes the valuesφ for whichφ takes are numbers (as with the Euler characteristic), butoften they will be more complicated objects such as polynomials or groups. It is perfectly possible forφ(X) to equal φ(Y ) even whenwould be the invariant X and Y are not equivalent. An extreme exampleφ that simply took the value 0

I. Introduction

for every object X. However, sometimes it is so hard to prove that objects are not equivalent that invariants canbe considered useful and interesting even when they work only part of the time. There are two main properties that one looks for in an invariant tions. One is that it should be asφ, and they tend to pull in opposite direc-fine as possible: that is, as often as possibleφ(X) and φ(Y )are different if Xpossible one should actually be able to establish whenand Y are not equivalent.
The other is that as often asφ(X)having a fine invariant if it is impossible to calculate.is different fromφ(Y ). There is not much use in (An extreme example would be the “trivial” invariant that simply mapped eachis as fine as possible, but unless we have some indepen-X to its equivalence class. It dent means of specifying it, then it does not represent an advance on the original problem of showing that two objects are not equivalent.) The most powerful invariants therefore tend to be ones that can be calculated, but not very easily. lucky:
not only is the Euler characteristic an invariant In the case of compact orientable surfaces, we are that is easy to calculate, but it also classifies the compact orientable surfaces completely. To be precise, the Euler characteristic of a compact orientable surfacek is if and only if it is of the form 2-2 g for some nonnega-tive integer2,0,-2, -4, . . .g (so the possible Euler characteristics are), and two compact orientable surfaces with the same Euler characteristic are equivalent.
Thus, if we regard equivalent surfaces as the same, then the num be rg gives us a complete specific at i on of a surface. It is called the genus of the surface, and can be interpreted geometrically as the number of “holes” the surface has (so the genus of the sphere is 0 and that of the torus is 1). For other examples of invariants, see algebraic topology [IV.6](/part - 04/algebraic - topology) and knot polynomials [III.44](/part - 03/knot - polynomials). 3 Generalizing When an important mathematical definition is formulated, or theorem proved, that is rarely the end of the story.
However clear a piece of mathematics may seem, it is nearly always possible to understand it better, and one of the most common ways of doing so is to present it as a special case of something more general. Thereare various different kinds of generalization, of which we discuss a few here.

I.4. The General Goals of Mathematical Research

3.1 Weakening Hypotheses and Strengthening

Conclusions

The number 1729 is famous for being expressible as thesum of two cubes in two different ways: it is 13$+123 and$ also 93$+ 103$. Let us now try to decide whether there is a number that can be written as the sum of four cubesin ten different ways. clear that any such number, if it exists, must be very At first this problem seems alarmingly difficult. It is large and would be extremely tedious to find if we sim-ply tested one number after another. So what can we do that is better than this? our hypotheses.
The problem we wish to solve is of The answer turns out to be that we should weaken the following general kind. We are given a sequence$a1$, a2, a3, . . . of positive integers and we are told that it has a certain property. We must then prove that there is a positive integer that can be written as a sum offour terms of the sequence in ten different ways.
This is perhaps an artificial way of thinking about the prob-lem since the property we assume of the sequence is the property of “being the sequence of cubes,” whichis so specific that it is more natural to think of it as anthinking encourages us to consider the possibility that identification of the sequence. However, this way of the conclusion might be true for a much wider class ofsequences. And indeed this turns out to be the case. 1 000 000 000.
We shall now see that this property aloneis sufficient to guarantee that there is a number that There are a thousand cubes less than or equal to can be written as the sum of four cubes in ten different ways. That is, if$a1$, a2$, a3$, . . . is any sequence of pos- itive integers, and if none of the first thousand terms exceeds 1 000 000 000, then some number can be writ-ten as the sum of four terms of the sequence in ten different ways. ber of different ways of choosing four distinct termsfrom the sequence To prove this, all we have to do is notice that the num-a , a , . . .
, a is 1000 . imes 999 . imes 998 . imes 997 sum of any four terms of the sequence cannot exceed/24, which is greater than 4(01)2 1000. imes  1 000 000 000. The$4$. imes 1 000 000 000. It follows that the average number of ways of writing one of the first 4 000 000 000 numbersas the sum of four terms of the sequence is at least ten. But if the average number of representations is at leastten, then there must certainly be numbers that have at least this number of representations. way? One might think that it would be harder to prove Why did it help to generalize the problem in this

a result if one assumed less. However, that is oftennot true. The less you assume, the fewer options you have when trying to use your assumptions, and thatcan speed up the search for a proof. Had we not generalized the problem above, we would have had toomany options. For instance, we might have found ourselves trying to solve very difficult Diophantine equa-tions involving cubes rather than noticing the easy counting argument. In a way, it was only once we had weakened our hypotheses that we understood the true nature of the problem. strengthening of the conclusion:
the problem asks for We could also think of the above generalization as a a statement about cubes, and we prove not just thatbut much more besides. There is no clear distinction between weakening hypotheses and strengthening conclusions, since if we are asked to prove a statementof the form P ⇒ Q, we can always reformulate it as¬hypotheses of Q ⇒ ¬P . Then, if we weaken P ⇒ Q but strengthening the conclusion P we are weakening the$of$¬Q ⇒ ¬P .

3.2 Proving a More Abstract Result

A famous result in modular arithmetic, known asmat’s little theorem [III.58](/part-03/modular-arithmetic), states that ifp fer-is a prime anda remainder of 1 when you divide bya is not a multiple of p, thenp. That is,(ap)-1 aleave(sp)-1 iscongruent to 1 mod p. is a good illustration of a certain kind of generalization. There are several proofs of this result, one of which Here is the argument in outline. The first step is to showthat the numbers 1,2, . . . , p - 1 form a group[I.3 §2.1](/part - 01/fundamental - definitions) under multiplication modp.
(This means multiplica- tion followed by taking the remainder on division by For example, if$p =$7 then the “product” of 3 and 6 is 4, p. since 4 is the remainder when you divide 18 by 7.) Thenext step is to note that if 1⩽ a ⩽ p - 1 then the powers ofthe size of the subgroup is the smallest positive inte-a (mod p) form a subgroup of this group. Moreover,$ger$ m such that am is congruent to 1 mod p. One then appliesof a group is always divisible by the size of any of its Lagrange’s theorem, which states that the size subgroups.
In this case, the size of the group isfrom which it follows thatp - 1 is divisible by mp. But- 1, then, since$a^{m} = 1$, it follows that (ap)-1 = 1. when viewed appropriately, just one special case of This argument shows that Fermat’s little theorem is, Lagrange’s theorem. (The word “just” is, however, a lit-tle misleading, because it is not wholly obvious that the

integers modis proved usingp form a group in the way stated. This fact euclid’s algorithm [III.22].) Fermat could not have viewed his theorem in this way, since the concept of a group had not been invented when he proved it. Thus, the abstract concept of a group helps one to see Fermat’s little theorem in a completely new way: it can be viewed as a special case ofa more general result, but a result that cannot even be stated until one has developed some new, abstract concepts.
obviously, it provides us with a more general theo-rem, one that has many other interesting particular This process of abstraction has many benefits. Most cases. Once we see this, then we can prove the gen-eral result once and for all rather than having to prove each case separately. A related benefit is that it enables us to see connections between results that may origi-nally have seemed quite different. And finding surprising connections between different areas of mathematics almost always leads to significant advances in the subject.

3.3 Identifying Characteristic Properties

There is a marked contrast between the way one defines. qrt2 and the way one defines$\sqrt{-1}$, or i as it is usually written. In the former case one begins, if one is being careful, by proving that there is exactly one positive real number that squares to 2. Then$\sqrt{}$2 is defined to be this number. is no real number that squares toasks the following question: if there were a number that This style of definition is impossible for i since there-1. So instead one squared to - 1, what could one say about it?
Such a number would not be a real number, but that does notrule out the possibility of extending the real number system to a larger system that contains a square rootof - 1. thing about i: that ithat i obeys the normal rules of arithmetic, then we can At first it may seem as though we know precisely one2= −1. But if we assume in addition do more interesting calculations, such as(i + 1)2 = i2 + 2 i + 1 . qrt= −1 + 2 i + 1 = 2 i, which implies that(i + 1)/ 2 is a square root of i.
From these two simple assumptions—that i2$= −1$ and that i obeys the usual rules of arithmetic—wecan develop the entire theory of complex numbers [I.3 §1.5](/part-01/fundamental-definitions) without ever having to worry about what i actually is. And in fact, once you stop to think about it,

I. Introduction

the existence oftice anything like as important as$\sqrt{2}$, though reassuring, is not in prac-its defining properties, which are very similar to those of i: it squares to 2 and obeys the usual rules of arithmetic. in a similar way. Another example is the definition ofxa Many important mathematical generalizations workwhen x and a are real numbers with x positive. It is difficult to make sense of this expression in a direct wayunlessa is a positive integer, and yet mathematicians are completely comfortable with it, whatever the valueof$a$. How can this be?
The answer is that what really matters aboutxa is not its numerical value but its char- acteristic properties when one thinks of it as a function of$x^{a}a^{+b}$. The most important of these is the property that= xaxb. Together with a couple of other simple properties, this completely determines the function$xa$. More importantly, it is these characteristic properties that one uses when reasoning about$xa$. This example is discussed in more detail in the exponential and logarithmic functions [III.25](/part-03/the-exponential-and-logarithmic-functions). tion and classification.
The word “abstract” is oftenused to refer to a part of mathematics where it is There is an interesting relationship between abstracmore common to use characteristic properties of anobject than it is to argue directly from a definition of the object itself (though, as the example of$\sqrt{2} shows$, this distinction can be somewhat hazy). The ultimatein abstraction is to explore the consequences of a system of axioms, such as those for a group or a vector space.
However, sometimes, in order to reason aboutsuch algebraic structures, it is very helpful to classify them, and the result of classification is to make them more concrete again. For instance, every finite-dimensional real vector space V is isomorphic to Rn for some nonnegative integer ful to think of V as the concrete objectn, and it is sometimes help-Rn, rather than as an algebraic structure that satisfies certain axioms. Thus, in a certain sense, classification is the opposite of abstraction.

3.4 Generalization after Reformulation

dimension part of everyday language: for example, we say that ais a mathematical idea that is also a familiar photograph of a chair is a two-dimensional representation of a three-dimensional object, because the chairhas height, breadth, and depth, but the image just has height and breadth. Roughly speaking, the dimension of a shape is the number of independent directions one can move about in while staying inside the shape,

I.4. The General Goals of Mathematical Research and this rough conception can be made mathematically precise (using the notion of a vector space [I.3 §2.3](/part-01/fundamental-definitions)). If we are given any shape, then its dimension, as one would normally understand it, must be a nonnegative integer: it does not make much sense to say that one can move about in 1.4 independent directions, for example. And yet there is a rigorous mathematical theory oftional dimension, in which for every nonnegative real frac numberdyou can find many shapes of dimensiond. possible?
The answer is that they How do mathematicians achieve the seemingly im-reformulate the concept of dimension and only then do they generalize it. What this means is that they give a new definition of dimension with the following two properties. (i) For all “simple” shapes the new definition agrees with the old one. For example, under the new definition a line will still be one dimensional, a squaretwo dimensional, and a cube three dimensional. (ii) With the new definition it is no longer obvious that the dimension of every shape must be a positive integer.
There are several ways of doing this, but most of them focus on the differences between length, area, and vol-ume. Notice that a line segment of length 2 can be expressed as a union of two nonoverlapping line segments of length 1, a square of side-length 2 can beexpressed as a union of four nonoverlapping squares of side-length 1, and a cube of side-length 2 can be expressed as a union of eight nonoverlapping cubes ofside-length 1. It is because of this that if you enlarge ad- dimensional shape by a factor“volume” is multiplied byrd.
Now suppose that your , then its d-dimensional would like to exhibit a shape of dimension 1 of doing it is to letr = 25/7, so that (r1().){4} =.2, and find4. One way a shape X such that if you expand X by a factor of r , then the expanded shape can be expressed as a unionof two disjoint copies of X. Two copies of X ought to have twice the “volume” ofd of X ought to satisfy the equation X itself, so the dimensionrd = 2. By our choice of For more details, seer , this tells us that the dimension ofdimension [III.17](/part-03/dimension). X is 1.4.
Another concept that seems at first to make no sense isapplies to noncommutative geometry binary operations. The word “commutative”[I.2 §2.4](/part-01/language-and-grammar) and therefore belongs to algebra rather than geometry, so what could “noncommutative geometry” possibly mean? reformulates part of geometry in terms of a certain By now the answer should not be a surprise: one

algebraic structure and then generalizes the algebra. The algebraic structure involves a commutative binary operation, so one can generalize the algebra by allowing the binary operation not to be commutative. The part of geometry in question is the study of manifolds the set C(X)[I.3 §6.9](/part-01/fundamental-definitions). Associated with a manifoldof all continuous complex-valued func-X is tions defined on X.
Given two functions f , g in C(X), and two complex numbersnation. ambda f + \mu g is another continuous complex-valued. ambda and μ, the linear combi- function, so it also belongs tois a vector space. However, one can also C(X). Therefore, multiply C(X)f$and$(f g)(x)g to form the continuous function= f (x)g(x)). This multiplication has variousf g(defined by natural properties (for instance,$f (g + h) = f g + f h$ for all functions algebra, and even a$f$, Cg*, and h) that make[IV.15 §3](/part-04/operator-algebras).
It turns out C(X) into an that a great deal of the geometry of a compact mani--algebra fold responding X can be reformulated purely in terms of the cor-C*-algebra C(X). The word “purely” here means that it is not necessary to refer to the manifold X in terms of which the algebra C(X) was originally defined—all one uses is the fact that C(X) is an alge- bra. This raises the possibility that there might be alge-bras that do not arise geometrically, but to which the reformulated geometrical concepts nevertheless apply. An algebra has two binary operations: addition and multiplication.
Addition is always assumed to be commutative, but multiplication is not: when multiplica-tion is commutative as well, one says that the algebra is commutative. Sincesame function, the algebraf g C(X)and gfis a commutative are clearly the C*-algebra, so the algebras that arise geometrically are always commutative. However, many geometrical con-cepts, once they have been reformulated in algebraic terms, continue to make sense for noncommutative C*- algebras, and that is why the phrase “noncommuta - tive” geometry is used.
For more details, see operator algebras This process of reformulating and then generalizing[IV.15 §5](/part - 04/operator - algebras). underlies many of the most important advances in mathematics. Let us briefly look at a third example. the fundamental theorem of arithmetic [V.14](/part - 05/the - fundamental - theorem - of - arithmetic) is, as its name suggests, one of the foundation stones of number theory:
it states that every positive integer can be written in exactly one way as a product of prime numbers. However, number theorists like to look at enlarged number systems, and for most of these the obvious analogue of the fundamental theorem of arithmetic isno longer true. For example, in the ring [III.81 §1](/part - 03/rings - ideals - and - modules) of numbers of the form required to be integers), the number 6 can be writ - a + b . qrt{-5} (where a and b are ten either as 2 none of the numbers 2, 3, 1 . imes 3 or as (1 ++. qrt. qrt--55, or 1) . imes (1 --. qrt. qrt--55 can be).
Since decomposed further, the number 6 has two genuinely different prime factorizations in this ring. There is, however, a natural way of generalizing the concept of “number” to include[III.81 §2](/part - 03/rings - ideals - and - modules) that allow one to prove a version of the fun-ideal numbers damental theorem of arithmetic in rings such as theone just defined. First, we must reformulate: we associate with each numberδγ, where δ belongs to the ring. This set, which isγ the set of all its multiples denoted andβ belong to(γ), has the following closure property:
if(γ) and δ and are any two elementsα of the ring, thenδα + β belongs to (γ). an A subset of a ring with that closure property is called ideal. If the ideal is of the form(γ) for some num- berare ideals that are not principal, so we can think of theγ, then it is called a principal ideal. However, there set of ideals as generalizing the set of elements of the original ring (once we have reformulated each element γnatural notions of addition and multiplication that canas the principal ideal (γ)). It turns out that there are be applied to ideals.
Moreover, it makes sense to definean ideal$I$to be “prime” if the only way of writing I as a product enlarged set, unique factorization turns out to hold. JK is if one of J and Kis a “unit.” In this These concepts give us a very useful way to measure “the extent to which unique factorization fails” in the original ring. For more details, see algebraic numbers [IV.1 §7](/part-04/number-theory).

3.5 Higher Dimensions and Several Variables

We have already seen that the study of polynomial equations becomes much more complicated when one looks not just at single equations in one variable, but at systems of equations in several variables. Similarly, we have seen thattions [I.3 §5.4](/part-01/fundamental-definitions), which can be thought of as differen-partial differential equatial equations involving several variables, are typically much more difficult to analyze than ordinary differential equations, that is, differential equations in just one variable.
These are two notable examples of a process that has generated many of the most important prob-lems and results in mathematics, particularly over the last century or so: the process of generalization fromone variable to several variables. variables, Suppose one has an equation that involves three realx, y , and z. It is often useful to think of I. Introduction packing of circles in the plane. Figure 1 The densest possible the triple than as a collection of three numbers. Further more,(x, y, z) as an object in its own right, rather this object has a natural interpretation:
it represents a point in three-dimensional space. This geometrical interpretation is important, and goes a long way toward explaining why extensions of definitions and theorems from one variable to several variables are so interest - ing. If we generalize a piece of algebra from one variable to several variables, we can also think of what weare doing as generalizing from a one-dimensional setting to a higher-dimensional setting. This idea leadsto many links between algebra and geometry, allowing techniques from one area to be used to great effect in the other.
4 Discovering Patterns Suppose that you wish to fill the plane as densely aspossible with nonoverlapping circles of radius 1. How should you do it? This question is an example of a socalledis what one might expect: you should arrange the cir-packing problem. The answer is known, and it cles so that their centers form a triangular lattice, as shown in figure 1. In three dimensions a similar resultis true, but much harder to prove: until recently it was a famous open problem known as the Kepler conjec - ture.
Several mathematicians wrongly claimed to have solved it, but in 1998 a long and complicated solution, obtained with the help of a computer, was announced by Thomas Hales, and although his solution has proved very hard to check, the consensus is that it is probably correct. any number of dimensions, but they become harderand harder as the dimension increases. Indeed, it is Questions about packing of spheres can be asked in likely that the best density for a ninety - seven - dimen-sional packing, say, will never be known.
Experience with similar problems suggests that the best arrange-ment will almost certainly not have a simple structure such as one sees in two dimensions, so that the only I.4. The General Goals of Mathematical Research method for finding it would be a “brute-force search”of some kind. However, to search for the best possible complicated structure is not feasible: even if one could somehow reduce the search to finitely many possibili - ties, there would be far more of them than one could feasibly check. When a problem looks too difficult to solve, one should not give up completely.
A much more productive reaction is to formulate related but more approach-able questions. In this case, instead of trying to discover the very best packing, one can simply see how dense apacking one can find. Here is a sketch of an argument that gives a goodish packing inn dimensions, when n is large. One begins by taking ais, one simply picks sphere after sphere until it is nomaximal packing: that longer possible to pick another one without it overlap-ping one of the spheres already chosen. Now letx be any point in Rn.
Then there must be a sphere in our collection such that the distance between ter is less than 2, since otherwise we could take a unitx and its cen- sphere about other spheres. Therefore, if we take all the spheres inx and it would not overlap any of the the collection and expand them by a factor of 2, thenwe cover all of Rn. Since expanding an n-dimensional sphere by a factor of 2 increases its (volume by a factor of 2 n, the proportion ofn - dimensional)Rn covered by the unexpanded spheres must be at least 2 - n.
Notice that in the above argument we learned nothing at all about the nature of the arrangements of spheres with density 2 - n. All we did was take a maximal pack - ing, and that can be done in a very haphazard way. Thisis in marked contrast with the approach that worked in two dimensions, where we defined a specific pattern of circles. This contrast pervades all of mathematics.
For some problems, the best approach is to build a highly struc-tured pattern that has the properties you need, while for others—usually problems for which there is no hope of obtaining an exact answer—it is better to lookfor less specific arrangements. “Highly structured” in this context often means “possessing a high degree ofsymmetry.” The triangular lattice is a rather simple pattern, but some highly structured patterns are much more com - plicated, and much more of a surprise when they are discovered. A notable example occurs in packing prob - lems.
By and large, the higher the dimension you are working in, the more difficult it is to find good patterns, but an exception to this general rule occurs attwenty-four dimensions. Here, there is a remarkable construction, known as therise to a miraculously dense packing. Formally, a Leech lattice, which gives lattice in Rn is a subset Λ with the following three properties. (i) Ifx and y belong to Λ, then so do x + y and x - y. (ii) Ifx belongs to Λ, then x is isolated. That is, there is someand any other point ofd > 0 such that the distance betweenΛ is at least d.
x (iii)Λsubspace ofis not contained in any Rn$. (n - 1)-dimensional$ A good example of a lattice is the setin Rn with integer coordinates. If one is searching for Zn of all points a dense packing, then it is a good idea to look at lattices, since if you know that every nonzero point in alattice has distance at leastd from 0, then you know thatother. This is because the distance between any two points have distance at leastdxfrom eachand y is the same as the distance between 0 andy - x, both of which lie in the lattice ifhaving to look at the whole lattice, one can get awayx and y do.
Thus, instead of with looking at a small portion around 0. is a lattice and that it is unique, in the sense that any other lattice In twenty-four dimensions it can be shown that thereΛ with the following additional properties, with those properties is just a rotation of the first one. (iv) There is a 24 . imes 24 matrix M with determinant [III.15](/part - 03/determinants) equal to 1 such thatΛ consists of all integer (v) if combinations of the columns offrom 0 tov is a point inv is an even integer.Λ, then the square of the distance M .
(vi) The nonzero vector nearest to 0 is at distance 2.Thus, the balls of radius 1 about the points inΛ form a packing of R24. The nonzero vector nearest to 0 is far from unique: in fact there are 196 560 of them, which is a remarkably large number considering that these points must all be at distance at least 2 from each other. of symmetry. To be precise, it has 8 315 553 613 086720 000 rotational symmetries.
(This number equals The Leech lattice also has an extraordinary degree 222· 39 · 54 · 72 · 11 · 13 · 23.) If you take the tie nt consisting of the identity and minus the identity, then[I.3 §3.3](/part - 01/fundamental - definitions) of its symmetry group by the subgroup quo you obtain thefamous sporadic Conway group simple groups Co[V.7](/part - 05/the - classication - of - finite - simple - groups).
The existence of1, which is one of the so many symmetries makes it easier still to determine the smallest distance from 0 of any nonzero point ofthe lattice, since once you have checked one distance you have automatically checked lots of others (just as, in the triangular lattice, the six-fold rotational symmetry tells us that the distances from 0 to its six neighbors are all the same). principle of mathematical research: often, if a mathe-matical construction has one remarkable property, it These facts about the Leech lattice illustrate a general will have others as well.
In particular, a high degree ofsymmetry will often be related to other interesting features. So, although it is a surprise that the Leech lattice exists at all, it is not as surprising when one then discovers that it gives an extremely dense packing of R24. In fact, it was shown in 2004 by Henry Cohn and Abhi-nav Kumar that it gives the densest possible packing of spheres in twenty-four-dimensional space, at least among all packings derived from lattices. It is probably the densest packing of any kind, but this has not yetbeen proved.
5 Explaining Apparent Coincidences The largest of all the sporadic finite simple groups iscalled the Monster group. Its name is partly explained by the fact that it has 246· 320 · 59 · 76 · 112 · 133 · 17 ·$19$· 23 · 29 · 31 · 41· 47 · 59 · 71 elements. How can one hope to understand a group of this size?One of the best ways is to show that it is a group of symmetries of some other mathematical object (seethe article on representation theory [IV.9](/part-04/representation-theory) for much more on this theme), and the smaller that object is, thebetter.
We have just seen that another large sporadic group, the Conway group Cosymmetry group of the Leech lattice. Might there be a1, is closely related to the lattice that played a similar role for the Monster group?It is not hard to show that there will be at least some lattice that works, but more challenging is to find oneof small dimension. It has been shown that the smallest possible dimension that can be used is 196 883.Now let us turn to a different branch of mathematics.
If you look at the article about[IV.1 §8](/part-04/number-theory) you will see a definition of a function algebraic numbersj(z), called thetance in algebraic number theory. It is given as the sum elliptic modular function, of central imporof a series that starts j(z) = (e-2()π){i}z + 744 + 196 884(e2()π){i}z + 21 493 760(e4()π){i}z + 864 299 970(e6()π){i}z + · · · . Rather intriguingly, the coefficient of e2πi z in this series is 196 884, one more than the smallest possible dimen-sion of a lattice that has the Monster group as its group of symmetries.

I. Introduction

observation, and when it was first made by John Mc Kay It is not obvious how seriously we should take this opinions differed about it. Some believed that it was probably just a coincidence, since the two areas seemed to be so different and unconnected. Others took the attitude that the function are so important in their respective areas, and the num-j(z) and the Monster group ber 196 883 so large, that the surprising numerical factwas probably pointing to a deep connection that had not yet been uncovered.
studying the coefficients in the series forand John Thompson were led to a conjecture that It turned out that the second view was correct. Afterj(z), Mc Kay related them all (and not just 196 884) to the Mon-ster group. This conjecture was extended by John Conway and Simon Norton, who formulated the “Monstrous Moonshine” conjecture, which was eventually proved by Richard Borcherds in 1992. (The word “moonshine” reflects the initial disbelief that there would be a seri-ous relationship between the Monster group and the

j-function.)

duced a new algebraic structure, which he called a In order to prove the conjecture, Borcherds intro-vertex algebra used results from[IV.17](/part-04/vertex-operator-algebras). And to analyze vertex algebras, hestring theory [IV.17 §2](/part-04/vertex-operator-algebras). In other words, he explained the connection between two very different-looking areas of pure mathematics with thehelp of concepts from theoretical physics. This example demonstrates in an extreme way another general principle of mathematical research:
if youcan obtain the same series of numbers (or the same structure of a more general kind) from two different mathematical sources, then those sources are probably not as different as they seem. Moreover, if you can find one deep connection, you will probably beled to others. There are many other examples where two completely different calculations give the same answer, and many of them remain unexplained. this phenomenon results in some of the most difficult and fascinating unsolved problems in mathematics.
(See the introduction to mirror symmetry [IV.16](/part - 04/mirror - symmetry) for another example.) mathematical “coincidence.” There may not seem to beanything special about the number e Interestingly, thej-function leads to a second famousπ. qrt163, but here is the beginning of its decimal expansion: e$π\sqrt{}163 = 262 537 412 640 768 743$.99\,999\,999\,999\,925 . . . , I.4. The General Goals of Mathematical Research which is astonishingly close to an integer. Again it isinitially tempting to dismiss this as a coincidence, but one should think twice before yielding to the tempta - tion.
After all, there are not all that many numbers that can be defined as simply as eπ. qrt163, and each one has a probability of less than one in a million million ofbeing as close to an integer as eπ. qrt163 is. In fact, it is not a coincidence at all: for an explanation see numbers [IV.1 §8](/part - 04/number - theory). algebraic 6 Counting and Measuring How many rotational symmetries are there of a regular icosahedron? Here is one way to work it out. Choose a vertexv of the icosahedron and let v^ be one of its neighbors.
An icosahedron has twelve vertices, so thereare twelve places wherev could end up after the rota - tion. Once we know where bi li ties forv(since each vertex has five neighbors andvgoes, there are five possiv^ must still be a neighbor of v after the rotation).
Once we have determined wherev and v^  go, there is no fur- ther choice we can make, so the number of rotational symmetries is 5$\times 12 = 60$.$is$, an answer to a question that begins “How many.”However, the word “argument” is at least as important This is a simple example of a counting argument, that as the word “counting,” since we do not put all the sym-metries in a row and say “one, two, three,. . ., sixty,” as we might if we were counting in real life. What we do instead is come up with a reason for the number of rotational symmetries being 5. imes  12.
At the end of the process, we understand more about those symmetries than merely how many there are. Indeed, it is possibleto go further and show that the group of rotations of the icosahedron is$A^{5}$, the alternating group [III.68](/part-03/permutation-groups) on five elements.

6.1 Exact Counting

Here is a more sophisticated counting problem. a dimensional random walk ofn steps is a sequence one- of integers differenceaa0-, aa1$, a2$, . . . , ais either 1 orn, such that for each-1. For example, i the0 number of, 1, 2, 1, 2, n1,-step random walks that start at 0 is clearlyi0, -1 is a seven-step random walk. Thei^-1$2$ n, since there are two choices for each step (either you add 1 or you subtract 1). walks of length 2 Now let us try a slightly harder problem. How manyn are there that start and endat 0?
(We look at walks of length 2 n since a walk that starts and ends in the same place must have an even numberof steps.) the letters R and L (for “right” and “left”) to denote adding 1 and subtracting 1, respectively. This gives In order to think about this problem, it helps to use us an alternative notation for random walks that startat 0: for example, the walk 0, 1, 2, 1, 2, 1, 0, -1 would berewritten as RRLRLLL. Now a walk will end at 0 if andonly if the number of Rs is equal to the number of Ls. Moreover, if we are told the set of steps where an Roccurs, then we know the entire walk.
So what we are counting is the number of ways of choosing2 n steps as the steps where an R will occur. And this isn of the well-known to be(2 n)!$/(n$!)2. ably less easy to determine: the number Now let us look at a related quantity that is consider-W (n) of walks of length 2 ative. Here, in the notation introduced for the previousn that start and end at 0 and are never neg- problem, is a list of all such walks of length 6: RRRLLL, RRLRLL, RRLLRL, RLRRLL, and RLRLRL. end at 0 but visit it in the middle:
RRLLRL visits it after Now three of these five walks do not just start and four steps, RLRRLL after two, and RLRLRL after two andfour. Suppose we have a walk of length 2 n that is never negative and visits 0 for the first time after 2 Then the remainder of the walk is a walk of lengthk steps.$2$(n - k) that starts and ends at 0 and is never nega- tive. There are W (n - k)of these. As for the first 2$k$ steps of such a walk, they must begin with R and endwith L, and in between must never visit 0.
This means that between the initial R and the final L they give awalk of length 2(k - 1) that starts and ends at 1 and is never less than 1. The number of such walks is clearly the same as$W (k - 1)$. Therefore, since the first visit to 0 must take place after 21 andn, Wsatisfies the following slightly compl i ca te dk steps for some k between recurrence relation: $W (n) = W (0)W (n - 1) + · · · + W (n - 1)W (0)$. Here, This allows us to calculate the first few values of W (0) is taken to be equal to 1.W . We have W (1) = W (0)W (0) = 1, which is eas- ier to see directly:
the only possibility is RL. Then$W (2) = W (1)W (0) + W (0)W (1) = 2$, and W (3), which counts the number of such walks of length 6, equals W (0)W (2) + W (1)W (1) + W (2)W (0) =5, confirming our earlier calculation. Of course, it would not be a good idea to use the recurrence relation directly if one wished to work out W (n) for large values of n such as 1010.
However, the recurrence is of a sufficiently nice form that itis amenable to treatment by generating functions [[IV.18 §§2.4, 3]](/part - 04/enumerative - and - algebraic - combinatorics), as is explained in enumerative and algebraic combinatorics nection with that discussion, replace the letters R and[IV.18 §3](/part - 04/enumerative - and - algebraic - combinatorics). (To see the con L by the square brackets [ and ], respectively. A legal bracketing then corresponds to a walk that is never negative.)The argument above gives an efficient way of calculating W (n) exactly.
There are many other exact count- ing arguments in mathematics. Here is a small further sample of quantities that mathematicians know how to count exactly without resorting to “brute force.” (Seethe introduction to [IV.18](/part-04/enumerative-and-algebraic-combinatorics) for a discussion of when one regards a counting problem as solved.) by concurrent. The first four values of(i) The numbern lines if no two of the lines are parallel and no threer (n) of regions that a plane is cut intor (n) are 2, 4, 7, and

11. It is not hard to prove thatwhich leads to the formula$r (n)r (n)=1(n = 2 + r (nn +-21))$. This+ n, statement, and its proof, can be generalized to higher dimensions. 2 (ii) The numbers(n) of ways of writing n as a sum of four squares. Here we allow zero and negative numbers and we count different orderings as different (so, for example, 142+2^2, and 0^2+3^2^2++14^2^2++22^2^2+, 35^2^2+are considered to be four4^2+1^2+2^2, 1^2 +(-3)^2 + different ways of writing 30 as a sum of four squares).It can be shown thats(n) is equal to 8 times the sum of all the divisors ofexample, the divisors of
12 are 1, 2, 3, 4, 6, and 12, ofn that are not multiples of 4. For which 1, 2, 3, and 6 are not multiples of 4. Therefore$s(12) = 8(1 + 2 + 3 + 6) =$96. The different ways are 12$+12 + 12 + 32$, 0 + 22 + 22 + 22, and the other expressions that can be obtained from these ones by reordering and replacing positive integers by negative ones.
four lines Leral position.” (This means that they do not have special(iii) The number of lines in space that meet a given1, L2, L3, and L4 when those four are in “gen properties such as two of them being parallel or intersecting each other.) It turns out that for anylines, there is a subset of R3 known as a quadric surface three such that contains them, and this quadric surface is unique. Let us take the surface for L , L , and L and call it S. allow us to solve the problem.
The main one is thatone can find a continuous family of lines (that is, a col-The surface S has some interesting properties tha(t1)2 3 lection of lines varies continuously with L(t), one for each real numbert) that, between them, maket, that I. Introduction up the surface and L . But there is also S and include each of the lines Lanother such continuous fam - 1, L2, ily of lines exactly one point. In particular, every line3 M(s), each of which meets every line M(s)L(t)meetsin all of Lof L , L1, L, and L2, and Lmust be one of the lines3, and in fact every line that meets all M(s).
exactly two points, P and Q . Now P lies in some line M(s)It can be shown that L1 from the second family, and Q lies in some othe(r2()3)4 intersects the surface S in lineequal M(s M(s)^ )(which must be different, or else Land intersect L1, L2, and L3, contradicting4 would the fact that the lines L are in general position). There$i$ fore, the two lines M(s) and M(s^ ) intersect all four of the lines Lbe one of the linesi. But every line that meets all the LM(s) and has to go through eitheri has to P or Q (since the lines M(s) lie in S and L4 meets S at only those two points).
Therefore, the answer is 2.This question can be generalized very considerably, and answered by means of a technique known as Schubert calculus. integer number is 11, since 6(iv) The numbern as a sum of positive integers. Whenp(n)=of ways of expressing a positive1 + 1 + 1 + 1 + 1 + 1 = n2 +=16 this + 1 +$13$++13 ==24++21++11+=1 = 4 + 2 + 2 2=+52+=1 3=+6. The function1 + 1 + 1 = 3 + 2 + p(n)1 = is called the partition function.
A remarkable formula, due to approximation hardy [VI.73](/part - 06/godfrey - harold - hardy - 18771947) andα(n) to p(n)ramanujan that is so accurate that[VI.82](/part - 06/srinivasa - ramanujan - 18871920), gives anp(n) is always the nearest integer to α(n).

6.2 Estimates

Once we have seen example (ii) above, it is natural toask whether it can be generalized. Is there a formula for the numberten sixth powers, for example? It is generally believedt(n) of ways of writing n as a sum of that the answer to this question is no, and certainly nosuch formula has been discovered. However, as with packing problems, even if an exact answer does notseem to be forthcoming, it is still very interesting to obtain easily calculated function estimates.
In this case, one can try to define anf such that f (n) is always approximately one can try to findequal totwot(n)easily calculated functions. If even that is too hard, L$and$ U such that L(n) ⩽ t(n) ⩽ U(n) for every n. If we succeed, then we callan upper bound. Here are a few examples of quanti-L a lower bound for t and U ties that nobody knows how to count exactly, but for which there are interesting approximations, or at least interesting upper and lower bounds.

I.4. The General Goals of Mathematical Research problem in all of mathematics is to estimate(i) Probably the most famous approximate countingπ(n), the number of prime numbers less than or equal tosmall values ofn, we can of course computenπ(n). For exactly: for example,π(20) = 8 since the primes less than or equal to 20 are 2, 3, 5, 7, 11, 13, 17, and 19.
However, there does not seem to be a useful formula forπ(n), and although it is easy to think of a brute-force algorithm for computingup ton, test whether it is prime, and keep count as youπ(n)—look at every number go along—such a procedure takes a prohibitively longtime ifn is at all large. Further more, it does not give us much insight into the nature of the functionπ(n).
roughly find ourselves in the area known as If, however, we modify the question slightly, and askhow many primes there are up toanalytic numbern, then we theory [IV.2](/part-04/number-theory), a branch of mathematics with many fascinating results.
In particular, the famousber theorem [V.26](/part-05/the-prime-number-theorem-and-the-vi34-jnos-bolyai-18021860), proved by hadamard prime num-[VI.65](/part - 06/jacques - hadamard - 18651963) and de la vallée poussin te en th century, states that[VI.67](/part - 06/charles - jean - de - la - valle - poussin - 18661962) at the end of the nine-π(n) is approximately equal ton/ . og n/ . og n converges to 1 asn, in the sense that the ratio ofntends to infinity.π(n) to “density” of primes close tosense that a randomly chosen integer close to This statement can be refined.
It is believed that then is about 1/ . og nn}, in thehas aprobability of about 1/ . og n of being prime. This wouldn suggest thattion ofn that is known as theπ(n) should be about logarithmic integral0 dt/ . og t, a func - of n, or li(n). thefamous unsolved problem in mathematics, is equiva-How accurate is this estimate? Nobody knows, but riemann hypothesis [V.26](/part - 05/the - prime - number - theorem - and - the - vi34 - jnos - bolyai - 18021860), perhaps the most lent to the statement thatmostc. qrt{n} . og n for some constantπ(n) and lic.
Since(n)differ by at. qrt{n} . og n is much smaller thanwas an extremely good approximation toπ(n), this would tell us that liπ(n). (n) is a sequence of points(a(ii) A, b )self-avoiding walkwith the following properties.(aof length0$, b0)$,(a1, bn1)in the plane$,(a2$, b2), . . .
, nn•• The numbers For each i, one obtainsai and bi are all integers.(a , b ) from (a , b ) by taking a horizontal or vertical step of length 1.That is, eithera = a andi bi = b ±i1 or - 1 (ai)-1=• a No two of the point(si)-1 ± 1 and bi = i (bi()-i)1(a-.1 i, bi) are equal.i i^-1 i The first two conditions tell us that the sequence formsa two-dimensional walk of lengthn, and the third says

that this walk never visits any point more than once—hence the term “self-avoiding.” Let S(n) be the number of self-avoiding walks of lengthfor S(n)n , and it is very unlikely that such a formula that start at (0,0). There is no known formula exists. However, quite a lot is known about the way the function S(n) grows as n grows. For instance, it is fairly easy to prove that S(n()1)/n converges to a limit c. The value ofhelp of a computer) to lie between 2 c is not known, but it has been shown (with the.62 and 2.68. with integer coordinates contained in a circle of radiust about the origin.
That is,(iii) Let C(t) be the number of points in the plane C(t) is the number of pairs(a, b)radius of integers such thatt has area πt2, and the plane can be tiled bya2 + b2 ⩽ t2. A circle of unit squares, each of which has a point with integer coordinates at its center. Therefore, whent is large it is fairly clear (and not hard to prove) that imately$πt^{2}$. However, it is much less clear how good C(t) is approx- this approximation is. To make this question more precise, let us set(t) to equal|C(t) - πt2|. That is, (t) is the error in πt2 as an estimate for C(t).
It was shown in 1915, by Hardy. qrt and Landau, that constantc > 0, and this estimate, or something very(t) must be at least c t for some similar, probably gives the right order of magnitude for(t). However, the best upper bound known, which was proved by Huxley in 2003 (the latest in a long line of successive improvements), is that$At13(1/)208(\log t()2()$.){2}6 for some constant A(t). is at most

6.3 Averages

So far, our discussion of estimates and approximations has been confined to problems where the aim is to count mathematical objects of a given kind. However, that is by no means the only context in which estimates can be interesting. Given a set of objects, one may wishto know not just how large the set is, but also what a typical object in the set looks like. Many questions ofthis kind take the form of asking what the average value is of some numerical parameter that is associated with each object. Here are two examples.
(i) What is the average distance between the starting point and the endpoint of a self-avoiding walk oflength n? In this instance, the objects are self-avoiding walks of length parameter is the end-to-end distance.n that start at (0, 0), and the numerical and almost nothing is known. It is obvious that Surprisingly, this is a notoriously difficult problem, n is

an upper bound forical self-avoiding walk to take many twists and turns S(n), but one would expect a typ- and end up traveling much less far thanits starting point. However, there is no known uppern away from bound for In the other direction, one would expect the end-S(n) that is substantially better than n. to-end distance of a typical self-avoiding walk to begreater than that of an ordinary walk, to give it room to avoid itself.
This would suggest that cantly greater than$\sqrt{n}$, but it has not even been proved S(n)is signifithat it This is not the whole story, however, and the problemis greater. will be discussed further in section 8. and letn. On average, how large will(ii) Letω(n)n be a large randomly chosen positive integerbe the number of distinct prime factors ofω(n)be? As it stands, this question does not quite make sense because there are infinitely many positive integers, so one cannot choose one randomly.
However, one can make the question precise by specifying a large integerm and choosing a random integer out that the average size ofn betweenω(n)m and 2 is around log logm. It then turnsn. know about aage, then a great deal of its behavior is not determined, In fact, much more is known than this. If all yourandom variable [III.71 §4](/part-03/probability-distributions) is its averso for many problems calculating averages is just the beginning of the story.
In this case, Hardy and Ramanujan gave an estimate for the[III.71 §4](/part-03/probability-distributions) ofω(n), showing that it is about standard deviation log log n. Then Erd ̋cise estimate for the probability thatos and Kac went even further and gave a pre-ω(n)differs from log logprising fact that the distribution ofn by more than c log log nω, proving the sur-is approximately gaussian [III.71 §5](/part-03/probability-distributions). the range of possible values ofn To put these results in perspective, let us think about might be a prime itself, in which case it obviouslyω(n).
At one extreme, has just one prime factor. At the other extreme, we canwrite the primes in ascending order as$p^{1}$, p2$, p3$, . . . and take numbers of the formthe help of the prime number theorem, one can show$n = p^{1}p^{2} · · · p^{k}$. With that the order of magnitude ofwhich is much bigger than log logk is logn. However, then/ log log n, results above tell us that such numbers are exceptional: a typical number has a few distinct prime factors, but nothing like as many as logn/ log log n.

6.4 Extremal Problems

There are many problems in mathematics where onewishes to maximize or minimize some quantity in

I. Introduction

the presence of various constraints. These are called extremal problems. As with counting questions, there are some extremal problems for which one can realis-tically hope to work out the answer exactly, and many more for which, even though an exact answer is outof the question, one can still aim to find interesting estimates. Here are some examples of both kinds. nnone of these subsets is contained in any other?(i) Let elements.
How many subsets ofn be a positive integer and let X can be chosen if X be a set with A simple observation one can make is that if two different sets have the same size, then neither is containedin the other. Therefore, one way of satisfying the constraints of the problem is to choose all the sets of some particular sizek. Now the number of subsets of X of sizen C ), and it is not hard to show thatk is n!$/k$!(n - k)!, which is usually writtenn is largest whe(nn)k (ork =k n/2 if n is even and when k = (n±k 1)/2 if n is odd. For simplicity let us concentrate on the case wheneven.
What we have just proved is that it is possible ton is pickthat none of them contains any other. That is, n/n 2 subsets of an n-element set in such a wayn is a lower bound for the problem. A result known as Sperner’s theorem states that it is an upper bound as$n/ {}^{2}$ well. That is, if you choose more than$n/ {}^{n2} subsets$ ofwill be contained in another. Therefore, the question X, then, however you do it, one of these subsets is answered exactly, and the answer isis odd, then the answer isn , as one might nown/n 2. (When n(n+1^)/2

expect.)

attached to two hooks on the ceiling and that the chainis not supported anywhere else. What shape will the(ii) Suppose that the two ends of a heavy chain are hanging chain take? tion or minimization problem, but it can be quickly turned into one. That is because a general principle At first, this question does not look like a maxim iz a from physics tells us that the chain will settle in theshape that minimizes its potential energy. We therefore find ourselves asking a new question: let A and Bbe two points at distanced apart, and let C be the set of all curves of length endpoints.
Which curvel that have A and B as their two C \in  C has the smallest poten- tial energy? Here one takes the mass of any portion of the curve to be proportional to its length. The poten-tial energy of the curve is equal tomgh, where m is the mass of the curve, g is the gravitational constant, and Sincehmis the height of the center of gravity of the curve.and g do not change, another formulation of

I.4. The General Goals of Mathematical Research the question is: which curve C \in C has the smallest average height?This problem can be solved by means of a technique known asidea is this. We have a set, the calculus of variations C, and a function. Very roughly, thehdefined on C that takes each curve C \in  C to its average height.
We are trying to minimize approach that task is to define some sort of derivativeh, and a natural way to and look for a curve Notice that the word “derivative” here does C at which this derivative is 0.not refer to the rate of change of height as you move along thecurve. Rather, it means the (linear) way that the average height of the entire curve changes in response to small perturbations of the curve.
Using this kind of deriva-tive to find a minimum is more complicated than looking for the stationary points of a function defined onsince C is an infinite-dimensional set and is therefore R, much more complicated than R. However, the approach can be made to work, and the curve that minimizes the average height is known.
(It is called a catenary, after the Latin word for chain.) Thus, this is another minimization problem that has been answered exactly. For a typical problem in the calculus of variations, one is trying to find a curve, or surface, or more gen-eral kind of function, for which a certain quantity is minimized or maximized.
If a minimum or maximum exists (which is by no means automatic when one is working with an infinite-dimensional set, so this canbe an interesting and important question), the object that achieves it satisfies a system oftial equations [I.3 §5.4](/part-01/fundamental-definitions) known as the partial differen-Euler–Lagrange equationsor maximization, see. For more about this style of minimization variational methods [III.94](/part-03/variational-methods) (and also[III.64](/part-03/optimization-and-lagrange-multipliers)). optimization and lagrange multipliers andmetic progression?
If(iii) How many numbers can you choose between 1 n if no three of them are allowed to lie in an arith - n = 9 then the answer is 5. To see this, note first that no three of the five numbers 1 see if we can find six numbers that work., 2, 4, 8, 9 lie in an arithmetic progression. Now let us out either 4 or 6, or else we would have the progression4, If we make one of our numbers 5, then we must leave5, 6. Similarly, we must leave out one of 3 and 7, one of 2 and 8, and one of 1 and 9. But then we have leftout four numbers. It follows that we cannot choose 5 as one of the numbers.
and 9, so if we leave out 5 then we must include 4 and6. But then we cannot include 2 or 8. But we must also We must leave out one of 1, 2, and 3, and one of 7, 8, leave out at least one of 1, 4, and 7, so we are forced toleave out at least four numbers. ble whenare far too many cases for it to be possible to con-An ugly case - by-case argument of this kind is feasi - n = 9, but as soon as n is at all large there sider them all. For this problem, there does not seemto be a tidy answer that tells us exactly which is the largest set of integers between 1 andno arithmetic progression of length 3.
 So instead onen that contains looks for upper and lower bounds on its size. To provea lower bound, one must find a good way of constructing a large set that does not contain any arithmetic progressions, and to prove an upper bound one must show that any set of a certain size must necessarily contain an arithmetic progression. The best bounds todate are very far apart. In 1947, Behrend found a set$\sqrt{}$ of sizen/ec . og n that contains no arithmetic progres - sion, and in 1999 Jean Bourgain proved that every setof size Cn log log n/ . og n contains an arithmetic pro - gression.
(If it is not obvious to you that these num-bers are far apart, then consider what happens when. qrtn = 10100, say. Then e . og n is about 4 000 000, while. og n/ log log n is about 6.5.) minimization problems: if one is programming a com-puter to perform a certain task, then one wants it to do(iv) Theoretical computer science is a source of many so in as short a time as possible. Here is an elementary-sounding example: how many steps are needed to multiply two Even if one is not too precise about what is meant n-digit numbers together?
by a “step,” one can see that the traditional method, long multiplication, takes at least$n^{2} \text{steps since}$, dur- ing the course of the calculation, each digit of thefirst number is multiplied by each digit of the second. One might imagine that this was necessary, butin fact there are clever ways of transforming the problem and dramatically reducing the time that a computer needs to perform a multiplication of this kind. The fastest known method uses[III.26](/part-03/the-fast-fourier-transform) to reduce the number of steps fromthe fast fourier trans- n2 formto Cn . og n log log n.
Since the logarithm of a number is much smaller than the number itself, one thinks of Cn . og n log log n as being only just worse than a bound of the formand for a problem like this are clearly the best one can Cn. Bounds of this form are called linear, hope for, since it takes 2 of the two numbers.n steps even to read the digits there are fast algorithms for matrix multiplication. Tomultiply two Another question that is similar in spirit is whethern . imes  n matrices using the obvious method

one needs to don3 individual multiplications of the numbers in the matrices, but once again there areless obvious methods that do better. The main breakthrough on this problem was due to Strassen, who hadthe idea of splitting each matrix into fourn/2 . imes n/2 matrices and multiplying those together. At first itseems as though one has to calculate the products of eight pairs ofn/2 . imes  n/2 matrices, but these products are related, and Strassen came up with cu la tions from which the eight products could quickly seven such calbe derived.
One can then applythe same idea to speed up the calculation of the seven recursion: that is, use n/2 . imes  n/2 matrix products, and so on. cal multiplications from about$\log$ Strassen’s algorithm reduces the number of numeri-7 is less than 2.81, this is a significant improve-n3 to about n\lo(g2)7. Since ment, but only when conquer strategy has been developed further, and the2 n is large. His basic divide-and- current record is better than$n2^{}$.}4. In the other direction, the situation is less satisfactory:
nobody has found aproof that one needs to use significantly more than$n^{2}$ multiplications. For more problems of a similar kind, see computational complexity algorithm design [VII.5](/part-07/the-mathematics-of-algorithm-design).[IV.20](/part-04/computational-complexity) and the mathematics of are of a more subtle kind. For example, suppose thatone is trying to understand the nature of the differ-(v) Some minimization and maximization problems ences between successive primes.
The smallest such difference is 1 (the difference between 2 and 3), and it is not hard to prove that there is no largest difference(given any integern greater than 1, none of the num- bers between n!$+ 2 and n$!+ n is a prime). Therefore, there do not seem to be interesting maximization or minimization problems concerning these differences. ing problems if one firstway.
As was mentioned earlier in this section, the prime However, one can in fact formulate some fascinat-normalizes in an appropriate number theorem states that the density of primes nearn is about 1/ . og n, so an average gap between two primes nearcessive primes, we can therefore define a “normalizedn will be about log n. If p and q are suc- gap” to be(q - p)/ . og p. The average value of this nor- malized gap will be 1, but is it sometimes much smaller and sometimes much bigger?
It was shown by Westzynthius in 1931 that even normalized gaps can be arbitrarily large, and it was widely believed that they could also be arbitrarily close to zero. (The famous twin prime conjecture—that thereare infinitely many primesp for which p + 2 is also

I. Introduction

a prime—implies this immediately.) However, it tookuntil 2005 for this to be proved, by Goldston, Pintz, and Yıldırım. (Seefor a discussion of this problem.)analytic number theory [[IV.2 §§6–8]](/part-04/analytic-number-theory) 7 Determining Whether Different Mathematical Properties Are Compatible In order to understand a mathematical concept, such asthat of a group or a manifold, there are various stages one typically goes through.
Obviously it is a good ideato begin by becoming familiar with a few representative examples of the structure, and also with tech-niques for building new examples out of old ones. It is also extremely important to understand the homomor-phisms, or “structure-preserving functions,” from one example of the structure to another, as was discussedin some fundamental mathematical definitions [[I.3 §§4.1, 4.2]](/part-01/some-fundamental-mathematical-de-nitions). understand? Well, for a general theory to be useful, itshould tell us something about specific examples.
For Once one knows these basics, what is there left to instance, as we saw in section 3.2, Lagrange’s theorem can be used to prove Fermat’s little theorem. Lagrange’s theorem is a general fact about groups: that if G is a group of sizemust be a factor ofn, then the size of any subgroup ofn. To obtain Fermat’s little theorem, G one applies Lagrange’s theorem to the particular casewhen G is the multiplicative group of nonzero integers mod$p$. The conclusion one obtains—that$a^{p} \text{is always}$ congruent to$a$—is far from obvious.
a groupis, suppose that we wish to determine whether However, what if we want to know something about$G$that might not be true for all groups? That G has some property P that some groups have and others do not. Since we cannot prove that the property lo ws from the group axioms, it might seem that we are P fol- forced to abandon the general theory of groups andlook at the specific group G. However, in many situ- ations there is an intermediate possibility:
to identify some fairly general property Q that the group G has, and show that P that interests us. Q implies the more particular property a different context. Suppose we wish to determine whether the polynomial Here is an illustration of this sort of technique in$p(x) = x^{4} - 2x^{3} - x^{2} - 2x + 1$ has a real root. One method would be to study this par-ticular polynomial and try to find a root. After quite a lot of effort we might discover thatized as$(x^{2} + x + 1)(x^{2} - 3x + 1)$. The first factor is alwaysp(x) can be factor-

I.4. The General Goals of Mathematical Research positive, but if we apply the quadratic formula to thesecond, we find thatp(x) = 0 when x = (3 ±. qrt{5})/2. An alternative method, which uses a bit of general theory, is to notice thatp(1) is negative (in fact, it equals -3) and thatx4 term is far bigger than anything else), and then top(x) is large when x is large (because then the use the continuous function that is negative somewhere and intermediate value theorem, the result that any positive somewhere else must be zero somewhere inbetween.
some computation to do—finding a value ofp(x)Notice that, with the second approach, there was stillis negative—but that it was much easier than thex for which computation in the first approach—finding a value ofx for which p(x) is zero. In the second approach, we established thatbeing negative some whe rep had the rather general property of, and used the intermediate value theorem to finish off the argument. ematics, and as they arise certain general properties become established as particularly useful.
For exam-There are many situations like this through out mathple, if you know that a positive integer that a group G is Abelian (that is, gh n= is prime, orhg for any two elements complex numbers to complex numbers isg and h of G), or that a function taking hol om or- phic properties you know a lot more about the objects in[I.3 §5.6](/part-01/fundamental-definitions), then as a consequence of these general question. portant, they give rise to a large class of mathemati-cal questions of the following form:
given a mathemat-Once properties have established themselves as imical structure and a selection of interesting properties that it might have, which combinations of these properties imply which other ones? Not all such questions are interesting, of course—many of them turn out to be quite easy and others are too artificial—but someof them are very natural and surprisingly resistant to one’s initial attempts to solve them. This is usually a sign that one has stumbled on what mathematicians would call a “deep” question.
In the rest of this section let us look at a problem of this kind. A group G is called finitely generated if there is some finite set${x^{1}}$, x2}, . . . , xk of elements of G such that all the rest can be written as products of elements inthat set. For example, the group SL(Z) consists of all$2and$. imes 2 matricesad - bc =(a bc d1. This group is finitely generated: it is) such that a, b, c2, and d are integers a nice exercise to show that every such matrix can bebuilt from the four matrices(1 1 )$, (1^{-}1 )$, (1 0 ), and(-1 01 1 )using matrix multiplication.
(See [I.3 §3.2](/part-01/fundamental-definitions) for a0 1 0 1 1 1

discussion of matrices. A first step toward proving this result is to show that(1 m )(1 n ) = (1 m + n ).) Now let us consider a second property. If0 1 0 1 0 1 x is an ele- ment of a group there is some power of G, thenxxthat equals the identity. Theis said to have finite order if smallest such power is called theple, in the multiplicative group of nonzero integers order ofx. For exam - mod 7, the identity is 1, and the order of the element4 is 3, because 41$= 4$, 42 = 16 ≡ 2 and 43 = 64 ≡ 1$mod 7$. As for 3, its first six powers are 3, 2, 6, 4, 5,1, so it has order 6.
Now some groups have the very special property that there is some integerxn equals the identity for every x—or, equivalently, then such that order of everysuch groups?x is a factor of n. What can we say about order 2. writing assuming that Let us look first at the case where all elements havea2 e= for the identity element, we aree for every element a. If we mul- tiply both sides of this equation by the inverse then we deduce that$a = a - 1$. The opposite implication a - 1, is equally easy, so such groups are ones where every element is its own inverse. Now leta and b be two elements of G.
For any two elements(ab)-1 = ba - and1 a - 1 b(simply becauseof any group we have the identity abb - 1 a - 1 = aa - 1 =etheir inverses we can deduce from this that), and in our special group where all elements equalab = ba. That is, G is automatically Abelian. that every element ofanother, that Already we have shown that one general property, G is Abelian. Now let us add the condi-G squares to the identity, implies tion thatbe a minimal Gis finitely generated, and letset of generators. That is, suppose that$x^{1}$, x2, . . .
, xk every element ofthat we need all of the G can be built up out of thex to be able to do this. Becausexi andi Gits own inverse, we can rearrange products of theis Abelian and because every element is equal toxi

into aonce and the indices increase. For example, take the standard form, where each$x^{i} \text{occurs at most}$ product this equalsx4 xx3 xx1 xx4 xx4 xx1 xx3 xx1 xx5. Becausex , and because each G is Abelian, element is its own inverse this equals standard form of the original expression.1 1 1 3 3 4 4 4 5$x1x4x5$, the This shows that G can have at most 2 k elements, since for eachx we have the choice of whether ori

not to include it in the product (after it has been putin the form above). In particular, the properties “G is finitely generated” and “every nonidentity element of Gturns out to be fairly easy to prove that two elements has order 2” imply the third property “Gis finite.” It

whose standard forms are different are themselves dif-ferent, so in fact G has exactly 2 k elements (where k is the size of a minimal set of generators). greater than 2 andis, if Now let us ask what happens if Gis finitely generated andxn = e for every element xnn=is some integere for everyx. Thatx, must question, originally asked by Gbe finite? This turns out to be a much harder burnside [VI.60](/part - 06/william - burnside - 18521927).
Burnside himself showed that Gmust be finite ifn = 3, but it was not until 1968 that his problem was solved, when Adian and Novikov proved the remarkable result that if n ⩾ 4381 then G does nothave to be finite. There is of course a big gap between 3 and 4381, and progressin bridging it has been slow. It was only in 1992 that this was improved ton ⩾ 13, by Ivanov. And to give an idea of how hard the Burnside problem is, it is still notknown whether a group with two generators such that the fifth power of every element is the identity must befinite.
8 Working with Arguments That Are Not Fully Rigorous A mathematical statement is considered to be estab-lished when it has a proof that meets the high standards of rigor that are characteristic of the subject. However, nonrigorous arguments have an important place in mathematics as well. For example, if one wishes to apply a mathematical statement to another field, such as physics or engineering, then the truth of the statement is often more important than whether onehas proved it. not proved a statement, then what grounds could there However, this raises an obvious question:
if one has be for believing it? There are in fact several different kinds of nonrigorous justification, so let us look at some of them.

8.1 Conditional Results

As was mentioned earlier in this article, the riemann hypothesis is the most famous unsolved problem in mathematics. Why is it considered so important? Why, for example, is it considered more important than the twin prime conjecture, another problem to do with the behavior of the sequence of primes? and its generalizations have a huge number of interest-ing consequences. In broad terms, the Riemann hypoth-The main reason, though not the only one, is that it esis tells us that the appearance of a certain degree of

I. Introduction

“randomness” in the sequence of primes is not mislead-ing: in many respects, the primes really do behave like an appropriately chosen random set of integers. imagine that they would be hard to analyze, but infact randomness can be an advantage. For example, If the primes behave in a random way, then one might it is randomness that allows me to be confident thatat least one girl was born in London on every day of the twentieth century. If the sex of babies were less random, I would be less sure:
there could be some strange pattern such as girls being born on Mondays to Thursdays and boys on Fridays to Sundays. Simi-larly, if I know that the primes behave like a random sequence, then I know a great deal about their average behavior in the long term. The Riemann hypothesis and its generalizations formulate in a precise way the idea that the primes, and other important sequences that arise in number theory, “behave randomly.” That is why they have so many consequences.
There are large numbers of papers with theorems that are proved only under the assumption of some version of the Riemann hypothesis. Therefore, anybody who proves the Riemann hypothesis will change the status of all these theorems from conditional to fully proved. mann hypothesis? One could simply say that the proof establishes that such and such a result is implied by How should one regard a proof if it relies on the Riethe Riemann hypothesis and leave it at that. But most mathematicians take a different attitude. They believe the Riemann hypothesis, and believe that it will one daybe proved.
 So they believe all its consequences as well, even if they feel more secure about results that can beproved unconditionally. Another example of a statement that is generally believed and used as a foundation for a great deal offurther research comes from theoretical computer science. As was mentioned in section 6.4 (iv), one of themain aims of computer science is to establish how quickly certain tasks can be performed by a computer. This aim splits into two parts:
finding algorithms thatwork in as few steps as possible, and proving that every algorithm must take at least some particular numberof steps. The second of these tasks is notoriously difficult: the best results known are far weaker than what is believed to be true. There is, however, a class of computational problems, calledbe of equivalent NP-complete difficulty. That is, if there were an effi-problems, that are known to cient algorithm for one of these problems, then it could be converted into an efficient algorithm for any other.

I.4. The General Goals of Mathematical Research However, largely for this very reason it is almost univer-sally believed that there is in fact no efficient algorithm for any of the problems, or, as it is usually expressed, that “P does not equal NP.” Therefore, if you want to demonstrate that no quick algorithm exists for some problem, all you have to do is prove that it is at leastas hard as some problem that is already known to be NP-complete. This will not be a rigorous proof, but it will be a convincing demonstration, since most mathe-maticians are convinced that P does not equal NP.
(See computational complexity this topic.) [IV.20](/part-04/computational-complexity) for much more on Some areas of research depend on several conjectures rather than just one. It is as though researchers in such areas have discovered a beautiful mathematical landscape and are impatient to map it out despite thefact that there is a great deal that they do not understand. And this is often a very good research strategy, even from the perspective of finding rigorous proofs. There is far more to a conjecture than simply a wild guess:
for it to be accepted as important, it should havebeen subjected to tests of many kinds. For example, does it have consequences that are already known to be true? Are there special cases that one can prove? Ifit were true, would it help one solve other problems? Is it supported by numerical evidence? Does it makea bold, precise statement that would probably be easy to refute if it were false?
It requires great insight and hard work to produce a conjecture that passes all these tests, but if one succeeds, one has not just an isolated statement, but a statement with numerous connections to other statements. This increases the chances that it will be proved, and greatly increases the chances that the proof of one statement will lead to proofsof others as well. Even a counterexample to a good conjecture can be extraordinarily revealing: if the con-jecture is related to many other statements, then the effects of the counterexample will permeate the wholearea.
algebraic number theory Langlands program is a collection of conjectures, due One area that is full of conjectural statements is[IV.1](/part-04/number-theory). In particular, the to Robert Langlands, that relate number theory to representation theory (it is discussed intation theory [IV.9 §6](/part-04/representation-theory)). Between them, these con-re pre sen je ct ures generalize, unify, and explain large numbersof other conjectures and results.
For example, the Shimura–Taniyama–Weil conjecture, which was centralto Andrew Wiles’s proof of fermat’s last theorem [V.10](/part-05/fermats-last-theorem), forms one small part of the Langlands program.

The Langlands program passes the tests for a good con-jecture supremely well, and has for many years guided the research of a large number of mathematicians. Another area of a similar nature is known as mirror symmetry that relates objects known as[IV.16](/part-04/mirror-symmetry). This is a sort ofcalabi–yau manifolds duality [III.19](/part-03/duality) [III.6](/part-03/calabiyau-manifolds), which arise in algebraic geometry [IV.4](/part-04/algebra) and also infolds.
Just as certain differential equations can become string theory [IV.17 §2](/part-04/vertex-operator-algebras), to other, dual manimuch easier to solve if one looks at theforms [III.27](/part-03/the-fourier-transform) of the functions in question, so there are fourier trans calculations arising in string theory that look impos-sible until one transforms them into equivalent calculations in the dual, or “mirror,” situation.
There is at present no rigorous justification for the transforma-tion, but this process has led to complicated formulas that nobody could possibly have guessed, and some of these formulas have been rigorously proved in otherways. Maxim Kontsevich has proposed a precise conjecture that would explain the apparent successes ofmirror symmetry.

8.2 Numerical Evidence

Theeven number greater than or equal to 4 is the sum ofgoldbach conjecture [V.27](/part-05/problems-and-results-in-vi36-peter-gustav-lejeune-dirichlet-18051859) states that every two primes. It seems to be well beyond what anybody could hope to prove with today’s mathematical machinery, even if one is prepared to accept statements such as the Riemann hypothesis. And yet it is regarded asalmost certainly true. bach’s conjecture. The first is a reason we have already met:
one would expect it to be true if the primes are There are two principal reasons for believing Gold“randomly distributed.” This is because ifeven number, then there are many ways of writingn is a largen = a + b, and there are enough primes for one to expect that from time to time bothbe prime.a and b would for some value ofunlucky, and it might just happen that Such an argument leaves open the possibility thatn that is not too large one might ben - a was com- posite whenever evidence comes in. It has now been checked that everya was prime.
This is where numerical even number up to 1014 can be written as a sum of two primes, and once extremely unlikely that it could “just happen,” by an is greater than this, it becomes fluke, to be a counterexample. a way to make it even more convincing. If one makes This is perhaps rather a crude argument, but there is

more precise the idea that the primes appear to be ran-domly distributed, one can formulate a stronger version of Goldbach’s conjecture that says not only thatevery even number can be written as a sum or two primes, but also roughly how many ways there are ofdoing this. For instance, ifa and n - a are both prime, then neither is a multiple of 3 (unless one of them isequal to 3 itself). Ifn is a multiple of 3, then this merely says that3 m + 1 thena is not a multiple of 3, but ifa cannot be of the form 3 nk is of the form + 1 either (orn - a would be a multiple of 3).
So, in a certain sense, it is twice as easy foris a multiple of 3. Taking this kind of information inton to be a sum of two primes if it account, one can estimate in how many ways it “ought” to be possible to write turns out that, for every evenn as a sum of two primes. Itn, there should be many such representations. Moreover, one’s predictions of howdence: that is, they are true for values ofmany are closely matched by the numerical evi-n that are small enough to be checked on a computer.
This makes the numerical evidence much more convincing, sinceit is evidence not just for Goldbach’s conjecture itself, but also for the more general principles that led us to believe it. cise the predictions that follow from a conjecture, themore impressive it is when they are confirmed by later This illustrates a general phenomenon: the more pre numerical evidence. Of course, this is true not just of mathematics but of science more generally.

8.3 “Illegal” Calculations

In section 6.3 it was stated that “almost nothing is known” about the average end-to-end distance of anstep self-avoiding walk. That is a statement with whichn- theoretical physicists would strongly disagree. Instead, they would tell you that the end-to-end distance of a typical region ofn-step self-avoiding walk is somewhere in the(n3()/){4}. This apparent disagreement is explained by the fact that, although almost nothing has been rig-orously proved, physicists have a collection of nonrigorous methods that, if used carefully, seem to give correct results.
With their methods, they have in someareas managed to establish statements that go well beyond what mathematicians can prove. Such results are fascinating to mathematicians, partly because ifone regards the results of physicists as mathematical conjectures then many of them are excellent conjectures, by the standards explained earlier: they are deep, completely unguessable in advance, widely believed to

I. Introduction

be true, backed up by numerical evidence, and so on. Another reason for their fascination is that the effort to provide them with a rigorous underpinning often leads to significant advances in pure mathematics. To give an idea of what the nonrigorous calculations of physicists can be like, here is a rough descrip-tion of a famous argument of Pierre-Gilles de Gennes, which lies behind some of the results (or predictions, if you prefer to call them that) of physicists.
In statis-tical physics there is a model known as then-vector model described in, closely related to the Ising and Potts models probabilistic models of critical phenomena vector in [IV.25]. At each point of R n. This gives rise to a random configuration Zd one places a unit of unit vectors, with which one associates an “energy”that increases as the angles between neighboring vectors increase. De Gennes found a way of transform-ing the self - avoiding-walk problem so that it could be regarded as a question about thethe casen = 0.
The 0-vector problem itself does notn-vector model in make obvious sense, since there is no such thing asa unit vector in R0, but de Gennes was nevertheless able to take parameters associated with then-vector model and show that if you letthen you obtained parameters associated with self - n converge to zero avoiding walks. He proceeded to choose other parame-ters in then-vector model to derive information about self-avoiding walks, such as the expected end - to-end distance. To a pure mathematician, there is something very worrying about this approach.
The formulas that arisein then-vector model do not make sense when n = 0, so instead one has to regard them as limiting values when integer in then tends to zero. Butn-vector model, so how can one say that itn is very clearly a positive tends to zero? Is there some way of defining anmodel for more general$n$? Perhaps, but nobody hasn-vector found one. And yet de Gennes’s argument, like many other arguments of a similar kind, leads to remarkably precise predictions that agree with numerical evidence. There must be a good reason for this, even if we do not understand what it is.
The examples in this section are just a few illustrations of how mathematics is enriched by nonrigor-ous arguments. Such arguments allow one to penetrate much further into the mathematical unknown, open-ing up whole areas of research into phenomena that would otherwise have gone unnoticed. Given this, one might wonder whether rigor is important: if the results established by nonrigorous arguments are clearly true, I.4. The General Goals of Mathematical Research then is that not good enough?
As it happens, there are examples of statements that were “established” by nonrigorous methods and later shown to be false, but themost important reason for caring about rigor is that the understanding one gains from a rigorous proof is fre-quently deeper than the understanding provided by a nonrigorous one. The best way to describe the situationis perhaps to say that the two styles of argument have profoundly benefited each other and will undoubtedly continue to do so. 9 Finding Explicit Proofs and Algorithms There is no doubt that the equationa solution.
After all, if we setf (x) =x5 x-5 x--x13 - 13, then = 0 hasf (and 2 there will be an1) = −13 and f (2) x=for which17, so somewhere between 1 f (x) = 0. That is an example of a pure existence argument—in other words, an argument that establishes that some-thing exists (in this case, a solution to a certain equation), without telling us how to find it. If the equa-tion had beenx2 - x - 13 = 0, then we could have used an argument of a very different sort:
the for-mula for quadratic equations tells us that there are precisely two solutions, and it even tells us what they are(they are$(1 + \sqrt{53})/2 and (1 - \sqrt{53})/2)$. However, there is no similar formula for quintic equations. (see insolubility of the quintic [V.21](/part-05/the-insolubility-of-the-quintic).) the chotomy in mathematics.
If you are proving that a mathematical object exists, then sometimes you can These two arguments illustrate a fundamental dido so explicitly, by actually describing that object, and sometimes you can do so onlythat its nonexistence would lead to a contradiction.indirectly, by showing As it was presented, the argument above showed mere-ly that the equation There is also a spectrum of possibilities in between.$x^{5} - x - 13 = 0 \text{has a solution}$ between 1 and 2, but it also suggests a method for cal-culating that solution to any desired accuracy.
If, for example, you want to know it to two decimal places, then run through the numbers 1, 1.01,1.02, . . . , 1.99, 2 evaluating is approximately fat each one. You will find that-0.0889 and that f (1.72) is approx - f (1.71) imately 0.3337, so there must be a solution between the two (which the calculations suggest will be closerto 1.71 than to 1.72). And in fact there are much better ways, such asmating solutions. For many purposes, a pretty formula newton’s method [II.4 §2.3](/part-02/algorithms), of approxifor a solution is less important than a method of cal-culating or approximating it.
(See numerical analysis

[IV.21 §1](/part-04/numerical-analysis) for a further discussion of this point.) And ifone has a method, its usefulness depends very much on whether it works quickly. mulas that define mathematical objects and can easilybe used to find them, at the other one has proofs that Thus, at one end of the spectrum one has simple for establish existence but give no further information, andin between one has proofs that yield algorithms for finding the objects, algorithms that are significantly more useful if they run quickly.
preferable to a nonrigorous one, so an explicit or algo-rithmic argument is worth looking for even if an indi-Just as, all else being equal, a rigorous argument is rect one is already established, and for similar reasons: the effort to find an explicit argument very often leads to new mathematical insights.
(Less obviously, as weshall soon see, finding indirect arguments can also lead to new insights.) tence argument concerns[III.41](/part-03/irrational-and-transcendental-numbers), which are real numbers that are not roots of One of the most famous examples of a pure exis-transcendental numbers any polynomial with integer coefficients. The first per-son to prove that such numbers existed was liouville [VI.39](/part-06/joseph-liouville-18091882), in 1844.
He proved that a certain condition was sufficient to guarantee that a number was transcendental and demonstrated that it is easy to construct numbers satisfying his condition (see liouville’s theorem and roth’s theorem [V.22](/part-05/liouvilles-theorem-and-roths-theorem)). After that, various important numbers such as e andto be transcendental, but these proofs were difficult.π were proved Even now there are many numbers that are almost cer-tainly transcendental but which have not been proved to be transcendental.
(See irrational and transcendental numbers this.) [III.41](/part-03/irrational-and-transcendental-numbers) for more information about explicit. Then in 1873 pletely different proof of the existence of transcenden-All the proofs mentioned above were direct andcantor [VI.54](/part-06/georg-cantor-18451918) provided a comtal numbers, using his theory of He proved that the algebraic numbers were countable countability [III.11](/part-03/countable-and-uncountable-sets). and the real numbers uncountable.
Since countable sets are far smaller than uncountable sets, this showed that almost every real number (though not necessarily almost every real number you will actually meet)is transcendental. us something that the other does not. Cantor’s proof shows that there are transcendental numbers, but it In this instance, each of the two arguments tells does not provide us with a single example. (strictly speaking, this is not true: one could specify a way of

listing the algebraic numbers and then apply Cantor’sfamous diagonal argument to that particular list. However, the resulting number would be virtually devoid ofmeaning.) Liouville’s proof is much better in that way, as it gives us a method of constructing several transcen-dental numbers with fairly straightforward definitions. However, if one knew only the explicit arguments suchas Liouville’s and the proofs that e andπ are transcen- dental, then one might have the impression that tran-scendental numbers are numbers of a very special kind.
The insight that is completely missing from these argu-ments, but present in Cantor’s proof, is that a typical real number is transcendental. For much of the twentieth century, highly abstract and indirect proofs were fashionable, but in more recent years, especially with the advent of the computer, attitudes have changed. (Of course, this is a very general statement about the entire mathematical community rather than about any single mathematician.) Nowadays, more attention is often paid to the questionof whether a proof is explicit, and, if so, whether it leads to an efficient algorithm.
selves, and not just for the light they shed on mathe-matical proofs. Let us conclude this section with a brief Needless to say, algorithms are interesting in them description of a particularly interesting algorithm thathas been developed by several authors over the last few years. It gives a way of computing the volume ofa high-dimensional convex body. and A shapey in KK, the line segment joiningis called convex if, given any two pointsx to y lies entirelyx insidebut a five-pointed star is not. This concept can be gen-K.
For example, a square or a triangle is convex, eralized straightforward ly toas can the notions of area and volume.n dimensions, for any n, Now let us suppose that ann-dimensional convex bodyhave a computer program that runs quickly and tells us, Kis specified for us in the following sense: we for each point$(x^{1}$, . . . , xn), whether or not that point belongs to One of the most powerful methods for problems like K. How can we estimate the volume of K? this iswhether they belong to statistical:
you choose points at random and see K, basing your estimate of the volume ofexample, if you wanted to estimate K on the frequency with which they do. Forπ, you could take a circle of radius 1, enclose it in a square of side-length 2, and choose a large number of points randomly fromthe square. Each point has a probabilityπ/4 (the ratioof the areaπ of the circle to the area 4 of the square)

I. Introduction

of belonging to the circle, so we can estimate ing the proportion of points that fall in the circle andπ by tak- multiplying it by 4. sions but as soon as difficulty. Suppose for example that we were to try to This approach works quite easily for very low dimen-n is at all large it runs into a severe use the same method for estimating the volume of ann-dimensional sphere. We would enclose that sphere in anin the cube, and see how often they belonged to then-dimensional cube, choose points at random sphere as well.
However, the ratio of the volume of ann-dimensional sphere to that of an n-dimensional cube that contains it is exponentially small, which meansthat the number of points you have to pick before even one of them lands in the sphere is exponen-tially large. Therefore, the method becomes hopelessly impractical. All is not lost, though, because there is a trick for getting around this difficulty. You define a sequenceof convex bodies, K , K , . . .
, K , each contained in the next, starting with the convex body whose volume youwant to know, and ending with the cube, in such a way0 1 mthat the volume of Ki is always at least half that of (Ki)+1. Then for each K- and K . The product of all these ratios will be thei you estimate the ratio of the volumes of ratio of the volume ofthe volume of(i1)i K , this tells you the volume of K0 to that of Km. Since you know K . How do you estimate the ratio of the volumes of m0 (Ki)-1 andand see how many of them belong to$K^{i}$? You simply choose points at random from$K^{-}$.
However, it is Ki just here that the true subtlety of the problem arises: how do you choose points at random from a convex$i^{1}$ body$K$that you do not know much about? Choosing a

$i$

random point in theall you need to do is independently choosen-dimensional cube is easy, sincen random numbers general convex body it is not easy at all.$x^{1}$, . . . , xn, each between -1 and 1. But for a this problem. It is to design carefully a random walk There is a wonderfully clever idea that gets around that starts somewhere inside the convex body and ateach step moves to another point, chosen at random from just a few possibilities.
The more random stepsof this kind that are taken, the less can be said about where the point is, and if the walk is defined prop-erly, it can be shown that after not too many steps, the point reached is almost purely random. However, the proof is not at all easy. (It is discussed further in high-dimensional geometry and its probabilistic analogues [IV.26 §6].)

I.4. The General Goals of Mathematical Research ematical importance, see For further discussion of algorithms and their math-algorithms [II.4](/part-02/algorithms), computational number theory plex i ty [IV.20](/part-04/computational-complexity), and the mathematics of algorithm[IV.3](/part-04/computational-number-theory), computational comdesign [VII.5](/part-07/the-mathematics-of-algorithm-design). 10 What Do You Find ina Mathematical Paper? Mathematical papers have a very distinctive style, onethat became established early in the twentieth century.
This final section is a description of what mathematicians actually produce when they write. A typical paper is usually a mixture of formal and informal writing. Ideally (but by no means always), theauthor writes a readable introduction that tells the reader what to expect from the rest of the paper. Andif the paper is divided into sections, as most papers are unless they are quite short, then it is also very helpfulto the reader if each section can begin with an informal outline of the arguments to follow.
But the main sub-stance of the paper has to be more formal and detailed, so that readers who are prepared to make a sufficient effort can convince themselves that it is correct. matical statements for example, the justification for the paper may be The object of a typical paper is to establish. Sometimes this is an end in itself: mathethat it proves a conjecture that has been open fortwenty years. Sometimes the mathematical statements are established in the service of a wider aim, such ashelping to explain a mathematical phenomenon that is poorly understood.
But either way, mathematical statements are the main currency of mathematics. ally called theorems, but one also finds statements called propositions, lemmas, and corollaries. One can-The most important of these statements are usunot always draw sharp distinctions between these kinds of statements, but in broad terms this is what the dif-ferent words mean.
A theorem is a statement that you regard as intrinsically interesting, a statement that youmight think of isolating from the paper and telling other mathematicians about in a seminar, for instance. The statements that are the main goals of a paper are usually called theorems. Aorem, but it tends to be slightly “boring.” It may seem proposition is a bit like a theodd to want to prove boring results, but they can beimportant and useful. What makes them boring is that they do not surprise us in any way.
They are statements that we need, that we expect to be true, and that we donot have much difficulty proving. choose to call a proposition. Thea binary operation Here is a quick example of a statement that one might[I.2 §2.4](/part - 01/language - and - grammar) “*associative law for” states thatx* (y*z) = (x*y)*z. One often describes this law informally by saying that “brackets do not matter.” However, whileit shows that we can write x* y* z without fear ofambiguity, it does not show quite so obviously that wecan writea* b* c* d* e, for example.
How do we know that, just because the positions of brackets donot matter when you have three objects, they do not matter when you have more than three? versity without noticing that this is a problem. It just Many mathematics students go happily through uniseems obvious that the associative law shows that brackets do not matter. And they are basically right: although it is not completely obvious, it is certainly nota surprise and turns out to be easy to prove. Since we often need this simple result and could hardly call it atheorem, we might call it a proposition instead.
To get a feel for how to prove it, you might wish to show thatthe associative law implies that(a* ((b* c)* d))* e = a* (b* ((c* d)* e)). Then you can try to generalize what it is you are doing. becomes long and complicated, in which case if youwant anybody to read it you need to make the structure Often, if you are trying to prove a theorem, the proof of the argument as clear as possible. One of the bestways of doing this is to identify subgoals, which take the form of statements intermediate between your initial assumptions and the conclusion you wish to draw from them.
These statements are usually called pose, for example, that you are trying to give a very lemmas. Sup detailed presentation of the standard proof that$\sqrt{2} is$ irrational. One of the facts you will need is that every fractionp/q is equal to a fraction r /s with r and s not both even, and this fact requires a proof. For the sakeof clarity, you might well decide to isolate this proof from the main proof and call the fact a lemma. Thenyou have split your task into two separate tasks: proving the lemma, and proving the main theorem usingthe lemma.
One can draw a parallel with computer programming: if you are writing a complicated program, itis good practice to divide your main task into subtasks and write separate mini-programs for them, which youcan then treat as “black boxes,” to be called upon by other parts of the program whenever they are useful. Some lemmas are difficult to prove and are useful in many different contexts, so the most important lem-mas can be more important than the least important

theorems. However, a general rule is that a result willbe called a lemma if the main reason for proving it is in order to use it as a stepping stone toward the proofs of other results. A corollary of a mathematical statement is another statement that follows easily from it. Sometimes themain theorem of a paper is followed by several corollaries, which advertise the strength of the theorem. Sometimes the main theorem itself is labeled a corollary, because all the work of the proof goes into proving a different, less punchy statement from which the theo-rem follows very easily.
If this happens, the author may wish to make clear that the corollary is the main result of the paper, and other authors would refer to it as atheorem. of athat proofs are possible: that, for example, an argument A mathematical statement is established by means proof. It is a remarkable feature of mathematics invented bycan still be accepted today and regarded as a com-euclid [VI.2](/part-06/euclid-ca) over two thousand years ago pletely convincing demonstration.
It took until the late nineteenth and early twentieth centuries for this phenomenon to be properly understood, when the language of mathematics wasguage and grammar of mathematics formalized (see[I.2](/part-01/language-and-grammar), and espe-the lancially section 4, for an idea of what this means). Then itbecame possible to make precise the notion of a proof as well. From a logician’s point of view a proof is a sequence of mathematical statements, each written in aformal language, with the following properties:
the first few statements are the initial assumptions, oreach remaining statement in the sequence follows from premises; earlier ones by means of logical rules that are so simple that the deductions are clearly valid (for instance rulessuch as “if P ∧ Q is true then Pis true,” where “∧” is the logical symbol for “and”); and the final statementin the sequence is the statement that is to be proved.
The above idea of a proof is a considerable idealization of what actually appears in a normal mathemat-ical paper under the heading “Proof.” That is because a purely formal proof would be very long and almost impossible to read. And yet, the fact that arguments can in principle be formalized provides a very valuable underpinning for the edifice of mathematics, becauseit gives a way of resolving disputes. If a mathematician produces an argument that is strangely unconvincing, then the best way to see whether it is correct is to ask him or her to explain it more formally and in greater detail.
This will usually either expose a mistake or makeit clearer why the argument works.

I. Introduction

papers is Another very important component of mathematical definitions. This book is full of them: see in particular part III. Some definitions are given simply because they enable one to speak more concisely. For example, if I am proving a result about triangles and I keep needing to consider the distances between the vertices and the opposite sides, then it is a nuisance tohave to say “the distances from A, B, and C to the lines BC, AC, and AB, respectively,” so instead I will probably choose a word like “altitude” and write, “Given a vertex of a triangle, define itsthat vertex to the
opposite side.” If I am looking at tri-altitude to be the distance from angles with obtuse angles, then I will have to be more careful: “Given a vertex A of a triangle ABC, define its altitude that passes through B and C.” From then on, I can useto be the distance from A to the unique line the word “altitude” and the exposition of my proof willbe much more crisp. Definitions like this are mere definitions of convenience. When the need arises, it is pretty obvious whatto do and one does it.
But the really interesting definitions are ones that are far from obvious and that makeyou think in new ways once you know them. A very good example is the definition of the derivative of a function. If you do not know this definition, you will have no idea how to find out for which nonneg at iv ef (x) = 2 x3-3 x2-6 x+1 takes its smallest value. If youx the function do know it, then the problem becomes a simple exer-cise.
That is perhaps an exaggeration, since you also need to know that the minimum will occur either at 0 or at a point where the derivative vanishes, and you will need to know how to differentiate simple facts—propositions rather than theorems—andf (x), but these are the real breakthrough is the concept itself. this, but interestingly they are more common in some There are many other examples of definitions like branches of mathematics than in others.
Some math-ematicians will tell you that the main aim of their research is to find the right definition, after which their whole area will be illuminated. Yes, they will have to write proofs, but if the definition is the one they are looking for, then these proofs will be fairly straightforward. And yes, there will be problems they can solvewith the help of the new definition, but, like the minimization problem above, these will not be central tothe theory. Rather, they will demonstrate the power of the definition.
For other mathematicians, the main purpose of definitions is to prove theorems, but even very theorem - oriented mathematicians will from time I.4. The General Goals of Mathematical Research to time find that a good definition can have a major effect on their problem-solving prowess. This brings us to mathematical problems. The main aim of an article in mathematics is usually to prove the - orems, but one of the reasons for reading an article is to advance one’s own research. It is therefore very wel-come if a theorem is proved by a technique that can be used in other contexts.
It is also very welcome if an article contains some good unsolved problems. By wayof illustration, let us look at a problem that most mathematicians would not take all that seriously, and try tosee what it lacks. A number is called palindromic if its representation in base 10 is a palindrome: some simple examples are 22, 131, and 548 845. Of these, 131 is interesting because it is also a prime. Let us try to find some moreprime palindromic numbers.
Single-digit primes are of course palindromic, and two-digit palindromic numbers are multiples of 11, so only 11 itself is also a prime. So let us move quickly on to three-digit numbers. Here there turn out to be several examples: 101, 131, 151,181, 191, 313, 353, 373, 383, 727, 757, 787, 797, 919, and 929. It is not hard to show that every palindromic number with an even number of digits is a multiple of11, but the palindromic primes do not stop at 929—for example, 10 301 is the next smallest. And now anybody with a modicum of mathematical curiosity will ask the question:
are there infinitely many palindromic primes? This, it turns out, is an unsolved problem. It is believed (on the combined grounds that the primes should be sufficiently random and that palindromic numbers with an odd number of digits do not seem to have any particular reason to be factorizable) that there are, but nobody knows how toprove it. understand, which makes it appealing in the way that fermat’s last theorem This problem has the great virtue of being easy to[V.10](/part - 05/fermats - last - theorem) and goldbach’s conjecture tral problem in the way that those two are:
most math-[V.27](/part - 05/problems - and - results - in - vi36 - peter - gustav - lejeune - dirichlet - 18051859) are appealing. And yet, it is not a cen ematicians would put it into a mental box marked“recreational” and forget about it. What is the reason for this dismissive attitude? Are the primes not central objects of study in mathematics?Well, yes they are, but palindromic numbers are not. And the main reason they are not is that the definition of “palindromic” is extremely unnatural.
If you know that a number is palindromic, what you know is less a feature of the number itself and more a feature of the particular way that, for accidental historical reasons, we choose to represent it. In particular, the property depends on our choice of the number 10 as our base. For example, if we write 131 in base 3, then it becomes11212, which is no longer the same when written backwards. By contrast, a prime number is prime however you write it.
nation, since there could conceivably be interesting properties that involved the number 10, or at least Though persuasive, this is not quite a complete explasome artificial choice of number, in an essential way. For example, the problem of whether there are infinitely many primes of the form 2 n - 1 is considered interest-ing, despite the use of the particular number 2. How-ever, the choice of 2 can be justified here: an - 1 hasa factorwould be no. Moreover, numbers of the form 2 a - 1, so for any larger integer the answern - 1 have special properties that make them more likely tobe prime.
(See computational number theory [IV.3](/part - 04/computational - number - theory) for an explanation of this point.)But even if we replace 10 by the “more natural” number 2 and look at numbers that are palindromic when written in binary, we still do not obtain a property that would be considered a serious topic for research. Suppose that, given an integer reverse of n—that is, the number obtained if you write$n$, we definer (n) to be thendromic number, in the binary sense, is a numberin binary and then reverse its digits. Then a palin-n such that$n = r (n)$.
But the function r (n) is very strange and “unmathematical.” For instance, the reverses of the numbers from 1 to 20 are 1, 1, 3, 1, 5, 3, 7, 1, 9, 5, 13, 3, 11, 7, 15, 1, 17, 9, 25, and 5, which gives us a sequence with no obvious pattern. Indeed, when one calculates this sequence, one realizes that it is even more artificial than it at first seemed. One might imagine that the reverse of the reverse of a number is the number itself, but that is not so. If you take the number 10, for exam-ple, it is 1010 in binary, so its reverse is 0101, which is the number 5.
But this we would normally write as 101, so the reverse of 5 is not 10 but 5. But we can not solve this problem by deciding to write 5 as 0101, since then we would have the problem that 5 was no longer palindromic, when it clearly ought to be. Does this mean that nobody would be interested in a proof that there were infinitely many palindromic primes? Not at all.
It can be shown quite easily that the number of palindromic numbers less thanthe region of$\sqrt{n}$, which is a very small fraction indeed.n is in It is notoriously hard to prove results about primes insparse sets like this, so a solution to this conjecture would be a big breakthrough. However, the definition

of “palindromic” is so artificial that there seems to beno way of using it in a detailed way in a mathematical proof. The only realistic hope of solving this problem would be to prove a much more general result, of whichthis would be just one of many consequences. Such a result would be wonderful, and undeniably interesting, but you will not discover it by thinking about palindromic numbers. Instead, you would be better off either trying to formulate a more general question, or else looking at a more natural problem of a similar kind. Anexample of the latter is this:
are there infinitely many primes of the formm2 + 1 for some positive integer m? lem is generality: the solution to a good problem should Perhaps the most important feature of a good prob usually have ramifications beyond the problem itself. Amore accurate word for this desirable quality is “general iz ability,” since some excellent problems may look rather specific. For example, the statement that$\sqrt{2} is$ irrational looks as though it is about just one number,

I. Introduction

but once you know how to prove it, you will have no difficulty in proving that. qrt{3} is irrational as well, and in fact the proof can be generalized to a much wider class of numbers (seequite common for a good problem to look uninterest-algebraic numbers [IV.1 §14](/part-04/number-theory)). It is ing until you start to think about it. Then you realize that it has been asked for a reason: it might be the “first difficult case” of a more general problem, or it mightbe just one well-chosen example of a cluster of problems, all of which appear to run up against the same difficulty.
quently the person who asks a mathematical question has a good idea of what the answer is. ASometimes a problem is just a question, but fre-conjecture is a mathematical statement that the author firmly believes but cannot prove. As with problems, some conjectures are better than others: as we have already discussed insection 8.1, the very best conjectures can have a major effect on the direction of mathematical research.

Modern Mathematics

II.1 From Numbers to

Number Systems

Fernando Q. Gouvêa

People have been writing numbers down for as long asthey have been writing. In every civilization that has developed a way of recording information, we also finda way of recording numbers. Some scholars even argue that numbers came first. It is fairly clear that numbers first arose as adjectives: they specified how many or how much of something there was. Thus, it was possible to talk about three apricots, say, long before it was possible to talk about the number 3.
But once the concept of “threeness” ison the table, so that the same adjective specifies three fish and three horses, and once a written symbol suchas “3” is developed that can be used in all of those instances, the conditions exist for 3 itself to emerge as an independent entity. Once it does, we are doing mathematics. times when new kinds of numbers have been intro-duced: first a number is used, then it is represented This process seems to have repeated itself many symbolically, and finally it comes to be conceived as athing in itself and as part of a system of similar entities.
1 Numbers in Early Mathematics The earliest mathematical documents we know about go back to the civilizations of the ancient Middle East, in Egypt and in Mesopotamia. In both cultures, a scribal class developed. Scribes were responsible for keeping records, which often required them to do arithmetic and solve simple mathematical problems. Most of the mathematical documents we have from those cultures seem to have been created for the use of young scribes learning their craft. Many of them are collections of

Part II

The Origins of

problems, provided with either answers or brief solu-tions: twenty-five problems about digging trenches in one tablet, twelve problems requiring the solution ofa linear equation in another, problems about squares and their sides in a third. Numbers were used both for counting and for measuring, so a need for fractional numbers must havecome up fairly early. Fractions are complicated to write down, and computing with them can be difficult. Hence, the problem of “broken numbers” may well have been the first really challenging mathematical problem. Howdoes one write down fractions?
The Egyptians and the Mesopotamians came up with strikingly different answers, both of which are also quite different from the way we write them today. ranean world), the fundamental notion was “thepart,” as in “the third part of six is two.” In this lan-In Egypt (and later in Greece and much of the Mediter-$nth$ guage, one would express the idea of dividing 7 by 3 as, “What is the third part of seven?” The answer is, “Two and the third.” The process was complicated by an additional restriction: one never recorded a final result using more than one of the same kind of part.
Thus, thenumber we would want to express as “two fifth parts” would have to be given as “the third and the fifteenth.”In Mesopotamia, we find a very different idea, which may have arisen to allow easy conversion between dif-ferent kinds of units. First of all, the Babylonians had a way to generate symbols for all the numbers from 1 to59. For larger numbers, they used a positional system much like the one we use today, but based on 60 rather than 10. So something like 1, 20 means one sixty and twenty units, that is, 1. imes 60 + 20 = 80.
The same system was then extended to fractions, so that one half was represented as thirty sixtieths. It is convenient to mark the beginning of the fractional part with a semicolon, though this and the comma are a modern convention that has no counterpart in the original texts. Then, for

example, 1;24,36 means 1 more usually write as 141, or 1$+ {}^{2}4^{6}0$.+41. The Mesopotamian60362, which we would way of writing numbers is called avalue system by analogy with the system we use today,100 sexagesimal place which is, of course, a Neither of these systems is really equipped to deal decimal place-value system. well with complicated numbers. In Mesopotamia, for example, only finite sexagesimal expressions were employed, so the scribes were not able to write down anexact value for the reciprocal of 7 because there is no finite sexagesimal expression for 17 .
In practice, this meant that to divide by 7 required finding an approxi-mate answer. The Egyptian “parts” system, on the other hand, can represent any positive rational number, butdoing so may require a sequence of denominators that to our eyes looks very complicated. One of the sur-viving papyri includes problems that look designed to produce just such complicated answers. One of these answers is “14, the 4 th, the 56 th, the 97 th, the 194 th, the 388 th, the 679 th, the 776 th,” which in modern nota-tion is the fraction 1428 .
It seems that the joy of computation for its own sake became well-established veryearly in the development of mathematics.97 systems for a while. Most everyday numbers were spec-ified using the system of “parts.” On the other hand, Mediterranean civilizations preserved both of these astronomy and navigation required more precision, sothe sexagesimal system was used in those fields. This included measuring time and angles. The fact that westill divide an hour into sixty minutes and a minute into sixty seconds goes back, via the Greek astronomers, to the Babylonian sexagesimal fractions;
almost four thousand years later, we are still influenced by the Babylonian scribes. 2 Lengths Are Not Numbers Things get more complicated with the mathematics of classical Greek and Hellenistic civilizations. The Greeks, of course, are famous for coming up withthe first mathematical proofs. They were the first to attempt to do mathematics in a rigorously deductive way, using clear initial assumptions and careful statements.
This, perhaps, is what led them to be very careful about numbers and their relations to other magnitudes. Sometime before the fourth century b.c.e., the Greeks made the fundamental discovery of “incommensurable magnitudes.” That is, they discovered that it is not always possible to express two given lengths as (inte-ger) multiples of a third length. It is not just that lengths

II. The Origins of Modern Mathematics

and numbers are conceptually distinct things (though this was important too). The Greeks had found a proof that one cannot use numbers to represent lengths. If their lengths are both given by numbers, then those numbers will at worst involve some fractions. By chang-Suppose, they argued, you have two line segments. ing the unit of length, then, we can make sure that bothof the lengths correspond to whole numbers. In other words, it must be possible to choose a unit length sothat each of our segments consists of a whole number multiple of the unit.
The two segments, then, could be“measured together,” i.e., would be “commensurable.” Now here’s the catch: the Greeks could prove that this was not always the case. Their standard example had todo with the side and the diagonal of a square. We do not know exactly how they first established that these two segments are not commensurable, but it might have been something like this: if you subtract the side from the diagonal, you will get a segment shorter than eitherof them; if both side and diagonal are measured by a common unit, then so is the difference. Now repeat the argument:
take the remainder and subtract it from the side until we get a second remainder smaller than the first (it can be subtracted twice, in fact). The second remainder will also be measured by the common unit. It turns out to be quite easy to show thatwill never terminate; instead, it will produce smaller andthis process smaller remainder segments. Eventually, the remainder segment will be smaller than the unit that supposedly measures it a whole number of times.
That is impossible (no whole number is smaller than 1, after all), andhence we can conclude that the common unit does not, in fact, exist. Today, we would say that if the length of the side isone unit, then the length of the diagonal is Of course, the diagonal does in fact have a length.$\sqrt{2} units$, and we would interpret this argument as showing thatthe number. qrt{2} is not a fraction. The Greeks did not quite see in what senseit was a length, or, even better, the ratio between the. qrt{2} could be a number. Instead, length of the diagonal and the length of the side.
Sim-ilar arguments could be applied to other lengths; for example, they knew that the side of a square of area 1 and a square of area 10 are incommensurable. The conclusion, then, is that lengths are not numbers: instead, they are some other kind of magnitude. Butnow we are faced with a proliferation of magnitudes: numbers, lengths, areas, angles, volumes, etc. Each of these must be taken as a different kind of quantity, not comparable with the others.

II.1. From Numbers to Number Systems

want to measure things. The Greeks solved this prob-This is a problem for geometry, particularly if we lem by relying heavily on the notion of aquantities of the same type have a ratio, and this ratio ratio. Two was allowed to be equal to the ratio of two quantities ofanother type: equality of two ratios was defined using Eudoxus’s theory of proportion, the latter being one ofthe most important and deep ideas of Greek geometry.
So, for example, rather than talking about a number calledπ, which to them would not be a number at all, they would say that “the ratio of the circle to the squareon its radius is the same as the ratio of the circumference to the diameter.” Notice that one of the two ratiosis between two areas, the other between two lengths. The numberics, but the Greeks did compare it with ratios betweenπ itself had no name in Greek mathemat- numbers:
little bit less than the ratio of 22 to 7 and just a little archimedes [VI.3](/part-06/archimedes-ca) showed that it was just a bit more than the ratio of 223 to 71. Doing things this way seems ungainly to us, but it worked very well. Further more, it is philosophically sat-isfying to conceive of a great variety of magnitudes organized into various kinds (segments, angles, sur-faces, etc.). Magnitudes of the same kind can be related to one another by ratios, and ratios can be compared with each other because they are relations perceived by our minds.
In fact, the word for ratio, both in Greek andin Latin, is the same as the word for “reason” or “explanation” (ning, “irrational” (logos in Greek, alogos ratio in Greek) could mean bothin Latin). From the begin“without a ratio” and “unreasonable.” what disconnected from the everyday needs of people Inevitably, this austere theoretical system was somewho needed to measure things such as lengths andangles. Astronomers kept right on using sexagesimal approximations, as did mapmakers and other scientists. There was some “leakage” of course:
in the firstcentury c.e., Heron of Alexandria wrote a book that reads like an attempt to apply the theoreticians’ dis-coveries to practical measurement. It is to him, for example, that we owe the recommendation to useas an approximation forπ. (Presumably, he chose227 Archimedes’ upper bound because it was the simpler number.) In theoretical mathematics, however, the distinction between numbers and other kinds of magni-tudes remained firm. hundred years that followed the classical Greek period The history of numbers in the West over the fifteen can be seen as having two main themes:
first, the Greek

compartmentaliz ation between different kinds of quan-tities was slowly demolished; second, in order to do this the notion of number had to be generalized over andover again. 3 Decimal Place Value Our system for representing whole numbers goes back, ultimately, to the mathematicians of the Indian subcontinent. Sometime before (probably well before) the fifth century c.e., they created nine symbols to designate the numbers from one to nine and used the position of these symbols to indicate their actual value.
So a 3 in the units position meant three, and a 3 in the tens position meant three tens, i.e., thirty. This, of course, iswhat we still do; the symbols themselves have changed, but not the principle. At about the same time, a place marker was developed to indicate an unoccupied space; this eventually evolved into our zero. Indian astronomy made extensive use of sines, which are almost never whole numbers. To represent these, a Babylonian-style sexagesimal system was used, with each “sexagesimal unit” being represented using the decimal system.
So “thirty-three and a quarter” might be represented as 33 15, i.e., 33 units and 15 “minutes” (sixtieths). Decimal place-value numeration was passed on from India to the Islamic world fairly early. In the ninth cen-tury c.e. in Baghdad, the recently established capital of the caliphate, one finds al-kh$\bar{w}ariz \bar{m}$ı [VI.5](/part-06/abu-jafar-muhammad-ibn-musa-al-khwarizm-vi55-william-kingdon-cliord-18451879) writing a treatise on numeration in the Indian style, “usingnine symbols.” Several centuries later, al-Kh$\bar{w}ariz \bar{m}$ı’s treatise was translated into Latin.
It was so popular and influential in late-medieval Europe that decimal numeration was often referred to as “algorism.” It is worth noting that in al-Kh$\bar{w}ariz \bar{m}$ı’s writing zero still had a special status: it was a place holder, nota number. But once we have a symbol, and we start doing arithmetic using these symbols, the distinction quickly disappears. We have to know how to add and multiply numbers by zero in order to multiply multi-digit numbers. In this way, “nothing” slowly became a number.
4 What People Want Is a Number As Greek culture was displaced by other influences, the practical tradition became more important. One can see this in al-Kh$\bar{w}ariz \bar{m}$ı’s other famous book, whose title

gave us the word “algebra.” The book is actually a com-pendium of many different kinds of practical or semipractical mathematics problems. Al-Kh. ar{w}the book with a declaration that tells us at once that weariz. ar{m}ı opens are no longer in the Greek mathematical world: “When I considered what people generally want in calculating, I found that it is always a number.”The first portion of al-Kh$\bar{w}ariz \bar{m}$ı’s book deals with quadratic equations and with the algebraic manipula-tions (done entirely in words, with no symbols whatsoever) needed to deal with them.
His procedure is exactly the quadratic formula we still use, which of course requires extracting a square root. But in every example the number whose square root we need to find turnsout to be a square, so that the square root is easily found—and al-Kh. ar{w}At other points in the book, however, we can seeariz$\bar{m}$ı does get a number! that al-Kh$\bar{w}$ square roots as number-like entities.
He teaches theariz$\bar{m}$ı is beginning to think of irrational reader how to manipulate symbols with square rootsin them, and gives (in words, of course) examples such asthe book, which deals with geometry and measurement,(20-. qrt{200})+(. qrt{200}-10) = 10. In the second part of one even sees an approximation to a square root: “The product is one thousand eight hundred and seventyfive; take its root, it is the area;
it is forty-three and alittle.” enced not only by the practical tradition represented The mathematicians of medieval Islam were influby al-Kh. ar{w}cially euclidariz . ar{m}ı, but also by the Greek tradition, espe-’s [VI.2](/part-06/euclid-ca) Elements. One finds in their writing a mixture of Greek precision and a more prac-tical approach to measurement. In Omar Khayyam’s Algebra Greek style and the desire for numerical solutions.
In, for example, one sees both theorems in the his discussion of cubic equations Khayyam manages tofind solutions by means of geometric constructions but laments his inability to find numerical values. Slowly, however, the realm of “number” began to grow.
The Greeks might have insisted thata number, but rather a name for a line segment, the$\sqrt{10} \text{was not}$ side of a square whose area is 10, or a name for a ratio. Among the medieval mathematicians, both in Islam and in Europe, number, entering into operations and even appearing. qrt{10} started to behave more and more like a as the solution of certain problems. 5 Giving Equal Status to All Numbers The idea of extending the decimal place-value systemto include fractions was discovered by several mathe-

II. The Origins of Modern Mathematics

maticians independently. The most influential of thesewas stevin [VI.10](/part-06/simon-stevin-15481620), a Flemish mathematician and engineer who popularized the system in a booklet called De Thiende (“The tenth”), which was first published in

1585. By extending place value to tenths, hundredths, and so on, Stevin created the system we still use today. More importantly, he explained how it simplified cal-culations that involved fractions, and gave many practical applications. The cover page, in fact, announces that the book is for “astrologers, surveyors, measurersof tapestries.” ated by his move. He knew, for example, that the dec-imal expansion for Stevin was certainly aware of some of the issues cre-1 was infinitely long;
his discussion simply says that while it might be more correct3 to say that the full infinite expansion was the correct representation, in practice it made little difference if we truncated it. Stevin was also aware that his system provided a way to attach a “number” (meaning a decimal expansion)to every single length. He saw little difference between 1 of.1764705882 (the beginning of the decimal expansion20 ) and 1.4142135623 (the beginning of the decimal expansion of17. qrt{2}).
In his Arithmetic he boldly declared that all (positive) numbers were squares, cubes, fourth powers, etc., and that roots were just numbers. He also says that “there are no absurd, irrational, irregular, inexplicable, or surd numbers.” Those were all terms used for irrational numbers, i.e., numbers that are not fractions. incredible diversity of “quantities” or “magnitudes”What Stevin was proposing, then, was to flatten the into one expansive notion of number, defined by dec-imal expansions. He was aware that these numbers could be represented as lengths along a line.
This amounted to a fairly clear notion of what we now callthe positive real numbers. ential by the invention of logarithms. Like the sine and Stevin’s proposal was made immensely more influthe cosine, these were practical computational tools. Inorder to be used, they needed to be tabulated, and the tables were given in decimal form. Very soon, every one was using decimal representation. what a bold leap this move represented. The positive It was only much later that it came to be understood real numbers are not just a larger number system;
theyare an immensely larger number system, whose internal complexity we still do not fully understand (see set theory [IV.22](/part-04/set-theory)). II.1. From Numbers to Number Systems 6 Real, False, Imaginary Even as Stevin was writing, the next steps were being taken: under the pressure of the theory of equations, negative numbers and complex numbers began to be useful. Stevin himself was already aware of negative numbers, though he was clearly not quite comfortable with them.
For example, he explained that the fact that - 3 is a root of x2 + x - 6 really means that 3 is a root of the associated polynomial x2 - x - 6, obtained by replacingx by -x every where. ated more difficult problems. The work of several Ital-This was an easy dodge, but cubic equations creian mathematicians of the sixteenth century led to amethod for solving cubic equations. As a crucial step, this method involved extracting a square root.
The problem was that the number whose root was needed sometimes came out negative. Up until then, it had always turned out that when an algebraic problem led to the extraction of the square root of a negative number, the problem simply had no solution. But the equation have a solution—indeed, x = x34 is one—it was just that= 15 x + 4 clearly did applying the cubic formula required computing$\sqrt{-121}$. engineer, who decided to bite the bullet and just seewhat happened.
In his It was bombelli [VI.8](/part-06/rafael-bombelli-1526after), also a mathematician and Algebra, published in 1572, he went ahead and computed with this “new kind of rad-ical” and showed that he could find the solution of the cubic in this way. This showed that the cubic for-mula did indeed work in this case; more importantly, it showed that these strange new numbers could beuseful. these new quantities.
About fifty years later, we findboth Albert Girard and It took a while for people to become comfortable with descartes [VI.11](/part-06/ren-descartes-15961650) saying that equations can have three sorts of roots: true (mean-ing positive), false (negative), and imaginary. It is not completely clear that they understood that these imag-inary roots would be what we now call complex numbers;
Descartes, at least, sometimes seems to be saying that an equation of degreen must have n roots, and that the ones that are neither “true” nor “false” must simply be imagined. Slowly, however, complex numbers began to be used. They came up in the theory of equations, in debates about the logarithms of negative numbers, and in connection to trigonometry. Their connection with the sine and cosine functions (via the exponential) was turned into a powerful tool by euler [VI.19](/part-06/leonhard-euler-17071783) in the eighteenth

century. By the middle of the eighteenth century, it waswell-known that every polynomial had a complete set of roots in the complex numbers. This result became known as[V.13](/part-05/the-fundamental-theorem-of-algebra); it was finally proved to everyone’s satisfaction the fundamental theorem of algebra by gauss [VI.26](/part-06/carl-friedrich-gauss-17771855). Thus, the theory of equations did not seem to require any further extension of the notion ofnumber.
7 Number Systems, Old and New Since complex numbers are clearly different from real numbers, their presence stimulated people to begin classifying numbers into different kinds. Stevin’s egal-itarianism had its impact, but it could not quite erase the fact that whole numbers are nicer than decimals, and that fractions are generally easier to grasp than irrational numbers. In the nineteenth century, all sorts of new ideas created the need for a more careful look at this classifi-cation.
In number theory, Gauss and kummer [VI.40] started looking at subsets of the complex numbers that behaved in a way analogous to the integers, such as theset of all numbersa + b. qrt{-1} with a and b both integers. In the theory of equations, that in order to do a careful analysis of the solvability ofgalois [VI.41](/part-06/variste-galois-18111832) pointed out an equation one must start by agreeing on what num-bers count as “rational.” So, for example, he pointed out that in abel’s [VI.33](/part-06/niels-henrik-abel-18021829) theorem on the unsolvability of the quintic, “rational” meant
“expressible as a quotientof polynomials in the symbols used as the coefficients of the equation,” and he noted that the set of all such expressions obeyed the usual rules of arithmetic. lished that e and In the eighteenth century, Johann Lambert had estab-π were irrational, and conjectured that in fact they werewere not roots of any polynomial equation. Even the transcendental, that is, that they existence of transcendental numbers was not known atthe time; liouville [VI.39](/part-06/joseph-liouville-18091882) proved that such numbers exist in 1844.
Within a few decades, it was proved thatboth e andπ were transcendental, and later in the cen- turyity of real numbers were transcendental. Cantor’s dis-cantor [VI.54](/part-06/georg-cantor-18451918) showed that in fact the vast majorcovery highlighted, for the first time, that the system Stevin had popularized contained unexpected depths.
number, however, came aftercovery, in 1843, of a completely new number system. Perhaps the most important change in the concept ofhamilton’s [VI.37](/part-06/william-rowan-hamilton-18051865) dis Hamilton had noticed that coordinatizing the plane using complex numbers (rather than simply using pairs

of real numbers) vastly simplified plane geometry. Heset out to find a similar way to parametrize three dimensional space. This turned out to be impossible, but led Hamilton to ahe called the quaternions four-dimensional system, which[III.76](/part-03/quaternions-octonions-and-normed-iv25-probabilistic-models-of-critical-phenomena). These behaved much like numbers, with one crucial difference: mul-tiplication was not commutative, that is, if q and q are quaternions, qq^  and q^ q are usually not the same. complex numbers,” and their appearance generated lots of new questions.
Were there other such systems?The quaternions were the first system of “hyper What counts as a number system? If certain “numbers”can fail to satisfy the commutative law, can we make numbers that break other rules?In the long run, this intellectual ferment led mathematicians to let go of the vague notion of “number”or “quantity” and to hold on, instead, to the more formal notion of an algebraic structure. Each of the number systems, in the end, is simply a set of entities onwhich we can do operations.
What makes them interesting is that we can use them to parametrize, or coor-dinatize, systems that interest us. The whole numbers (or integers, to give them their latinized formal name), for example, formalize the notion of counting, whilethe real numbers parametrize the line and serve as the basis for geometry. By the beginning of the twentieth century, there were many well-known number systems.
The integers had pride of place, followed by a nested hierarchy con-sisting of the rational numbers (i.e., the fractions), the real numbers (Stevin’s decimals, now carefully formal-ized), and the complex numbers. Still more general than the complex numbers were the quaternions. But these were by no means the only systems around. Number theorists worked with several different fields of algebraic numbers, subsets of the complex num-bers that could be understood as autonomous systems. Galois had introduced finite systems that obeyed the usual rules of arithmetic, which we now call finite fields.
Function theorists worked with fields of functions; they certainly did not think of these as numbers, but their analogy to number systems was known and exploited. duced thefrom the rational numbers by giving a special role to a Early in the twentieth century, Kurt Hensel intro-p-adic numbers [III.51](/part-03/local-and-global-in-number-theory), which were built prime numberin fact created infinitely many new number systems.)p. (Since p can be chosen at will, Hensel These too “obeyed the usual rules of arithmetic,” inthe sense that addition and multiplication behaved as

II. The Origins of Modern Mathematics

expected; in modern language, they were$p$-adics provided the first system of things that were fields. The recognizably numbers but that had no visible relationto the real or complex numbers—apart from the fact that both systems contained the rational numbers. As a result, they led Ernst Steinitz to create an abstract theory of fields. work had also occurred in other parts of mathemat-The move to abstraction that appears in Steinitz’s ics, most notably the theory of groups and their repre-sentations and the theory of algebraic numbers.
All of these theories were brought together into conceptual unity byknown as “abstract algebra.” This left numbers behind noether [VI.76](/part-06/emmy-noether-18821935), whose program came to be completely, focusing instead on the abstract structure of sets with operations. as a “number.” The objects from the original sequenceof “integer, rational, real, and complex” are certainly Today, it is no longer that easy to decide what counts numbers, but so are therarely referred to as “numbers,” on the other hand, p-adics.
The quaternions are though they can be used to coordinatize certain mathematical notions. In fact, even stranger systems canshow up as coordinates, such as Cayley’s octonions [III.76](/part-03/quaternions-octonions-and-normed-iv25-probabilistic-models-of-critical-phenomena). In the end, whatever serves to parametrize or coordinatize the problem at hand is what we use. If the requisite system turns out not to exist yet, well, one just has to invent it. Further Reading Berlinghoff, W. P., and F. Q. Gouvêa. 2004.Ages: A Gentle History for Teachers and Others Math through the, expanded edn.
Farmington, ME/Washington, DC: Oxton House/The Mathematical Association of America. Ebbingaus, H.-D., et al. 1991.Fauvel, J., and J. J. Gray, eds. 1987.Numbers The History of Mathe-. New York: Springer. Fowler, D. 1985. 400 years of decimal fractions.matics: A Readerics Teaching 110:20–21.. Basingstoke: Macmillan. Mathemat Gouvêa, F. Q. 2003.Oxford: Oxford University Press.edn. New York: Springer.. 1999. The Mathematics of Plato’s Academy$p$-adic Numbers: An Introduction, 2 nd edn., 2 nd Katz, V. J. 1998.MA: Addison - Wesley. A History of Mathematics, 2 nd edn. Reading, China, India, and Islam:
 A Sourcebook Princeton University Press., ed. 2007. The Mathematics of Egypt, Mesopotamia,. Princeton, NJ: Mazur, B. 2002.Root of Minus Fifteen)Imagining Numbers (Particularly the Square. New York: Farrar, Straus, and Giroux. II.2. Geometry Menninger, K. 1992.A Cultural History of Numbers Number Words and Number Symbols:. New York: Dover. (Translated by P. Broneer from the revised German edition of1957/58: Zahlwort und Ziffer. Eine Kul tur geschichte der Reid, C. 2006.Zahl Interesting. Göttingen: Vandenhoeck und Ruprecht.). Natick, MA: A. K. Peters. From Zero to Infinity:
What Makes Numbers II.2 Geometry Jeremy Gray 1 Introduction The modern view of geometry was inspired by the novel geometrical theories of hilbert [VI.63](/part - 06/david - hilbert - 18621943) and Einstein in the early years of the twentieth century, which built intheir turn on other radical reformulations of geometry in the nineteenth century. For thousands of years, the geometrical knowledge of the Greeks, as set out most notably in euclid’s [VI.2](/part - 06/euclid - ca) Elements, was held up as a paradigm of perfect rigor, and indeed of human know - ledge.
The new theories amounted to the overthrow of an entire way of thinking. This essay will pursue the his-tory of geometry, starting from the time of Euclid, continuing with the advent of non-Euclidean geometry, andending with the work of riemann [VI.49], klein [VI.57], and poincaré [VI.61](/part - 06/jules - henri - poincar - 18541912). Along the way, we shall examine how and why the notions of geometry changed so remarkably. Modern geometry itself will be discussed in later parts of this book.
2 Naive Geometry Geometry generally, and Euclidean geometry in particular, is informally and rightly taken to be the math-ematical description of what you see all around you: a space of three dimensions (left–right, up–down, for - wards–backwards) that seems to extend indefinitely far. Objects in it have positions, they sometimes move around and occupy other positions, and all of these positions can be specified by measuring lengths along straight lines: this object is twenty meters from thatone, it is two meters tall, and so on.
We can also measure angles, and there is a subtle relationship between angles and lengths. Indeed, there is another aspect to geometry, which we do not see but which we rea-son about. Geometry is a mathematical subject that is full of Pythagorean theorem, and so on—which collectively theorems—the isosceles triangle theorem, the summarize what we can say about lengths, angles, shapes, and positions. What distinguishes this aspect of geometry from most other kinds of science is itshighly deductive nature.
It really seems that by taking the simplest of concepts and thinking hard aboutthem one can build up an impressive, deductive body of knowledge about space without having to gather experimental evidence. genuine knowledge of space without ever leaving our But can we? Is it really as simple as that? Can we have armchairs? It turns out that we cannot: there are other geometries, also based on the concepts of length and angle, that have every claim to be useful, but that disagree with Euclidean geometry.
This is an astonishing discovery of the early nineteenth century, but, before it could be made, a naive understanding of fundamental concepts, such as straightness, length, and angle, had to be replaced by more precise definitions—a process that took many hundreds of years. Once this had been done, first one and then infinitely many new geometries were discovered. 3 The Greek Formulation Geometry can be thought of as a set of useful facts about the world, or else as an organized body of knowledge. Either way, the origins of the subject are much disputed.
It is clear that the civilizations of Egypt and Babylonia had at least some knowledge of geometry—otherwise, they could not have built their large cities, elaborate temples, and pyramids. But not only is it dif-ficult to give a rich and detailed account of what was known before the Greeks, it is difficult even to makesense of the few scattered sources that we have from before the time of Plato and Aristotle. One reason forthis is the spectacular success of the later Greek writer, and author of what became the definitive text on geometry, Euclid of Alexandria (ca.
300 his famous Elements shows that a proper account ofb.c.e.). One glance at the history of geometry will have to be about some-thing much more than the acquisition of geometrical facts. Thebody of knowledge. It is divided into a number of dis-Elements is a highly organized, deductive tinct themes, but each theme has a complex theoretical structure.
Thus, whatever the origins of geom-etry might have been, by the time of Euclid it had become the paradigm of a logical subject, offering akind of knowledge quite different from, and seemingly higher than, knowledge directly gleaned from ordinary experience. history of geometry, this essay will trace the high road Rather, therefore, than attempt to elucidate the early of geometry’s claim on our attention: the apparent cer-tainty of mathematical knowledge. It is exactly this claim to a superior kind of knowledge that led eventually to the remarkable discovery ofgeometry:
there are geometries other than Euclid’s thatnon-Euclidean are every bit as rigorously logical. Even more remark - ably, some of these turn out to provide better models of physical space than Euclidean geometry. of plane figures: triangles, quadrilaterals, and circles. The famous theorem of Pythagoras is the forty-seventh The Elements opens with four books on the study proposition of the first book. Then come two books onthe theory of ratio and proportion and the theory of similar figures (scale copies), treated with a high degreeof sophistication.
The next three books are about whole numbers, and are presumably a reworking of mucholder material that would now be classified as elementary number theory. Here, for example, one finds the famous result that there are infinitely many prime num - bers. The next book, the tenth, is by far the longest, and deals with the seemingly specialist topic of lengthsof the forma ± . qrt{b} (to write them as we would). The final three books, where the curious lengths studied in Book X play a role, are about three-dimensional geom - etry.
They end with the construction of the five regular solids and a proof that there are no more. The discov-ery of the fifth and last had been one of the topics that excited Plato. Indeed, the five regular solids are crucial to the cosmology of Plato’s late work the Most books of the Elements open with a number Timaeus. of definitions, and each has an elaborate deductive structure. For example, to understand the Pythagorean theorem, one is driven back to previous results, and thence to even earlier results, until finally one comesto rest on basic definitions.
The whole structure is quite compelling: reading it as an adult turned the philosopher Thomas Hobbes from incredulity to lasting belief in a single sitting. What makes the Elements so convincing is the nature of the arguments employed. With some exceptions, mostly in the number-theoretic books, these arguments use the axiomatic method. That is to say, they start with some very simple axioms that are intended to be self-evidently true, and proceed by purely logical means to deduce theorems from them. For this approach to work, three features must be in place. The first is thatfully avoided.
That is, if you are trying to prove a state-circularity should be carement P and you deduce it from an earlier statement, and deduce that from a yet earlier statement, and soon, then at no stage should you reach the statement II. The Origins of Modern Mathematics Pbut merely show that all the statements in your chain again. That would not prove P from the axioms, were equivalent. Euclid did a remarkable job in this respect. The second necessary feature is that the rules of inference should be clear and acceptable.
Some geomet-rical statements seem so obvious that one can fail to notice that they need to be proved: ideally, one should use no properties of figures other than those that havebeen clearly stated in their definitions, but this is a difficult requirement to meet. Euclid’s success here was still impressive, but mixed. On the one hand, the Elements is a remarkable work, far outstripping any contemporary account of any of the topics it covers, and capableof speaking down the millennia. On the other, it has little gaps that from time to time later commentators would fill.
For example, it is neither explicitly assumed nor proved in the Elements that two circles will meet if their centers lie outside each other and the sum oftheir radii is greater than the distance between their centers. However, Euclid is surprisingly clear that thereare rules of inference that are of general, if not indeed universal, applicability, and others that apply to math-ematics because they rely on the meanings of the terms involved. The third feature, not entirely separable from the second, is adequate definitions. Euclid offered two, orperhaps three, sorts of definition.
Book I opens with seven definitions of objects, such as “point” and “line,”that one might think were primitive and beyond definition, and it has recently been suggested that these definitions are later additions. Then come, in Book I and again in many later books, definitions of familiar figures designed to make them amenable to mathematical reasoning: “triangle,” “quadrilateral,” “circle,” andso on. The postulates of Book I form the third class of definition and are rather more problematic. Book I states five “common notions,” which are rules of inference of a very general sort.
For example, “Ifequals be added to equals, the wholes are equals.” The book also has five “postulates,” which are more nar-rowly mathematical. For example, the first of these asserts that one may draw a straight line from any pointto any point. One of these postulates, the fifth, became notorious: the so - called“If a straight line falling on two straight lines make the parallel postulate. It says that interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, meet on that side on which are the angles less than two right angles.” II.2.
Geometry meet. A helpful rephrasing of Euclid’s parallel postulate was introduced by the Scottish editor, Robert Simson. It Parallel lines, therefore, are straight lines that do not appears in his edition of Euclid’s There he showed that the parallel postulate is equiva-Elements from 1806. lent, if one assumes those parts of thedo not depend on it, to the following statement: given Elements that any line m in a plane, and any point P in that plane that does not lie on the line m, there is exactly one line nin the plane that passes through the point P and does not meet the line m.
From this formulation it is clearthat the parallel postulate makes two assertions: given a line and a point as described, a parallel line exists and it is It is worth noting that Euclid himself was probably unique. well aware that the parallel postulate was awkward. Itasserts a property of straight lines that seems to have made Greek mathematicians and philosophers uncomfortable, and this may be why its appearance in thements is delayed until proposition 29 of Book I.
The Ele comment at or Proclus (fifth centurysive discussion of Book I of the Elementsc.e., observed that), in his extenthe hyperbola and asymptote get closer and closer as they move outwards, but they never meet. If a line and acurve can do this, why not two lines? The matter needs further analysis. Unfortunately, not much of thements would be left if mathematicians dropped the par-Eleallel postulate and retreated to the consequences of the remaining definitions: a significant body of knowledge depends on it.
Most notably, the parallel postulate is needed to prove that the angles in a triangle add up totwo right angles—a crucial result in establishing many other theorems about angles in figures, including the Pythagorean theorem. Euclid’sof experts knew that it was an unsatisfactory compro-Whatever claims educators may have made about Elements down the ages, a significant number mise: a useful and remarkably rigorous theory could be had, but only at the price of accepting the parallel pos - tulate. But the parallel postulate was difficult to accept on trust:
it did not have the same intuitively obvious feel of the other axioms and there was no obvious way of verifying it. The higher one’s standards, the more painful this compromise was. What, the experts asked, was to be done? view, if the truth of the parallel postulate was not obvi - ous, and yet geometry was bare without it, then the only One Greek discussion must suffice here. In Proclus’s possibility was that it was true because it was a theo - rem. And so he gave it a proof. He argued as follows.
Let two lines m and n cross a third line k at P and Q , respec - tively, and make angles with it that add up to two right angles. Now draw a line l that crosses m at P and entersthe space between the lines m and n. The distance between l and m as one moves away from the point Pc on ti nu ally increases, said Proclus, and therefore line l must eventually cross line n. Proclus’s argument is flawed. The flaw is subtle, and sets us up for what is to come. He was correct that the distance between the lines l and m increases indef - initely.
But his argument assumes that the distance between lines m and n does notnitely, and is instead bounded. Now Proclus knew veryalso increase indefiwell that if the parallel postulate is granted, then it can be shown that the lines m and n are parallel and thatthe distance between them is a constant. But until the parallel postulate is proved, nothing prevents one say-ing that the lines m and n diverge.
Proclus’s proof does not therefore work unless one can show that lines that do not meet also do not diverge. Proclus’s attempt was not the only one, but it is typical of such arguments, which all have a standard form. They start by detaching the parallel postulate from Euclid’s Elements, together with all the arguments and theorems that depend on it. Let us call what remains the “core” of the Elements. Using this core, an attempt is then made to derive the parallel postulate as a the - orem.
The correct conclusion to be derived from Proclus’s attempt is not that the parallel postulate is a theorem, but rather that, given the core of thethe parallel postulate is equivalent to the statement Elements, that lines that do not meet also do not diverge. Aganis, a writer of the sixth century c.e. about whom almost nothing is known, assumed, in a later attempt, that parallel lines are every where equidistant, and his argument showed only that, given the core, the Euclidean definition of parallel lines is equivalent to defining them tobe equidistant.
Notice that one cannot even enter this debate unless one is clear which properties of straight lines belong tothem by definition, and which are to be derived as theorems. If one is willing to add to the store of “common - sense” assumptions about geometry as one goes along, the whole careful deductive structure of the Elements collapses into a pile of facts. This deductive character of the Elements is clearly something that Euclid regarded as important, but onecan also ask what he thought geometry was about. Was it meant, for example, as a mathematical description of space?
No surviving text tells us what he thought about this question, but it is worth noting that the most celebrated Greek theory of the universe, developed by Aristotle and many later commentators, assumed thatspace was finite, bounded by the sphere of the fixed stars. The mathematical space of thenite, and so one has at least to consider the possibility Elements is infithat, for all these writers, mathematical space was not intended as a simple idealization of the physical world.
4 Arab and Islamic Commentators What we think of today as Greek geometry was thework of a handful of mathematicians, mostly concentrated in a period of less than two centuries. They were eventually succeeded by a somewhat larger number of Arabic and Islamic writers, spread out over a much greater area and a longer time. These writers tend to be remembered as commentators on Greek mathematics and science, and for transmitting them to later Western authors, but they should also be remembered ascreative, innovative mathematicians and scientists in their own right.
A number of them took up the studyof Euclid’s Elements, and with it the problem of the parallel postulate. They too took the view that it was nota proper postulate, but one that could be proved as a theorem using the core alone. Among the first to attempt a proof was T. ar{h}abit ibn Qurra. He was a pagan from near Aleppo who lived andworked in Baghdad, where he died in 901. Here there is room to describe only his first approach.
He argued that if two lines m and n are crossed by a third, k, and if they approach each other on one side of the line k, then they diverge indefinitely on the other side of k. He deduced that two lines that make equal alternate angles with a transversal (the marked angles in figure 1) cannot approach each other on one side of a transversal: the symmetry of the situation would imply that they approached on the other side as well, but he had shownthat they would have to diverge on the other side.
From this he deduced the Euclidean theory of parallels, buthis argument was also flawed, since he had not considered the possibility that two lines could directions. diverge in both tist ibn al-Haytham was born in Basra in 965 and diedin Egypt in 1041. He took a quadrilateral with two equal The distinguished Islamic mathematician and sciensides perpendicular to the base and dropped a perpen-dicular from one side to the other.
He now attempted to prove that this perpendicular is equal to the base, and to do so he argued that as one of two original perpendiculars is moved toward the other, its tip sweeps II. The Origins of Modern Mathematics makbn Figure 1 angles The lines m and n make equal alternatea and b with the transversal k. A D A' B B' C Figure 2 angle, ABAB and CD are equal, the angle ADC is a right^ is an intermediate position of AB as it moves toward CD. out a straight line, which will coincide with the per-pendicular just dropped (see figure 2).
This amounts to the assumption that the curve every where equidis-tant from a straight line is itself straight, from which the parallel postulate easily follows, and so his attempt fails. His proof was later heavily criticized by Omar Khayyam for its use of motion, which he found fun-damentally unclear and alien to Euclid’s Elements. It is indeed quite distinct from any use Euclid had for motion in geometry, because in this case the natureof the curve obtained is not clear:
it is precisely what needs to be analyzed. The last of the Islamic attempts on the parallel postulate is due to Nas.ır al-$\bar{D}$ın al-T. ̄u$\bar{s}$ı. He was born in Iranin 1201 and died in Baghdad in 1274. His extensive commentary is also one of our sources of knowledgeof earlier Islamic mathematical work on this subject. Al-T. ̄u. ar{s}ı focused on showing that if two lines begin toconverge, then they must continue to do so until they eventually meet.
To this end he set out to show that (*) if l and m are two lines that make an angle of less than a right angle, then every line perpendicular to l meets the line m.

II.2. Geometry

He showed that if (follows. However, his argument for (*) is true, then the parallel postulate*) is flawed. some of these arguments if one uses only the tech-It is genuinely difficult to see what is wrong with niques available to mathematicians of the time. islamic mathematicians showed a degree of sophistication that was not to be surpassed by their Western successors until the eighteenth century.
Unfortunately, however, their writings did not come to the attention of the Westuntil much later, with the exception of a single work in the Vatican Library, published in 1594, which wasfor many years erroneously attributed to al-T. ̄u. ar{s}ı (and which may have been the work of his son). 5 The Western Revival of Interest The Western revival of interest in the parallel postu-late came with the second wave of translations of Greek mathematics, led by Commandino and Maurolico in the sixteenth century and spread by the advent of printing.
Important texts were discovered in a number ofolder libraries, and ultimately this led to the production of new texts of Euclid’shad something to say about the problem of parallels, Elements. Many of these pithily referred to by Henry Savile as “a blot on Euclid.”For example, the powerful Jesuit Christopher Clavius, who edited and reworked theargue that parallel lines could be defined as equidistant Elements in 1574, tried to lines.
space of Euclidean geometry came about gradually dur-ing the sixteenth and seventeenth centuries, after the The ready identification of physical space with the acceptance of Copernican astronomy and the aboli-tion of the so-called sphere of fixed stars. It was canonized by newton [VI.14](/part - 06/isaac - newton - 16421727) in his Principia mathematica firmly situated in Euclidean space.
Although Newto-, which proposed a theory of gravitation that was nian physics had to fight for its acceptance, Newto-nian cosmology had a smooth path and became the unchallenged orthodoxy of the eighteenth century. Itcan be argued that this identification raised the stakes, because any unexpected or counter intuitive conclusion drawn solely from the core of the Elements was now, possibly, a counter intuitive fact about space. In 1663 the English mathematician John Wallis took a much more subtle view of the parallel postulate thanany of his predecessors.
He had been instructed by Halley, who could read Arabic, in the contents of the apoc-ryphal edition of al - T. ̄u. ar{s}ı’s work in the Vatican Library, and he too gave an attempted proof. Unusually, Wallis also had the insight to see where his own argument wasflawed, and commented that what it really showed was that, in the presence of the core, the parallel postulate was equivalent to the assertion that there exist similar figures that are not congruent. Half a century later, Wallis was followed by the most persistent and thoroughgoing of all the defenders ofthe parallel postulate, Gerolamo
Saccheri, an Italian Jesuit who published in 1733, the year of his death, a short book called little masterpiece of classical reasoning opens with a Euclid Freed of Every Flaw. This trichotomy. Unless the parallel postulate is known, theangle sum of a triangle may be either less than, equal to, or greater than two right angles. Saccheri showed that whatever happens in one triangle happens for them all, so there are apparently three geometries compatible with the core. In the first, every triangle has an anglesum less than two right angles (call this case L).
In the second, every triangle has an angle sum equal to two right angles (call this case E). In the third, every trian-gle has an angle sum greater than two right angles (call this case G). Case E is, of course, Euclidean geometry, which Saccheri wished to show was the only case possible. He therefore set to work to show that each of the other cases independently self - destructed. He was suc-cessful with case G, and then turned to case L “which alone obstructs the truth of the [parallel] axiom,” as heput it.
Case L proved to be difficult, and during the course of his investigations Saccheri established a number of interesting propositions. For example, if case L is true, then two lines that do not meet have just one common perpendicular, and they diverge on either side of it. In the end, Saccheri tried to deal with his difficulties by relying on foolish statements about the behavior oflines at infinity: it was here that his attempted proof failed. Saccheri’s work sank slowly, though not completely, into obscurity.
It did, however, come to the attention of the Swiss mathematician Johann Lambert, who pur-sued the trichotomy but, unlike Saccheri, stopped short of claiming success in proving the parallel postulate. Instead the work was abandoned, and was published only in 1786, after his death. Lambert distinguished carefully between unpalatable results and impossibil - ities. He had a sketch of an argument to show that in case L the area of a triangle is proportional to the dif-ference between two right angles and the angle sum of the triangle.
He knew that in case L similar triangles had to be congruent, which would imply that the tables of trigonometric functions used in astronomy were not in fact valid and that different tables would have to be produced for every size of triangle. In par - ticular, for every angle less than 60◦ there would be precisely one equilateral triangle with that given angleat each vertex.
This would lead to what philosophers called an “absolute” measure of length (one could take, for instance, the length of the side of an equilateral triangle with angles equal to 30◦), which leibniz’s [VI.15](/part - 06/gottfried - wilhelm - leibniz - 16461716) follower Wolff had said was impossible. And indeed itis counter intuitive: lengths are generally defined in relative terms, as, for instance, a certain proportion of thelength of a meter rod in Paris, or of the circumference of Earth, or of something similar.
But such arguments, said Lambert, “were drawn from love and hate, with which a mathematician can have nothing to do.” 6 The Shift of Focus around 1800 The phase of Western interest in the parallel postu-late that began with the publication of modern editions of Euclid’s Elements started to decline with a further turn in that enterprise.
After the French revolution, legendre [VI.24](/part - 06/adrien - marie - legendre - 17521833) set about writing textbooks, largely for the use of students hoping to enter the École Polytechnique, that would restore the study of elementary geometry to something like the rigorous form in which it appeared in theto seek to replace books of a heavily intuitive kind, but Elements. However, it was one thing quite another to deliver the requisite degree of rigor. Legendre, as he came to realize, ultimately failed in his attempt.
Specifically, like everyone before him, he was unable to give an adequate defense of the parallel pos - tulate. Legendre’s Éléments de Géométrie ran to numerous editions, and from time to time a different attempton the postulate was made. Some of these attempts would be hard to describe favorably, but the best canbe extremely persuasive. took it for granted that the parallel postulate had tobe true. But by around 1800 this attitude was no longer Legendre’s work was classical in spirit, and he still universally held.
Not everybody thought that the postu-late must, somehow, be defended, and some were prepared to contemplate with equanimity the idea that itmight be false. No clearer illustration of this shift can be found than a brief note sent to F. K. Schweikart, a Professor of Law at the university gauss [VI.26](/part - 06/carl - friedrich - gauss - 17771855) by of Marburg, in 1818. Schweikart described in a page the main results he had been led to in what he called“astral geometry,” in which the angle sum of a triangle II. The Origins of Modern Mathematics was less than two right angles:
squares had a partic-ular form, and the altitude of a right-angled isosceles triangle was bounded by an amount Schweikart called“the constant.” Schweikart went so far as to claim that the new geometry might even be the true geometry ofspace. Gauss replied positively. He accepted the results, and he claimed that he could do all of elementary geometry once a value for the constant was given. One could argue, somewhat ungenerously, that Schweikart had done little more than read Lambert’s posthumous book—although the theorem about isosceles triangles is new.
However, what is notable is the attitude ofmind: the idea that this new geometry might be true, and not just a mathematical curiosity. Euclid’s Elements shackled him no more. Unfortunately, it is much less clear what Gauss himself thought. Some historians, bearing Gauss’s remark-able mathematical originality in mind, have been inclined to interpret the evidence in such a way that Gauss emerges as the first person to discover non - Eu-clidean geometry. However, the evidence is slight, and it is difficult to draw firm conclusions from it.
There aretraces of some early investigations by Gauss of Euclidean geometry that include a study of a new definition of parallel lines; there are claims made by Gauss late inlife that he had known this or that fact for many years; and there are letters he wrote to his friends.
But thereis no material in the surviving papers that allows us to reconstruct what Gauss knew or that supports the claim that Gauss discovered non-Euclidean geometry. Rather, the picture would seem to be that Gauss came to realize during the 1810 s that all previous attemptsto derive the parallel postulate from the core of Euclidean geometry had failed and that all future attempts would probably fail as well. He became more and more convinced that there was another possible geometry of space.
Geometry ceased, in his mind, to have thestatus of arithmetic, which was a matter of logic, and became associated with mechanics, an empirical science. The simplest accurate statement of Gauss’s posi-tion through the 1820 s is that he did not doubt that space might be described by a non-Euclidean geometry, and of course there was only one possibility: that of case L described above. It was an empirical matter, but one that could not be resolved by land-based measure-ments because any departure from Euclidean geometry was, evidently, very small.
In this view he was sup-ported by his friends, such as Bessel and Olbers, both professional astronomers. Gauss the scientist was convinced, but Gauss the mathematician may have retained II.2. Geometry a small degree of doubt, and certainly never devel-oped the mathematical theory required to describe non-Euclidean geometry adequately. One theory available to Gauss from the early 1820 s was that of differential geometry. Gauss eventually published one of his masterworks on this subject, his(1827).
In it he showed how to describe geometry on Disquisitiones Generales circa Superficies Curvas any surface in space, and how to regard certain fea-tures of the geometry of a surface as intrinsic to the surface and independent of how the surface was embedded into three-dimensional space.
It would have been possible for Gauss to consider a surface of constant negativeon such a surface are described by hyperbolic trigono - curvature [III.78](/part - 03/ricci - flow), and to show that triangles metric formulas, but he did not do this until the 1840 s. Had he done so, he would have had a surface on which the formulas of a geometry satisfying case L apply. A surface, however, is not enough. We accept the validity of two-dimensional Euclidean geometry be-cause it is a simplification of three-dimensional Euclidean geometry.
Before a two-dimensional geometry sat-isfying the hypotheses of case L can be accepted, it is necessary to show that there is a plausible three - dimen-sional geometry analogous to case L. Such a geometry has to be described in detail and shown to be as plau-sible as Euclidean three-dimensional geometry. This Gauss simply never did. 7 Bolyai and Lobachevskii The fame for discovering non-Euclidean geometry goesto two men, bolyai [VI.34] in Hungary and lobachevskii ilar accounts of it.
In particular, both men described a[VI.31](/part - 06/nicolai - ivanovich - lobachevskii - 17921856) in Russia, who independently gave very simsystem of geometry in two and three dimensions that differed from Euclid’s but had an equally good claim to be the geometry of space. Lobachevskii published first, in 1829, but only in an obscure Russian journal, and then in French in 1837, in German in 1840, and againin French in 1855. Bolyai published his account in 1831, in an appendix to a two-volume work on geometry byhis father.
Both men defined parallels in a novel way, as follows. Given a point P and a line m there will be some lines It is easiest to describe their achievements together. through P that meet m and others that do not. Sepa-rating these two sets will be two lines through P that do not quite meet m but which might come arbitrarily close, one to the right of P and one to the left. This situation is illustrated in figure 3: the two lines in question P n'' n' m Figure 3 The lines nand n^ through P separate the lines through P that meet the line m from those that do not.
P Figure 4 A curve perpendicular to a family of parallels. are nand n^ . Notice that lines on the diagram appear curved. This is because, in order to represent them on a flat, Euclidean page, it is necessary to distort them, unless the geometry is itself Euclidean, in which case one can put nand n^ together and make a single line that is infinite in both directions.
Given this new way of talking, it still makes sense to talk of dropping the perpendicular from P to the line m. The left and right parallels to m through P make equal angles with the perpendicular, called the angle of parallelism is Euclidean. However, if it is less than a right angle,. If the angle is a right angle, then the geometry then the possibility arises of a new geometry. It turns out that the size of the angle depends on the lengthof the perpendicular from P to m.
Neither Bolyai nor Lobachevskii expended any effort in trying to show that there was not some contradiction in taking the angle of parallelism to be less than a right angle. Instead, they simply made the assumption and expended a great dealof effort on determining the angle from the length of the perpendicular. allel (in the same direction) to a given line, and givena point on one of the lines, there is a curve through They both showed that, given a family of lines all parthat point that is perpendicular to each of the lines(figure 4).
In Euclidean geometry the curve defined in this way is the straight line that is at right angles to the fam-ily of parallel lines and that passes through the given P Figure 5 a family of Euclidean parallels. A curve perpendicular to P Q a family of Euclidean lines through a point. Figure 6 A curve perpendicular to point (figure 5). If, again in Euclidean geometry, onetakes the family of all lines through a common point Q and chooses another point P, then there will be a curve through P that is perpendicular to all the lines: the circle with center Q that passes through P (figure 6).
some of the properties of both these Euclidean con-The curve defined by Bolyai and Lobachevskii has struc tions: it is perpendicular to all the parallels, but itis curved and not straight. Bolyai called such a curve an L - curve. Lobachevskii more helpfully called it a horocycle, and the name has stuck. three-dimensional geometry. Here Lobachevskii’s argu-ments were somewhat clearer than Bolyai’s, and both Their complicated arguments took both men into men notably surpassed Gauss.
If the figure defining ahorocycle is rotated about one of the parallel lines, the lines become a family of parallel lines in three dimensions and the horocycle sweeps out a bowl-shaped sur - face, called the F -surface by Bolyai and the horosphere by Lobachevskii. Both men now showed that something remarkable happens. Planes through the horosphere cut it either in circles or in horocycles, and if a triangle II. The Origins of Modern Mathematics is drawn on a horosphere whose sides are horocycles, then the angle sum of such a triangle is two right angles.
To put this another way, although the space that contains the horosphere is a three-dimensional version ofcase L, and is definitely not Euclidean, the geometry you obtain when you restrict attention to the horosphere is(two - dimensional) Euclidean geometry! Bolyai and Lobachevskii also knew that one can draw spheres in their three-dimensional space, and they showed (though in this they were not original) that the formulas of spherical geometry hold independently ofthe parallel postulate.
Lobachevskii now used an ingenious construction involving his parallel lines to show that a triangle on a sphere determines and is deter-mined by a triangle in the plane, which also determines and is determined by a triangle on the horo - sphere. This implies that the formulas of spherical geometry must determine formulas that apply to the triangles on the horosphere. On checking through the details, Lobachevskii, and in more or less the same way Bolyai, showed that the triangles on the horosphere are described by the formulas of hyperbolic trigonometry.
The formulas for spherical geometry depend on the radius of the sphere in question. Similarly, the formu-las of hyperbolic trigonometry depend on a certain real parameter. However, this parameter does not have asimilarly clear geometrical interpretation. That defect apart, the formulas have a number of reassuring properties.
In particular, they closely approximate the famil-iar formulas of plane geometry when the sides of the triangles are very small, which helps to explain howthis geometry could have remained undetected for so long—it differs very little from Euclidean geometry in small regions of space. Formulas for length and areacan be developed in the new setting: they show that the area of a triangle is proportional to the amount bywhich the angle sum of the triangle falls short of two right angles.
Lobachevskii, in particular, seems to have felt that the very fact that there were neat and plausible formulas of this kind was enough reason to accept the new geometry. In his opinion, all geometry was about measurement, and theorems in geometry were unfailing connections between measurements expressed by formulas. His methods produced such formulas, andthat, for him, was enough. tion of a novel three-dimensional geometry, raised the question of which geometry is true:
is it Euclidean Bolyai and Lobachevskii, having produced a descrip geometry or is it the new geometry for some value ofthe parameter that could presumably be determined II.2. Geometry experimentally? Bolyai left matters there, but Loba-chevskii explicitly showed that measurements of stellar parallax might resolve the question. Here he was unsuc - cessful: such experiments are notoriously delicate. By and large, the reaction to Bolyai and Lobachevskii’s ideas during their lifetimes was one of neglect and hostility, and they died unaware of the success their discoveries would ultimately have.
Bolyai and his father sent their work to Gauss, who replied in 1832 that he could not praise the work “for to do so would be to praise myself,” adding, for extra measure, a simpler proof of one of Janos Bolyai’s opening results. He was, he said, nonetheless delighted that it was the son of hisold friend who had taken precedence over him. Janos Bolyai was enraged, and refused to publish again, thus depriving himself of the opportunity to establish his priority over Gauss by publishing his work as an articlein a mathematics journal.
Oddly, there is no evidence that Gauss knew the details of the young Hungarian’s work in advance. More likely, he saw at once how thetheory would go once he appreciated the opening of Bolyai’s account. would be that, by 1830, Gauss was convinced of the possibility that physical space might be described by A charitable interpretation of the surviving evidence non-Euclidean geometry, and he surely knew how tohandle two-dimensional non-Euclidean geometry using hyperbolic trigonometry (although no detailed accountof this survives from his hand).
But the three-dimensional theory was known first to Bolyai and Lobachev - skii, and may well not have been known to Gauss until he read their work. Lobachevskii fared little better than Bolyai. His initial publication of 1829 was savaged in the press by Ostrogradskii, a much more established figure who was, moreover, in St Petersburg, whereas lobachevskii was in provincial Kazan. His account in Journal für die reine und angewandte mathematik as Crelle’s Journal) suffered grievously from referring(otherwise known to results proved only in the Russian papers fromwhich it had been adapted.
His booklet of 1840 drew only one review, of more than usual stupidity. He did, however, send it to Gauss, who found it excellent andhad Lobachevskii elected to the Göttingen Academy of Sciences. But Gauss’s enthusiasm stopped there, and Lobachevskii received no further support from him. analysis on several levels. It has to be said that the defi-Such a dreadful response to a major discovery invites nition of parallels upon which both men depended was, as it stood, inadequate, but their work was not crit-icized on that account.
It was dismissed with scorn, as if it were self-evident that it was wrong: so wrongthat it would be a waste of time finding the error it surely contained, so wrong that the right response wasto heap ridicule upon its authors or simply to dismiss them without comment. This is a measure of the holdthat Euclidean geometry still had on the minds of most people at the time. Even Copernicanism, for example, and the discoveries of Galileo drew a better reception from the experts.
8 Acceptance of Non-Euclidean Geometry When Gauss died in 1855, an immense amount of un-published mathematics was found among his papers. Among it was evidence of his support for Bolyai and Lobachevskii, and his correspondence endorsing the possible validity of non-Euclidean geometry. As thiswas gradually published, the effect was to send people off to look for what Bolyai and Lobachevskii had written and to read it in a more positive light.
Göttingen who was capable of moving the matter deci-sively forward, even though the actual amount of con-Quite by chance, Gauss had also had a student at tact between the two was probably quite slight. Thiswas riemann [VI.49]. In 1854 he was called to defend his Habilitation thesis, the postdoctoral qualification that was a German mathematician’s license to teach in a university. As was the custom, he offered three titles and Gauss, who was his examiner, chose the one Riemann least expected:
“On the hypotheses that lie atthe foundation of geometry.” The paper, which was to be published only posthumously, in 1867, was nothing less than a complete reformulation of geometry. what he called“spaces” of points, together with a notion of distance Riemann proposed that geometry was the study ofmanifolds [[I.3 §§6.9, 6.10]](/part - 01/some - fundamental - mathematical - de - nitions). These were that looked like Euclidean distance on small scales butwhich could be quite different at larger scales.
This kind of geometry could be done in a variety of ways, he sug - gested, by means of the calculus. It could be carried out for manifolds of any dimension, and in fact Rie-mann was even prepared to contemplate manifolds for which the dimension was infinite. A vital aspect of Riemann’s geometry, in which he followed the lead of Gauss, was that it was concerned only with those properties of the manifold that were intrinsic embedding into a larger space.
In particular, the dis-, rather than properties that depended on some tance between two pointsx and ywas defined to be the length of the shortest curve joining lay entirely within the surface. Such curves are calledx and y that geodesics. (On a sphere, for example, the geodesics are arcs of great circles.)Even two-dimensional manifolds could have different, intrinsic curvatures—indeed, a single two - dimen-sional manifold could have different curvatures in different places—so Riemann’s definition led to infinitely many genuinely distinct geometries in each dimension. Further more, these
geometries were best defined without reference to a Euclidean space that contained them, so the hegemony of Euclidean geometry was broken once and for all. suggests, Riemann was not at all interested in the sortsof assumptions needed by Euclid. Nor was he much As the word “hypotheses” in the title of his thesis interested in the opposition between Euclidean andnon-Euclidean geometry.
He made a small reference at the start of his paper to the murkiness that lay atthe heart of geometry, despite the efforts of Legendre, and toward the end he considered the three different geometries on two-dimensional manifolds for which the curvature is constant. He noted that one was spherical geometry, another was Euclidean geometry, and thethird was different again, and that in each case the angle sums of all triangles could be calculated as soon as oneknew the sum of the angles of any one triangle.
But he made no reference to Bolyai or Lobachevskii, merely noting that if the geometry of space was indeed a three-dimensional geometry of constant curvature, then to determine which geometry it was would involve tak-ing measurements in unfeasibly large regions of space. He did discuss generalizations of Gauss’s curvature to spaces of arbitrary dimension, and he showed what metrics [III.56](/part - 03/metric - spaces) (that is, definitions of distance) there could be on spaces of constant curvature.
The formulahe wrote down is very general, but as with Bolyai and Lobachevskii it depended on a certain real parameter— the curvature. When the curvature is negative, his defi-nition of distance gives a description of non-Euclidean geometry. Riemann died in 1866, and by the time his thesis was published an Italian mathematician, Eugenio Beltrami, had independently come to some of the same ideas. He was interested in what the possibilities were if one wished to map one surface to another.
For example, onemight ask, for some particular surface S, whether it is possible to find a map from S to the plane such that the geodesics inplane. He found that the answer was yes if and only if S are mapped to straight lines in the II. The Origins of Modern Mathematics the space has constant curvature. There is, for example, a well-known map from the hemisphere to a plane with this property.
Beltrami found a simple way of modify-ing the formula so that now it defined a map from a surface of constant ri or of a disk, and he realized the significance of what negative curvature onto the intehe had done: his map defined a metric on the interiorof the disk, and the resulting metric space obeyed the axioms for non-Euclidean geometry; therefore, those axioms would not lead to a contradiction. Some years earlier, Minding, in Germany, had found a surface, sometimes called the pseudosphere, that had constant negative curvature.
It was obtained by rotating a curve called the tractrix about its axis. This surface has the shape of a bugle, so it seemed rather less natural than the space of Euclidean plane geometry and unsuitable as a rival to it. The pseudosphere was independently rediscovered by liouville [VI.39](/part - 06/joseph - liouville - 18091882) some years later, and Codazzi learned of it from that source and showed that triangles on this surface are describedby the formulas of hyperbolic trigonometry. But none of these men saw the connection to non-euclidean geometry—that was left to Beltrami.
Beltrami realized that his disk depicted an infinite space of constant negative curvature, in which the geometry of Lobachevskii (he did not know at that time of Bolyai’s work) held true. He saw that it related to the pseudosphere in a way similar to the way that a plane relates to an infinite cylinder. After a period of some doubt, he learned of Riemann’s ideas and realized thathis disk was in fact as good a depiction of the space of non-Euclidean geometry as any could be; there wasno need to realize his geometry as that of a surface in Euclidean three-dimensional space.
He thereupon published his essay, in 1868. This was the first time thatsound foundations had been publicly given for the area of mathematics that could now be called non-euclidean geometry. In 1871 the young klein [VI.57] took up the subject. He already knew that the English mathematician cayley [VI.46](/part - 06/arthur - cayley - 18211895) had contrived a way of introducing Euclidean metrical concepts intoetry [I.3 §6.7](/part - 01/fundamental - definitions).
While studying at Berlin, Klein saw a way projective geomof generalizing Cayley’s idea and exhibiting Beltrami’s non-Euclidean geometry as a special case of projective geometry. His idea met with the disapproval of weierstrass who objected that projective geometry was not a metri-[VI.44](/part - 06/karl - weierstrass - 18151897), the leading mathematician in Berlin, cal geometry: therefore, he claimed, it could not generate metrical concepts. However, Klein persisted and in a II.2.
Geometry series of three papers, in 1871, 1872, and 1873, showed that all the known geometries could be regarded as subgeometries of projective geometry. His idea was torecast geometry as the study of a group acting on a space. Properties of figures (subsets of the space) that remain invariant under the action of the group are the geometric properties.
So, for example, in a projective space of some dimension, the appropriate group for projective geometry is the group of all transformations that map lines to lines, and the subgroup that maps the interior of a given conic to itself may be regarded as the group of transformations of non-Euclidean geometry: see the box on p. 94. (For a fuller discussion of Klein’s approach to geometry, see [I.3 §6](/part - 01/fundamental - definitions).)In the 1870 s Klein’s message was spread by the first and third of these papers, which were published inthe recently founded journal Mathematische Annalen.
As Klein’s prestige grew, matters changed, and by the 1890 s, when he had the second of the papers repub-lished and translated into several languages, it was this, thenamed after the university where Klein became a pro-Erlanger Programm, that became well - known. It is fessor, at the remarkably young age of twenty - three, but it was not his inaugural address. (That was about mathematics education.) For many years it was a singu-larly obscure publication, and it is unlikely that it had the effect on mathematics that some historians havecome to suggest.
9 Convincing Others Klein’s work directed attention away from thein geometry and toward the transformations that dofigures not alter the figures in crucial respects. For example, in Euclidean geometry the important transformations arethe familiar rotations and translations (and reflections, if one chooses to allow them). These correspond to the motions of rigid bodies that contemporary psycholo-gists saw as part of the way in which individuals learn the geometry of the space around them.
But this theorywas philosophically contentious, especially when it could be extended to another metrical geometry, non-Euclidean geometry. Klein prudently entitled his main papers “On the so-called non-Euclidean geometry,” tokeep hostile philosophers at bay (in particular Lotze, who was the well-established Kantian philosopher at Göttingen). But with these papers and the previous work of Beltrami the case for non-Euclidean geometry was made, and almost all mathematicians were per - suaded.
They believed, that is, that alongside Euclidean geometry there now stood an equally valid mathemati-cal system called non-Euclidean geometry. As for which one of these was true of space, it seemed so clear that Euclidean geometry was the sensible choice that there appears to have been little or no discussion. Lipschitz showed that it was possible to do all of mechanics inthe new setting, and there the matter rested, a hypothetical case of some charm but no more.
Helmholtz, the leading physicist of his day, became interested—hehad known Riemann personally—and gave an account of what space would have to be if it was learned about through the free mobility of bodies. His first account was deeply flawed, because he was unaware of non-Euclidean geometry, but when Beltrami pointed this out to him he reworked it (in 1870).
The reworked version also suffered from mathematical deficiencies, which were pointed out somewhat later byhad more immediate trouble from philosophers.lie [VI.53](/part - 06/sophus - lie - 18421899), but he theory of non-Euclidean geometry?” Kantian philoso-phy was coming back into fashion, and in Kant’s view Their question was, “What sort of knowledge is this knowledge of space was a fundamental pure a priori intuition, rather than a matter to be determined by experiment: without this intuition it would be impossible to have any knowledge of space at all.
Faced witha rival theory, non-Euclidean geometry, neo-Kantian philosophers had a problem. They could agree that the mathematicians had produced a new and prolonged logical exercise, but could it be knowledge of the world? Surely the world could not have two kinds of geom - etry?
Helmholtz hit back, arguing that knowledge of Euclidean geometry and non-Euclidean geometry wouldbe acquired in the same way—through experience—but these empiricist overtones were unacceptable to the philosophers, and non-Euclidean geometry remained aproblem for them until the early years of the twentieth century. Mathematicians could not in fact have given a completely rigorous defense of what was becoming the accepted position, but as the news spread that therewere two possible descriptions of space, and that one could therefore no longer be certain that euclidean geometry was correct, the
educated public took up the question: what was the geometry of space? Among the first to grasp the problem in this new formulation was poincaré [VI.61](/part - 06/jules - henri - poincar - 18541912). He came to mathematical fame in the early 1880 s with a remarkable series of essays in whichhe reformulated Beltrami’s disk model so as to make it conformal: that is, so that angles in non-Euclidean geometry were represented by the same angles in the

Cross-ratios and distances in conics.tive transformation of the plane sends four distinct A pro jec points on a line, A, B, C, D, to four distinct collinear points, A, B^ , C^ , D^ , in such a way that the quantity

ADAB CDCB

is preserved: that is,

ABAD CDCB= AA DB CC DB.

This quantity is called thepoints A, B, C, D, and is written CRcross-ratio(A, B, of the four C, D). as the geometry of points inside a fixed conic, where the transformations allowed are the projec-In 1871, Klein described non-Euclidean geometry K, DRQAPK

Figure 7 straight line in Klein’s projective model of non-Euclidean Three points, P, Q, and R, on a non-Euclidean geometry. model. He then used his new disk model to connect complex function theory, the theory of linear differential equations, riemann surface [III.79](/part-03/riemann-surfaces) theory, and non-Euclidean geometry to produce a rich new bodyof ideas. Then, in 1891, he pointed out that the disk model permitted one to show that any contradiction in non-Euclidean geometry would yield a contradiction in Euclidean geometry as well, and vice versa.
Therefore, Euclidean geometry was consistent if and only if non-Euclidean geometry was consistent. A curious con-sequence of this was that if anybody had managed to derive the parallel postulate from the core of Euclidean geometry, then they would have inadvertently proved that Euclidean geometry was in consistent! described the actual universe was to appeal to physics. One obvious way to try to decide which geometry But Poincaré was not convinced by this. He argued inanother paper (1902) that experience was open to many

II. The Origins of Modern Mathematics

tive transformations that map interior to its interior (see figure 7). To define the K to itself and its distance between two points P and Q inside noted that if the line PQ is extended to meet KK, Kleinat A and D, then the cross-ratio CRchange if one applies a projective transformation:(A, P, D, Q ) does not that is, it is aa third point on the line PQ and the points lie in the projective invariant. Moreover, if R is order P, Q , R, then CR(A$, P, D,Q ) CR(A, Q ,D,R) =$ CRbetween P and Q as(A, P, D, R).
Accordingly, he defined the distance$d(PQ ) = −^{1} \text{log CR}(A$, P, D, Q ) (the factor of introduction of trigonometry). With this definition,-1 2 is introduced to facilitate the later2 distance is additive along a line: d(PQ ) + d(QR) =d(PR). interpretations and there was no logical way of decid-ing what belonged to mathematics and what to physics. Imagine, for example, an elaborate set of measure-ments of angle sums of figures, perhaps on an astronomical scale. Something would have to be taken to bestraight, perhaps the paths of rays of light.
Suppose, finally, that the conclusion is that the angle sum of a tri-angle is indeed less than two right angles by an amount proportional to the area of the triangle. Poincaré saidthat there were two possible conclusions: light rays are straight and the geometry of space is non - Euclidean; or light rays are somehow curved, and space is Euclidean. Moreover, he continued, there was no logical wayto choose between these possibilities. All one could do was to make a convention and abide by it, and the sen-sible convention was to choose the simpler geometry:
Euclidean geometry. This philosophical position was to have a long life in the twentieth century under the name of conventionalism time. A prominent critic of conventionalism was the, but it was far from accepted in Poincaré’s life Italian Federigo Enriques, who, like Poincaré, was both apowerful mathematician and a writer of popular essays on issues in science and philosophy. He argued thatone could decide whether a property was geometrical or physical by seeing whether we had any control over it.
We cannot vary the law of gravity, but we can change the force of gravity at a point by moving mat-ter around. Poincaré had compared his disk model to a metal disk that was hot in the center and got cooleras one moved outwards. He had shown that a simple law of cooling produced figures identical to those ofnon-Euclidean geometry. Enriques replied that heat was II.3. The Development of Abstract Algebra likewise something we can vary. A property such as Poincaré invoked, which was truly beyond our control, was not physical but geometric.
10 Looking Ahead In the end, the question was resolved, but not inits own terms. Two developments moved mathematicians beyond the simple dichotomy posed by Poincaré.Starting in 1899, hilbert [VI.63](/part - 06/david - hilbert - 18621943) began an extensive rewriting of geometry along axiomatic lines, which eclipsed earlier ideas of some Italian mathematicians and opened the way to axiomatic studies of many kinds. Hilbert’s work captured very well the idea thatif mathematics is sound, it is sound because of the nature of its reasoning, and led to profound investi-gations in mathematical logic.
And in 1915 Einstein proposed his general theory of relativity, which is in large part a geometric theory of gravity. confidence in mathematics was restored; our sense of geometry was much enlarged, and our insights into the rela-tionships between geometry and space became considerably more sophisticated. Einstein made full use of contemporary ideas about geometry, and his achieve-ment would have been unthinkable without Riemann’s work.
He described gravity as a kind of curvature in thefour-dimensional manifold of spacetime (see general relativity and the einstein equations [IV.13](/part - 04/general - relativity - and - the - einstein - equations)). His work led to new ways of thinking about the large-scale structure of the universe and its ultimate fate, and to questions that remain unanswered to this day. Further Reading Bonola, R. 1955.lated by H. S. Carslaw and with a preface by F. Enriques. History of Non-Euclidean Geometry, trans Euclid. 1956.New York: Dover.edn. New York:
Dover. The Thirteen Books of Euclid’s Elements, 2 nd Gray, J. J. 1989.and Relativistic, 2 nd edn. Oxford: Oxford University Press. Ideas of Space: Euclidean, Non - Euclidean, Gray, J. J. 2004.the Nature of Space Janos Bolyai, non-Euclidean Geometry and. Cambridge, MA: Burndy Library. Hilbert, D. 1899.quent editions). Tenth edn., 1971, translated by L. Unger, Grundlagen der Geometrie (many subse Poincaré, H. 1891. Les géométries non - Euclidiennes. Foundations of Geometry Générales des Sciences Pures et Appliquées. Chicago, IL: Open Court.2:769–74.Revue (Reprinted, 1952, in New York:
Dover.) Science and Hypothesis, pp. 35–50. l’Hypothèse Hypothesis. 1902. L’expérience et la géométrie. In, pp. 72–88. New York: Dover.), pp. 95–110. (Reprinted, 1952, in La Science et Science and

II.3 The Development of

Abstract Algebra

Karen Hunger Parshall

1 Introduction

What is algebra? To the high school student encoun-tering it for the first time, algebra is an unfamiliar abstract language ofx’s and$y$’s,$a$’s and$b$’s, together with rules for manipulating them. These letters, someof them variables and some constants, can be used for many purposes. For example, one can use them toexpress straight lines as equations of the formy =ax +b, which can be graphed and thereby visualized in the Cartesian plane.
Further more, by manipulating and interpreting these equations, it is possible to determine such things as what a given line’s root is (if it has one)—that is, where it crosses the$x$-axis—and what its slope is—that is, how steep or flat it appears in the plane relative to the axis system. There are also techniques for solving simultaneous equations, or equivalently for determining when and where two lines intersect (or demonstrating that they are parallel). niques and abstract manipulations involved in deal-ing with lines, the ante is upped.
More complicated Just when there already seem to be a lot of tech curves like quadratics, cubics, y = ax3 + bx2 y+=cxax + 2 d+, and quartics, bx + c, and eveny = ax4 + bx3 + cx2 + dx + e, enter the picture, but the same sort of notation and rules apply, and similar sortsof questions are asked. Where are the roots of a given curve? Given two curves, where do they intersect?Suppose now that the same high school student, having mastered this sort of algebra, goes on to university and attends an algebra course there.
Essentially gone are the by now familiar ti ally gone are the nice graphs that provide a way to x’s,$y$’s,$a$’s, and$b$’s; es sen picture what is going on. The university course reflects some brave new world in which the algebra has somehow become “modern.” this abstract structures—groups [I.3 §2.1](/part-01/fundamental-definitions), modern algebra involves rings [III.81 §1](/part-03/rings-ideals-and-modules), fields [I.3 §2.2](/part-01/fundamental-definitions), and other so-called objects—each one defined in terms of a relatively small number of axiomsand built up of substructures like
subgroups, ideals, and subfields. There is a lot of moving around between these objects, too, via maps like group homomorphisms and ring automorphisms [I.3 §4.1](/part-01/fundamental-definitions). One objective of this new type of algebra is to understand the underlying structure of the objects and, in doing so, to build entire theories of groups or rings or fields. these abstract theories may then be applied in diverse settings where the basic axioms are satisfied but where itmay not be at all apparent a priori that a group or a ring or a field may be lurking.
This, in fact, is one of modern algebra’s great strengths: once we have proved a gen-eral fact about an algebraic structure, there is no need to prove that fact separately each time we come acrossan instance of that structure. This abstract approach allows us to recognize that contexts that may look quite different are in fact importantly similar.
sis of polynomial equations and the modern algebra of How is it that two endeavors—the high school analythe research mathematician—so seemingly different intheir objectives, in their tools, and in their philosophical outlooks are both called “algebra”? Are they even related? In fact, they are, but the story of how they are is long and complicated. From Old Babylon to the Hellenistic Era2 Algebra before There Was Algebra:
Solutions of what would today be recognized as first-and second-degree polynomial equations may be found in Old Babylonian cuneiform texts that date to the sec-ond millennium b.c.e. However, these problems were neither written in a notation that would be recogniz-able to our modern-day high school student nor solved using the kinds of general techniques so characteris-tic of the high school algebra classroom. Rather, particular problems were posed, and particular solutions obtained, from a series of recipe-like steps.
No general theoretical justification was given, and the problems were largely cast geometrically, in terms of measurable line segments and surfaces of particular areas. Con - sider, for example, this problem, translated and transcribed from a clay tablet held in the British Museum (catalogued as BM 13901, problem 1) that dates from between 1800 and 1600 b.c.e.: The surface of my confrontation I have accumulated:45 is it. 1, the projection, you posit. The moiety of 1 you break, 30 append: by 1, 1 is equalside. 30 and 30^ you make hold.
15^ which you have made^ to 45^ you hold in the inside you tear out: 30 the confrontation. This may be translated into modern notation as the equation x2 + 1 x =3, where it is important to notice that the Babylonian number system is base 60, so 45 denotes 45=3. The text then lays out the following4^ algorithm for solving the problem: take 1, the coeffi-cient of the linear term, and halve it to get60 4 1 . Square 1 2 2 II. The Origins of Modern Mathematics to getthe square of 1. Subtract from this the14. Add 14 to 34 , the constant term, to get 1.
This is1 which you multiplied by to getreader can easily see that this algorithm is equivalent to12, the side of the square. The modern2 what is now called the quadratic formula, but the Baby-lonian tablet presents it in the context of a particular problem and repeats it in the contexts of other partic-ular problems. There are no equations in the modern sense; the Babylonian writer is literally effecting a construction of plane figures.
Similar problems and simi-lar algorithmic solutions can also be found in ancient Egyptian texts such as the Rhind papyrus, believed to have been copied in 1650 about a century and a half older.b.c.e. from a text that was ented, untheoretical approach characteristic of textsfrom this early period and the axiomatic and deductive There is a sharp contrast between the problem-oriapproach thatics in around 300 euclidb.c.e.[VI.2](/part - 06/euclid - ca) introduced into mathemat-in his magisterial, geometrical treatise, the Elements.
(See geometry [II.2](/part - 02/geometry - origins) for a further discussion of this work.) There, building on explicit definitions and a small number of axioms or selfevident truths, Euclid proceeded to deduce known—and almost certainly some hitherto unknown—results within a strictly geometrical context. Geometry donein this axiomatic context defined Euclid’s standard of rigor. But what does this quintessential ly geometrical text have to do with algebra? Consider the sixth propo-sition in Euclid’s Book II, ostensibly a book on plane figures, and in particular quadrilaterals:
If a straight line be bisected and a straight line beadded to it in a straight line, the rectangle contained by the whole with the added straight line and the added straight line together with the square on the half is equal to the square on the straight line made up ofthe half and the added straight line. While clearly a geometrical construction, it equally clearly describes two constructions—one a rectangle and one a square—that have equal areas. It therefore describes something that we should be able to write as an equation.
Figure 1 gives the picture correspond-ing to Euclid’s construction: he proves that the area of rectangle ADMK equals the sum of rectangles CDMLand HMFG. To do this, he adds the square on CB— namely, square LHGE—to CDML and HMFG. This gives square CDFE. It is not hard to see that this is equivalent to the high school procedure of “completing thesquare” and to the algebraic equation$(2 a + b)b + a2 =(a + b)2$, which we obtain by setting CB = a and II.3. The Development of Abstract Algebra ACBDMKLHEGF Figure 1 The sixth proposition from Euclid’s Book II. BD = b.
Equivalent, yes, but for Euclid this is a spe- cificrical geometrical equivalence. For this reason, he could not deal construction and a particular geometwith anything but positive real quantities, since the sides those terms. Negative quantities did not and could notof a geometrical figure could only be measured in enter into Euclid’s fundamentally geometrical mathematical world.
Nevertheless, in the historical literature, Euclid’s Book II has often been described as dealing with “geometrical algebra,” and, because of our easy translation of the book’s propositions into the lan-guage of algebra, it has been argued, albeit a historically, that Euclid had algebra but simply presented it geometrically.
to be regarded as a pinnacle of mathematical achieve - ment, it was in many ways not typical of the math-Although Euclid’s geometrical standard of rigor came ematics of classical Greek antiquity, a mathematics that focused less on systematization and more on the clever and individualistic solution of particular prob - lems. There is perhaps no better exemplar of this than archimedes [VI.3](/part - 06/archimedes - ca), held by many to have been one of the three or four greatest mathematicians of alltime. Still, Archimedes, like Euclid, posed and solved particular problems geometrically.
As long as geometry defined the standard of rigor, not only negative numbers but also what we would recognize as polynomial equations of degree higher than three effectively fell outside the sphere of possible mathemati-cal discussion. (As in the example from Euclid above, quadratic polynomials result from the geometrical process of completing the square; cubics could conceiv-ably result from the geometrical process of completing the cube;
but quartics and higher-degree polynomials could not be constructed in this way in familiar, three-dimensional space.) However, there was another math- ematician of great importance to the present story, Diophantus of Alexandria (who was active in the middle of the third century c.e.). Like Archimedes, he posed particular problems, but he solved them in an algorith-mic style much more reminiscent of the Old Babylonian texts than of Archimedes’ geometrical construc - tions, and as a result he was able to begin to exceed the bounds of geometry.
eral, indeterminate problems, which he then restricted by specifying that the solutions should have partic-In his text Arithmetica, Diophantus put forward genular forms, before providing specific solutions. Heexpressed these problems in a very different way from the purely rhetorical style that held sway for centuries after him. His notation was more algebraic and was ultimately to prove suggestive to sixteenth-century math - ematicians (see below).
In particular, he used special abbreviations that allowed him to deal with the first six positive and negative powers of the unknown as wellas with the unknown to the zeroth power. Thus, whatever his mathematics was, it was not the “geometrical algebra” of Euclid and Archimedes. Consider, for example, this problem from Book II of thethe square of any one of them minus the next fol-Arithmetica: “To find three numbers such that lowing gives a square.” In terms of modern notation, he began by restricting his attention to solutions of the form(x + 1)2-((x2 x++11),2=xx+^2 and1, 4 x(2+x1+)1.
It is easy to see that)^2-(4 x+1) = 4 x^2, so two of the conditions of the problem are immediately satisfied, but he needed(4 x + 1)2 -(x + 1) = 16 x2 + 7 x to be a square as well. Arbitrarily setting 1625 x2, Diophantus then determined that x =7 x2 gave him+ 7 x = what he needed, so a solution wasdone. He provided no geometrical justification because169,239 ,379, and he was9 in his view none was needed; ation was all he required.
He did not set up what wesingle numerical soluwould recognize as a more general set of equations and try to find all possible solutions. Diophantus, who lived more than four centuries after Archimedes’ death, was doing neither geometry nor algebra in our modern sense, yet the kinds of problems and the sorts of solutions he obtained for them were very different from those found in the works of either Euclid or Archimedes.
The extent to which Diophantus created a wholly new approach, rather than drawing onan Alexandrian tradition of what might be called “algorithmic algebraic,” as opposed to “geometric algebraic,” scholarship is unknown. It is clear that by the time Dio-phantus’s ideas were introduced into the Latin West in

the sixteenth century, they suggested new possibilities to mathematicians long conditioned to the authority of geometry. 3 Algebra before There Was Algebra: The Medieval Islamic World The transmission of mathematical ideas was, however, a complex process.
After the fall of the Roman Empire and the subsequent decline of learning in the West, both the Euclidean and the Diophantine traditions ultimately made their way into the medieval Islamic world. There they were not only preserved—thanks to the active translation initiatives of Islamic scholars—but also studied and extended.al-kh$\bar{w}ariz \bar{m}$ı [VI.5](/part-06/abu-jafar-muhammad-ibn-musa-al-khwarizm-vi55-william-kingdon-cliord-18451879) was a scholar at the royally funded House of Wisdom in Baghdad.
He linked thekinds of geometrical arguments Euclid had presented in Book II of his solving algorithms that dated back to Old Babylonian Elements with the indigenous problem times. In particular, he wrote a book on practical math-ematics, entitled al-Ki$\bar{t}$ ab al-mukhtas.ar $\bar{f}$ı h.i$\bar{s}$ ab al-jabr wa’l-mu$\bar{q}$ abala (“The compendious book on calculation by completion and balancing”), beginning it witha theoretical discussion of what we would now recognize as polynomial equations of the first and second degrees.
(The latinization of the word “al-jabr” or “completion” in his title gave us our modern term “alge-bra.”) Because he employed neither negative numbers nor zero coefficients, al-Kh$\bar{w}ariz \bar{m}$ı provided a systematization in terms of six separate kinds of examples where we would need just one, namely$ax^{2} + bx + c = 0$. He considered, for example, the case when “a squareand 10 roots are equal to 39 units,” and his algorithmic solution in terms of multiplications, additions, and subtractions was in precisely the same form as the above solution from tablet BM 13901.
This, however, was not enough for al-Kh. ar{w}sary,” he said, “that we should demonstrate geomet-ariz$\bar{m}$ı. “It is ne ces ri cally the truth of the same problems which we have explained in numbers,” and he proceeded to do this by “completing the square” in geometrical terms rem-iniscent of, but not as formal as, those Euclid used in Book II. (A$\bar{b}$ mathematician of the generation after al-Kh$\bar{w}$ u $\bar{K}$ amil (ca.
850–930), an Egyptian Islamicariz$\bar{m}$ı, introduced a higher level of Euclidean formality intothe geometric–algorithmic setting.) This juxtaposition made explicit how the relationships between geometrical areas and lines could be interpreted in terms ofnumerical multiplications, additions, and subtractions,

II. The Origins of Modern Mathematics

a key step that would ultimately suggest a move awayfrom the geometrical solution of particular problems and toward anequations. algebraic solution of general types of ematician and poet Omar Khayyam (ca. 1050–1130) ina book he entitled Another step along this path was taken by the math-Al-jabr after al-Kh$\bar{w}ariz \bar{m}$ı’s work. Here he proceeded to systematize and solve what we would recognize, in the absence of both negative num-bers and zero coefficients, as the cases of the cubic equation.
Following al-Kh. ar{w}geometrical justifications, yet his work, even more thanariz$\bar{m}$ı, Khayyam provided that of his predecessor, may be seen as closer to ageneral problem-solving technique for specific cases of equations, that is, closer to the notion of algebra. in the early eleventh century) also knew well and The Persian mathematician al-Kara$\bar{j}$ı (who flourished appreciated the geometrical tradition stemming from Euclid’s Elements.
However, like A$\bar{b}$ u-. ar{K}amil, he was aware of the Diophantine tradition too, and synthe-sized in more general terms some of the procedures Diophantus had laid out in the context of specific exam-ples in the Arithmetica. Although Diophantus’s ideas and style were known to these and other medieval Islamic mathematicians, they would remain unknownin the Latin West until their rediscovery and translation in the sixteenth century.
Equally unknown inthe Latin West were the accomplishments of Indian mathematicians, who had succeeded in solving some quadratic equations algorithmically by the beginning of the eighth century and who, like Bragmagupta four hundred years later, had techniques for finding integer solutions to particular examples of what are today called Pell’s equations, namely, equations of the form $ax2 + b = y2$, where a and b are integers and a is not a square. 4 Algebra before There Was Algebra:
The Latin West Concurrent with the rise of Islam in the East, the Latin West underwent a gradual cultural and polit-ical stabilization in the centuries following the fall of the Roman Empire. By the thirteenth century, this relative stability had resulted in the firm entrenchment of the Catholic Church as well as the establish-ment both of universities and of an active economy. Moreover, the Islamic conquest of most of the Iberian peninsula in the eighth century and the subsequent establishment there of an Islamic court, library, and

II.3. The Development of Abstract Algebra

research facility similar to the House of Wisdom in Baghdad brought the fruits of medieval Islamic scholarship to western Europe’s doorstep. However, as Islam found its position on the Iberian peninsula increas-ingly compromised in the twelfth and thirteenth centuries, this Islamic learning, as well as some of the ancient Greek scholarship that the medieval Islamic scholars had preserved in Latin translation, began to filter into medieval Europe.
In particular,[VI.6](/part-06/leonardo-of-pisa-known-as-fibonacci-vi57-christian-felix-klein-18491925), son of an influential administrator within the fibonacci Pisan city state, encountered al-Kh$\bar{w}$ recognized not only the impact that the Arabic num-ariz$\bar{m}$ı’s text and ber system detailed there could have on accounting and commerce (Roman numerals and their cumber-some rules for manipulation were still widely in use) but also the importance of al-Kh. ar{w}discussion, with its wedding of geometrical proof andariz$\bar{m}$ı’s theoretical the algorithmic solution of what we can
interpret as first- and second-degree equations. In his 1202 book Liber Abbaci, Fibonacci presented al-Kh$\bar{w}ariz \bar{m}$ı’s work almost verbatim, and extolled all of these virtues, thus effectively introducing this knowledge and approach into the Latin West. cal aspects of al-Kh. ar{w}known in Europe.
So-called abacus schools (named Fibonacci’s presentation, especially of the practi-ariz$\bar{m}$ı’s text, soon became wellafter Fibonacci’s text and not after the Chinese calculat-ing instrument) sprang up all over the Italian peninsula, particularly in the fourteenth and fifteenth centuries, for the training of accountants and bookkeepers in an increasingly mercantilistic Western world. The teach-ers in these schools, the “maestri d’abaco,” built on and extended the algorithms they found in Fibonacci’stext.
Another tradition, the Cossist tradition—after the German word “Coss” connoting algebra, that is, “Kun-strechnung” or “artful calculation”—developed simultaneously in the Germanic regions of Europe and aimedto introduce algebra into the mainstream there. this is the operative word: Pacioli’s text is one of the earliest In 1494 the Italian Luca Pacioli published (by now printed mathematical texts) a compendium of all known mathematics.
By this time, the geometrical justifications that al-Kh$\bar{w}ariz \bar{m}$ı and Fibonacci had presented had long since fallen from the mathematical ver-nacular. By reintroducing them in his book, the Summa, Pacioli brought them back to the mathematical fore. Not knowing of Khayyam’s work, he asserted that solutions had been discovered only in the six cases treatedby both al-Kh$\bar{w}ariz \bar{m}$ıand Fibonacci, even though there had been abortive attempts to solve the cubic and even

though he held out the hope that it could ultimately besolved. lem: could algorithmic solutions be determined for the various cases of the cubic? And, if so, could these be Pacioli’s book had highlighted a key unsolved prob justified geometrically with proofs similar in spirit tothose found in the texts of al-Kh. ar{w}ariz . ar{m}ıand Fibonacci? Among several sixteenth-century Italian mathematicians who eventually managed to answer the first ques-tion in the affirmative was cardano [VI.7](/part-06/girolamo-cardano-15011576).
In his Ars Magna, or The Great Art, of 1545, he presented algorithms with geometric justifications for the various cases of the cubic, effectively completing the cube where al - Kh. ar{w}square. He also presented algorithms that had been dis - ariz$\bar{m}$ı and Fibonacci had completed the covered by his student Ludovico Ferrari (1522–65) for solving the cases of the quartic. These intrigued him, because, unlike the algorithms for the cubic, they werenot justified geometrically.
As he put it in his book, “all those matters up to and including the cubic are fully demonstrated, but the others which we will add, either by necessity or out of curiosity, we do not go beyond barely setting out.” An algebra was breaking out of the geometrical shell in which it had been encased. 5 Algebra Is Born This process was accelerated by the rediscovery and translation into Latin of Diophantus’s Arithmetica in the 1560 s, with its abbreviated presentational styleand ungeometrical approach.
Algebra, as a general problem-solving technique, applicable to questions ingeometry, number theory, and other mathematical settings, was established in Algebra of 1572 and, more importantly, inraphael bombelli’s [VI.8](/part - 06/rafael - bombelli - 1526after)viète’s [VI.9](/part - 06/franois - vite - 15401603)to the Analytic Art In Artem Analyticem Isagoge, of 1591.
The aim of the latter, or Introduction was, in Viète’s words, “to leave no problem unsolved,”and to this end he developed a true notation—using vowels to denote variables and consonants to denote coefficients—as well as methods for solving equations in one unknown. He called his techniques “specious logistics.”Dimensionality—in the form of his so-called law of homogeneity As he put it, “[o]nly homogeneous magnitudes are—was, however, still an issue for Viète. to be compared to one another.” The problem wasthat he distinguished two types of magnitudes:
“ladder magnitudes”—that is, variables (modern notation), ( A square) (or x2 A), (side) (or A cube) (orx in ourx^3),

100

etc.; and “compared magnitudes”—that is, coefficients(B length) of dimension one, (B plane) of dimension two, (B solid) of dimension three, etc. In the light of his law of homogeneity, then, Viète could legitimately perform the operation(A cube)+(B plane)(A side) (orx3+bx in our notation), since the dimension of (A cube) is three, as is that of the product of the two-dimensional coefficient (B plane) and the one-dimensional vari- able (dimensional variable (A side), but he could not legally add the three-A cube) to the two-dimensional product of the one-dimensional coefficient (and the
one-dimensional variable (A side) (or, again, B length)x3 + bxin our notation). Be this as it may, his “analytic art” still allowed him to add, subtract, multiply, and divide letters as opposed to specific numbers, and those letters, as long as they satisfied the law of homo - geneity, could be raised to the second, third, fourth, or, indeed, any power.
He had a rudimentary algebra, although he failed to apply it to curves. The first mathematicians to do that were fermat [VI.12](/part - 06/pierre - fermat - 1601665) and development of the analytic geometry so familiar todescartes [VI.11](/part - 06/ren - descartes - 15961650) in their independent the high school algebra student of today. Fermat, and others like Thomas Harriot (ca.
1560–1621) in England, were influenced in their approaches by Viète, while Descartes not only introduced our present-day notational convention of representing variables by x’s and$y$’s and constants by$a$’s,$b$’s, and$c$’s but also began the arithmetization of algebra. He introduced a unit that allowed him to interpret all geometrical magnitudes as line segments, whether they were$x^{4}$’s, or any higher power ofx, thereby removing con-x’s,$x^{2}$’s,$x^{3}$’s, cerns about homogeneity.
Fermat’s main work in this direction was a 1636 manuscript written in Latin, entitled “Introduction to plane and solid loci” and circu-lated among the early seventeenth-century mathematical cognoscenti; Descartes’s wasin French as one of three appendices to his philosoph-La Géométrie, written ical tract, Both were regarded as establishing the identification Discours de la Méthode, published in 1637.
of geometrical curves with equations in two unknowns, or in other words as establishing analytic geometry and thereby introducing algebraic techniques into the solution of what had previously been considered metrical problems. In Fermat’s case, the curves were ge ol in es or conic sections—quadratic expressions inand$y$; Descartes did this too, but he also considered$x$ equations more generally, tackling questions about the roots of polynomial equations that were connected with transforming and reducing the polynomials.

II. The Origins of Modern Mathematics

eral statement of it, Descartes had a rudimentary ver-sion of what we would now call In particular, although he gave no proof or even gen-the fundamental theorem of algebra nomial equationxn + a[V.13](/part-05/the-fundamental-theorem-of-algebra), the result that a poly-(xn)-1 + · · · + a x + a of degree plex numbers. For example, while he held that a givenn has precisely nnroots over the field - 1 1 C of com - 0 polynomial of degree linear factors, he also recognized that the cubicn could be decomposed intox3 n-$6$ x2 + 13 x - 10 = 0 has three roots: the real root 2 and two complex roots.
In his further exploration of these issues, moreover, he developed algebraic techniques, involving suitable transformations, for analyzing polynomial equations of the fifth and sixth degrees. Liber-ated from homogeneity concerns, Descartes was thus able to use his algebraic techniques freely to explore territory where the geometrically bound Cardano had clearly been reluctant to venture.
newton [VI.14](/part - 06/isaac - newton - 16421727) took the liberation of algebra from geometrical concerns astep further in his Arithmetica Universalis (or Universal arithmetic met ization of algebra, that is, for modeling algebra and) of 1707, arguing for the complete arith algebraic operations on the real numbers and the usual operations of arithmetic. Descartes’s La Géométrie highlighted at least two problems for further algebraic exploration: the funda-mental theorem of algebra and the solution of polynomial equations of degree greater than four.
Although eighteenth - century mathematicians like[VI.20](/part - 06/jean - le - rond - dalembert - 17171783) and euler [VI.19](/part - 06/leonhard - euler - 17071783) attempted proofs of the fun - d’alembert damental theorem of algebra, the first person to proveit rigorously was gauss [VI.26](/part - 06/carl - friedrich - gauss - 17771855), who gave four distinct proofs over the course of his career.
His first, an algebraic geometrical proof, appeared in his doctoral dis-sertation of 1799, while a second, fundamentally different proof was published in 1816, which in modern terminology essentially involved constructing the polynomial’s splitting field. While the fundamental theorem of algebra established how many roots a given poly-nomial equation has, it did not provide insight into exactly what those roots were or how precisely to findthem.
That problem and its many mathematical repercussions exercised a number of mathematicians in the late eighteenth and nineteenth centuries and formedone of the strands of the mathematical thread that became modern algebra in the early twentieth century. Another emerged from attempts to understand the general behavior of systems of (one or more) polynomials inapproach number-theoretic questions algebraically.nunknowns, and yet another grew from efforts to II.3.
The Development of Abstract Algebra 6 The Search for the Rootsof Algebraic Equations The problem of finding roots of polynomials providesa direct link from the algebra of the high school classroom to that of the modern research mathematician. Today’s high school student dutifully employs the quadratic formula to calculate the roots of seconddegree polynomials. To derive this formula, one trans-forms the given polynomial into one that can be solved more easily. By more complicated manipulations ofcubics and quartics, Cardano and Ferrari obtained formulas for the roots of those as well.
It is natural to ask whether the same can be done for higher-degree poly - nomials. More precisely, are there formulas that involve just the usual operations of arithmetic—addition, subtraction, multiplication, and division—together withthe extraction of roots? When there is such a formula, one says that the equation is solvable by radicals.
(including Euler, Alexandre - Théophile Vandermonde Although many eighteenth - century mathematicians (1735–96),83)) contributed to the effort to decide whether higher - waring [VI.21](/part - 06/edward - waring - ca), and Étienne Bézout (1730 order polynomial equations are solvable by radicals, it was not until the years from roughly 1770 to 1830 thatthere were significant breakthroughs, particularly in the work of lagrange [VI.22](/part - 06/joseph - louis - lagrange - 17361813), abel [VI.33](/part - 06/niels - henrik - abel - 18021829), and Gauss.
algébrique des équations” (Reflections on the algebraic In a lengthy set of “Réflections sur la résolution resolution of equations) published in 1771, lagrange tried to determine principles underlying the resolution of algebraic equations in general by analyzing in detail the specific cases of the cubic and the quartic.
Build-ing on the work of Cardano, Lagrange showed that a cubic of the formx3 + ax2 + bx + c = 0 could always be transformed into a cubic with no quadratic termx3 + px + q = 0 and that the roots of this could be written asx = u + v , where u3 and v3 are the roots of a certain quadratic polynomial equation. Lagrange was then able to show that ifroots of the cubic, the intermediate functions$x^{1}$, x2, x3 are the threeu and v could actually be written asand$v = 1 (x +α2x +αx )$, foru =α^1^3 a primitive cube root(x^1 + αx^2 + α^2 x^3) of unity.
That is, expressions or resolvents in3 1 u2 and v3 could be written as rationalx , x , x . Conversely, starting with a linear expression in the roots$x^{1}$, x2, x3 and then permuting the roots1 y =2 A(x3)1 + Bx2 + Cx3 in all possible ways yielded six expressions each ofwhich was a root of a particular sixth-degree polynomial equation. An analysis of the latter equation (which

101

involved the exploitation of properties of symmetric polynomials) yielded the same expressions foru and v in terms of$x1$, x2, x3 and the cube root of unity α. As Lagrange showed, this kind of two-pronged analysis—involving intermediate expressions rational in the roots that are solutions of a solvable equation as well as the behavior of certain rational expressions under permutation of the roots—yielded the complete solution in the cases both of the cubic and the quartic. It was approach that encompassed the solution of both typesone of equation.
But could this technique be extended tothe case of the quintic and higher-degree polynomials? Lagrange was unable to push it through in the case of the quintic, but by building on his ideas, first his stu-dent Paolo Ruffini (1765–1822) at the turn of the nineteenth century and then, definitively, the young Norwe-gian mathematician Abel in the 1820 s showed that, in fact, the quintic is not solvable by radicals.
(See the insolubility of the quintic result, however, still left open the questions of which[V.21](/part-05/the-insolubility-of-the-quintic).) This negative algebraic equations As Lagrange’s analysis seemed to underscore, thewere solvable by radicals and why. answer to this question in the cases of the cubic and the quartic involved in a critical way the cube and fourth roots of unity, respectively. By definition, these satisfy the particularly simple polynomial equations andx4 - 1 = 0, respectively.
It was thus natural tox3 - 1 = 0 examine the general case of the so-called cyclotomic equationxn - 1 = 0 and ask for what values n thenthis question in equivalent algebraic terms: for whichth roots of unity are actually constructible. To put nunity that expresses them in terms of integers using theis it possible to find a formula for thenth roots of usual arithmetical operations and extraction of square(but not higher) roots? This was one of the many questions explored by Gauss in his wide - ranging, magiste - rial, and groundbreaking 1801 treatise Disquisitiones Arithmeticae.
One of his most famous results was that the regular 17 - gon (or, equivalently, a 17 th root ofunity) was constructible. In the course of his analysis, he not only employed techniques similar to those devel-oped by Lagrange but also developed key concepts such asthe modular “worlds”modular arithmetic Z , for[III.58](/part - 03/modular - arithmetic) and the properties ofp a prime, and, more gen - erally, tive element (a generator) of what would later be termed Z$n$, for n \in Z+, as well as the notion of a primi - p a cyclic group. Although it is not clear how well he knew Gauss’s work, in the
years around 1830 from the ideas both of Lagrange on the analysis ofgalois [VI.41](/part - 06/variste - galois - 18111832) drew 102 resolvents and of substitutions to obtain a solution to the general prob - cauchy [VI.29](/part - 06/augustin - louis - cauchy - 17891857) on permutations and lem of solvability of polynomial equations by radicals. Although his approach borrowed from earlier ideas, it was in one important respect fundamentally new.
Whereas prior efforts had aimed at deriving analgorithm for calculating the roots of a polynomial of aexplicit given degree, Galois formulated a theoretical process based on constructs more general than but derived from the given equation that allowed him to assess whether or not that equation was solvable To be more precise, Galois recast the problem into. one in terms of two new concepts: fields (which he called “domains of rationality”) and groups (or, more precisely, groups of substitutions).
A polynomial equationf (x) = 0 of degree n was reducible over its domain of rationality—the ground field from which its coef-ficients were taken—if alln of its roots were in that ground field; otherwise, it was irreducible over thatfield. It could, however, be reducible over some larger field. Consider, for example, the polynomial$x^{2} + 1 as$ a polynomial over R, the field of real numbers.
While we know from high school algebra that this polynomial does not factor into a product of two real, linear factors (that is, there are no real numbers$r^{1} and r^{2}$ such thatover C, the field of complex numbers, and, specifically,$x^{2} + 1 = (x - r^{1})(x - r^{2}))$, it does fac to rx numbers of the form^2 + 1 = (x + . qrt{-1})(xa +-b. qrt. qrt--1$, where1)$. Thus, if we take alla and b belong to polynomial R, then we enlargex2 +1 is reducible.
If Rto a new field F is a field and C in which thex is an element ofa similar process we can adjoin an element F that does not have annth root iny F, then byto F and stipulate thatyn = x. We call y a radical. The set of all polynomial expressions in$y$, with coefficients in F, can be shown to form a larger field. Galois showed thatif it was possible to enlarge F by successively adjoining radicals to obtain a fieldinton linear factors, then f (x)K in which= 0 was solvable byf (x) factored radicals.
He developed a process that hinged both onthe notion of adjoining an element—in particular, a socalled primitive element—to a given ground field andon the idea of analyzing the internal structure of this new, enlarged field via an analysis of the (finite) groupof substitutions (automorphisms of K) that leave invari- ant all rational relations of the n roots of f (x) = 0. The group-theoretic aspects of Galois’s analysis were par-ticularly potent; he introduced the notions, although not the modern terminology, of a normal subgroup of agroup, a factor group, and a solvable group. Galois thus

II. The Origins of Modern Mathematics

resolved the concrete problem of determining when apolynomial equation was solvable by radicals by examining it from the abstract perspective of groups and their internal structure. Galois’s ideas, although sketched in the early 1830 s, did not begin to enter into the broader mathemati-cal consciousness until their publication in 1846 in liouville’s [VI.39](/part-06/joseph-liouville-18091882) Journal des Mathématiques Pures et Appliquéestwo decades later when first Joseph Serret (1819–85), and they were not fully appreciated until and then In particular, Jordan’sjordan
[VI.52](/part-06/camille-jordan-18381922) fleshed them out more fully. Traité des Substitutions et des Équations Algébriqueson algebraic equations”) of 1870 not only highlighted(“Treatise on substitutions and Galois’s work on the solution of algebraic equations but also developed the general structure theory of per-mutation groups as it had evolved at the hands of Lagrange, Gauss, Cauchy, Galois, and others. By the endof the nineteenth century, this line of development of group theory, stemming from efforts to solve algebraic equations by radicals, had intertwined with three others:
the abstract notion of a group defined in terms of a group multiplication table, which was formulated by cayley [VI.46](/part-06/arthur-cayley-18211895), the structural work of mathematicians like Ludwig Sylow (1832–1918) and Otto Hölder(1859–1937), and the geometrical work of lie [VI.53](/part-06/sophus-lie-18421899) and1914) codified much of this earlier work by giving theklein [VI.57].
By 1893, when Heinrich Weber (1842 first actual abstract definitions of the notions both ofgroup and field, thereby recasting them in a form much more familiar to the modern mathematician, groupsand fields had been shown to be of central importance in a wide variety of areas, both mathematical and physical. 7 Exploring the Behavior of Polynomials inn Unknowns The problem of solving algebraic equations involved finding the roots of polynomials in one unknown.
At least as early as the late seventeenth century, however, mathematicians like interested in techniques for solving simultaneously leibniz [VI.15](/part-06/gottfried-wilhelm-leibniz-16461716) had been systems of linear equations in more than two vari-ables. Although his work remained unknown at the time, Leibniz considered three linear equations in three unknowns and determined their simultaneous solvability based on the value of a particular expression in the coefficients of the system. This expression, equiva-lent to what Cauchy would later call the determinant

II.3. The Development of Abstract Algebra

[III.15](/part-03/determinants) and which would ultimately be associated withann . imes  n square array or matrix[I.3 §4.2](/part-01/fundamental-definitions) of coefficients, was also developed and analyzed independently by Gabriel Cramer (1704–52) in the mid eighteenth century in the general context of the simultaneous solutionof a system ofn linear equations in n unknowns.
From these beginnings, a theory of determinants, indepen-dent of the context of solving systems of linear equations, quickly became a topic of algebraic study in its own right, attracting the attention of Vandermonde, laplace [VI.23](/part-06/pierre-simon-laplace-17491827), and Cauchy, among others. Determinants were thus an example of a new algebraic construct, the properties of which were then systematically explored.
of whatof matrices proper grew initially from the context not Although determinants came to be viewed in terms sylvester [VI.42](/part - 06/james - joseph - sylvester - 18141897) would dub matrices, a theory of solving simultaneous linear equations but rather oflinearly transforming the variables of homogeneous polynomials in two, three, or more generally ab les.
In the Disquisitiones Arithmeticae, for exam - n vari - ple, Gauss considered how binary and ternary quad-ratic forms with integer coefficients—expressions of the forma z2 + 2 aa1 xyx2 ++22 aa2 xyxz ++a23 ay2 yzand, respectively—are$a1 x2 + a2 y2 +$affected by a linear transformation of their variables. In the ternary case, he applied the linear transforma - 3 4 5 6 tionz = αx^ =x^ αx+ β^ +^ yβy^ +^ +γ^ γzz^ to derive a new ternary form., y = α^ x^ + β^ y^ + γ^ z^ , and He denoted the linear transformation of the variablesby the square array α, β, γα, β, γα, β, γ and, in the process of showing
what the composition of two such transformations was, gave an explicit exam-ple of matrix multiplication. By the middle of the nineteenth century, Cayley had begun to explore matrices per se and had established many of the properties thatthe theory of matrices as a mathematical system in its own right enjoys. This line of algebraic thought was eventually reinterpreted in terms of the theory of alge - bras (see below) and developed into the independent area of linear algebra and the theory of[I.3 §2.3](/part - 01/fundamental - definitions).
vector spaces Another theory that arose out of the analysis of linear transformations of homogeneous polynomials wasthe theory of invariants, and this too has its origins in 103 some sense in Gauss’sof ternary quadratic forms, Gauss began his study Disquisitiones. As in his study of binary forms by applying a linear transformation, specifically, x = αx^ + βy^ , y = γx^ + δy^ . The result was the new binary formwhere, explicitly, a^ = aa1α(x2^ +)22 + a2 aαγ2 x+^ ya^ +γ(a2)3, (ya^ )2=, aa1αβδ2.
As Gauss noted, if you multiply the second of + a2(αδ + βγ)1 + a3γδ1, and (a3)2 = a1β2 3 + 2 a2βδ2 + these equations by itself and subtract from this the product of the first and the third equations, you obtain3 the relation use language that Sylvester would develop in the early(a2)2 - a1 a3 = ((a2)2 - a1 a3)(αδ - βγ)2. To 1850 s, Gauss realized that the expression(a2)2 - a1 a3 in the coefficients of the original binary quadratic formis an invariant in the sense that it remains unchanged up to a power of the determinant of the linear trans - formation.
By the time Sylvester coined the term, the invariant phenomenon had also appeared in the work of the English mathematician attracted Cayley’s attention. It was not until after Cay - boole [VI.43](/part - 06/george - boole - 18151864), and had ley and Sylvester met in the late 1840 s, however, thatthe two of them began to pursue a theory of invariants proper, which aimed to determine all invariants for homogeneous polynomials of degreeas well as simultaneous invariants for systems of suchm in n unknowns polynomials. Although Cayley and (especially) Sylvester pursued this line of research from a
purely algebraic point of view, invariant theory also had number-theoretic and geometric implications, the former explored by Gotthold Eisenstein (1823–52) andlatter by Otto Hesse (1811–74), Paul Gordan (1837–hermite [VI.47](/part - 06/charles - hermite - 18221901), the 1912), and Alfred Clebsch (1833–72), among others. It was of particular interest to understand how many“genuinely distinct” invariants were associated with a specific form, or system of forms.
In 1868, gordan achieved a fundamental breakthrough by showing that the invariants associated with any binary form inn vari- ables can always be expressed in terms of a finite num-ber of them. By the late 1880 s and early 1890 s, however, associated with the theory of algebras (see below) tohilbert [VI.63](/part-06/david-hilbert-18621943) brought new, abstract concepts bear on invariant theory and, in so doing, not only reproved Gordan’s result but also showed that the resultwas true for forms of degreem in n unknowns.
With Hilbert’s work, the emphasis shifted from the concrete calculations of his English and German predecessors to the kind of structurally oriented existence theorems that would soon be associated with abstract, modern algebra.

104

8 The Quest to understand the Properties of “Numbers” As early as the sixth century had studied the properties of numbers formally. Forb.c.e., the Pythagoreans example, they defined the concept of aber, which is a positive integer, such as 6 perfect num-= 1 + 2 + 3$and 28 = 1 + 2 + 4 + 7 + 14$, which is the sum of its divisors (excluding the integer itself). In the sixteenth century, Cardano and Bombelli had willingly worked with new expressions, complex numbers, of the form$a + \sqrt{-b}$, for real numbers a and b, and had explored their computational properties.
In the seventeenth century, Fermat famously claimed that he could prove thatthe equation$x^{n} + y^{n} = z^{n}$, for n an integer greater than 2, had no solutions in the integers, except for the trivial cases whenz = x or z = y and the remaining variable is zero. The latter result, known aslast theorem [V.10](/part-05/fermats-last-theorem), generated many new ideas, espe-fermat’s cially in the eighteenth and nineteenth centuries, as mathematicians worked to find an actual proof of Fermat’s claim.
Central to their efforts were the creation and algebraic analysis of new types of number systems that extended the integers in much the same way that Galois had extended fields. This flexibility to create and analyze new number systems was to become one of the hallmarks of modern algebra as it would develop intothe twentieth century. In the proof of Fermat’s last theorem for thecase that he gave in his One of the first to venture down this path was Euler. Elements of Algebra of 1770, n = 3 Euler introduced the system of numbers of the form$a + b \sqrt{-3}$, where a and b are integers.
He then blithely proceeded to factorize them into primes, without further justification, just as he would have factorized ordinary integers. By the 1820 s and 1830 s, Gauss had launched a more systematic study of numbers that are now called thebers of the form Gaussian integers$a + b \sqrt{-1}$, for integers. These are all num-a and b. He showed that, like the integers, the Gaussian integers are closed under addition, subtraction, and multiplication;
he defined the notions of unit, prime, and norm in order to prove an analogue ofof arithmetic [V.14](/part-05/the-fundamental-theorem-of-arithmetic) for them. He thereby demon-the fundamental theorem strated that there were whole new algebraic worlds tocreate and explore. (See algebraic numbers [IV.1](/part-04/number-theory) for more on these topics.) Whereas Euler had been motivated in his work by Fermat’s last theorem, Gauss was trying to generalize the law of quadratic reciprocity [V.28](/part-05/from-quadratic-reciprocity-to-vi38-augustus-de-morgan-18061871) to a law of

II. The Origins of Modern Mathematics

biquadratic reciprocity. In the quadratic case, the prob-lem was the following. Ifa and m are integers withmif the equation⩾ 2, then we say thatx2 = a has a solution moda is a quadratic residuem; that is, mod$m$ if there is an integerx such that x2 is congruent toaprimes. If you know whether mod m. Now suppose that pp andis a quadratic residueq are distinct odd$mod$ q, is there a simple way of telling whether q is a quadratic residue modand answered this question—the status of$p$?
In 1785, Legendre had posedq mod p will be the same as that ofofp and qis congruent to 1 mod 4, and different ifp mod q if at least one they are both congruent to 3 mod 4—but he had given a faulty proof. By 1796, Gauss had come up with thefirst rigorous proof of the theorem (he would ultimately give eight different proofs of it), and by the 1820 s hewas asking the analogous question for the case of two biquadratic equivalences x4 ≡ p (mod q) and y4 ≡ q(modtion that he introduced the Gaussian integers and sig - p).
It was in his attempts to answer this new ques- naled at the same time that the theory of residues ofhigher degrees would make it necessary to create and analyze still other new sorts of “integers.” Although Eisenstein, and kronecker dirichlet[VI.48](/part - 06/leopold - kronecker - 18231891), among others, pushed these[VI.36], Hermite, kummer [VI.40], ideas forward in this Gaussian spirit, it was[VI.50](/part - 06/julius - wilhelm - richard - dedekind - 18311916) in his tenth supplement to Dirichlet’sdedekind Vorlesungen über Zahlentheorie (Lectures on Number Theory ) of 1871 who
fundamentally re conceptual iz ed the prob-lem by treating it not number theoretically but rather set theoretically and axiomatically. Dedekind intro - duced, for example, the general notions—if not what would become the precise axiomatic definitions—of fields, rings, and analyzed his number-theoretic setting in terms ofideals [III.81 §2](/part - 03/rings - ideals - and - modules), and modules [III.81 §3](/part - 03/rings - ideals - and - modules) these new, abstract constructs. His strategy was, froma philosophical point of view, not unlike that of Galois:
translate the “concrete” problem at hand into new, more abstract terms in order to solve it more cleanlyat a “higher” level. In the early twentieth century, noether van der Waerden (1903–96), would develop Dedekind’s[VI.76](/part-06/emmy-noether-18821935) and her students, among them Bartel ideas further to help create the structural approach toalgebra so characteristic of the twentieth century.
evolution of the notion of “number” on the continent of Europe, a very different set of developments was taking Parallel to this nineteenth-century, number-theoretic place, initially in the British Isles. From the late eighteenth century, British mathematicians had debated not only the nature of number—questions such as,

II.3. The Development of Abstract Algebra

“Do negative and imaginary numbers make sense?”—but also the meaning of algebra—questions like, “In an expression like$y$legitimately take on and what precisely may ‘ax + by, what values may a, b,+x’ con-, and note?” By the 1830 s, the Irish mathematician[VI.37](/part-06/william-rowan-hamilton-18051865) had come up with a “unified” interpretation ofhamilton the complex numbers that circumvented, in his view, the logical problem of adding a real number and an imaginary one, an apple and an orange. Given real num-bersa and b, Hamilton conceived of the complex num- berple”)a(a$, b)+ b \sqrt{}$.
He then defined addition, subtraction, mul--1 as the ordered pair (he called it a “co ut i pl ic at i on, and division of such couples. As he realized, this also provided a way of representing numbers inthe complex plane, and so he naturally asked whether he could construct algebraic, ordered triples so as torepresent points in 3-space.
After a decade of contemplating this question off and on, Hamilton finally answered it not for triples but for quadruples, the so-called quaternions [III.76](/part-03/quaternions-octonions-and-normed-iv25-probabilistic-models-of-critical-phenomena), “numbers” of the form (a, b, c, d)and where i, j, k satisfy the relations ij = a + bi + cj + dk, where a, b, c= −, andji d=are realk, jk =-kj = i, ki = −ik = j, i2 = j2 = k2 = −1.
As in the two- dimensional case, addition is defined component - wise, but multiplication, while definable in such a way that every nonzero element has a multiplicative inverse, isnot commutative. Thus, this new number system did not obey all of the “usual” laws of arithmetic.
questioned the extent to which mathematicians werefree to create such new mathematical worlds, others, Although some of Hamilton’s British contemporaries like Cayley, immediately took the idea further and created a system of ordered 8 - tuples, the octonions, the multiplication of which was neither commutative nor even, as was later discovered, associative. Several questions naturally arise about such systems, but onethat Hamilton asked was what happens if the field of coefficients, the base field, is not the reals but rather the complexes?
In that case, it is easy to see thatthe product of the two nonzero complex quaternions (is 1-. qrt-+1 j,20=, 11,0+) = −(-1. qrt) -=10. In other words, the complex + j and (. qrt{-1},0, 1, 0) = . qrt{-1} + j quaternions contain zero divisors—nonzero elements the product of which is zero—another phenomenon that distinguishes their behavior fundamentally from that of the integers.
As it flourished in the hands of mathematicians like Benjamin Peirce (1809–80), frobenius [VI.58](/part-06/ferdinand-georg-frobenius-18491917), Georg Scheffers (1866–1945), Theodor Molien (1861–1941), Wedderburn (1882–1948), among others, this line ofcartan [VI.69](/part-06/lie-joseph-cartan-18691951), and Joseph H. M.

105

thought resulted in a freestanding theory of algebras. This naturally intertwined with developments in the theory of matrices (theof dimension n2 over their base field) as it had evolvedn . imes n matrices form an algebra through the work of Gauss, Cayley, and Sylvester. It also merged with the not unrelated theory ofn-dimensional vector spaces (sional vector spaces with a vector multiplication asn-dimensional algebras are n - dimen- well as a vector addition and scalar multiplication) that issued from ideas like those of Hermann Grassmann (1809–77).
9 Modern Algebra By 1900, many new algebraic structures had been iden-tified and their properties explored. Structures that were first isolated in one context were then found toappear, sometimes unexpectedly, in others: thus, these new structures were mathematically more general thanthe problems that had led to their discovery. In the opening decades of the twentieth century, algebraists(the term is not ahistorical by 1900) increasingly recognized these commonalities—these shared structures such as groups, fields and rings—and asked questions at a more abstract level.
For example, what are all ofthe finite simple groups? Can they be classified? (See the classification of finite simple groups Moreover, inspired by the set-theoretic and axiomatic[V.7](/part - 05/the - classication - of - finite - simple - groups).) work ofto appreciate the common standard of analysis andcantor [VI.54](/part - 06/georg - cantor - 18451918), Hilbert, and others, they came comparison that axiomatization could provide.
Coming from this axiomatic point of view, Ernst Steinitz (1871–1928), for example, laid the groundwork for an abstract theory of fields in 1910, while Abraham Fraenkel (1891–1965) did the same for an abstract theory of rings four years later. As van der Waerden came to realize in thelate 1920 s, these developments could be interpreted as dovetailing philosophically with results like Hilbert’s ininvariant theory and Dedekind’s and Noether’s in the algebraic theory of numbers.
That interpretation, laidout in 1930 in van der Waerden’s classic textbook Moderne Algebra ern algebra” that subsumed the algebra of polynomials, codified the structurally oriented “modof the high school classroom and that continues to characterize algebraic thought today. Further Reading Bashmakova, I., and G. Smirnova. 2000.Evolution of Algebra, translated by A. Shenitzer. Washing-The Beginnings and ton, DC: The Mathematical Association of America. 106 Corry, L. 1996.matical Structures Modern Algebra and the Rise of Mathe-. Science Networks, volume 17. Basel: Edwards, H. M. 1984.Heath, T. L.
 1956.Birkhäuser. The Thirteen Books of Euclid’s Elements Galois Theory. New York: Springer. , Høyrup, J. 2002.2 nd edn$. (3 vols.)$. New York: Dover. Babylonian Algebra and Its Kin Lengths, Widths, Surfaces: A Portrait of Old. New York: Springer. Klein, J. 1968.of Algebra, translated by E. Brann. Cambridge, MA: The Greek Mathematical Thought and the Origin Netz, R. 2004.MIT Press. Early Mediterranean World: From Problems to Equations The Transformation of Mathematics in the. Parshall, K. H. 1988. The art of algebra from al-Kh. ar{w}Cambridge: Cambridge University Press.to Viète:
A study in the natural selection of ideas. Historyariz$\bar{m}$ı of Science. 1989. Toward a history of nineteenth-century invari-26:129–64. ant theory. Inby D. E. Rowe and J. Mc Cleary, volume 1, pp. 157–206.The History of Modern Mathematics, edited Sesiano, J. 1999.Amsterdam: Academic Press. Résolution des équations des Mésopotamiens à la Renais-Une Introduction à l’histoire de l’algèbre: sance Romandes.. Lausanne: Presses Polytechniques et Universitaires Van der Waerden, B. 1985.Kh$\bar{w}ariz \bar{m}$ı to Emmy Noether A History of Algebra from al-. New York: Springer. Wussing, H. 1984.cept:
A Contribution to the History of the Origin of Abstract The Genesis of the Abstract Group Con Group Theory The MIT Press., translated by A. Shenitzer. Cambridge, MA: II.4 Algorithms Jean-Luc Chabert 1 What Is an Algorithm? It is not easy to give a precise definition of the word “algorithm.” One can provide approximate synonyms: some other words that (sometimes) mean roughly the same thing are “rule,” “technique,” “procedure,” and “method.” One can also give good examples, such aslong multiplication, the method one learns in high school for multiplying two positive integers together.
However, although informal explanations and well-chosen examples do give a good idea of what an algorithm is, the concept has undergone a long evolution: it was not until the twentieth century that a satisfactory formal definition was achieved, and ideas about algorithms have evolved further even since then. In this arti-cle, we shall try to explain some of these developments and clarify the contemporary meaning of the term.

II. The Origins of Modern Mathematics

1.1 Abacists and Algorists

Returning to the example of multiplication, an obvious point is that how you try to multiply two numbers together is strongly influenced by how you represent those numbers. To see this, try multiplying the Roman numerals CXLVII and XXIX together without first converting them into their decimal counterparts, 147 and

29. It is difficult and time-consuming, and explains why arithmetic in the Roman empire was extremely rudimentary. A numeration system can be additive, as itwas for the Romans, or positional, like ours today. If it is positional, then it can use one or several bases—for instance, the Sumerians used both base 10 and base 60.For a long time, many processes of calculation used abacuses on to which one placed stones (the Latin for small stone. Originally, these were lines traced on sand, iscounting tables equipped with rows or columns on to calculus) to represent numbers.
Later there were which one placed tokens. These could be used to rep-resent numbers to a given base. For example, if the base was 10, then a token would represent one unit, ten units, one hundred units, etc., according to whichrow or column it was in. The four arithmetic operations could then be carried out by moving the tokens accord-ing to precise rules. The Chinese counting frame can be regarded as a version of the abacus. cal works were translated into Latin, the denary posi-tional numeration system spread through Europe.
This In the twelfth century, when the Arabic mathemat i system was particularly suitable for carrying out the arithmetic operations, and led to new methods of cal-culation. The term algoritmus was introduced to refer to these, and to distinguish them from the traditional methods that used tokens on an abacus. Although the signs for the numerals had been adapted from Indian practice, the numerals became knownas Arabic. And the origin of the word “algorithm” is Arabic:
it arose from a distortion of the namekh$\bar{w}ariz \bar{m}$ı [VI.5](/part-06/abu-jafar-muhammad-ibn-musa-al-khwarizm-vi55-william-kingdon-cliord-18451879), who was the author of the oldest al known work on algebra, in the first half of the ninth century. His treatise, entitled al-Ki$\bar{t}$ ab al-mukhtas.ar $\bar{f}$ı h.i$\bar{s}$ ab al-jabr wa’l-mu$\bar{q}$ abalaon calculation by completion and balancing”), gave rise(“The compendious book to the word “algebra.”

1.2 Finiteness

As we have just seen, in the Middle Ages the term “algorithm” referred to the processes of calculation basedon the decimal notation for the integers. However, in

II.4. Algorithms

the seventeenth century, according to[VI.20](/part-06/jean-le-rond-dalembert-17171783) Encyclopédie, the word was used in a more gen-d’alembert’s eral sense, referring not just to arithmetic but also tomethods in algebra and to other calculational procedures such as “the algorithm of the integral calculus”or “the algorithm of sines.” tematic calculation that could be carried out by meansof very precise rules. Finally, with the growing role of Gradually, the term came to mean any process of sys computers, the important role of understood:
it is essential that the process stops and finiteness was fully provides a result after a finite time. Thus one arrives atthe following naive definition: An algorithm is a set of finitely many rules for manip-ulating a finite amount of data in order to produce a result in a finite number of steps. Note the insistence on finiteness: finiteness in the writ-ing of the algorithm and finiteness in the implementation of the algorithm. ical definition in the classical sense of the term.
As we The formulation above is not of course a mathemat shall see later, it was important to formalize it further. But for now, let us be content with this “definition” and look at some classical examples of algorithms in mathematics. 2 Three Historical Examples A feature of algorithms that we have not yet mentionedis iteration, or the repetition of simple procedures. To see why iteration is important, consider once again the example of long multiplication. This is a method that works for positive integers of any size.
As the numbers get larger, the procedure takes longer, but—andthis is of vital importance—the method is “the same”: if you understand how to multiply two three-digit num-bers together, then you do not need to learn any new principles in order to multiply two 137-digit numbers together (even if you might be rather reluctant to do the calculation). The reason for this is that the methodfor long multiplication involves a great deal of carefully structured repetition of much smaller tasks, such as multiplying two one-digit numbers together.
We shall see that iteration plays a very important part in the algorithms to be discussed in this section.

2.1 Euclid’s Algorithm: Iteration

One of the best, and most often used, examples to illus-trate the nature of algorithms is euclid’s algorithm

107

[III.22], which goes back to the third centuryis a procedure described by euclid [VI.2](/part-06/euclid-ca) to determineb.c.e. It the ge rs greatest common divisora and b. (Sometimes the greatest common divisor(gcd) of two positive inte- is known as the When one first meets the concept of the greatest com-highest common factor (hcf).) mon divisor oflargest positive integer that is a divisor (or factor) ofa and b, it is usually defined to be the both convenient to think of it as the unique positive inte-a and b.
However, for many purposes it is more gerdivisor ofd with the following two properties. First, a and b, and second, if c is any other divi-d is a sor of determining a and db, thenis provided by the first two pro posit i onsd is divisible by c. The method for of Book VII of Euclid’s“Two unequal numbers being set out, and the less being Elements. Here is the first one:
continually subtracted in turn from the greater, if thenumber which is left never measures the one before it until a unit is left, the original numbers will be primeto one another.” In other words, if by carrying out successive alternate subtractions one obtains the number 1, then the gcd of the two numbers is equal to 1. In thiscase one says that the numbers are relatively prime or coprime.

2.1.1 Alternate Subtractions

Let us describe Euclid’s procedure in general. It is basedon two simple observations: (i) ifa = b then the gcd of a and b is b (or a); (ii)dis a common divisor ofis a common divisor ofa -ab and and bb if and only if it, which implies that the gcd ofa - b and b. a and b is the same as the gcd of Now suppose that we wish to determine the gcd ofandb and suppose that a ⩾ b. If a = b then obser-a vation (i) tells us that the gcd istion (ii) tells us that the answer will be the same as it isb. Otherwise, observa- for the two numbers the larger of these two numbers anda - b and b.
If we now letb the smaller (ofa1 be course, if they are equal then we just setthen we are faced with the same task that we started1 a1 = b1 = b), with—to determine the gcd of two numbers—but thelarger of these two numbers, a , is smaller than a, the larger of the original two numbers. We can therefore repeat the process: ifa = b1 then the gcd of a andbwe replace1, and hence that ofa by a - ba1 andand reorganize the numbers1 b, is b1, and otherwise1 acomes first.1 - b1 and1 b1 so that if one of them is larger then i(t1)1108 a and 0\le b integersb \le a yes a= b no

the gcd of the given numbers is the  c a- b

current value of a

yes c$< b no$

abacbc

procedure in Euclid’s algorithm. Figure 1 A flow chart for the that this procedure works. It is the following fundamen-One further observation is needed if we want to show tal fact about the positive integers, sometimes knownas the well-ordering principle. (iii) A strictly decreasing sequence of positive integersa > a > a > · · ·must be finite.
0 1 2 Since the iterative procedure just described produces exactly such a strictly decreasing sequence, the iterations must eventually stop, which means that at somepointa and b will be equal, and that value is thus the gcd of$a^{k} and b^{k}$(see figure 1).

2.1.2 Euclidean Divisions

Euclid’s algorithm is usually described in a slightly different way. One makes use of a more complex pro-cedure called Euclidean division—that is, division with remainder—which greatly reduces the number of stepsthat the algorithm takes. The basic fact underlying this procedure is that ifa and b are two positive integers then there are (unique) integersq and r such thata = bq + r and 0 ⩽ r < b.

The numberder. Remarks (i) and (ii) above are then replaced by theq is called the quotient and r is the remain- following ones: (ii(i^ ) if) the gcd ofr . r = 0 then the gcd ofa and b is the same as the gcd ofa and b is equal to bb; and This time, at the first step, one replaces Ifr = 0, then at the second step one replaces(a, b) by(b, r )(b, r )by.

II. The Origins of Modern Mathematics

(r , rby r1, and so on. The sequence of remainders is strictly), where r1 is the remainder in the division of b decreasing ( b > r > r1 > r2 ⩾ 0), so the process stops and the gcd is the last nonzero remainder. It is not hard to see that the two approaches are equivalent. Suppose, for example, that$b =$37. If you use the first approach, then you will$a = 103 438 and$ repeatedly subtract 37 from 103 438 until you reach a number that is smaller than 37. This number will be the remainder when 103 438 is divided by 37, which is the first number you would calculate if you used the second approach.
Thus, the reason for the second approach is that repeated subtraction can be a very inefficient wayof calculating remainders. This efficiency gain is very important in practice: the second approach gives riseto a polynomial-time algorithm [IV.20 §2](/part-04/computational-complexity), while the time taken by the first is exponentially long. 2.1.3 Generalizations Euclid’s algorithm can be generalized to many other contexts where we have notions of addition, subtraction, and multiplication.
For example, there is a variantof it that applies to the ring [III.81 §1](/part - 03/rings - ideals - and - modules) Z[i] of Gaussian integers, that is, numbers of the form$a + bi$, where a andring of all polynomials with real coefficients (or coeffi - b are ordinary integers. It can also be applied to the cients in any field, for that matter). The one require-ment is that we should be able to find some analogue of the notion of division with remainder, after whichthe algorithm is virtually identical to the algorithm for positive integers.
For example, we have the following statement for polynomials: given any two polynomials Anomialsand B with Q and B Rnot the zero polynomial, there are poly-such that A = BQ + R and either R = 0 or the degree of As Euclid noticed (R is less than the degree of Elements, Book X, proposition 2), B. one may also carry out the procedure on pairs of num-bersa and b that are not necessarily integers. It is easy to check that the process will stop if and only if the ratioto the concept ofa/b is a rational number. This observation leads continued fractions [III.22], which are discussed in part III.
They were not studied explic-itly before the seventeenth century, but the roots of the idea can be traced back to archimedes [VI.3](/part - 06/archimedes - ca). 2.2 The Method of Archimedes to Calculate Approximation and Finitenessπ: The ratio of the circumference of a circle to the diam-eter is a constant that has been denoted byπ since II.4. Algorithms the eighteenth century (see [[III.70]](/part - 03/)). Let us see how Archimedes, in the third century b.c.e., obtained the classical approximation inscribed polygons (whose vertices lie on the circle) and227 for this ratio.
If one draws circumscribed polygons (whose sides are tangent to thecircle) and if one computes the length of these polygons, then one obtains lower and upper bounds forthe value ofπ, since the circumference of the circle is greater than the length of any inscribed polygon andless than the length of any circumscribed polygon (figure 2). Archimedes started with regular hexagons, andthen repeatedly doubled the number of sides, obtaining more and more precise bounds. He finished with ninety-six-sided polygons, obtaining the estimates 3$+1071 ⩽ π ⩽ 3 + 1 7$. to call it an algorithm?
Strictly speaking it is not: how-ever many sides you take for your polygon, all you This process clearly involves iteration, but is it right will get is an approximation tonot finite. However, what we do have is an algorithmπ, so the process is that will calculate ple, if you demand an approximation that is correctπto any desired accuracy: for examto ten decimal places, then after a finite number ofsteps the algorithm will give you one. What matters now is that the process that the values that come out of the iteration get arbi-converges.
That is, it is important trarily close tocan be used to prove that this is indeed the case, andπ. The geometric origin of the method in 1609 in Germany Ludolph van Ceulen obtained an approximation accurate to thirty-five decimal places using polygons with 262 sides. algorithm for approximating for calculating the gcd of two positive integers.
Algo-Nevertheless, there is a clear difference between thisπand Euclid’s algorithm rithms like Euclid’s are often calledand are contrasted with numerical algorithms discrete algorithms, which, are algorithms that are used to compute numbers thatare not integers (see numerical analysis [IV.21](/part-04/numerical-analysis)). 2.3 The Newton–Raphson Method: Recurrence Formulas In around 1670, finding roots of equations, which he explained with ref - newton [VI.14](/part - 06/isaac - newton - 16421727) devised a method for erence to the example x3 - 2 x - 5 = 0.
His explanation starts with the observation that the root mately equal to 2. He therefore writes x x = is approxi - 2 + p and obtains an equation forp by substituting 2 + p for x in the original equation. This new equation works out tobep3 + 6 p2 + 10 p - 1 = 0. Because x is close to 2, p is 109 TGHADFNEOBC Figure 2 Approximation ofπ. small, so he then estimatesp3 and 6 p2 (since these should be considerably smallerp by for getting the terms than 10 orp= p1. Of course, this is not an exact solution, but it- 1).
This gives him the equation 10 p -1 = 0, provides him with a new and better approximation, 2 forx. He then repeats the process, writing10 x = 2.1 +.q1,, substituting to obtain an equation forq, solving this equation approximately, and refining his estimate still further. The estimate he obtains for$q is - 0$.0054, so the next approximation for How, though, can we be sure that this process really$x is 2$.0946. does converge to$x$? Let us examine the method more closely.

2.3.1 Tangents and Convergence

Newton’s method can be interpreted geometrically in terms of the graph of a function self did not do so. A rootx of the equationf , though Newton him-f (x) = 0 corresponds to a point where the curve with equationy = f (x) intersects the x-axis. If you start with an approximate valuedid above, then when you substitutea for x and set p =a +x p- afor, as wex to obtain a new function the origin from(0, 0)g(p)to the point, you are effectively moving$(a, 0)$.
Then when you forget all powers oflinear terms, you are finding the best linear approxima-p other than the constant and tion to the function$g$—which, geometrically speaking, is the tangent line to approximate value you obtain forg at the pointp(is the0, g(0 x))-coordinate. Thus, the of the point where the tangent at(0, g(0)) crosses the

110

a a + p + q a + p

Figure 3 Newton’s method.

xand gives the new approximation to the root of-axis. Adding a to this value returns the origin tof . This(0,0) is why Newton’s method is often called themethod (figure 3). And one can now see that the new tangent approximation will definitely be better than the old oneif the tangent tof at (a, f (a)) intersects the x-axis at a point that lies betweeny = f (x) intersects theaxand the point where the curve - axis. of the valueimate value 2 As it happens, this is not the case for Newton’s choicea =.1 and for all subsequent ones.
Geo - 2 above, but it is true for the approx- metric ally, the favorable situation occurs if the point(a, f (a)) lies above the x-axis in a convex part of the curve that crosses the concave part of the curve that crosses thex-axis or below thex - axis. Underx-axis in a these circumstances, and provided the root is not amultiple one, the convergence is quadratic, meaning that the error at each stage is roughly the square of the error at the previous stage—or, equivalently, the approximation is valid to a number of decimal places that roughly doubles at each stage. This is enormously fast.
ously important, and raises unexpectedly subtle ques-The choice of the initial approximation value is obvitions. These are clearer if we look atmials and their complex roots. Newton’s method can becomplex poly no easily adapted to this more general context. Supposethatz is a root of some complex polynomial and thatz0 is an initial approximation for z. Newton’s method then gives us a sequence may not converge to z. We define the$z^{0}$, z1$, z2$, . .
.domain of attrac-, which may or tionbers, denotedz such that the resulting sequence does indeed A(z), to be the set of all complex num- converge to The first person to ask this problem was0 z. How do we determine A(z)? cayley [VI.46](/part-06/arthur-cayley-18211895), in 1879. He noticed that the solution is easy

II. The Origins of Modern Mathematics

for quadratic polynomials but difficult as soon as thedegree is 3 or more. For example, the domains of attraction of the roots±1 of the polynomial z2 - 1 are the open half-planes bounded by the vertical axis, but the domains corresponding to the roots 1,ω, andω2 of z3 - 1 are extremely complicated sets. They were described by Julia in 1918—such subsets are nowcalled fractal sets. Newton’s method and fractal sets are discussed further in dynamics [IV.14](/part - 04/dynamics).
2.3.2 Recurrence Formulas At each stage of his method, Newton had to producea new equation, but in 1690 Raphson noticed that this was not really necessary. For particular examples, hegave single formulas that could be used at each step, but his basic observation applies in general and leads to a general formula for every case, which one caneasily obtain using the interpretation in terms of tangents. Indeed, the tangent to the curve point ofx-coordinate a has the equationy = yf (x)- f (a)at the = fx^ -coordinate(a)(x - a), and it cuts thea - f (a)/f^ (a).
What we now call thex-axis at the point with Newton–Raphson methodmula. One starts with an initial approximation springs from this simple for-$a = a$ and then defines successive approximations using the recurrence formula 0

(an)+1 = an - ff (a ((an)n)).xa pp ro xi ma tions of the square root2 As an example, let us consider the function- c. Here, Newton’s method provides a sequence of. qrt{c} of c, given byf (x) = the recurrence formulawe obtain by substituting an(x+1)2 +=(c1)2 for(anf+in the generalc/an) (which formula above). This method for approximating square roots was known by Heron of Alexandria in the first century. Note that ifclose,. qrt{c} lies between them, anda0 is close to a. qrt{c}=, then1(ac/a+ c/a0 is also) is 1 2 0 0 their arithmetic mean. 3 Does an Algorithm Always Exist?

3.1 Hilbert’s Tenth Problem:

The Need for Formalization

In 1900, at the Second International Congress of Math-ematicians, hilbert [VI.63](/part-06/david-hilbert-18621943) proposed a list of twenty three problems. These problems, and Hilbert’s works in general, had a huge influence on mathematics duringthe twentieth century (Gray 2000). We are interested here in Hilbert’s tenth problem: given a Diophantine

II.4. Algorithms

equation, that is, a polynomial equation with any num-ber of indeterminates and with integer coefficients, “a process is sought by which it can be determined, in a finite number of operations, whether the equation issolvable in integral numbers.” In other words, we have to find an algorithm which tells us, for any Diophan-tine equation, whether or not it has at least one integer solution. Of course, for many Diophantine equations it is easy to find solutions, or to prove that no solutions exist. However, this is by no means always the case:
consider, for instance, the Fermat equation xn + yn = zn(n ⩾ 3). (Even before the solution offermat’s last theorem mining for any specific[V.10](/part - 05/fermats - last - theorem) an algorithm was known for deter - n whether this equation had a solution. However, one could not call it easy.)If Hilbert’s tenth problem has a positive answer, then one can demonstrate it by exhibiting a “process” of thesort that Hilbert asked for. To do this, it is not necessary to have a precise understanding of what a “process” is.
However, if you want to give ayou have to show that no algorithm exists negative , and for that answer, then you need to say precisely what counts as an algorithm. In section 1.2 we gave a definition that seems to be reasonably precise, but it is not precise enough to enable us to think about Hilbert’s tenth problem. What kind ofrules are we allowed to use in an algorithm? How can we be sure that no algorithm achieves a certain task, rather than just that we are unable to find one? 3.2 Recursive Functions: Church’s Thesis What we need is aalgorithm.
In the seventeenth century, formal definition of the notion of anleibniz [VI.15](/part - 06/gottfried - wilhelm - leibniz - 16461716) envisaged a universal language that would allow one toreduce mathematical proofs to simple computations. Then, during the nineteenth century, logicians suchas Charles Babbage, boole [VI.43](/part - 06/george - boole - 18151864), frege [VI.56](/part - 06/gottlob - frege - 18481925), and peanoing by an “algebraization” of logic.
Finally, between[VI.62](/part - 06/giuseppe - peano - 18581932) tried to formalize mathematical reason1931 and 1936, gödel [VI.92](/part - 06/kurt - gdel - 19061978), church [VI.89](/part - 06/alonzo - church - 19031995), and Stephen Kleene introduced the notion oftions (see Davis (1965), which contains the original recursive functexts). Roughly speaking, a recursive function is onethat can be calculated by means of an algorithm, but the definition of recursive functions is different, and is completely precise.
3.2.1 Primitive Recursive Functions Another rough definition of a recursive function is asfollows: a recursive function is one that has an induc - 111 tive definition. To give an idea of what this means, let usconsider addition and multiplication as functions from N . imes N to N. To emphasize this, we shall write sum(x, y) and prod(x, y) for x + y and xy, respectively. A familiar fact about multiplication is that it is “repeated addition.” Let us examine this idea more pre-cisely. We can define the function “prod” in terms of the function “sum” by means of the following tworules:
prod(1, y) equals y and prod(x + 1, y) equals sumyou know how to calculate sums, then you can work out(prod(x, y), y). Thus, if you know prod(x, y) and prod$(x + 1$, y). Since you also know the “base case” prodthese simple rules completely determine the function$(1, y)$, a simple inductive argument shows that “prod.” sively defined” in terms of another. We now want to understand the class of We have just seen how one function can be “recur-all functions from Nn to N that can be built up in a few basic ways, of which recursionis the most important.
We shall refer to functions from Nn to N as n-ary functions. out of which the rest will be built. It turns out that a To begin with, we need an initial stock of functions very simple set of functions is enough. Most basic arethe constant functions: that is, functions that take every n-tuple in Nnto some fixed positive integerc. Another very simple function, but the function that allows usto create much more interesting ones, is the successor function one, n +, which takes a positive integer1. Finally, we have projection functionsn to the next:
the function maps it to the(Uk)n takes a sequence kth coordinate x(x.1, . . . , xn) in Nn and from other functions. The first ism We then have two ways of constructing functions-ary function φ and m n-ary functionsk substitutionψ. Given an, . . . , ψ , 1 m one defines ann-ary function by(x1, . . . , xn) \to φ(ψ1(x1, . . . , xn), $. . . , ψm(x1, . . . , xn))$. For example, so we can obtain the function(x + y)2 = prod(sum(x, y)(x, y)$,\to sum(x(x$, y))+ y)2, from the functions “sum” and “prod” by means of substitution. tive recursion The second method of construction is called.
This is a more general form of the induc-primitive method we used above in order to construct the function “prod” from the function “sum.” Given an (n - 1)-ary function ψ and an (n + 1)-ary function μ, one defines ann-ary function φ by saying thatφ(1, x2, $. . . , xn) = ψ(x2$, $. . . , xn) 112 and φ(k + 1, x2$, . . . , xn)= \mu(k, φ(k, x2, . . . , xn), x2, . . . , xn). In other words,(the values when the first coordinate is 1) andψtells you the “initial values” of\mu tellsφ you how to work outofφ(k, x , . . . , x ), x $, . . . , xφ(k + and1, x^{2}k, . . . , x$.
(The sum–prod-n) in terms uct example was simpler because we did not have adependence on2$k^{n}$.()2)n be built from the initial stock of functions using the two operations, substitution and primitive recursion, that A primitive recursive function is any function that can we have just described.

3.2.2 Recursive Functions

If you think for a while about primitive recursion andknow a small amount about programming computers, you should be able to convince yourself that they are effectively computable: that is, that for any primitive recursive function there is an algorithm for computingit. (For example, the operation of primitive recursion can usually be realized in a rather direct way as a FOR loop.)How about the converse? Are all computable functions primitive recursive? Consider, for example, the function that takes the positive integern to p , then algorithm for computingth prime number.
It is not hard to devise a simplep , and it is then a good exer-^n cise (if you want to understand primitive recursion) toconvert this algorithm into a proof that the function is$n$ primitive recursive. However, it turns out that this function is not typical: there are computable functions that are not primitive recursive. In 1928, Wilhelm Ackermann defined a function, now known as the“doubly inductive” definition. The following function is Ackermann function, that has a not quite the same as Ackermann’s, but it is very simi-lar.
It is the function A(x, y) that is determined by the following recurrence rules: (iii)(ii)(i)A(A(x$, A(xand1, y)+y >11)$, y==1.+2 for everyy1+) 2 for every= A(x, A(xx;$y+$;1$, y)) whenever x > 1$ For example, From this and the fact that A(2, y +1) = A(A(1, A(2, 1)2, y))= 2 it follows that= A(2, y)+ 2.A(show that2, y) =A(2 y3, y)for every= 2 y, and in general that for eachy. In a similar way one canx

II. The Origins of Modern Mathematics

the function that takes$y to A(x + 1$, y)“iterates” the function that takes values of A(x, y) are extremely large even wheny to A(x, y). This means that thex andy are fairly small. For example$, A(4, y + 1) = 2 A(4 , y)$, so in generalof height$y$. We have A(4, y)is given by an “exponential tower”A(4, 1) = 2, A(4, 2) = 22 = 4, A(A(44,,35)) == 2265 5364 =, which is too large a number for its16, A(4, 4) = 216 = 65 536, and decimal notation to be reproduced here. It can be shown that for every primitive recursive functionφ there is some x such that the function A(x, y)inductive argument.
To oversimplify slightly, ifgrows faster than φ(y). This is proved by anψ(y) andthanμ(y)A(x, y)have already been shown to grow more slowly, then one can show that the functionφgrows more slowly. This allows us to define a “diag-produced from them by primitive recursion also onal” function A(y) = A(y, y) that is not primi- tive recursive because it grows faster than any of the functions A(x, y).
functions can be calculated algorithmically, then our definition will surely have to encompass functions like If we are trying to understand in a precise way which the Ackermann function, since they can in principle becomputed. Therefore, we must consider a larger class of functions than just the primitive recursive ones. This is what Gödel, Church, and Kleene did, and they obtained in different ways the same class offunctions. For instance, Kleene added a third method ofrecursive construction, which he called$(n + 1)$-ary function, one defines an min im iz at io nn-ary function.
If f is ang by taking$f$ (x , . . . , xg(x, y)1, . . . , x= 0. (If there is no suchn) to be the smallesty, one regardsy such that gc om pl ic at i on in what follows.)as undefined for1 n (x1, $. . . , x^{n})$. We shall ignore this recursive, but so are all functions that one can writea computer program to calculate. So this gives us the It turns out that, not only is the Ackermann function formal definition of computability that we did not have before.

3.2.3 Effective Calculability

Once the notion of recursive functions had been formulated, Church claimed that the class of recursive func-tions was exactly the same as the class of “effectively calculable” functions. This claim is widely believed, but it is a conviction that cannot be proved since the notion of recursive function is a mathematically precise concept while that of an effectively calculable function is an intuitive notion, rather like that of

II.4. Algorithms

“algorithm.” Church’s statement lies in the realm of metamathematics and is now called Church’s thesis.

3.3 Turing Machines

One of the strongest pieces of evidence for Church’sthesis is that in 1936 turing [VI.94](/part-06/alan-turing-19121954) found a very different-looking way of formalizing the notion of analgorithm, which he showed was equivalent. That is, every function that was computable in his new sensewas recursive and vice versa. His approach was to define a notion that is now called awhich can be thought of as an extremely primitive com-Turing machine, puter, and which played an important part in the devel-opment of actual computers.
Indeed, functions that are computable by Turing machines are precisely thosethat can be programmed on a computer. The primitive architecture of Turing machines does not makethem any less powerful: it merely means that in practice they would be too cumbersome to program or toimplement in hardware.
Since recursive functions are the same as Turing-computable functions, it follows that recursive functions too are those functions that can be programmed on a computer, so to disbelieve Church’s thesis would be to maintain that there are some “effective procedures” that cannot be converted into computer programs—which seems rather implausible. A description of Turing machines can be found in Turing introduced his machines in response to a computational complexity [IV.20 §1](/part-04/computational-complexity). question that generalized Hilbert’s tenth problem.
The entscheidungspr oblem asked by Hilbert, in 1922. He wanted to know whether, or decision problem, was also there was a “mechanical process” by which one could determine whether any given mathematical statement could be proved. In order to think about this, turing needed a precise notion of what constituted a “mechanical process.” Once he had defined Turing machines, he was able to show by means of a fairly straightforward diagonal argument that the answer to Hilbert’squestion was no.
His argument is outlined in the insolubility of the halting problem [V.20](/part-05/the-insolubility-of-the-halting-problem). 4 Properties of Algorithms 4.1 Iteration versus Recursion As previously mentioned, we often encounter compu-tation rules which define each element of a sequence in terms of the preceding elements. This gives rise totwo different ways of carrying out the computation. 113 The first isone obtains succeeding terms by means of a recurrence iteration: one computes the first terms, then formula.
The second is recursion, a procedure which seems circular at first because one defines a procedurein terms of itself. However, this is allowed because the procedure calls on itself with smaller values of the variables. The concept of recursion is subtle and powerful. Let us try to clarify the difference between recursion and iteration with some examples. Suppose that we wish to compute n!$= 1 · 2 ·$ 3 the recurrence relation· · · (n - 1) · n. An obvious way of doing it is to noten!$= n · (n - 1)$! and the initial value 1!= 1.
Having done so, one could then compute successively the numbers 2!, 3!, 4!, and soon until one reached$n$!, which would be the iterative approach. Alternatively, one could say that if factthe result of a procedure that leads to$n$!, then fact$(n)(n) is = n \t\text{imes fact}(n - 1)$, which would be a recursive procedure. The second approach says that to obtain know how to obtain$(n - 1)$!, and to obtainn(n! it suffices to-1)! it suffices to know how to obtain knows that 1!$= 1$, one can obtain(n - 2)!, and so on. Since one$n$!.
Thus, recursion is a bit like iteration but thought of “backwards.” clearly the difference between the two procedures. In some ways this example is too simple to show Moreover, if one wishes to compute seems simpler and more natural than recursion. We n!, then iteration now look at an example where recursion is far simpler than iteration.

4.1.1 The Tower of Hanoi

The Tower of Hanoi is a problem that goes back toÉdouard Lucas in 1884. One is givenn disks, all of dif- ferent sizes and each with a hole in the middle, stacked on a peg A in order of size, with the largest one at thebottom. We also have two empty pegs B and C. The problem is to move the stack from peg A to peg B while obeying the following rules. One is allowed to move just one disk at a time, and each move consists in takingthe top disk from one of the pegs and putting it onto another peg. In addition, no disk may ever be placed above a smaller disk.
but becomes rapidly harder as the number of disks The problem is easy if you have just three disks, increases. However, with the help of recursion one cansee very quickly that an algorithm exists for moving the disks in the required way. Indeed, suppose that weknow a procedure H(n -1) that solves the problem forn - 1 disks. Here is a procedure H(n) for ndisks: move 114 the first H(n - 1)n, then move the last disk on A to B, and finally- 1 disks on top of A to C with the procedure apply once more the procedure H(n - 1) to move all the disks from C to B.
If we writethat movesn disks from peg A to peg B according to the HAB(n) for the procedure rules, then we can represent this recursion symbolically as HAB(n) = HAC(n - 1)HAB(1)HBC(n - 1)$. Thus,1$), which are clearly equivalent to HAB(n) is deduced from HAC(n H-1(n) and- 1 H). Since BC(n -HABOne can easily check by induction that this proce-(1) is certainly easy, we have the full recursion. ABdure takes 2 n - 1 moves—moreover, it turns out that the task cannot be accomplished in fewer moves.
Thus, the number of moves is an exponential function ofn, so for large Further more, the largern the procedure will be very long.n is, the more memory one must use to keep track of where one is in the procedure. By contrast, if we wish to carry out an iteration during an iterative procedure, it is usually enough to know justthe result of the previous iteration. Thus, the most we need to remember is the result of one iteration. Thereis in fact an iterative procedure for the Tower of Hanoi as well. It is easy to describe, but it is much less obvious that it actually solves the problem.
It encodes the positions of thestep applies a very simple rule to obtain the nextn disks as an n-bit sequence and at eachn-bit sequence. This rule makes no reference to how manysteps have so far taken place, and therefore the amount of memory needed, beyond that required to store the positions of the disks, is very small. 4.1.2 The Extended Euclid Algorithm Euclid’s algorithm is another example that lends itselfin a very natural way to a recursive procedure. Recall that ifcan writea anda =bqbare two positive integers, then we + r with 0 ⩽ r < b.
The algo- rithm depended on the observation that gcd(a$, b) =$ gcdily from(b, r )a. Since the remainder and b, and since the pairr can be calculated eas-(b, r ) is smaller than the pairwhich stops when we reach a pair of the form(a, b), this gives us a recursive procedure,(a, 0). An important extension of Euclid’s algorithm is Bézout’s lemmative integers(a, b), which states that for any pair of posi-there exist (not necessarily positive) integersu and v such thatua + vb = d = gcd(a, b). How can we obtain such integersis given by the extended Euclid algorithmu and v, which again? The answer II.
 The Origins of Modern Mathematics can be defined using recursion. Suppose we can find apair(u^ , v^ ) that works for b and r: that is, u^ b + v^ r =dthis equation and deduce that. Since a = qb + r , we can substituted = u^ br+=v^ a(a--qbqb)into = v^ a+(u^ -v^ q)b. Thus, setting u = v^ and v = u^ -v^ q, we havefora anduab can be easily calculated from a pair + vb = d. Since a pair (u, v) that works(u^ , v^ ) that works for the smallersive procedure. The “bottom” of the recursion is whenb and r , this gives us a recur - r = 0, in which case we know that 1 b + 0 r = d.
Once we reach this, we can “run back up” through Euclid’s algo - rithm, successively modifying our pair(u, v) according to the rule just given. Notice, incidentally, that the factthat this procedure exists is a proof of Bézout’s lemma. 4.2 Complexity So far we have considered algorithms in a theoretical way and ignored their obvious practical importance. However, the mere existence of an algorithm for carrying out a certain task does not guarantee that your computer can do it, because some algorithms take so many steps that no computer can implement them (unless you are prepared to wait
billions of years forthe answer). The complexity of an algorithm is, loosely speaking, the number of steps it takes to complete its task (as a function of the size of the input). more precisely, this is the time complexity of the algorithm. There is also its maximum amount of memory a computer needs inspace complexity, which measures the order to implement it. Complexity theory is the study of the computational resources that are needed to carryout various tasks.
It is discussed in detail in computational complexity [IV.20](/part-04/computational-complexity)—here we shall give a hint of it by examining the complexity of one algorithm.

4.2.1 The Complexity of Euclid’s Algorithm

The length of time that a computer will take to imple-ment Euclid’s algorithm is closely related to the number of times one needs to compute quotients and remain-ders: that is, to the number of times that the recursive procedure calls on itself. Of course, this number depends in turn on the size of the numbers whose gcd is to be determined. An initial observation a and b is that if 0< b ⩽ a, then the remainder in the divi- sion ofifb ⩾ aa/by2 then the remainder isb is less than a/2.
To see this, notice thata - b, which is at mosta/2, whereas if b ⩽ a/2 then we know that the remainder is at mostb and so is again at most a/2. It

II.4. Algorithms

follows that after two steps of calculating the remain-der, one arrives at a pair where the larger number is at most half what it was before. From this it is easy to show that the number of such calculations needed is atmost 2 loga + 1, which is roughly proportional to the number of digits ofthana itself, the algorithm can be used easily for very2 a. Since this number is far smaller large numbers, which gives it great practical utility togo with its theoretical significance. does not appear to have been studied until the first halfof the nineteenth century:
the above bound of 2 log The number of divisions needed in the worst casea+ 1 was given by Pierre-Joseph-Étienne Finck in 1841. Itis in fact not hard to improve this result slightly and2 prove that the algorithm takes longest when consecutive Fibonacci numbers.
This implies that thea and b are number of divisions needed is never more than log1, whereφ is the golden ratio$.^{φ} a+$ once one has replaced a pair Euclid’s algorithm also has low space complexity:(a, b) by a new pair (b, r ), one can forget the original pair, so at any stage onedoes not have to hold very much in one’s memory (or store it in the memory of one’s computer).
By contrast, the extended Euclid algorithm appears to require one to remember the entire sequence of calculations thatleads to the gcdd of a and b, so that one can make a series of substitutions and eventually findsuch thatua + vb = d. However, a closer look at itu and v reveals that one can perform it while keeping track of only a few numbers at any one time. Let us see how this works with an example. We shall set38 ua+=2138$, v = b$1. We begin by writing down the first step$=$21, and find integersu and v such that of Euclid’s algorithm: 38$= 1 \times 21 + 17$. This tells us that 17 = 38 - 21.
Now we write down thesecond step: 21$= 1 \times 17 + 4$. We know how to write 17 in terms of 38 and 21, so letus do a substitution: 21$= 1 \times (38 - 21) + 4$. Rearranging this, we discover that 4= 2 . imes 21 - 38. Now we write down the third step of Euclid’s algorithm: 17$= 4 \times 4 + 1$. We know how to write 17 and 4 in terms of 38 and 21, so let us substitute again: 38$- 21 = 4 \times (2 \times 21 - 38) + 1$.

115

Rearranging this, we find that 1$= 5 \times 38 - 9 \times 21$, and we have finished. at each stage one just has to keep track of how two numbers are expressed in terms of If you think about this procedure, you will see thata and b. Thus, the space complexity of the extended Euclid algorithm is small if you implement it properly. 5 Modern Aspects of Algorithms

5.1 Algorithms and Chance

Earlier it was remarked that the notion of algorithm has continued to develop even since its formalization in the 1920 s and 1930 s. One of the main reasons for this has been the realization thata very useful tool in algorithms. This may seem puz-randomness can be zling at first, since algorithms as we have described them are deterministic procedures; in a moment we shall give an example that illustrates how randomness can be used. A second reason is the recent development of the notion of a quantum algorithm: for more about this, see quantum computation [III.74](/part-03/quantum-computation).
 can be useful. Given an integer tion The following simple example illustrates how chancef (n)that is not too hard to calculate but is diffi-n, we shall define a funccult to analyze. If. qrt{n}to the point where the firstn has d digits, then you approximated digits after the dec- imal point are correct (using Newton’s method, say), and letf (n) equal the dth digit. Now suppose that you wish to know roughly what proportion of numbers between 1030 and 1031 have$f (n) = 0$.
There does notn seem to be a good way of determining this theoretically, but calculating it on a computer looks very hard, too, as there are so many numbers between 1030 and 1031. However, if one chooses a random sample of 10 000 numbers between 1030 and 1031 and does the calculation for just those numbers, then with high probability the proportion of those numbers with$f (n) = 0 \text{will be}$roughly the same as the proportion of all numbers inthe range withf (n) = 0.
Thus, if you do not demand absolute certainty but instead are satisfied with a verysmall error probability, then you can achieve your goal with much more modest computational resources. 5.1.1 Pseudorandom Numbers How, though, does one use a deterministic computer toselect ten thousand random numbers between 1030 and 1031? The answer is that one does not in fact need to: it is almost always good enough to make a pseudorandom 116 selection instead. The basic idea is well-illustrated bya method proposed by von neumann [VI.91](/part - 06/john - von - neumann - 19031957) in the mid 1940 s.
One begins with a 2 the “seed,” calculates a2, and extracts fromn-digit integeraa2, calleda new2 n-digit number b by taking all the digits of a2 from the(n + 1)st to the 3 nth. One then repeats the pro- cedure for pl ic at i on jumbles up digits, the resulting sequence ofb, and so on. Because of the way multi - 2 truly random sequence, and can be used in randomizedn-digit numbers is very hard to distinguish from a algorithms. There are many other ways of producing pseudorandom sequences, and this raises an obvious question:
what properties should a sequence have for usto regard it as pseudorandom? This turns out to be a complex question, and several different answers havebeen proposed. Randomized algorithms and pseudo randomness are discussed in depth in computational complexity“pseudorandom generators” can be found there.
(See [[IV.20 §§6, 7]](/part - 04/computational - complexity), and a formal definition of also account of a famous randomized algorithm for testing computational number theory [IV.3 §2](/part - 04/computational - number - theory) for an whether a number is prime.) Here, let us discuss a similar question about infinite sequences of zeros and ones. When should we regard such a sequence as “random”? One idea is to consider simple statistical tests: wewould expect that in the long run the frequency of zeros Again, many different answers have been suggested.
should be roughly the same as that of ones, and more generally that any small subsequence such as 00110 should appear with the “right” frequency (which forthis sequence would be 1 since it has length 5). It is perfectly possible, however, for a sequence to32 pass these simple tests but to be generated by a deter-ministic procedure. If one is trying to decide whether a sequence of zeros and ones isthat is, produced by some means such as tossing aactually random— coin—then we will be very suspicious of a sequence if we can identify an algorithm that produces the same sequence.
For example, we would reject a sequence that was derived in a simple way from the digits ofif it passed the statistical tests. However, merely to askπ, even that a sequence cannot be produced by a recursive procedure does not give a good test for randomness: for example, if one takes any such sequence and alternates the terms of that sequence with zeros, one then obtainsa new sequence that is far from random, but which still cannot be produced recursively. sequence of zeros and ones should be called random if For this reason, von Mises suggested in 1919 that a II.
The Origins of Modern Mathematics it is not only the case that the limit of the frequency ofones is 1, but also that the same is true for any subsequence that can be extracted “by means of a reasonable procedure.” In 1940 Church made this more precise by2 translating “by means of a reasonable procedure” into “by means of a recursive function.” However, even this condition is too weak: there are such sequences that do not satisfy the “law of the iterated logarithm” (some-thing that a random sequence would satisfy).
Currently, the so-called Martin–Löf thesis, formulated in 1966, is one of the most commonly used definitions of random - ness: a random sequence is a sequence that satisfies all the “effective statistical sequential tests,” a notion that we cannot formulate precisely here, but which uses inan essential manner the notion of recursive function. By contrast with Church’s thesis, with which almost every mathematician agrees, the Martin–Löf thesis is still verymuch under discussion.
5.2 The Influence of Algorithms on Contemporary Mathematics Through out its history, mathematics has concerned itself with problems of existence. For example, are there transcendental numbers [III.41](/part - 03/irrational - and-\text{transcendental} - numbers), that is, numbers that are not the root of any polynomial with integer coefficients? There are two kinds of answers to such questions:
either one actually exhibits a number such asby Carl Lindemann in 1873), or one gives an “indirectπ and proves that it is transcendental (this was done existence proof,” such as cantor’s [VI.54](/part - 06/georg - cantor - 18451918) demonstration that there are “far more” real numbers than thereare roots of polynomials with integer coefficients (see countable and uncountable sets [III.11](/part - 03/countable - and - uncountable - sets)), which shows in particular that some real numbers must be transcendental.
5.2.1 Constructivist Schools In around 1910, under the leadership of[VI.75](/part - 06/luitzen - egbertus - jan - brouwer - 18811966), the intuitionist school [II.7 §3.1](/part - 02/foundations - crisis) of mathe - l. e. j. brouwer matics arose, which rejected the principle of the ex-cluded middle, the principle that every mathematical assertion is either true or false. In particular, Brouwer did not accept that the existence of a mathematical object such as a transcendental number is proved by the fact that its nonexistence would lead to a contra - diction.
This was the first of several “constructivist” schools, for which an object exists if and only if it can be constructed explicitly. II.5. The Development of Rigor in Mathematical Analysis to these principles, but almost all would agree that Not many working mathematicians have subscribed there is an important difference between constructive proofs and indirect proofs of existence, a difference that has come to seem more important with the riseof computer science. This has added a further level of refinement:
sometimes, even if you know that a math-ematical object can be produced algorithmically, you still care whether the algorithm can be made to work in a reasonably short time. 5.2.2 Effective Results In number theory there is an important distinction between “effective” and “ineffective” results. For example, and finally proved by Faltings in 1983, states that amordell’s conjecture [V.29](/part - 05/rational - points - on - curves - and - vi40 - ernst - eduard - kummer - 18101893), proposed in 1922 smooth rational plane curve of degree most finitely many points with rational coefficients.
n > 3 has at Among its many consequences is that the Fermat equa-tionxn + yn = znhas only finitely many integral solutions for eachn ⩾ 4. (Of course, we now know that it has no nontrivial solutions, but the Mordell conjecture was proved before Fermat’s last theorem, and it has many other consequences.) However, Faltings’s proof is in effective ma tion about how many solutions there are (except that, which means that it does not give any inforthere are not infinitely many), or how large they can be, so one cannot use a computer to find them all and know that one has finished the job.
There are many othervery important proofs in number theory that are ineffective, and replacing any one of them with an effective argument would be a major breakthrough. A completely different set of issues was raised by another solution to a famous open problem, thecolor theorem [V.12](/part-05/the-four-color-theorem), which was conjectured by Fran-fourcis Guthrie, a student ofand proved in 1976 by Appel and Haken, with a proofde morgan [VI.38], in 1852 that made essential use of computers.
They began witha theoretical argument that reduced the problem to checking finitely many cases, but the number of cases was so large that it could not be done by hand and was instead done by computers. But how should we judge such a proof? Can we be sure that the computer hasbeen programmed correctly? And even if it has, how do we know with a computation of that size that the computer has operated correctly? And does a proof that relies on a computer really tell usrem is true? These questions continue to be debated why the theotoday.

117

Further Reading

Archimedes. 2002.T. L. Heath. London: Dover. Originally published 1897, The Works of Archimedes, translated by Chabert, J.-L., ed. 1999.Cambridge University Press, Cambridge. Pebble to the Microchip A History of Algorithms: From the. Berlin: Springer Davis, M., ed. 1965.Press. The Undecidable. New York: The Raven Euclid. 1956.lated by T. L. Heath (3 vols.), 2 nd edn. London: Dover. The Thirteen Books of Euclid’s Elements, trans Originally published 1929, Cambridge University Press, Cambridge. Gray, J. J. 2000.University Press. The Hilbert Challenge. Oxford: Oxford Newton, I. 1969.edited by D. T.
Whiteside, volume 3 (1670–73), pp. 43–47.The Mathematical Papers of Isaac Newton, Cambridge: Cambridge University Press. II.5 The Development of Rigor in

Mathematical Analysis

Tom Archibald

1 Background

This article is about how rigor came to be introduced into mathematical analysis. This is a complicated topic, since mathematical practice has changed considerably, especially in the period between the founding of the cal-culus (shortly before 1700) and the early twentieth century. In a sense, the basic criteria for what constitutes acorrect and logical argument have not altered, but the circumstances under which one would require such anargument, and even to some degree the purpose of the argument, have altered with time.
The voluminous and successful mathematical analysis of the 1700 s, associated with names such as Johann and Daniel[VI.18](/part-06/the-bernoullis-), euler [VI.19](/part-06/leonhard-euler-17071783), and lagrange [VI.22](/part-06/joseph-louis-lagrange-17361813), lacked bernoulli foundational clarity in ways that were criticized and remedied in subsequent periods. By around 1910 a general consensus had emerged about how to make arguments in analysis rigorous.
calculation, methods for describing important features Mathematics consists of more than techniques for of geometric objects, and models of worldly phenom-ena. Nowadays, almost all working mathematicians are trained in, and concerned with, the production of rig-orous arguments that justify their conclusions. These conclusions are usually framed as statements of fact, accompanied by an argument, ortheorems, which are proof, that the theorem is indeed true. Here is a simple example: every positive whole number that is divisible

118

by 6 is also divisible by 2. Running through the six times table (6, 12, 18, 24, ...) we see that each number is even, which makes the statement easy enough to believe. A possible justification of it would be to say that since 6 is divisible by 2, then every number divisible by 6 must also be divisible by 2.Such a justification might or might not be thought of as a thorough proof, depending on the reader. For on hearing the justification we can raise questions: is italways true that ifa, b, and c are three positive whole numbers such thatble bya, then c is divisible byc is divisible bya?
What is div is i bi li tyb and b is divisi- exactly? What is a whole number? The mathematician deals with such questions by precisely defining con-cepts (such as divisibility of one number by another), basing the definitions on a smallish number of unde-fined terms (“whole number” might be one, though it is possible to start even further back, with sets). For example, one could define a numberby a numberm if and only if there exists an integern to be divisibleq such thatmore precise proof: if$qm = n$.
Using this definition, we can give an is divisible by 6, then n = 6 q for some$q$, and therefore n = 2(3 q), which proves thatnto show that the definition of divisibility by 2 holdsis divisible by 2. Thus we have used the definitions whenever the definition of divisibility by 6 holds. Historically, mathematical writers have been satisfied with varying levels of rigor.
Results and methods have often been widely used without a full justification of the kind just outlined, particularly in bodies of mathematical thought that are new and rapidly developing. Some ancient cultures, the Egyptians for example, had methods for multiplication and division, but no justification of these methods has survived and it does notseem especially likely that formal justification existed. The methods were probably accepted simply because they worked, rather than because there was a thorough argument justifying them.
mathematical writers who were engaged in research were well-acquainted with the model of rigorous math-By the middle of the seventeenth century, European ematical argument supplied byments. The kind of deductive, or synthetic, argument euclid’s [VI.2](/part-06/euclid-ca) Elewe illustrated earlier would have been described as aproof more geometrico—in the geometrical way. While Euclid’s arguments, assumptions, and definitions arenot wholly rigorous by today’s standards, the basic idea was clear:
one proceeds from clear definitions and generally agreed basic ideas (such as that the whole isgreater than the part) to deduce theorems (also called

II. The Origins of Modern Mathematics

propositions) in a step-by-step manner, not bringingin anything extra (either on the sly or unintentionally). This classical model of geometric argument was widely used in reasoning about whole numbers (for example by[VI.11](/part-06/ren-descartes-15961650)), and in mechanics (Galileo).fermat [VI.12](/part-06/pierre-fermat-1601665)), in analytic geometry (descartes itself has had a shifting meaning.
Coming from ancient origins, by around 1600 the term was used to refer to This article is about rigor in analysis, a term which mathematics in which one worked with an unknown(something we would now write asx) to do a calculation or find a length. In other words, it was closely related toalgebra, though the notion was imported into geometry by Descartes and others. However, over the course of the eighteenth century the word came to be associated with the calculus, which was the principal area of application of analytic techniques.
When we talk about rigorin analysis it is the rigorous theory of the mathematics associated with differential and integral calculus that we are principally discussing. In the third quarter ofthe seventeenth century rival methods for the differential and integral calculus were devised by[VI.14](/part-06/isaac-newton-16421727) and leibniz [VI.15](/part-06/gottfried-wilhelm-leibniz-16461716), who thereby synthesized newton and extended a considerable amount of earlier work concerned with tangents and normals to curves andwith the areas of regions bounded by curves.
The techniques were highly successful, and were extended read-ily in a variety of directions, most notably in mechanics and in differential equations. The key common feature of this research was the use of infinities: in some sense, it involved devising meth-ods for combining infinitely many infinitely small quantities to get a finite answer. For example, suppose we divide the circumference of a circle into a (large) num-ber of equal parts by marking off points at equal distances, then joining the points and creating triangles byjoining the points to the center.
Adding up the areas of the triangles approximates the circular area, and the more points we use the better the approximation. Ifwe imagine infinitely many of these inscribed triangles, the area of each will be “infinitely small” ormal. But because the total involves adding up infinitely infinite simany of them, it may be that we get a finite positive total (rather than just 0, from adding up infinitely many zeros, or an infinite number, as we would get if we added the same finite number to itself infinitely many times).
Many techniques for doing such calculations were devised, though the interpretation of what was taking place varied. Were the infinities involved“real” or merely “potential”? If something is “really”

II.5. The Development of Rigor in Mathematical Analysis infinitesimal, is it just zero? Aristotelian writers had abhorred actual infinities, and complaints about them were common at the time. Newton, Leibniz, and their immediate followers provided mathematical arguments to justify these methods.
However, the introduction of techniques involv-ing reasoning with infinitely small objects, limiting processes, infinite sums, and so forth meant that the founders of the calculus were exploring new ground in their arguments, and the comprehensibili ty of these arguments was frequently compromised by vague terminology or by the drawing of one conclusion when another might seem to follow equally well.
The objects they were discussing included infinitesimals (quantities infinitely smaller than those we experience directly), ratios of vanishingly small quantities (i.e., fractionsin, or approaching, the form 0/0), and finite sums of infinitely many positive terms. Taylor series represen-tations, in particular, provoked a variety of questions.
A function may be written as a series in such a waythat the series, when viewed as a function, will have, at a given pointx = a, the same value as the function, the same rate of change (or first derivative), and the same higher-order derivatives to arbitrary order: f (x) = f (a) + f (a)(x - a) + {}12 f (a)(x - a)2 + · · ·. For example, sin$x = x - x^{3}/$3!$+ x^{5}/$5!$+ · · ·$, a fact already known to Newton though such series are nownamed after Newton’s disciple brook taylor [VI.16](/part-06/brook-taylor-16851731).
One problem with early arguments was that the terms being discussed were used in different ways bydifferent writers. Other problems arose from this lack of clarity, since it concealed a variety of issues. Per-haps the most important of these was that an argument could fail to work in one context, even though a very similar argument worked perfectly well in another.
In time, this led to serious problems in extending analysis. Eventually, analysis became fully rigorous and these difficulties were solved, but the process was a longone and it was complete only by the beginning of the twentieth century. ficulties that arose from the very beginning, using aresult of Leibniz. Suppose we have two variables, Let us consider some examples of the kinds of dif-$u$ and$x$, changes. An infinitesimal change inv, each of which changes when another variable, x is denoted dx, the differential ofquantity, thought of as a geometrical magnitude, such$x$.
The differential is an infinitesimal as a length, for example. This was imagined to be com-bined or compared with other magnitudes in the usual

119

ways (two lengths can be added, have a ratio, and so on).Whenx changes to x + dx, u and v change to u + du$and$ v + dv , respectively. Leibniz concluded that the productso that duv(uv)would then change to = u dv + v du. His argument is, roughly, uv + u dv + v du, that d(uv) = (u + du)(v + dv) - uv. Expanding the right-hand side using regular algebra and then simpli-fying givesu dv + v du + du dv. But the term dudv is a second-order infinitesimal, vanishingly small compared with the first-order differentials, and is thus treated as equal to 0.
Indeed, one aspect of the problems is that there appears to be anway that infinitesimals are treated. For instance, if you in consistency in the want to work out the derivative of y = x2, the calcu- lation corresponding to the one just given (expanding$(x + dx)2$, and so on) shows that dy/dx = 2 x+dx. We then treat the dthe one on the left-hand side seems as though it oughtx on the right-hand side as zero, but to be an infinitesimal we could not divide by it. So is it zero or not?
And if not, nonzero quantity, since otherwise how do we get around the apparent in consistency?At a slightly more technical level, the calculus required mathematicians to deal repeatedly with the“ultimate” values of ratios of the form dy/dx when the quantities in both numerator and denominator approach or actually reach 0. This phrasing uses, onceagain, the differential notation of Leibniz, though the same issues arose for Newton with a slightly different notational and conceptual approach.
Newton generally spoke of variables as depending on time, and he sought(for example) the values approached when “evanescent increments”—vanishingly small time intervals— are considered. One long-standing set of confusions arose precisely from this idea that variable quantities were in the process of changing, whether with timeor with changes in the value of another variable. This means that we talk about values of a variable approach-ing a given value, but without a clear idea of what this “approach” actually is.
2 Eighteenth-Century approaches and Critiques Of course, had the calculus not turned out to be an enormously fruitful field of endeavor, no one would have bothered to criticize it. But the methods of New-ton and Leibniz were widely adopted for the solution of problems that had interested earlier generations (notably tangent and area problems) and for the posing and solution of problems that these techniques suddenly

120

made far more accessible. Problems of areas, maximaand minima, the formulation and solution of differential equations to describe the shape of hanging chainsor the positions of points on vibrating strings, applications to celestial mechanics, the investigation of prob-lems having to do with the properties of functions (thought of for the most part as analytic expressions involving variable quantities)—all these fields and more were developed over the course of the eighteenth cen-tury by mathematicians such as Taylor, Johann and Daniel Bernoulli, Euler, and many others.
These people employed many vir-d’alembert [VI.20](/part-06/jean-le-rond-dalembert-17171783), Lagrange, tuoso arguments of suspect validity. Operations with divergent series, the use of imaginary numbers, and manipulations involving actual infinities were used effectively in the hands of the most capable of these writers. However, the methods could not always be explained to the less capable, and thus certain results were not reliably reproducible—a very odd state for mathematics from today’s standpoint. To do Euler’sc al cu la tions, one needed to be Euler.
This was a situation that persisted well into the following century. Specific controversies often highlighted issues that we now see as a result of foundational confusion. In thecase of infinite series, for example, there was confusion about the domain of validity of formal expressions. Consider the series 1- 1 + 1 - 1 + 1 - 1 + 1 − · · ·. In today’s usual elementary definition (due to[VI.29](/part - 06/augustin - louis - cauchy - 17891857) around 1820) we would now consider this series cauchy to be divergent because the sequence of partial sums1, 0, 1, 0, . . . does not tend to a limit.
But in fact there was some controversy about the actual meaning of such expressions. Euler and Nicolaus Bernoulli, for example, discussed the potential distinction between theand the value of an infinite sum, Bernoulli arguing thatsum something like 1 - 2 + 6 - 24 + 120+· · · has no sum but that this algebraic expression does constitute a value. Whatever may have been meant by this, Euler defended the notion that the sum of the series is the value of the finite expression that gives rise to the series.
Inhis 1755 Institutiones Calculi differential is, he gives the example of 1$- x + x2 - x3 + · · ·$, which comes from$1 that 1/(1 +-x)1$, and later defended the view that this meant + 1 - 1 + · · · =1. His view was not uni- versally accepted. Similar controversies arose in con-sidering how to extend the values of functions outside2 their usual domain, for example with the logarithms ofnegative numbers. II.
The Origins of Modern Mathematics tique of the language and methods of eighteenth - cen-tury analysis is due to the philosopher George Berke-Probably the most famous eighteenth-century criley (1685–1753). Berkeley’s motto, “To be is to beperceived,” expresses his idealist stance, which was coupled with a strong view that the abstraction of individual qualities, for the purposes of philosophical discussion, is impossible. The objects of philos-ophy should thus be things that are perceived, and perceived in their entirety.
The impossibility of per-ceiving infinitesimally small objects, combined with their manifestly abstracted nature, led him to attack their use in his 1734 treatise course Addressed to an Infidel Mathematician The Analyst: Or, a Dis-. Referring sarcastically in 1734 to infinitesimals as the “ghostsof departed quantities,” Berkeley argued that neglecting some quantity, no matter how small, was inap-propriate in mathematical argument.
He quoted Newton in this regard, to the effect that “in mathematical matters, errors are to be condemned, no matter how small.” Berkeley continued, saying that “[n]othing butthe obscurity of the subject” could have induced Newton to impose this kind of reasoning on his follow-ers. Such remarks, while they apparently did not dissuade those enamored of the methods, contributed to asentiment that aspects of the calculus required deeper explanation.
Writers such as Euler, d’Alembert, Lazare Carnot, and others attempted to address foundational criticisms by clarifying what differentials were, andgave a variety of arguments to justify the operations of the calculus.

2.1 Euler

Euler contributed to the general development of analy-sis more than any other individual in the eighteenth century, and his approaches to justifying his arguments were enormously influential even after his death, owingto the success and wide use of his important textbooks. Euler’s reasoning is sometimes regarded as rather care-less since he operated rather freely with the notation of the calculus, and many of his arguments are certainly deficient by later standards. This is particularly true of arguments involving infinite series and products.
Atypical example is provided by an early version of his proof that

$\infty 1 = π^{2}$.n2 6

His method is as follows. Using the known series ex-pansion for sinx he considered the zeros ofn=1. in . qrt. qrt{xx} = 1 -3!$x + x$5!2- x7!3$+ · · ·$.

II.5. The Development of Rigor in Mathematical Analysis These lie atπ2, (2π)2, (3π)2, . . .. Applying (with- out argument) the factor theorem for finite algebraic equations he expressed this equation as$\sqrt{} \sin \sqrt{xx} = 1 - πx^{2} 1 - 4xπ^{2} 1 - 9xπ^{2} · · ·$.$Now$, it can be seen that the coefficient ofnite sum,$- {}^{1}$, should equal the negative of the sumxin the infiof the coefficients ofently concluded this by imagining multiplying out the6 x in the product. Euler appar- infinitely many terms and selecting the 1 from all but one of them. This gives

$π12 + 4π12 + 9π12 + · · · = 16$,

and multiplying both sides byπ2 gives the required sum. problems. The product of the infinitely many terms We now think of this approach as having several may or may not represent a finite value, and todaywe would specify conditions for when it does. Also, applying a result about (finite) polynomials to (infi-nite) power series is a step that requires justification. Euler himself was to provide alternative arguments for this result later in his life. But the fact that hemay have known counterexamples—situations in which such usages would not work—was not, for him, a decisive obstacle.
This view, in which one reasoned in ageneric situation that might admit a few exceptions, was common at his time, and it was only in the late nineteenth century that a concerted effort was made tostate the results of analysis in ways that set out precisely the conditions under which the theorems would hold. sums or infinitesimals. Sometimes he was happy to Euler did not dwell on the interpretation of infinite regard differentials as actually equal to zero, and toderive the meaning of a ratio of differentials from the context of the problem:
An infinitely small quantity is nothing but a vanish-ing quantity and therefore will be actually equal to

0. . . . Hence there are not so many mysteries hidden inthis concept as there are usually believed to be. These supposed mysteries have rendered the calculus of the infinitely small quite suspect to many people. This statement, from the Institutiones Calculi differential is tions in which one of the ratios is 0 of 1755, was followed by a discussion of propor-$/$0, and a justification of the fact that differentials may be neglectedin calculations with ordinary numbers. This accurately

121

describes a good deal of his practice—when he worked with differential equations, for example. Controversial matters did arise, however, and debates about definitions were not unusual. The best-known example involves discussions connected with the so-called vibrating string problem, which involved Euler, d’Alembert, and Daniel Bernoulli. These were closely connected with the definition of functions [I.2 §2.2](/part-01/language-and-grammar), and the question of which functions studied by analysis actually could be represented by series (in particular trigonometric series).
The idea that a curve of arbitrary shape could serve as an initial position for a vibrating string extended the idea of function, andthe work of fourier [VI.25](/part-06/jean-baptiste-joseph-fourier-17681830) in the early nineteenth century made such functions analytically accessible. In this context, functions with broken graphs (a kind of discontinuous function) came under inspection.
Later, how to deal with such functions would be a decisive issue for the foundations of analysis, as the more “nat-ural” objects associated with algebraic operations and trigonometry gave way to the more general modern concept of function.

2.2 Responses from the Late Eighteenth Century One significant response to Berkeley in Britain was thatof Colin Maclaurin (1698–1746), whose 1742 textbook A Treatise of Fluxions attempted to clarify the foundations of the calculus and do away with the ideaof infinitely small quantities. Maclaurin, a leading figure of the Scottish Enlightenment of the mid eighteenth century, was the most distinguished british mathematician of his time and an ardent proponent of Newton’s methods.
His work, unlike that of many of his British contemporaries, was read with intereston the Continent, especially his elaborations of Newtonian celestial mechanics. Maclaurin attempted to basehis reasoning on the notion of the limits of what he termed “assignable” finite quantities. Maclaurin’s workis famously obscure, though it did provide examples of calculating the limits of ratios. Perhaps his most important contribution to the clarification of the foundations of analysis was his influence on d’Alembert.
and followed them in rejecting infinitesimals as real D’Alembert had read both Berkeley and Maclaurin quantities. While exploring the idea of a differential asa limit, he also attempted to reconcile his idea with the idea that infinitesimals may be consistently regarded as being actually zero, perhaps in a nod to Euler’sview. The main exposition of d’Alembert’s views may

122

be found in the fer en ti a ls (published in 1754) and on limits (1765).Encyclopédie, in the articles on dif D’Alembert argued for the importance of geometric rather than algebraic limits. His meaning seems to have been that the quantities being investigated should notbe treated merely formally, by substitution and simplification. Rather, a limit should be understood as thelimit of a length (or collection of lengths), area, or other dimensioned quantity, in much the way that a circlemay be seen as a limit of inscribed polygons.
His aim seems primarily to have been to establish the reality of the objects described by existing algorithms, sincethe actual calculations he employs are carried out with differentials.

2.2.1 Lagrange

In the course of the eighteenth century, the differential and the integral calculus gradually distinguished themselves as a set of methods distinct from their applica-tions in mechanics and physics. At the same time, the primary focus of the methods moved away from geom-etry, so that in work of the second half of the eighteenth century we increasingly see calculus treated as “alge-braic analysis” of “analytic functions.” The term “analytic” was used in a variety of senses.
For many writers, such as Euler, it merely referred to a function (that is, a relationship between variable quantities) that is givenby a single expression of the type used in analysis. was indebted to this algebraic viewpoint. lagrange concentrated on power-series expansions as the basic Lagrange provided a foundation for the calculus that entity of analysis, and through his work the term ana-lytic function evolved toward its more recent meaning connected with the existence of a convergent Tay-lor series representation. His approach reached a full expression in his1797.
This was a version of his lectures at the École Théorie des Fonctions Analytiques of Polytechnique, a new institution for the elite trainingof military engineers in revolutionary France. Lagrange assumed that a function must necessarily be express-ible as an infinite series of algebraic functions, basing this argument on the existence of expansions for known functions. He first sought to show that “in gen-eral” no negative or fractional powers would appear in the expansion, and from this he obtained a power-series representation.
His arguments here are surprising, and somewhat ad hoc, and I use an example givenby Fraser (1987). The slightly strange notation is based on that of Lagrange. Suppose that one seeks an expan-sion off (x) = . qrt{x} + i in powers of i. In general, only

II. The Origins of Modern Mathematics

integer powers will be involved. Terms of the form im/ndo not make sense, says Lagrange, since the expression of the function. qrt{x} + i is only two - valued, while im/n hasn values. Hence the series. qrtx + i = x + pi + qi2 + · · · +. qrt{ti}k + · · · obtains its two values from the term powers must be integral. With fractional exponents setx, and all other aside, Lagrange argued that f (x + i) = f (x) +ia P (x, i)$, \text{with Pfinite fori} = 0$.
Successive application of this result gave him the expansion $f (x + i) = f (x) + pi + qi^{2} + r i^{3} + · · ·$, whereon$x$, so Lagrange defined ai was a small increment. The number derived functionp dependsf^ (x) =p(x)derivative, and in Lagrange’s language. The French term dérivée is the origin of the term$f$is the “primitive” of this derived function. Similar arguments can be made to relate the higher coefficients to the higher derivatives in the usual Taylor formula.
This approach, which seems oddly circular to modern eyes, relied on the eighteenth-century distinction between the “algebraic” infinite process of the series expansion on the one hand, and the use of differentials on the other. Lagrange did not see the original series expansion as based on the limit process. With the renewed emphasis on limits and modern defini-tions developed by Cauchy, this approach was soon to be regarded as untenable. 3 The First Half of the Nineteenth Century

3.1 Cauchy

Many writers contributed to discussions on rigor inanalysis in the first decades of the nineteenth century. It was Cauchy who was to revive the limit approach to greatest effect. His aim was pedagogical, and his ideaswere probably worked out in the context of preparing his introductory lectures for the École Polytechnique atthe beginning of the 1820 s. Although the students were the best in France in scholarly ability, many found the approach too difficult.
As a result, while Cauchy himself continued to use his methods, other instructors held on to older approaches using infinitesimals, which they found more intuitively accessible for the studentsas well as better adapted to the solution of problems in elementary mechanics. Cauchy’s self-imposed exilefrom Paris in the 1830 s further limited the impact of his approach, which was initially taken up only by afew of his students.

II.5. The Development of Rigor in Mathematical Analysis nuity, and of the derivative gradually came into gen-Nonetheless, Cauchy’s definitions of limit, of contieral use in France, and were influential elsewhere aswell, especially in Italy. Moreover, his methods of using these definitions in proofs, and particularly his use ofmean value theorems in various forms, moved analysis from a collection of symbolic manipulations of quanti-ties with special properties toward the science of argument about infinite processes using close estimation via the manipulation of inequalities. In some respects,
Cauchy’s greatest contribution lay in his clear definitions. For earlier writers, the sumof an infinite series was a somewhat vague notion, sometimes interpreted by a kind of convergence argu-ment (as with the sum of a geometric series such as . nftyn=0 2-n) and sometimes as the value of the function from which the series was derived (as Euler, for exam-ple, often regarded it). Cauchy revised the definition to state that the sum of an infinite series was the limitof the sequence of partial sums.
This provided a unified approach for series of numbers and series of func-tions, an important step in the move to base calculus and analysis on ideas about real numbers. This trend, eventually dominant, is often referred to as the “arithmetization of analysis.” Similarly, a continuous function is one for which “an infinitely small increase ofthe variable produces an infinitely small increase of the function itself” (Cauchy 1821, pp. 34–35). not shy away from infinitely small quantities, nor didhe analyze this notion further.
The limit of a variable As we see from the example just given, Cauchy did quantity is defined in a way that we would now regardas conversational, or heuristic: When the values that are successively assigned to agiven variable approach a fixed value indefinitely, in such a way that it ends up differing from it as little asone wishes, this latter value is called the limit of all the others. Thus, for example, an irrational number is thelimit of the various fractions that provide values that are closer and closer to it. Cauchy (1821, p.
4) These ideas were not completely rigorous by modern standards, but he was able to use them to provide aunified foundation for the basic processes of analysis. example, in his definition of a continuous function. to paraphrase his definition, suppose that a function This use of infinitely small quantities appears, forf (x) is single-valued on some finite interval of the real line, and choose any valuex0 inside the interval. If the value123 ofby the amount x0 is increased tof (x x + 0 + a)a-, the function also changesf (x ).
Cauchy says that the function each value ofxf is continuous for this interval if, forin that interval, the numerical value o(f0)0 the difference to 0 witha. In other words, Cauchy defines continu-f ((x0)0 + a) - f (x0) decreases indefinitely ity as a propertyin essence by saying that on that interval infinitely on an interval rather than at a point, small changes in the argument produce infinitely small changes in the function value.
Cauchy appears to have considered continuity to be a property of a function on an interval. This definition emphasizes the importance of jumps in the value of the function for the understanding ofits properties, something that Cauchy had encountered early in his career when discussing theorem of calculus [I.3 §5.5](/part-01/fundamental-definitions). In his 1814 memoirthe fundamental on definite integrals, Cauchy stated: If the function tinuous manner betweenφ(z) increases or decreases in a con - z = b^ and z = b^ , the value of the integral [represented by$φ(b)b - b φ(bφ (z))$. But if ...
the functiondz] will ordinarily be passes suddenly from one value to another sensibly different ... the ordinary value of the integral must be diminished. Oeuvres (volume 1, pp. 402–3) defining the definite integral. He considered first of alla division of the interval of integration into a finite In his lectures, Cauchy assumed continuity when number of subintervals on which the function is either increasing or decreasing.
(This is not possible for all functions, but this appeared not to concern Cauchy.)He then defined the definite integral as the limit of the sum(X - Sx = )f (x(x1 - x)0)f (xas the number0) + (x2 - xn1)f (xbecomes very1) + · · · + large. Cauchy gives a detailed argument for the exis-tence of this limit, using his theorem of the mean and$(n - 1()n)-1$ the fact of continuity. Versions of the main subjects of Cauchy’s lectures were published in 1821 and 1823. Every student at theÉcole Polytechnique would have been aware of them subsequently, and many would have used them explic - itly.
They were joined in 1841 by a version of the course elaborated by Cauchy’s associate, the Abbé Moigno. They were referred to frequently in France and the definitions employed by Cauchy became standard there. We also know that the lectures were studied by others, notably byspent time in Paris in the 1820 s, and byabel [VI.33](/part - 06/niels - henrik - abel - 18021829) and dirichlet [VI.36], who riemann [VI.49].
124 of Lagrange rejected the “vagueness of algebra.” Al - Cauchy’s movement away from the formal approach though he was clearly guided by intuition (both geo-metric and otherwise), he was well aware that intuition could be misleading, and produced examples toshow the value of adhering to precise definitions. One famous example, the function that takes the valuee-1 /x2 when x . neq 0 and zero when x =0, is differentiable infinitely many times, yet it does not yielda Taylor series that converges to the function at the origin.
Despite this example, which he mentioned inhis lectures, Cauchy was not a specialist in counterexamples, and in fact the trend toward producing counterexamples for the purpose of clarifying definitions was a later development. work: his statement that a convergent series of contin-Abel famously drew attention to an error in Cauchy’s uous functions has a continuous sum. For this to betrue, the series must be uniformly convergent, and in 1826 Abel gave as a counterexample the series

. nf ty(-1()k)+1 . in kkx, k=1

which is discontinuous at odd multiples ofπ. Cauchy was led to make this distinction only much later, afterthe phenomenon had been identified by several writers. Historians have written extensively about this apparent error; one influential account, due to Bottazzini, proposes that for various reasons Cauchy would not havefound Abel’s example telling, even if he had known of it at the time (this account appears in Bottazzini (1990, p. LXXXV)).
Before leaving the time of Cauchy, we should note the related independent activity of Bolzano, a Bohemian priest and professor whose ideas bolzano [VI.28](/part-06/bernard-bolzano-17811848). were not widely disseminated at the time, investigated the foundations of the calculus extensively. In 1817, for example, he gave what he termed a “purely ana-lytic proof of the theorem that between any two values that possess opposite signs, at least one real root ofthe equation exists”: the intermediate value theorem. Bolzano also studied infinite sets:
what is now calledthe Bolzano–Weierstrass theorem states that for every bounded infinite set there is at least one point having the property that any disk about that point contains infinitely many points of the set. Such “limit points” were studied independently by By the 1870 s, Bolzano’s work became more broadly weierstrass [VI.44](/part-06/karl-weierstrass-18151897). known.

II. The Origins of Modern Mathematics

3.2 Riemann, the Integral, and Counterexamples Riemann is indelibly associated with the foundations of analysis because of the Riemann integral, which is partof every calculus course. Despite this, he was not always driven by issues involving rigor. Indeed he remains a standard example of the fruitfulness of nonrigorous intuitive invention. There are many points in Riemann’s work at which issues about rigor arise naturally, and the wide interest in his innovations did much to directthe attention of researchers to making these insights precise.
Riemann’s definition of the definite integral was presented in his 1854 sis,” which qualified him to lecture at a university for habilitationsch rift—the “second thefees. He generalized Cauchy’s notion to functions that are not necessarily continuous. He did this as part of an investigation of fourier series [III.27](/part-03/the-fourier-transform) expansions. The extensive theory of such series was devised by Fourier in 1807 but not published until the 1820 s. A fourier series represents a function in the form f (x) = a0 +n. nfty=1(an . os (nx) + bn . in (nx)) on a finite interval.
dirichlet earlier faulty work by Cauchy on the question of when The immediate inspiration for Riemann’s work was[VI.36], who had corrected and developed and whether the Fourier series expansion of a function converges to the function from which it is derived. In 1829 Dirichlet had succeeded in proving such convergence for a function with period 2 on an interval of that length, does not possess infinitelyπ that is integrable many maxima and minima there, and at jump discontinuities takes on the average value between the two limiting values on each side.
As Riemann noted, following his professor Dirichlet, “this subject stands in the closest connection to the principles of infinitesimal cal-culus, and can therefore serve to bring these to greater clarity and definiteness” (Riemann 1854, p. 238). Riemann sought to extend Dirichlet’s investigations to fur-ther cases, and was thus led to investigate in detail each of the conditions given by Dirichlet. Accordingly, he generalized the definition of a definite integral asfollows: We take between valuesx , x , . . .
, xa and, and for brevity designateb an increasing sequence ofx -a$by$δ1$, (x1)2 - 2x1 by δn - 2$,1. . ., b - xn-1 by δn and by1 a

II.5. The Development of Rigor in Mathematical Analysis positive proper fraction. Then the value of the sum S = δ1 f (a +1δ1) + δ2 f (x1 +2δ2)+ δ3 f (x2 +3δ3) + · · · + δnf (xn-1 +nδn) depends on the choice of the intervals ties . If it has the property that it approaches infinitelyδ and the quanti- closely a fixed limit chosen, asδbecomes infinitely small, then we call this A no matter how the δ and are valueab f (x) dx.
In connection with this definition of the integral, andin part to show its power, Riemann provided an example of a function that is discontinuous in any interval, yet can be integrated. The integral thus has pointsof nondifferentiab ility on each interval. Riemann’s definition rendered problematic the inverse relationship between differentiation and integration, and his example brought this problem out clearly. The role of such “pathological” counterexamples in pushing the devel-opment of rigor, already apparent in Cauchy’s work, intensified greatly around this time. lowing his death;
an expository version due to Gaston Riemann’s definition was published only in 1867, fol Darboux appeared in French in 1873. The populariza-tion and extension of Riemann’s approach went hand in hand with the increasing appreciation of the impor-tance of rigor associated with the Weierstrass school, discussed below. Riemann’s approach focused attention on sets of points of discontinuities, and thus were seminal for cantor’s [VI.54](/part-06/georg-cantor-18451918) investigations into point sets in the 1870 s and afterwards.
ther example of the way in which Riemann’s work drew The use of the Dirichlet principle serves as a fur attention to problems in the foundations of analysis. In connection with his research into complex analysis, Riemann was led to investigate solutions to the so-calledon the boundary of a closed region in the plane, does Dirichlet problem: given a function$g$, defined there exist a function partial differential equation$f$that satisfies the[I.3 §5.4](/part-01/fundamental-definitions) in the inte-laplace rior and takes the same values asg on the bound- ary?
Riemann asserted that the answer was yes. to demonstrate this, he reduced the question to proving the existence of a function that minimizes a cer-tain integral over the region, and argued on physical grounds that such a minimizing function must always exist. Even before Riemann’s death his assertion was questioned by weierstrass [VI.44](/part-06/karl-weierstrass-18151897), who published a counterexample in 1870. This led to attempts to refor-mulate Riemann’s results and prove them by other

125

means, and ultimately to a rehabilitation of the Dirich-let principle through the provision of precise and broad hypotheses for its validity, which were expressed byhilbert [VI.63](/part-06/david-hilbert-18621943) in 1900. 4 Weierstrass and His School Weierstrass had a passion for mathematics as a student at Bonn and Münster, but his student career was very uneven. He spent the years from 1840 to 1856 as a high school teacher, under taking research independently but at first publishing obscurely.
Papers from 1854 onward in Journal für die reine und angewandte mathematik wide attention to his talent, and he obtained a profes-(otherwise known as Crelle’s Journal) attracted sorship in Berlin in 1856. Weierstrass began to lecture regularly on mathematical analysis, and his approach to the subject developed into a series of four courses of lectures given cyclically between the early 1860 sand 1890. The lectures evolved over time and were attended by a large number of important mathemati-cal researchers.
They also indirectly influenced many others through the circulation of unpublished notes. This circle included R. Lipschitz, P. du Bois-Reymond, H. A. Schwarz, O. Hölder, Cantor, L. Koenigsberger, G. Mittag-Leffler, name only some of the most important. Through their kovalevskaya [VI.59](/part-06/sofya-sonya-kovalevskaya-18501891), and L. Fuchs, to use of Weierstrass i an approaches in their own research, and their espousal of his ideas in their own lectures, these approaches became widely used well before the eventual publication of a version of his lectures late in his life.
The account that follows is based largely onthe 1878 version of the lectures. His approach was also influential outside Germany: parts of it were absorbedin France in the lectures of hermite [VI.47](/part-06/charles-hermite-18221901) and jordan [VI.52](/part-06/camille-jordan-18381922), for example. (though the detailed relationship between the two bod-Weierstrass’s approach builds on that of Cauchy ies of work has never been fully examined).
The two overarching themes of Weierstrass’s approach are, on the one hand, the banning of the idea of motion, orchanging values of a variable, from limit processes, and, on the other, the representation of functions, notablyof a complex variable. The two are intimately linked. Essential to the motion-free definition of a limit is Weierstrass’s nascent investigation of what we wouldnow call the topology of the real line or complex plane, with the idea of a limit point, and a clear distinc-tion between local and global behavior. The central objects of study for Weierstrass are functions (of one

126

or more real or complex variable quantities), but itshould be borne in mind that set theory is not involved, so that functions are ordered pairs. not to be thought of as sets of The lectures begin with a now-familiar subject: the development of rational, negative, and real numbers from the integers. For example, negative numbers are defined operationally by making the integers closed under the operation of subtraction. He attempted a unified approach to the definition of rational and irrational numbers which involved unit fractions and decimal expansions and now seems somewhat murky.
Weier-strass’s definition of the real numbers appears unsatisfactory to modern eyes, but the general path oft ization of analysis was established by this approach. In a ri th me parallel to the development of number systems, he also developed different classes of functions, building them up from rational functions by using power-series rep-re sent at i ons. Thus, in Weierstrass’s approach, a polynomial (called an integer rational function) is general-ized to a “function of integer character,” which means a function with a convergent power-series expansion every where.
The Weierstrass factorization theorem asserts that any such function may be written as a (pos-sibly infinite) product of certain “prime” functions and exponential functions with polynomial exponents of acertain type. oughly modern features: The limit definition given by Weierstrass has thor That a variable quantity simultaneously with another quantity xbe comes infinitely smallymeans: “After the assumption of an arbitrarily small quantity boundδ for x may be found, such that for every valuea ofwill be less thanx for which |x|.”< δ, the corresponding value of |y| Weierstrass (1988, p.
57) Weierstrass immediately used this definition to givea proof of continuity for rational functions of several variables, using an argument that could appear in a textbook today. The former notions of variables tending to given values were replaced by quantified statements about linked inequalities. The framing of hypotheses in terms of inequalities became a guiding motif in the work of Weierstrass’s school: here we men-tion in passing the Lipschitz and Hölder conditions in the existence theory for differential equations.
The clar-ity that this language gave to problems involving the interchange of limits, for example, meant that previ-ously intractable problems could now be handled in

II. The Origins of Modern Mathematics

a routine way by those inculcated in the weierstrass approach. The fact that general functions were built from rational functions using series expansions gave the lat-ter a key role in Weierstrass’s work, and as early as 1841 he had identified the importance of uniform con-vergence. The distinction between uniform and pointwise convergence was made very clearly in his lectures. A series converges, as it does for Cauchy, ifits sequence of partial sums converges, though now the convergence is phrased in the following terms:
theseriesf (x) converges to s at x = x if, given an arbitrary positive|s - (f (xn ) + f (x, there is an integer) + · · · +0 f (x ))| <0 N such thatfor everyn > Nvariable if the same0. The convergence is uniform on a domain of th(e1)0 2 N0 will work for tha(tn)0 value for allx in the domain. Uniform convergence guarantees con- tinuity of the sum, since these are series of rational, hence continuous, functions. From this point of view, then, uniform convergence is important well beyondthe context of trigonometric series (important though those may be).
Indeed, it is a central tool of the entire theory of functions. others, notably Riemann, has already been noted. Morethan any other leading figure, he generated counter-Weierstrass’s role as a critic of rigor in the work of examples to illustrate difficulties with received notions and to distinguish between different kinds of analyti-cal behavior. One of his best-known examples was of an every where-continuous but nowhere-differentiable function, namely$f (x) = b^{n} \cos (a^{n}x)$, which is uni- formly convergent forentiable at anyx if ab >b <11 but fails to be differ-$+ {}^{3}π$.
Similarly he con- structed functions for which the Dirichlet principle fails, examples of sets constituting “natural bound-2 aries,” that is, obstacles to continuing series expan-sions into larger domains, and so forth. The careful distinctions he encouraged, and the very procedure of seeking pathological rather than typical examples, threw the spotlight on the precision of hypotheses in analysis to an unprecedented degree.
From the 1880 s, with the maturity of this program, analysis no longer dealt with generic cases and looked instead for absolutely precise statements in a way that has for the mostpart endured to the present. This was also to become a pattern and an imperative in other areas of mathe-matics, though sometimes the passage from reasoning from generic examples to fully expressed hypotheses and definitions took decades. (Algebraic geometry pro-vides a famous example, one in which reasoning with

II.5. The Development of Rigor in Mathematical Analysis generic cases lasted until the 1920 s.) In this sense theform of rigorous argument and exposition espoused by Weierstrass and his school was to become a pattern for mathematics generally.

4.1 The Aftermath of Weierstrass and Riemann

Analysis became the model subdiscipline for rigor fora variety of reasons. Of course, analysis was important for the sheer volume and range of application of its results. Not everyone agreed with the precise way in which Weierstrass approached foundational questions(through series, rational functions, and so on). Indeed, Riemann’s more geometric approach had also attracted followers, if not exactly a school, and the insights his approach afforded were enthusiastic ally embraced.
However, any subsequent discussion had to take placeat a level of rigor comparable to that which Weierstrass had attained. While approaches to the foundations ofanalysis were to vary, the idea that limits should be rigorously handled in much the way that Weierstrass didwas not to alter.
Among the remaining central issues for rigor was the definition of the number systems. For the real numbers, probably the most successful definition (in terms of its later use) was provided bythe integers as fundamental, and extended them to the dedekind [VI.50](/part-06/julius-wilhelm-richard-dedekind-18311916). Dedekind, like Weierstrass, took rationals, noting that the algebraic properties satisfiedby the latter are those satisfied by what we now call a field showed that the rational numbers satisfy a[I.3 §2.2](/part-01/fundamental-definitions).
(This idea is also Dedekind’s.) He then trichotomy law collection into three parts:. That is, each rational numberx itself, rational numbersx divides the entire greater thanalso showed that the rationals greater and less than ax, and rational numbers less than x. He given number extend to infinity, and that any rational corresponds to a distinct point on the number line. However, he also observed that along that line thereare infinitely many points that do not correspond to any rational.
Using the idea that to every point on theline there should correspond a number, he constructed the remainder of the continuum (that is, the real line)by the use of cuts. These are ordered pairs(A , A ) of nonempty sets of rational numbers such that every ele-ment of the first set is less than every element of the1 2 second, and such that taken together they contain allthe rationals. Such cuts may obviously be produced by an element ment of A1 xor the least element of, in which case x is either the greatest ele-A2.
But sometimes Ament, and in that case we can use the cut to define a1 does not have a greatest element, or A2 a least ele-127 new number, which is necessarily irrational. The set ofall such cuts may be shown to correspond to the points of the number line, so that nothing is left out. A critical reader might feel that this is begging the question, sincethe idea of the number line constituting a continuum in some way might seem to be a hidden premise. Dedekind’s construction stimulated a good deal of discussion, especially in Germany, about the best way to found the real numbers.
Participants included Can - tor, E. Heine, and the logician frege [VI.56](/part - 06/gottlob - frege - 18481925). Heine and Cantor, for example, considered real numbers as equivalence classes of Cauchy sequences of rationals, together with a machinery that permitted them to define the basic arithmetical operations. A very simi-lar approach was proposed by the French mathematician Charles Méray. Frege, by contrast, in his 1884 Grundlagen der Arithmetik, sought to found the inte-Die gerson logic.
While his attempts to construct the reals along these lines did not bear fruit, he had an important role in his insistence that the various construc-tions should not merely be mathematically functional but should also be demonstrably free from internal contradiction. real numbers, infinite sets, and other basic notions for analysis, consensus remained elusive.
For example, the Despite much activity on the foundations of the influential Berlin mathematician[VI.48](/part - 06/leopold - kronecker - 18231891) denied the existence of the reals, and held that leopold kronecker all true mathematics was to be based on finite sets. Like Weierstrass, with whom he worked and whom he influenced, he emphasized the strong analogies between the integers and the polynomials, and sought to use this algebraic foundation to build all of mathematics. Hencefor Kronecker the entire main path of research in analysis was anathema, and he opposed it ardently.
These views were influential, both directly and indirectly, on a number of later writers, including the intuitionist school around him, and the algebraist brouwer [VI.75](/part - 06/luitzen - egbertus - jan - brouwer - 18811966), and number theorist Kurt Hensel. or another on an underlying notion (not always made explicit) of quantity. The foundational framework of All efforts to found analysis were based in one way analysis, however, was to shift over the period from1880 to 1910 toward the theory of sets.
This had its origin in the work of Cantor, a student of weierstrass who began studying discontinuities of Fourier series in the early 1870 s. Cantor became concerned about howto distinguish between different types of infinite sets. His proofs that the rational numbers and the algebraic numbers are countable [III.11](/part - 03/countable - and - uncountable - sets) while the reals are not 128 led him to a hierarchy of infinite sets of different car - dinality.
The importance of this discovery for analysis was at first not widely recognized, though in the 1880 s Mittag-Leffler and Hurwitz both made significant appli-cations of notions about derived sets (the set of limit points of a given set) and dense or nowhere-dense sets. Cantor gradually came to the view that set theory could function as a foundational tool for all of mathematics. As early as 1882 he wrote that the scienceof sets encompassed arithmetic, function theory, and geometry, combining them into a “higher unity” basedon the idea of cardinality.
However, this proposal was vaguely articulated and at first attracted no adherents. Nonetheless, sets began to find their way intothe language of analysis, most notably through ideas ofone important route to the absorption of analysis bymeasure [III.55](/part - 03/measures) and measurability of a set. Indeed, set theory was the path that sought to determine what kind of function could “measure” a set in anabstract sense.
The work of lebesgue [VI.72](/part - 06/henri - lebesgue - 18751941) and borel [VI.70](/part - 06/emile - borel - 18711956) around 1900 on integration and measurability tied set theory to the calculus in a very concrete and intimate way. dations of analysis in the early twentieth century wasa new emphasis on mathematical theories as axiomatic A further key step in the establishment of the foun structures. This received enormous impetus from thework of Hilbert, who, beginning in the 1890 s, had sought to provide a renewed axiomatization of geom - etry.
peano [VI.62](/part - 06/giuseppe - peano - 18581932) in Italy headed a school with similar aims. Hilbert redefined the reals on these axiomatic grounds, and his many students and associates turned to axiomatics with enthusiasm for the clarity the approach could provide. Rather than proving the exis-tence of specific entities such as the reals, the mathematician posits a system satisfying the fundamental properties they possess. A real number (or whatever object) is then defined by the set of axioms provided.
As Epple has pointed out, such definitions were con-sidered to be on to logically neutral in that they did not provide methods for telling real numbers from other objects, or even state whether they existed at all (Epple 2003, p. 316). Hilbert’s student Ernst Zermelo began work on axiomatizing set theory along these lines, pub-lishing his axioms in 1908 (see [IV.22 §3](/part - 04/set - theory)). Problems with set theory had emerged in the form of paradoxes, the most famous due to russell [VI.71](/part-06/bertrand-arthur-william-russell-18721970):
if S is the set of all sets that do not contain themselves, then it isnot possible for S to be in S, nor can it not be in S. Zermelo’s axiomatics sought to avoid this difficulty, in part

II. The Origins of Modern Mathematics

by avoiding the definition of set. By 1910, was to refer to mathematics as the science of “weyl [VI.80](/part-06/hermann-weyl-18851955)$\in$,” or set membership, rather than the science of quantity. Nonetheless, Zermelo’s axioms as a foundational strategy were contested. For one thing, a consistency prooffor the axioms was lacking. Such “meaning-free” axiomatization was also contested on the grounds that itremoved intuition from the picture.
Against the complex and rapidly developing background of mathematics in the early twentieth century, these debates took on many dimensions that have implications well beyond the question of what consti-tutes rigorous argument in analysis. For the practicing analyst, however, as well as for the teacher of basic infinitesimal calculus, these discussions are marginalto everyday mathematical life and education, and are treated as such. Set theory is pervasive in the language used to describe the basic objects.
Real-valued functions of one real variable are defined as sets of ordered pairs of real numbers, for example; a set-theoretic defi-nition of an ordered pair was given by wiener [VI.85](/part-06/norbert-wiener-18941964) in 1914, and the set-theoretic definition of functions maybe dated from that time. However, research in analysis has been largely distinct from, and generally avoids, the foundational issues that may remain in connection withthis vocabulary. This is not at all to say that contemporary mathematicians treat analysis in a purely formalway.
The intuitive content associated with numbers and functions is very much a part of the way of thinking ofmost mathematicians. The axioms for the reals and for set theory form a framework to be referred to when necessary. But the essential objects of basic analysis, namely derivatives, integrals, series, and their existenceor convergence behaviors, are dealt with along the lines of the early twentieth century, so that the ontological debates about the infinitesimal and infinite are nolonger very lively. robinsonsis, published in 1961.
Robinson was an expert in model A coda to this story is provided by the researches of[VI.95](/part-06/abraham-robinson-19181974) (1918–74) into “nonstandard” analytheory: the study of the relationship between systemsof logical axioms and the structures that may satisfy them.
His differentials were obtained by adjoining tothe regular real numbers a set of “differentials,” which satisfied the axioms of an ordered field (in which there is ordinary arithmetic like that of the real numbers)but in addition had elements that were smaller than 1 this creation eliminated many of the unpleasant fea-/n for every positive integer n. In the eyes of some, tures of the usual way of dealing with the reals, and

II.6. The Development of the Idea of Proof

realized the ultimate goal of Leibniz to have a theory of infinitesimals which was part of the same structure as that of the reals. Despite stimulating a flurry of activity, and considerable acclaim from some quarters, Robin-son’s approach has never been widely accepted as a working foundation for analysis.

Further Reading

Bottazzini, U. 1990. Geometrical rigour and “modern analy-sis”: an introduction to Cauchy’s Cours d’Analyse. In Cauchy, A.-L. 1821.Cauchy (1821). Bologna: Editrice CLUB.technique: Première Partie—Analyse Algébrique Cours d’Analyse de l’École Royale Poly-. Paris: L’Imprimerie Royale. (Reprinted, 1990, by Editrice CLUB, Bologna.) Epple, M. 2003. The end of the science of quantity: foun-dations of analysis, 1860–1910. In A History of Analysis American Mathematical Society., edited by H. N. Jahnke, pp. 291–323. Providence, RI: Fraser, C. 1987.
Joseph Louis Lagrange’s algebraic vision ofthe calculus. Historia Mathematica 14:38–53. Jahnke, H. N., ed. 2003.RI: American Mathematical Society/London Mathematical A History of Analysis. Providence, Riemann, G. F. B. 1854. Ueber die Darstellbarkeit einer Society. Function durch eine trigonomet ri sc he Reihe. Königlichen Gesellschaft der Wissenschaften zu Göttingen Republished in Riemann’s collected works (1990):13:87–131.Gesammelte Mathematische Werke und wissenschaftlic he Nach-lass und Nachträge, edited by R. Narasimhan, 3 rd edn., Weierstrass, K. 1988.pp. 259–97. Berlin:
Springer.lytischen Functionen: Vorlesung Berlin 1878 Einleitung in die Theorie der Ana-, edited by P. Ullrich. Braunschweig: Vieweg/DMV. II.6 The Development of the

Idea of Proof

Leo Corry

Preliminary Considerations1 Introduction and

In many respects the development of the idea of proofis coextensive with the development of mathematics as a whole. Looking back into the past, one mightat first consider mathematics to be a body of scientific knowledge that deals with the properties of num-bers, magnitudes, and figures, obtaining its justifications from proofs rather than, say, from experiments or inductive inferences. Such a character ization, however, is not without problems. For one thing, it imme-diately leaves out important chapters in the history

129

of civilization that are more naturally associated with mathematics than with any other intellectual activity. For example, the Mesopotamian and Egyptian cultures developed elaborate bodies of knowledge that would most naturally be described as belonging to arithmetic or geometry, even though nothing is found in them thatcomes close to the idea of proof as it was later practiced in mathematics at large. To the extent that any justification is given, say, in the thousands of mathematical procedures found on clay tablets written incuneiform script, it is inductive or based on experience.
The tablets repetitively show—without additional explanation or attempts at general justifications—a given procedure to be followed whenever one is pursu-ing a certain type of result. Later on, in the context of Chinese, Japanese, Mayan, or Hindu cultures, one again finds important developments in fields naturally associated with mathematics.
The extent to which these cul-tures pursued the idea of mathematical proof—a question that is debated among historians to this day—was undoubtedly not as great as it was in Greek tradition, and it certainly did not take the specific formswe typically associate with the latter. Should one nevertheless say that these are instances of mathematical knowledge, even though they are not justified on the basis of some kind of general, deductive proof? If so, then we cannot characterize mathematics as a body ofknowledge that is backed up by proofs, as suggested above.
However, this litmus test certainly provides auseful criterion—one that we do not want to give up too easily—for distinguishing mathematics from other intellectual endeavors. Without totally ignoring these important questions, the present account focuses on a story that started, at some point in the past, usually taken to be before or around the fifth century realization that there was a distinctive body of claims, b.c.e.
in Greece, with the mainly associated with numbers and with diagrams, whose truth could be and needed to be vindicated ina very special way—namely, by means of a general, deductive argument, or “proof.” Exactly when and howthis story began is unclear. Equally unclear are the direct historical sources of such a unique idea.
Since the emphasis on the use of logic and reason in constructing an argument was well-entrenched in other spheres ofpublic life in ancient Greece—such as politics, rhetoric, and law—much earlier than the fifth century possible that it is in those domains that the origins ofb.c.e., it is mathematical proof are to be found.

130

tions, both historical and methodological. For instance, Thales of Miletus, the first mathematician known by The early stages of this story raise additional quesname (though he was also a philosopher and scientist), is reported to have proved several geometric theorems, such as, for instance, that the opposite angles between two intersecting straight lines are equal, or that if two vertices of a triangle are the endpoints of the diameter of a circle and the third is any other point onthe circle then the triangle must be right angled.
Even if we were to accept such reports at face value, sev-eral questions would immediately arise: in what sense can it be asserted that Thales “proved” these results? More specifically, what were Thales’s initial assump-tions and what inference methods did he take to be valid? We know very little about this. However, we doknow that, as a result of a complex historical process, a certain corpus of knowledge eventually developed that comprised known results, techniques employed, and problems (both solved and yet requiring solution).
This corpus gradually also incorporated the regulatory idea of proof: that is, the idea that some kind of general argument, rather than an example (or even many examples), was the necessary justification to be sought in all cases. As part of this development, the idea ofproof came to be associated with strictly deductive arguments, as opposed to, say, dialogic (meaning “nego-tiated”) or “probabilistic ally inferred” truth. It is an interesting and difficult historical question to establish why this was the case, and one that we will not address here.
around the year 300 euclid’s [VI.2](/part-06/euclid-ca) Elementsb.c.e. It stands out as the most suc-was compiled some time cessful and comprehensive attempt of its kind to orga-nize the basic concepts, results, proofs, and techniques required by anyone wanting to master this increasingly complex body of knowledge. Still, it is important to stress that it was not the only such attempt within the Hellenic world. This endeavor was not just a matter of compilation, codification, and canonization, such asone can find in any other evolving field of learning at any point in time.
Instead, the assertions it contained were of two different kinds, and the distinction was vitally important. On the one hand there were basic assumptions, ortheorems, which were typically more elaborate state-axioms, and on the other there were ments, together with accounts of how they followed from the axioms—that is, proofs. The way that proof was conceived and realized in the Elements became the paradigm for centuries to come.

II. The Origins of Modern Mathematics

deductive proof as initially shaped in the frameworkof Euclidean-style mathematics and as subsequently This article outlines the evolution of the idea of practiced in the mainstream mathematical culture ofancient Greece, the Islamic world, Renaissance Europe, early modern European science, and then in the nine-teenth century and at the turn of the twentieth. The main focus will be on geometry: other fields like arith-metic and algebra will be treated mainly in relation to it. This choice is amply justified by the subject matter itself.
Indeed, much as mathematics stands outamong the sciences for the unique way in which it relies on proof, so Euclidean-style geometry stood out—atleast until well into the seventeenth century—among closely related disciplines such as arithmetic, algebra, and trigonometry. Results in these other disciplines, or indeed the disciplines as a whole, were often regarded as fully legitimate only when they had been provided with a geometric (or geometric-like) foundation.
However, important developments in nineteenth-century math-ematics, mainly in connection with the rise of noneuclidean geometries lems in the foundations of analysis [[II.2 §§6–10]](/part-02/geometry) and with prob-[II.5](/part-02/rigor-in-analysis), eventually led to a fundamental change of orientation, where arithmetic (and eventually bastion of certainty and clarity from which other math-set theory [IV.22](/part-04/set-theory)) became the ematical disciplines, geometry included, drew their legitimacy and their clarity.
(See the crisis in the foundations of mathematics [II.7](/part-02/foundations-crisis) for a detailed account of this development.) And yet, even before this fundamental change, Euclidean-style proof was not the only way in which mathematical proof was con-ceived, explored, and practiced. By focusing mainly on geometry, the present account will necessarily leave out important developments that eventually became the mainstream of legitimate mathematical knowledge.
To mention just one important example in this regard, a fundamental question that will not be pursued here is how the principle of mathematical induction originated and developed, became accepted as a legitimate infer-ence rule of universal validity, and was finally codified as one of the basic axioms of arithmetic in the late nine-teenth century.
Moreover, the evolution of the notion of proof involves many other dimensions that will not be treated here, such as the development of the inter-nal organization of mathematics into subdisciplines, as well as the changing interrelations between math-ematics and its neighboring disciplines. At a different level, it is related to how mathematics itself evolved as

II.6. The Development of the Idea of Proof

a socially institutionaliz ed enterprise: we shall not dis-cuss interesting questions about how proofs are produced, made public, disseminated, criticized, and often rewritten and improved. 2 Greek Mathematics Euclid’sma them at i cs, partly for what it has to say about the Elements is the paradigmatic work of Greek basic concepts, tools, results, and problems of syn-thetic geometry and arithmetic, but also for how it regards the role of a mathematical proof and the form that such a proof takes. All proofs appearing in thements have six parts and are accompanied by a dia-Elegram.
I illustrate this with the example of proposi-tion I.37. Euclid’s text is quoted here in the classical translation of Sir Thomas Heath, and the meaning of some terms differs from current usage. Thus, two tri-angles are said to be “in the same parallels” if they have the same height and both their bases are contained ina single line, and any two figures are said to be “equal” if their areas are equal. For the sake of explanation, names of the parts of the proof have been added: thesedo not appear in the original. The proof is illustrated in figure 1.
Protasis (enunciation).same base and in the same parallels are equal to one Triangles which are on the Ekthesis (setting out).another.the same base BC and in the same parallels AD, BC.Let ABC, DBC be triangles on Diorismos (definition of goal).ABC is equal to the triangle DBC.I say that the triangle Kataskeue (construction).directions to E, F; through B let BE be drawn parallel Let AD be produced in both Apodeixis (proof).to CA, and through C let CF be drawn parallel to BD.DBCF is a parallelogram;
and they are equal, for they Then each of the figures EBCA, are on the same base BC and in the same parallels BC, EF. Moreover the triangle ABC is half of the parallelogram EBCA, for the diameter AB bisects it; andthe triangle DBC is half of the parallelogram DBCF, for the diameter DC bisects it. Therefore the triangle Sumperasma (conclusion).ABC is equal to the triangle DBC.are on the same base and in the same parallels are Therefore triangles which equal to one another. This is an example of a proposition that states a property of geometric figures.
the propositions that express a task to be carried out. An Elements also includes 131 EADFBC Figure 1 Proposition I.37 of Euclid’s Elements. ABGCEDLKHF Figure 2 Proposition IX.35 of Euclid’s Elements. example is proposition I.1: “On a given finite straight line to construct an equilateral triangle.” The same sixparts of the proof and the diagram invariably appear in propositions of this kind as well. This formal struc-ture is also followed in all propositions appearing in the three importantly, all of them are always accompanied by aarithmetic books of the Elements and, most diagram.
Thus, for instance, consider proposition IX.35, which in its original version reads as follows: If as many numbers as we please be in continued pro - portion, and there be subtracted from the second and the last numbers equal to the first, then, as the excessof the second is to the first, so will the excess of the last be to all those before it. hensible on first reading.
In more modern terms, an equivalent to this theorem would state that, given a This cumbersome formulation may prove incompre geometric progression$a1$, a2,$. . . , (an)+1$, we have(an + 1 - a1):$(a1 + a2 + · · · + an) = (a2 - a1):$ a1. This translation, however, fails to convey the spirit of the original, in which no formal symbolic manipulation is, or can be, made. More importantly, a modern algebraic proof fails to convey the ubiquity of diagrams in Greek mathematical proofs, even where they are notneeded for a truly geometric construction.
Indeed, the accompanying diagram for proposition IX.35 is shown

132

as figure 2 and the first few lines of the proof are asfollows: Let there be as many numbers as we please in contin-ued proportion A, BC, D, EF, beginning from A as least and let there be subtracted from BC and EF the num-bers BG, FH, each equal to A; I say that, as GC is to A, so is EH to A, BC, D. For let FK be made equal to BC and FL equal to D.. . .
This proposition and its proof provide good examples of the capabilities, as well as the limitations, ofancient Greek practices of notation, and especially of how they managed without a truly symbolic language. In particular, they demonstrate that proofs were never conceived by the Greeks, even ideally, as purely logical constructs, but rather as specific kinds of arguments that one applied to a diagram. The diagram was not just a visual aid to the argument at i on.
Rather, through the ekthesis part of the proof, it embodied the idea referred to by the general character and formulation of the proposition. Together with the centrality of diagrams, the sixpart structure is also typical of most of Greek math-ematics. The constructions and diagrams that typically appeared in Greek mathematical proofs were notof an arbitrary kind, but what we identify today as straightedge-and-compass constructions.
The reason-ing in the apodeixis part could be either a direct deduction or an argument by contradiction, but the result was always known in advance and the proof was a meansto justify it. In addition, Greek geometric thinking, and in particular Euclid-style geometric proofs, strictly adhered to a principle of homogeneity. That is, magnitudes were only compared with, added to, or subtracted from magnitudes of like kind—numbers, lengths, areas, or volumes.
(See numbers [II.1 §2](/part-02/from-numbers-to-number-systems) for more about this.) cerned with lengths of curves, as well as with areas or Of particular interest are those Greek proofs con volumes enclosed by curvilinear shapes. Greek mathe-maticians lacked a flexible notation capable of expressing the gradual approximation of curves by polygons and an eventual passage to the infinite.
Instead, they devised a special kind of proof that involved what can retrospectively be seen as an implicit passage to thelimit, but which did so in the framework of a purely geometric proof and thus unmistakably followed the six-part proof-scheme described above. This implicit passage to the infinite was based on the application of a continuity principle, later associated with[VI.3](/part-06/archimedes-ca). In Euclid’s formulation, for instance, the princi-archimedes

II. The Origins of Modern Mathematics

A or ke bd fh sp qlg mc

Figure 3 Proposition XII.2 of Euclid’s Elements. ple states that, given two unequal magnitudes of thesame kind, A, B (be they two lengths, two areas, or two volumes), with A a magnitude which is greater than A greater than B, and if we subtract from A/2, and from the remainder we subtract a magnitude that is greater than its half, and if this process is iterated a sufficient number of times, then we will eventually remain with amagnitude that is smaller than B.
Euclid used this prin- ciple to prove, for instance, that the ratio of the areasof two circles equals the ratio of the squares of their diameters (XII.2). The method used, later known as the exhaustion method, was based on a double contradiction This double contradiction is illustrated in figure 3, thethat became standard for many centuries to come. accompanying diagram to the proposition. is not the same as the ratio of circle ABCD to circle EFGH, then it must be the same as the ratio of circle If the ratio of the square on BD to the square on FH ABCD to an areacle EFGH.
The curvilinear figures are approximated by S either larger or smaller than cir- polygons, since the continuity principle allows the dif-ference between the inscribed polygon and the circle to be as close as desired (e.g., closer than the differ-ence between Sand EFGH). The “double contradiction” is reached if one assumes that S is either smaller or larger than EFGH.Forms of proof and constructions other than those mentioned so far are occasionally found in Greek math-ematical texts.
These include diagrams based on what is assumed to be the synchronized motion of two lines (e.g., the trisectrix, or Archimedes’ spiral), mechanical devices of many sorts, or reasoning based on idealized mechanical considerations. However, the Euclid-ean type of proof described above remained a model to be followed wherever possible. There is a famous Archimedes palimpsest that provides evidence of how less canonical methods, drawing on mechanical consid-erations (albeit of a highly idealized kind), were used to

II.6. The Development of the Idea of Proof

deduce results about areas and volumes. However, eventhis bears testimony to the primacy of the ideal model: there is a letter from Archimedes to Eratosthenes inwhich he displays the ingenuity of his mechanical methods but at the same time is at pains to stress their heuristic character. 3 Islamic and Renaissance Mathematics Just as Euclid is now considered to represent an entire mainstream tradition of Greek mathematics, so alkh. ar{w}Islamic mathematics.
There are two main traits of hisariz. ar{m}ı [VI.5](/part - 06/abu - jafar - muhammad - ibn - musa - al - khwarizm - vi55 - william - kingdon - cliord - 18451879) is regarded as a representative of work that are relevant to the present account andthat became increasingly central to the development of mathematics, starting with his works in the late eighth century and continuing until the works of cardanoa pervasive “algebraization” of mathematical thinking,[VI.7](/part - 06/girolamo - cardano - 15011576) in sixteenth-century Italy.
These traits are and a continued reliance on Euclidean-style geometric proof as the main way of legitimizing the validity of mathematical knowledge in general and of algebraic reasoning in mathematics in particular. al - Kh. ar{w}The prime example of this combination is found inariz. ar{m}ı’s seminal text al - Ki. ar{t} ab al-mukhtas.ar $\bar{f}$ı h.i$\bar{s}$ ab al-jabr wa’l-mu$\bar{q}$ abalaon calculation by completion and balancing”), where(“The compendious book he discusses the solutions of problems in which the unknown length appears in combination with numbers and squares (the side of
which is an unknown). Since heonly envisages the possibility of positive “coefficients” and positive rational solutions, al-Kh. ar{w}consider six different situations each of which requires ar iz. ar{m}ı needs to a different recipe for finding the unknown: the full-grown idea of a general quadratic equation and an algorithm to solve it in all cases does not appear in islamic mathematical texts.
For instance, the problem “squares and roots equal to numbers” (e.g., x2 + 10 x = 39, in modern notation) and the problem “roots and numbers equal to squares” (e$.g., 3$ x + 4 = x2) are considered to be completely different ones, as are their solutions, and accordingly al-Kh$\bar{w}ariz \bar{m}$ı treats them separately. In all cases, however, al-Kh$\bar{w}$ of the method described by translating it into geomet-ariz$\bar{m}$ı proves the validity ric terms and then relying on Euclid-like geometric the-orems built around a specific diagram.
It is noteworthy, however, that the problems refer to specific numeri-cal quantities associated with the magnitudes involved, and these measured magnitudes refer to the accompa-nying diagrams as well. In this way, al-Kh$\bar{w}ariz \bar{m}$ıinterestingly departs from the Euclidean style of proof. Still,

133

cafdbe

Figure 4 of the formula for a quadratic equation. Al-Kh$\bar{w}ariz \bar{m}$ı’s geometric justification the Greek principle of homogeneity is essentially pre-served, as the three quantities usually involved in the problem are all of the same kind, namely, areas. Consider, for instance, the equation$x^{2} + 10x =$ 39, which corresponds to the following problem ofal-Kh$\bar{w}ariz \bar{m}$ı. What is the square which combined with ten of its rootswill give a sum total of 39? The recipe prescribes the following steps. Take one-half of the roots itself[25]. Add this amount to 39 and obtain 64.
Take[5] and multiply them by the square root of this, which is eight, subtract from ithalf the roots, leaving three. The number three therefore represents one root of this square, which itself, ofcourse, is nine. The justification is provided by figure 4. x102 Here ab represents the said square, which for us isx, and the rectangles c, d, e, f represent an area ofeach, so that all of them together equal 10 x, as in the problem.
Thus, the small squares in the cor-4 ners represent an area of 6 plete” the large square, being equal to 64, and whose.25 each, and we can “comside is therefore 8, thus yielding the solution 3 for the unknown. iz$\bar{m}$ı, added force to this approach when he solved Abu Kamil Shuja, just one generation after al-Kh$\bar{w}$ ar additional problems while specifically relying on theo-rems taken from the Elements, including the accompanying diagrams, in order to justify his method of solution.
The primacy of the Euclidean-type proof, whichwas already accepted in geometry and arithmetic, thus also became associated with the algebraic methods that eventually turned into the main topic of inter-est in Renaissance mathematics. Cardano’s 1545 Ars

134

Magnasented a complete treatment of the equations of third, the foremost example of this new trend, preand fourth degree. Although the algebraic line of rea-soning that he adopted and developed became increasingly abstract and formal, Cardano continued to justify his arguments and methods of solution by reference to Euclid-like geometric arguments based on diagrams. 4 Seventeenth-Century Mathematics The next significant change in the conception of proof appears in the seventeenth century.
The most influen-tial development of mathematics in this period was the creation of the infinitesimal calculus simultaneously by newton [VI.14](/part-06/isaac-newton-16421727) and leibniz [VI.15](/part-06/gottfried-wilhelm-leibniz-16461716). This momentous development was the culmination of a process that spanned most of the century, involving the introduction and gradual improvement of important tech-niques for determining areas and volumes, gradients of tangents, and maxima and minima.
These develop-ments included the elaboration of traditional points of view that went back to the Greek classics, as well as the introduction of completely new ideas such as the “indi - visibles,” whose status as a legitimate tool for mathematical proof was hotly debated.
At the same time, the algebraic techniques and approaches that Renaissance mathematicians continued to expand upon, fol-lowing on from their Islamic predecessors, now gained additional impetus and were gradually incorporated— starting with the work ofcartes [VI.11](/part - 06/ren - descartes - 15961650)—into the arsenal of tools available forfermat [VI.12](/part - 06/pierre - fermat - 1601665) and des proving geometric results. Underlying these various trends were different conceptions and practices of mathematical proof, which are briefly described and illustrated now.
geometric proof was essentially followed but at thesame time fruitfully modified and expanded are found Examples of how the classical Greek conception of in the work of Fermat, as can be seen in his calcula-tion of the area enclosed by a generalized hyperbola (in modern notation(y/a)m = (x/b)n (m, n . eq 1)) and its asymptotes.
ypurely geometric relationship on any two of its points, The quadratic hyperbola (i.e., a figure represented by= 1/x2), for instance, is defined here in terms of a namely, that the ratio between the squares built on the abscissas equals the inverse ratio between the lengths of the ordinates. In its original version it is expressed asfollows: AG2 : AH2 :: IH : EG (see figure 5). It should be noticed that this is not an equation in the present sense

II. The Origins of Modern Mathematics

CEBINPAGHOM

Figure 5 of the area under a hyperbola. Diagram for Fermat’s proof of the word, on which the standard symbolic manipula-tions can be directly performed. Rather, this is a fourterm proportion to which the rules of Greek classical mathematics apply. Also, the proof was entirely geometric and indeed it essentially followed the euclidean style. Thus, if the segments AG, AH, AO, etc., are chosen in continued proportion, then one can prove thatthe rectangles EH, IO, NM, etc., are also in continued proportion, and indeed that EH : IO :: IO : NM ::· · ·:: AH : AG.
(mentioned above), which comprises an expression forthe sum of any number of quantities in a geometric Fermat made use of proposition IX.35 of the Elements progression, namely (in more modern notation): $((an)+1 - a1)$:$(a^{1} + a^{2} + · · · + a^{n}) = (a^{2} - a^{1})$:$a^{1}$.
But at this point his proof takes an interesting turn. He introduces the somewhat obscure concept of “adequare and which allows a kind of “approximate equality.”,” which he found in the works of Diophantus, Specifically, this idea allows him to bypass the cumber-some procedure of double contradiction typically used in Greek geometry as an implicit passage to the infi-nite.
A figure bounded by GE, by the horizontal asymptote, and by the hyperbola will equal the infinite sumof rectangles obtained when the rectangle EH “will vanish and will be reduced to nothing.” Further, proposi-tion IX.35 implies that this sum equals the area of the rectangle BG.
Significantly, Fermat still chose to rely onthe authority of the ancients, hinting at the method of double contradiction when he declared that this result“would be easy to confirm by a more lengthy proof carried out in the manner of Archimedes.”Attempts to expand the accepted canon of geometric proof eventually led to the more progressive approaches associated with the idea of indivisibles, as

II.6. The Development of the Idea of Proof

practiced by Cavalieri, Roberval, and Torricelli. Thisis well illustrated by Torricelli’s 1643 calculation of the volume of the infinite body created by rotating the hyperbolaxy = k2 around the y -axis, with val- ues ofx between 0 and a (as we would describe it in modern terms). sidered to be sums, or collections, of infinitely manyline segments, and volumes are considered to be sums, The essential idea of indivisibles is that areas are conor collections, of infinitely many areas.
In this exam - ple, Torricelli calculated the volume of revolution by considering it to be a sum of the curved surfaces of an infinite collection of cylinders successively inscribed within each other and having radii ranging from 0 toa. In modern algebraic terms, the height of the inscribed cylinder with radiusx is k2/x, so the area of its curved surface is 2 is independent ofπx(k2/x)x and equal to the area of a circle= π(. qrt{2 k})2, a constant value that of radiusthe geometry of indivisibles, the collection of all sur-$\sqrt{2 k}$.
Thus, in Torricelli’s approach based on faces that, when taken together, comprise the infinite body can be equated to a collection of circles with area2πk2, one for each x between 0 and a, or equivalently to a cylinder of volume 2πk2 a. The rules of Euclid-like geometric proof were completely contravened in proofs of this kind and thismade them unacceptable in the eyes of many. On the other hand, their fruitfulness was highly appealing, especially in cases like this one in which an infinite bodywas shown to have a finite volume, a result which Torricelli himself found extremely surprising.
Both supporters and detractors alike, however, realized that tech-niques of this kind might lead to contradictions and inaccurate results. By the eighteenth century, with the accelerated development of the infinitesimal calculus and its associated techniques and concepts, techniques based on indivisibles had essentially disappeared. The limits set by the classical paradigm of Euclidean geometric proof were then transgressed in a dif-ferent direction by the all - embracing algebraization of geometry at the hands of Descartes.
The fundamental step under taken by Descartes was to introduce unit lengths as a key element in the diagrams used in geometric proofs. The radical innovation implied by this step, allowing the hitherto nonexistent possibility ofdefining operations with line segments, was explicitly stressed by Descartes in La Géométrie in 1637:
Just as arithmetic consists of only four or five oper - ations, namely addition, subtraction, multiplication, 135 division, and the extraction of roots, which may be considered a kind of division, so in geometry, to find required lines it is merely necessary to add or subtract other lines;
or else, taking one line, which I shall call the unit in order to relate it as closely as possible to num - bers, and which can in general be chosen arbitrarily, and having given two other lines, to find a fourth linewhich shall be to one of the given lines as the other is to the unit (which is the same as multiplication); or again, to find a fourth line which is to one of the given lines as the unit is to the other (which is equivalent to division);
or, finally, to find one, two, or several mean proportionals between the unit and some other line (which is thesame as extracting the square root, cube root, etc., of the given line). division of their lengths is represented by BC in figure 6, Thus, for instance, given two segments BD, BE, the in which AB represents the unit length. Although the proof was Euclid-like in appearance (because of the diagram and the use of the theory of similar triangles), the introduction of the unit lengthand its use for defining the operations with segments set it radically apart and opened completely new
hori-zons for geometric proofs. Not only had measurements of length been absent from Euclidean-style proofs thus far, but also, as a consequence of the very existenceof these operations, the essential dimensionality traditionally associated with geometric theorems lost its significance.
Descartes used expressions such as$a$ - b$, a/b, a2$, b3, and their roots, but he stressed that they should all be understood as “only simple lines, which, however, I name squares, cubes, etc., so that I make use of the terms employed in algebra.” With the removal of dimensionality, the requirement of homogeneity also became unnecessary. Unlike his predeces-sors, who handled magnitudes only when they had a direct geometric significance, Descartes could not seeany problem in forming an expression such as$a2b2 - b$ and then extracting its cube root.
In order to do so, hesaid “we must consider the quantitya2 b2 divided once by the unit, and the quantityb multiplied twice by the unit.” Sentences of this kind would be simply incompre-hensible to Greek geometers, as well as to their Islamic and Renaissance followers.
newly created possibility of proving geometric factsvia algebraic procedures, was strongly related to the This algebraization of geometry, and particularly the recent consolidation of the idea of an algebraic equa-tion, seen as an autonomous mathematical entity, for which formal rules of manipulation were well-knownand could be systematically applied. This idea reached

136

ECBDA

Figure 6 of the division of two given segments. Descartes’s geometric calculation full maturity in the hands of1591. But not all mathematicians in the seventeenthviète [VI.9](/part-06/franois-vite-15401603) only around century saw the important developments associated with algebraic thinking either as a direction to be naturally adopted or as a clear sign of progress in the latter discipline.
A prominent opponent of any attemptto deviate from the classical Euclidean-style approach in geometry was none other thanin the Arithmetica Universalis (1707), was emphatic innewton [VI.14](/part-06/isaac-newton-16421727), who, expressing his views: Equations are expressions of arithmetic computation and properly have no place in geometry, except in so far as truly geometrical quantities (lines, surfaces, solids and proportions) are thereby shown equal, some to others.
Multiplications, divisions, and computations of that kind have recently been introduced into geometry, unadvisedly and against the first principle of this science. . . . Therefore these two sciences ought not to be confounded, and recent generations by confounding them have lost that simplicity in which all geometrical elegance consists.
Newton’s Principia bears witness to the fact that statements like this one were far from mere lip ser-vice, as Newton consistently preferred Euclidean-style proofs, considering them to be the correct language for presenting his new physics and for bestowing it with the highest degree of certainty. He used his own cal-culus only where strictly necessary, and barred algebra from his treatise entirely. Eighteenth-Century Mathematics5 Geometry and Proof in Mathematical analysis became the primary focus of mathematicians in the eighteenth century.
Questions relating to the foundations of analysis arose immediately after the calculus began to be developed and were

II. The Origins of Modern Mathematics

not settled until the late nineteenth century. To a con-siderable extent these questions were about the nature of legitimate mathematical proof, and debates about them played an important role in undermining the long-undisputed status of geometry as the basis for mathematical certainty and bestowing this status on arith-metic instead. The first important stage in this process was separated from its purely geometric roots, the calculus euler’s [VI.19](/part-06/leonhard-euler-17071783) reformulation of the calculus. Once came to be centered on the algebraically oriented con-cept of function.
This trend for favoring algebra over geometry was given further impetus by Euler’s suc-cessors. d’alembert [VI.20](/part-06/jean-le-rond-dalembert-17171783), for instance, associated mathematical certainty above all with algebra—becauseof its higher degree of generality and abstraction—and only subsequently with geometry and mechanics. This was a clear departure from the typical views of Newtonand of his contemporaries.
The trend reached a peak and was transformed into a well-conceived program inthe hands of lagrange [VI.22](/part-06/joseph-louis-lagrange-17361813), who in the preface to his 1788 a radical view about how one could achieve certainty Méchanique Analitique famously expressed in the mathematical sciences while distancing one self from geometry. He wrote as follows: One will not find figures in this work. The methods that I expound require neither constructions, nor geometrical or mechanical arguments, but only algebraic operations, subject to a regular and uniform course.
The details of these developments are beyond the scopeof this article. What is important to stress, however, is that in spite of their very considerable impact, the basic conceptions of proof in the more mainstream realm of geometry teenth century. An illuminating perspective on thesedid not change very much during the ei gh conceptions is offered by the views of contemporary philosophers, especially Immanuel Kant. Kant had a very profound knowledge of contemporary science, and particularly of mathematics. A philosophical knowledge and proof need not concern us here.
How-discussion of his views on mathematical ever, given his acquaintance with contemporary con-ceptions, they do provide an insightful historical perspective on proof as it was understood at the time. of particular interest is the contrast he draws between a philosophical argument, on the one hand, and ageometric proof, on the other. Whereas the former deals with general concepts, the latter deals with concrete, yet nonempirical, concepts, by reference to “visu-alizable intuitions” (Anschauung). This difference is

II.6. The Development of the Idea of Proof

epitomized in the following, famous passage from his Critique of Pure Reason. Suppose a philosopher be given the concept of a tri-angle and he is left to find out, in his own way, what relation the sum of its angles bears to a right angle. He has nothing but the concept of a figure enclosed by three straight lines, and possessing three angles. How-ever long he meditates on this concept, he will never produce anything new.
He can analyze and clarify the concept of a straight line or of an angle or of the number three, but he can never arrive at any properties not already contained in these concepts. Now let the geometric i an take up these questions. He at once begins by constructing a triangle. Since he knows that the sum of two right angles is exactly equal to the sum of all the adjacent angles which can be constructed from a single point on a straight line, he prolongs one side of his tri-angle and obtains two adjacent angles, which together are equal to two right angles.
He then divides the exter-nal angle by drawing a line parallel to the opposite side of the triangle, and observes that he has thus obtainedan external adjacent angle which is equal to an internal angle—and so on. In this fashion, through a chain of inferences guided through out by intuition, he arrives at a fully evident and universally valid solution of the problem. In a nutshell, then, for Kant the nature of mathematical proof that sets it apart from other kinds of deductive argument at i on (like philosophy) lies in the central-ity of the diagrams and the role that they play.
As in the Elements, this diagram is not just a heuristic guide for what is no more than abstract reasoning, but rather an“intuition,” a singular embodiment of the mathematical idea that is clearly located not only in space, but rather in space and time. In fact, I cannot represent to myself a line, however small, with-out drawing it in thought, that is gradually generating all its parts from a point. Only in this way can the intuition be obtained.
This role played by diagrams as “visualizable intuitions” is what provides, for Kant, the explanation of why geometry is not just an empirical science, but also not just a huge tautology devoid of any synthetic con-tent. According to him, geometric proof is constrained by logic but it is much more than just a purely logical analysis of the terms involved. This view was at theheart of a novel philosophical analysis whose starting point was the then-entrenched conception of what a mathematical proof is.

137

6 Nineteenth-Century Mathematics andthe Formal Conception of Proof The nineteenth century was full of important develop-ments in geometry and other parts of mathematics, not just of the methods but also of the aims of the various subdisciplines. Logic, as a field of knowledge, also underwent significant changes and a gradual mathematization that entirely transformed its scope and methods. Consequently, by the end of the century the con-ception of proof and its role in mathematics had also been deeply transformed.
In Göttingen in 1854 riemann [VI.49] gave his seminal talk “On the hypotheses which lie at the foun-dations of geometry.” At around the same time, the works of bolyai [VI.34] and lobachevskii [VI.31](/part-06/nicolai-ivanovich-lobachevskii-17921856) on non-Euclidean geometry, as well as the related ideas ofgauss [VI.26](/part-06/carl-friedrich-gauss-17771855), all dating from the 1830 s, began to be more generally known.
The existence of coherent, alternative geometries brought about a pressing need forthe most basic, longstanding beliefs about the essence of geometric knowledge, including the role of proofand mathematical rigor, to be revised. Of even greater significance in this regard was the renewed interest in projective geometry [I.3 §6.7](/part-01/fundamental-definitions), which became a very active field of research with its own open research questions and foundational issues after the publication of Jean Poncelet’s 1822 treatise.
The addition of projective geometry to the many other possible geometric perspectives prompted a variety of attempts at unifi-cation and classification, the most significant of which were those based on group-theoretic ideas. Particularly notable were those of1870 s. In 1882, Moritz Pasch published an influential klein [VI.57] and lie [VI.53](/part-06/sophus-lie-18421899) in the treatise on projective geometry devoted to a systematic exploration of its axiomatic foundations and the inter-relationships among its fundamental theorems.
Pasch’s book also attempted to close the many logical gaps that had been found in Euclidean geometry over the years. More systematically than any of his fellow nineteenth century mathematicians, Pasch emphasized that all geometric results should be obtained from axioms bystrict logical deduction, without relying on analytical means, and above all without appeal to diagrams or to properties of the figures involved.
Thus, although in some ways he was consciously reverting to the canonsof Euclid-like proof (which by then were somewhat loosened), his attitude toward diagrams was fundamentally different. Aware of the potential limitations of visualiz-ing diagrams (and perhaps their misleading influence)

138

he put a much greater emphasis on the pure logical structure of the proof than his predecessors had. Nevertheless, he was not led to an outright formalist viewof geometry and geometric proof. Rather, he consistently adopted an empirical approach to the origins and meaning of geometry and fell short of claiming that diagrams were for heuristic use only: The basic propositions [of geometry] cannot be under-stood without corresponding drawings; they express what has been observed from certain, very simple facts. The theorems are not founded on observations, but rather, they are proved.
Every inference performed dur-ing a deduction must find confirmation in a drawing, yet it is not justified by a drawing but from a certain preceding statement (or a definition). ing their central status in geometric proofs in favorof purely deductive relations, but it did not directly Pasch’s work definitely contributed to diagrams loslead to a thorough revision of the status of the axiomsof geometry, or to a change in the conception that geometry deals essentially with the study of our spa-tial, visualizable intuition (in the sense of Anschauung).
The all-important nineteenth-century developments in geometry produced significant changes in the concep-tion of proof only under the combined influence of additional factors. of research, and the study of its foundations became increasingly identified with arithmetic, rather than geo-Mathematical analysis continued to be a primary field metric, rigor.
This shift was provoked by the worksof mathematicians like cauchy [VI.29](/part-06/augustin-louis-cauchy-17891857), weierstrass [VI.44](/part-06/karl-weierstrass-18151897), cantor [VI.54](/part-06/georg-cantor-18451918), and dedekind [VI.50](/part-06/julius-wilhelm-richard-dedekind-18311916), which aimed at eliminating intuitive arguments and conceptsin favor of ever more elementary statements and definitions.
(In fact, it was not until the work of Dedekindon the foundations of arithmetic, in the last third of the century, that the rigorous formulation pursued in these works was given any kind of axiomatic underpin-ning.) The idea of investigating the axiomatic basis of mathematical theories, whether geometry, algebra, or arithmetic, and of exploring alternative possible sys-tems of postulates was indeed pursued during the nineteenth century by mathematicians such as George Peacock, Charles Babbage, John Herschel, and, in a different geographical and mathematical context, Hermann Grassmann.
But such investigations were the exception rather than the rule, and they had only a fairly limited role in shaping a new conception of proof in analysis and geometry.

II. The Origins of Modern Mathematics

combined to produce a new kind of approach to proof, is to be found in the works of One major turning point, where the above trends giuseppe peano [VI.62](/part-06/giuseppe-peano-18581932) and his Italian followers. Peano’s mainstream activities were as a competent analyst, but he was also interested in artificial languages, and particularly in developing an artificial language that would allow a completely formal treatment of mathematical proofs. In 1889 his successful application of such a conceptual language to arithmetic yielded his famousural numbers [III.67](/part-03/the-peano-axioms).
Pasch’s systems of axioms for postulates for the nat projective geometry posed a challenge to Peano’s arti-ficial language, and he set out to investigate the relationship between the logical and the geometric terms involved in the deductive structure of geometry. In this context he introduced the idea of an independent set of axioms, and applied this concept to his own systemof axioms for projective geometry, which were a slight modification of Pasch’s. This view did not lead Peano to a formalistic conception of proof, and he still conceived geometry in terms very similar to his predecessors:
Anyone is allowed to take a hypothesis and develop its logical consequences. However, if one wants to give this work the name of geometry it is necessary that such hypotheses or postulates express the result of simple and elementary observations of physical figures. a symbolism with which to handle abstract–formal the-Under the influence of Peano, Mario Pieri developed ories.
Unlike Peano and Pasch, Pieri consistently pro-moted the idea of geometry as a purely logical system, where theorems are deduced from hypothetical premises and where the basic terms are completely detached from any empirical or intuitive significance. proof was opened at the end of the nineteenth century with the publication of A new chapter in the history of geometry and ofhilbert’s [VI.63](/part-06/david-hilbert-18621943) Grundlagen der geometrie completion the various trends of geometric research, a work that synthesized and brought to described above.
Hilbert was able to achieve a com-prehensive analysis of the logical interrelations among the fundamental results of projective geometry, suchas the theorems of Desargues and Pappus, while paying particular attention to the role of continuity considerations within their proofs. His analysis was basedon the introduction of a generalized analytic geometry, in which the coordinates may be taken from a variety of different the real numbers alone. This approach created a purely number fields [III.63](/part-03/number-fields), rather than from

II.6. The Development of the Idea of Proof

synthetic arithmetization of any given type of geom-etry, and thus helped to clarify the logical structure of Euclidean geometry as a deductive system. It also clarified the relationship between Euclidean geometry and the various other kinds of known geometries—non Euclidean, projective, or non-Archimedean. This focuson logic implied, among other things, that diagrams should be relegated to a merely heuristic role. In fact, although diagrams still appear in many proofs in the Grundlagen, the entire purpose of the logical analysis is to avoid being misled by diagrams.
Proofs, and partic-ularly geometric proofs, have thus become purely logical arguments, rather than arguments about diagrams. And at the same time, the essence and the role of theaxioms from which the derivations in question start also underwent a dramatic change. Following Pasch’s lead, Hilbert introduced a new system of axioms for geometry that attempted to close the logical gaps inherent in earlier systems.
These axioms were of five kinds—axioms of incidence, of order, of congruence, of parallels, and of continuity—each of which expressed a particular way in which spatial intuition manifests itself in our understanding. They were formulated for three fundamental kinds ofobject: points, lines, and planes. These remained undefined, and the system of axioms was meant to providean implicit definition of them.
In other words, rather than defining points or lines at the outset and then postulating axioms that are assumed to be valid for them, a point and a line were not directly defined, except as entities that satisfy the axioms postulated by the sys-tem. Further, Hilbert demanded that the axioms in a system of this kind should be mutually independent, and introduced a method for checking that this demandis fulfilled; in order to do so, he constructed models of geometries that fail to satisfy a given axiom of thesystem but satisfy all the others.
Hilbert also required that the system be consistent, and that the consistency of geometry could be made to depend, in his system, on that of arithmetic. He initially assumed that prov-ing the consistency of arithmetic would not present a major obstacle and it was a long time before he realized that this was not the case. Two additional requirements that Hilbert initially introduced for axiomatic systems were simplicity and completeness.
Simplicity meant, inessence, that an axiom should not contain more than “a single idea.” The demand that every axiom in a sys-tem be “simple,” however, was never clearly defined or systematically pursued in subsequent works of Hilbert or any of his successors. The last requirement, com-

139

pleteness, meant for Hilbert in 1900 that any adequate axiomatization of a mathematical domain should allow for a derivation ofpline in question. Hilbert claimed that his axioms wouldall the known theorems of the disciindeed yield all the known results of Euclidean geometry, but of course this was not a property that he could formally prove. In fact, since this property of “completeness” cannot be formally checked for any given axiomatic system, it did not become one of the standard requirements of an axiomatic system.
It is important to note that the concept of completeness used by Hilbert in 1900 is completely different from the currently accepted, model-theoretical one that appeared much later. The latter amounts to the requirement that in a given axiomatic system every true statement, be it known or unknown, should be provable. The use of undefined concepts and the concomitant conception of axioms as implicit definitions gave enor-mous impetus to the view of geometry as a purely logical system, such as Pieri had devised it, and eventually transformed the very idea of truth and proof in mathe-matics.
Hilbert claimed on various occasions—echoing an idea of Dedekind—that, in his system, “points, lines, and planes” could be substituted by “chairs, tables, and beer mugs,” without thereby affecting in any sense the logical structure of the theory. Moreover, in the lightof discussions about set-theoretical paradoxes, Hilbert strongly emphasized the view that the logical consis-tency of a concept implicitly defined by axioms was the essence of mathematical existence.
Under the influence of these views, of the new methodological tools intro-duced by Hilbert, and of the successful overview of the foundations of geometry thus achieved, many math-ematicians went on to promote new views of mathematics and new mathematical activities that in many senses went beyond the views embodied in Hilbert’sapproach. On the one hand, a trend that thrived in the United States at the beginning of the twentieth century, led by Eliakim H.
Moore, turned the study of systems of postulates into a mathematical field in its own right, independent of direct interest in the field of research defined by the systems in question. For instance, these mathematicians defined the minimal set of indepen-dent postulates for groups, fields, projective geometry, etc., without then proceeding to investigate of any of these individual disciplines.
On the other hand, promi-nent mathematicians started to adopt and develop increasingly formalistic views of proof and of math-ematical truth, and began applying them in a growing number of mathematical fields. The work of the

140

radically modernist mathematician[VI.68](/part-06/felix-hausdor-18681942) provides important examples of this trend, as hefelix hausdorff was among the first to consistently associate Hilbert’sa ch i eve ment with a new, formalistic view of geometry. In 1904, for instance, he wrote: In all philosophical debates since Kant, mathematics, or at least geometry, has always been treated as heteronomous, as dependent on some external instanceof what we could call, for want of a better term, intuition, be it pure or empirical, subjective or scientifically amended, innate or acquired.
The most important and fundamental task of modern mathematics has been toset itself free from this dependency, to fight its way through from heteronomy to autonomy. around 1918, when he engaged in the debates about the Hilbert himself would pursue such a point of view consistency of arithmetic and formulated his “finitist”program. This program did indeed adopt a strongly formalistic view, but it did so with the restricted aim of solving this particular problem.
It is therefore impor-tant to stress that Hilbert’s conceptions of geometry were, and remained, essentially empiricist and that henever regarded his axiomatic analysis of geometry as part of an overall formalistic conception of mathematics. He considered the axiomatic approach as a tool forthe conceptual clarification of existing, well-elaborated theories, of which geometry provided only the most prominent example.
the concept of proof and of truth in mathematics pro-voked strong reactions from some mathematicians, The implication of Hilbert’s axiomatic approach for and prominently so fromare closely related to the changing status of logic at thefrege [VI.56](/part-06/gottlob-frege-18481925). Frege’s views turn of the twentieth century and its gradual process of mathematization and formalization. This process was an outcome of the successive efforts through the nineteenth century of Grassmann, Charles S.
Peirce, and Ernst Schröder atboole [VI.43](/part-06/george-boole-18151864), de morgan [VI.38], formulating an algebra of logic. The most significant step toward a new, formal conception of logic, however, came with the increased understanding of the roleof the logical quantifiers [I.2 §3.2](/part-01/language-and-grammar) (universal,∀, and existential,∃) in the process of formulating a modern mathematical proof.
This understanding emerged in aninformal, but increasingly clear, fashion as part of the process of the rigorization of analysis and the distancing from visual intuition, especially at the hands of Cauchy, bolzano [VI.28](/part-06/bernard-bolzano-17811848), and Weierstrass. It was formally defined and systematically codified for the first

II. The Origins of Modern Mathematics

time by Frege in his 1879 tem, as well as similar ones proposed later by Peano Begriffsschrift. Frege’s sysand bytinction between propositional connectives and quan-russell [VI.71](/part-06/bertrand-arthur-william-russell-18721970), brought to the fore a clear distifiers, as well as between logical symbols and algebraicor arithmetic ones. which one defines in advance all the allowable sym-bols, all the rules that produce well-formed formulas, Frege formulated the idea of a formal system, in all axioms (i.e., certain preselected, well-formed formu-las), and all the rules of inference.
In such systems any deduction can be checked words, by purely symbolic means. On the basis of such syntactically—in other systems Frege aimed to produce theories with no log-ical gaps in their proofs. This would apply not only to analysis and to its arithmetic foundation—the mathe-matical fields that provided the original motivation for his work—but also to the new systems of geometry thatwere evolving at the time. On the other hand, in Frege’s view the axioms of mathematical theories—even if they appear in the formal system merely as well-formed formulas—embody truths about the world.
This is pre-cisely the source of his criticism of Hilbert. It is the truth of the axioms, asserted Frege, that certifies their consistency, rather than the other way around, as Hilbert suggested. We thus see how foundational research in two separate fields—geometry and analysis—was inspired bydifferent methodologies and philosophical outlooks, but converged at the turn of the twentieth centuryto create an entirely new conception of mathematical proof.
In this conception a mathematical proof is seenas a purely logical construct validated in purely syntactic terms, independently of any visualization through diagrams. This conception has dominated mathematics ever since. Epilogue: Proof in the Twentieth Century The new notion of proof that stabilized at the beginningof the twentieth century provided an idealized model— broadly accepted to this day—of what should consti-tute a valid mathematical argument. To be sure, actual proofs devised and published by mathematicians since that time are seldom presented as fully formalized texts.
They typically present a clearly articulated argument in a language that is precise enough to convince the reader that it could—in principle, and perhaps with straightforward (if sustained) effort—be turned intoone. Through out the decades, however, some limitations of this dominant idea have gradually emerged

II.6. The Development of the Idea of Proof

and alternative conceptions of what should count as avalid mathematical argument have become increasingly accepted as part of current mathematical practice. full extent led, early on and very unexpectedly, to aserious difficulty with the notion of a proof as a com-The attempt to pursue this idea systematically to its pletely formalized and purely syntactic deductive argu-ment. In the early 1920 s, Hilbert and his collaborators developed a fully fledged mathematical theory whose subject matter was “proof,” considered as an object of study in itself.
This theory, which presupposed the for-mal conception of proof, arose as part of an ambitious program for providing a direct, finitistic consistency proof of arithmetic represented as a formalized sys-tem. Hilbert asserted that, just as the physicist examines the physical apparatus with which he carries outhis experiments and the philosopher engages in a critique of reason, so the mathematician should be able to analyze mathematical proofs and do so strictly by mathematical means.
About a decade after the program was launched, ing incompleteness theoremgödel [VI.92](/part-06/kurt-gdel-19061978) came up with his astonish-[V.15](/part-05/gdels-theorem), which famously showed that “mathematical truth” and “provability” were not one and the same thing. Indeed, in any consis-tent, sufficiently rich axiomatic system (including the systems typically used by mathematicians) there aretrue mathematical statements that cannot be proved.
Gödel’s work implied that Hilbert’s finitistic program was too optimistic, but at the same time it also madeclear the deep mathematical insights that could be obtained from Hilbert’s proof theory. A closely related development was the emergence of proofs that certain important mathematical statements were undecidable. Interestingly, these seemingly neg-ative results have given rise to new ideas about the legitimate grounds for establishing the truth of such statements.
For instance, in 1963 Paul Cohen established that the continuum hypothesis [IV.22 §5](/part-04/set-theory) can be neither proved nor disproved in the usual systemsof axioms for set theory. Most mathematicians simply accept this idea and regard the problem as solved(even if not in the way that was originally expected), but some contemporary set theorists, notably Hugh Woodin, maintain that there are good reasons to believe that the hypothesis is false. The strategy they follow in order to justify this assertion is fundamentally differ-ent from the formal notion of proof:
they devise new axioms, demonstrate that these axioms have very desir-able properties, argue that they should therefore be accepted, and then show that they imply the negation of

141

the continuum hypothesis. (Seefor further discussion.) set theory [IV.22 §10](/part-04/set-theory) increasing length of significant proofs appearing in A second important challenge came from the ever various mathematical domains. A prominent example was the classification theorem for finite simple groupsarate parts by a large numbers of mathematicians.
The[V.7](/part-05/the-classication-of-finite-simple-groups), whose proof was worked out in many sep resulting arguments, if put together, would reach about ten thousand pages, and errors have been found sincethe announcement in the early 1980 s that the proof was complete. It has always been relatively straightforward to fix the errors and the theorem is indeed accepted and used by group theorists. Nevertheless, the notion of a proof that is too long for a single human being tocheck is a challenge to our conception of when a proof should be accepted as such.
The more recent, very con-spicuous cases of fermat’s last theorem [V.10](/part-05/fermats-last-theorem) and the poincaré conjecture [V.25](/part-05/the-poincar-conjecture) were hard to survey for different reasons: not only were they long (though nowhere near as long as the classification of finite simple groups), but they were also very difficult. In bothcases there was a significant interval between the first announcement of the proofs and their complete acceptance by the mathematical community because check-ing them required enormous efforts by the very few people qualified to do so.
There is no controversy about either of these two breakthroughs, but they do raise an interesting sociological problem: if somebody claims tohave proved a theorem and nobody else is prepared to check it carefully (perhaps because, unlike the two theorems just mentioned, this one is not important enough for another mathematician to be prepared tospend the time that it would take), then what is the status of the theorem? also appeared in various mathematical domains, in-cluding number theory, group theory, and combina-Proofs based on probabilistic considerations have torics.
It is sometimes possible to prove mathematical statements (see, for example, the discussion of random primality testing in[IV.3 §2](/part-04/computational-number-theory)), not with complete certainty, but in such a way computational number theory that the probability of error is tiny—at most one in atrillion, say.
In such cases, we may not have a formal proof, but the chances that we are mistaken in considering the given statement to be true are probably lowerthan, say, the chance that there is a significant mistake in one of the lengthy proofs mentioned above. Another challenge has come from the introduction of computer-assisted methods of proof. For instance,

142

in 1976 Kenneth Appel and Wolfgang Haken settled afamous old problem by proving the four-color theorem huge number of different map configurations, which[V.12](/part-05/the-four-color-theorem). Their proof involved the checking of a they did with the help of a computer. Initially, this raised debates about the legitimacy of their proof but it quickly became accepted and there are now several proofs of this kind. Some mathematicians even believe that computer-assisted and, more importantly, computer-generated discipline.
Under this (currently minority) view, ourproofs are the future of the entire present views about what counts as an acceptable mathematical proof will soon become obsolete. ematics now contain conjectures that seem to be both fundamentally important and out of reach for the fore-A last point to stress is that many branches of math see able future. Mathematicians persuaded of the truthof such conjectures increasingly undertake the systematic study of their consequences, assuming that an acceptable proof will one day appear (or at least that the conjecture is true).
Such conditional results are pub-lished in leading mathematical journals and doctoral degrees are routinely awarded for them. These trends all raise interesting questions about existing conceptions of legitimate mathematical proofs, the status of truth in mathematics, and the relationship between “pure” and “applied” fields. The formal notionof a proof as a string of symbols that obeys certain syntactical rules continues to provide an ideal modelfor the principles that underlie what most mathematicians see as the essence of their discipline.
It allowsfar-reaching mathematical analysis of the power of certain axiomatic systems, but at the same time it falls short of explaining the changing ways in which mathematicians decide what kinds of arguments they are will-ing to accept as legitimate in their actual professional practice. Acknowledgments.for useful comments on previous versions of this text. I thank José Ferreirós and Reviel Netz

Further Reading

Bos, H. 2001.Transformation of the Early Modern Concept of Construc-Redefining Geometrical Exactness. Descartes’ Ferreirós, J. 2000.tion Theory and Its Role in Modern Mathematics. New York: Springer. Labyrinth of Thought. A History of Set. Boston, MA: Grattan-Guinness, I. 2000.Birkhäuser. Roots, 1870–1940: Logics, Set Theories and the Foun-The Search for Mathematical dations of Mathematics from Cantor through Russell to Gödel. Princeton, NJ: Princeton University Press.

II. The Origins of Modern Mathematics

Netz, R. 1999.ics: A Study in Cognitive History The Shaping of Deduction in Greek Mathemat-. Cambridge: Cambridge Rashed, R. 1994.University Press. Between Arithmetic and Algebra The Development of Arabic Mathematics:, translated by A. F. W. Armstrong. Dordrecht: Kluwer. II.7 The Crisis in the Foundations of

Mathematics

José Ferreirós

The foundational crisis is a celebrated affair among mathematicians and it has also reached a large nonmathematical audience. A well-trained mathematician is supposed to know something about the three viewpoints called “logicism,” “formalism,” and “intuition-ism” (to be explained below), and about what gödel’s incompleteness resultsof mathematical knowledge.
Professional mathemati-[V.15](/part-05/gdels-theorem) tell us about the status cians tend to be rather opinionated about such top-ics, either dismissing the foundational discussion as irrelevant—and thus siding with the winning party—or defending, either as a matter of principle or as an intriguing option, some form of revisionist approachto mathematics. But the real outlines of the historical debate are not well-known and the subtler philo-sophical issues at stake are often ignored.
Here we shall mainly discuss the former, in the hope that thiswill help bring the main conceptual issues into sharper focus. The foundational crisis is usually understood as a relatively localized event in the 1920 s, a heated debate between the partisans of “classical” (meaning late-nineteenth-century) mathematics, led byand their critics, led by brouwer [VI.75](/part-06/luitzen-egbertus-jan-brouwer-18811966), who advo-hilbert [VI.63](/part-06/david-hilbert-18621943), cated strong revision of the received doctrines.
Thereis, however, a second, and in my opinion very important, sense in which the “crisis” was a long and global process, in distinguishable from the rise of modern mathematics and the philosophical and methodologi-cal issues it created. This is the standpoint from which the present account has been written. Within this longer process one can still pick out some noteworthy intervals. Around 1870 there were many discussions about the acceptability of non-Euclidean geometries, and also about the proper foundations ofcomplex analysis and even the real numbers.
Early in the twentieth century there were debates about settheory, about the concept of the continuum, and about the role of logic and the axiomatic method versus

II.7. The Crisis in the Foundations of Mathematics the role of intuition. By about 1925 there was a cri-sis in the proper sense, during which the main opinions in these debates were developed and turned into detailed mathematical research projects. And in the 1930 s gödel [VI.92](/part-06/kurt-gdel-19061978) proved his incompleteness results, which could not be assimilated without some cherished beliefs being abandoned. Let us analyze some of these events and issues in greater detail.
1 Early Foundational Questions There is evidence that in 1899 Hilbert endorsed the viewpoint that came to be known as logicism. Logicism was the thesis that the basic concepts of mathemat-ics are definable by means of logical notions, and that the key principles of mathematics are deducible from logical principles alone. Over time this thesis has become unclear, based as it seems to be on a fuzzy and immature conception of thescope of logical theory.
But historically speaking logicism was a neat intellectual reaction to the rise of mod-ern mathematics, and particularly to the set-theoretic approach and methods. Since the majority opinion wasthat set theory is just a part of (refined) logic,1 this thesis was thought to be supported by the fact that the theories of natural and real numbers can be derived from set theory, and also by the increasingly important role of set-theoretic methods in algebra and in real and complex analysis. he understood mathematics.
For us, the essence of Hilbert’s and Dedekind’s early logicism is their self-Hilbert was following dedekind [VI.50](/part-06/julius-wilhelm-richard-dedekind-18311916) in the way conscious endorsement of certain modern methods, however daring they seemed at the time. These methods had emerged gradually during the nineteenth cen-tury, and were particularly associated with Göttingen mathematics (they experienced a crucial turning point withgauss [VI.26](/part-06/carl-friedrich-gauss-17771855) and dirichlet [VI.36]);
riemannther by Dedekind,’s [VI.49] novel ideas, and were developed fur-cantor [VI.54](/part-06/georg-cantor-18451918), Hilbert, and other, lesser figures. Meanwhile, the influential Berlin schoolof mathematics had opposed this new trend, kronecker subtly.
(The name of Weierstrass is synonymous with[VI.48](/part-06/leopold-kronecker-18231891) head-on and weierstrass [VI.44](/part-06/karl-weierstrass-18151897) more the introduction of rigor in real analysis, but in fact, aswill be indicated below, he did not favor the more modern methods elaborated in his time.) Mathematicians in disagreed (see Ferreirós 1999). The “majority” included Dedekind, peano1. One should mention that key figures like Riemann and Cantor[VI.62](/part-06/giuseppe-peano-18581932), Hilbert, russell [VI.71](/part-06/bertrand-arthur-william-russell-18721970), and others.

143

Paris and elsewhere also harbored doubts about thesenew and radical ideas. proach were: The most characteristic traits of the modern ap(i) acceptance of the notion of an “arbitrary” function proposed by Dirichlet; (ii) a wholehearted acceptance of infinite sets and thehigher infinite; (iii) a preference “to put thoughts in the place of calculations” (Dirichlet), and to concentrate on (iv) a frequent reliance on “purely existential” meth-“structures” characterized axiomatically; andods of proof.
An early and influential example of these traits was Dedekind’s approach (1871) totheory [IV.1](/part-04/number-theory)—his set-theoretic definition ofalgebraic number number fieldsby which he proved results such as the fundamen-[III.63](/part-03/number-fields) and ideals [III.81 §2](/part-03/rings-ideals-and-modules), and the methods tal theorem of unique decomposition. In a remark-able departure from the number-theoretic tradition, Dedekind studied the factorization properties of alge-braic integers in terms of ideals, which are certain infinite sets of algebraic integers.
Using this new abstract concept, together with a suitable definition of the product of two ideals, Dedekind was able to prove infull generality that, within any ring of algebraic integers, ideals possess a unique decomposition into prime ideals. Dedekind’s proofs do not enable us to calculate, ina particular case, the relevant divisors or ideals: that The influential algebraist Kronecker complained that is, the proof waswas that this abstract way of working, made possible purely existential .
Kronecker’s view by the set-theoretic methods and by a concentration on the algebraic properties of the structures involved, was too remote from an algorithmic treatment—that is, from so-called this complaint was misguided: it merely showed that constructive methods. But for Dedekind he had succeeded in elaborating the principle “to put thoughts in the place of calculations,” a principle that was also emphasized in Riemann’s theory of complex functions.
Obviously, concrete problems would require the development of more delicate computational tech-niques, and Dedekind contributed to this in several papers. But he also insisted on the importance of ageneral, conceptual theory. became better known through publications of the pe-riod 1867–72. These were found particularly shocking The ideas and methods of Riemann and Dedekind

144

because of their very explicit defense of the view that mathematical theories ought not to be based upon formulas and calculations—they should always be basedon clearly formulated general concepts, with analytical expressions or calculating devices relegated to the further development of the theory. larly clear case of the opposition between the differ-ent approaches of Riemann and Weierstrass to func-To explain the contrast, let us consider the particution theory.
Weierstrass explicitly represented analytic(or holomorphic [I.3 §5.6](/part-01/fundamental-definitions)) functions as collections of power series of the formwere connected with each other by. nftyn = 0 an(zanalytic con-- a)n, which ti nu at i on and more abstract approach, defining a function to be[I.3 §5.6](/part-01/fundamental-definitions).
Riemann chose a very different analytic if it satisfies the[I.3 §5.6](/part-01/fundamental-definitions).cauchy–riemann differen-2 This neat conceptual tiability conditions definition appeared objectionable to Weierstrass, as the class of differentiable functions had never been care-fully characterized (in terms of series representations, for example).
Exercising his famous critical abilities, Weierstrass offered examples of continuous functions that were nowhere differentiable. It is worth mentioning that, in preferring infinite series as the key means for research in analysis and function theory, Weierstrass remained closer to the old eighteenth-century idea of a function as an ana-lytical expression. On the other hand, Riemann and Dedekind were always in favor of Dirichlet’s abstract idea of a function$f$as an “arbitrary” way of associating with each$x some y = f (x)$.
(Previously it had been required thaty should be expressed in terms ofters, Weierstrass criticized this conception of Dirich-x by means of an explicit formula.) In his let- let’s as too general and vague to constitute the starting point for any interesting mathematical development. He seems to have missed the point that it was in factjust the right framework in which to define and analyze general concepts such asand integration [I.3 §5.5](/part-01/fundamental-definitions).
This framework came to be continuity [I.3 §5.2](/part-01/fundamental-definitions) called the mathematics.conceptual approach in nineteenth-century areas too. In a letter of 1870, Kronecker went as faras saying that the Bolzano–Weierstrass theorem was Similar methodological debates emerged in other de nt behavior at singular points. These traits determined the function via a2.
Riemann determined particular functions by a series oftraits such as the associated riemann surface [III.79](/part-03/riemann-surfaces) and the in de pen certain variational principle (the “Dirichlet principle”), which was also criticized by Weierstrass, who gave a counterexample to it. Hilbert and Kneser would later reformulate and justify the principle.

II. The Origins of Modern Mathematics

an “obvious sophism,” promising that he would offer counterexamples. The Bolzano–Weierstrass theorem, which states that an infinite bounded set of real numbers has an accumulation point, was a cornerstone of classical analysis, and was emphasized as such by Weierstrass in his famous Berlin lectures. The problem for Kronecker was that this theorem rests entirely on the completeness axiom for the real numbers (which, in one version, states that every sequence of nonempty nested closed intervals in R has a nonempty intersection).
The real numbers cannot be constructed in an elementary way from the rational numbers: one has to make heavy use of infinite sets (such as the set ofall possible “Dedekind cuts,” which are subsets C ⊂ Q such thatbers such thatp \in  Cp < qwhe never and pq and\in  C). To put it anotherq are rational num- way: Kronecker was drawing attention to the problem that, very often, the accumulation point in the Bolzano Weierstrass theorem cannot be constructed by elemen-tary operations from the rational numbers.
The classical idea of the set of real numbers, or “the continuum,”already contained the seeds of the nonconstructive ingredient in modern mathematics. ant theory led to a debate about his purely existen-tial proof of another basic result, the Later on, in around 1890, Hilbert’s work on invari-basis theorem, which states (in modern terminology) that every idealin a polynomial ring is finitely generated. Paul Gordan, famous as the “king” of invariants for his heavily algorithmic work on the topic, remarked humorously that this was “theology,” not mathematics!
(He appar-ently meant that, because the proof was purely existential, rather than constructive, it was comparable with philosophical proofs of the existence of God.)This early foundational debate led to a gradual clarification of the opposing viewpoints. Cantor’s proofs inset theory also became quintessential examples of the modern methodology of existential proof. He offered an explicit defense of the higher infinite and modern methods in a paper of 1883, which was peppered with hidden attacks on Kronecker’s views.
Kronecker in turn criticized Dedekind’s methods publicly in 1882, spoke privately against Cantor, and in 1887 published an attempt to spell out his foundational views. dedekind replied with a detailed set-theoretic (and “thus,” for him, logicistic) theory of the natural numbers in 1888.The early round of criticism ended with an apparent victory for the modern camp, which enrolled new and powerful allies such as Hurwitz, Hilbert, Volterra, Peano, and hadamard minkowski[VI.65](/part-06/jacques-hadamard-18651963), and[VI.64](/part-06/hermann-minkowski-18641909),

II.7. The Crisis in the Foundations of Mathematics which was defended by influential figures such as[VI.57]. Although Riemannian function theory was still klein in need of further refinement, recent developments in real analysis, number theory, and other fields were showing the power and promise of the modern meth-ods. During the 1890 s, the modern viewpoint in general, and logicism in particular, enjoyed great expan-sion.
Hilbert developed the new methodology into the axiomatic method, which he used to good effect in his treatment of geometry (1899 and subsequent editions) and of the real number system. doxes, discovered by Cantor, Russell, Zermelo, and oth-ers, which will be discussed below. These were of two Then, dramatically, came the so-called logical parakinds. On the one hand, there were arguments show-ing that assumptions that certain sets exist lead to contradictions. These were later called the paradoxes.
On the other, there were arguments, laterset-theoretic known as the difficulties with the notions of truth and definability.semantic paradoxes, which showed up These paradoxes completely destroyed the attractive view of recent developments in mathematics that had been proposed by logicism. Indeed, the heyday of logi-cism came before the paradoxes, that is, before 1900; it subsequently enjoyed a revival with Russell and his“theory of types,” but by 1920 logicism was of interest more to philosophers than to mathematicians.
How-ever, the divide between advocates of the modern methods and constructivist critics of these methods wasthere to stay. 2 Around 1900 Hilbert opened his famous list of mathematical prob-lems at the Paris International Congress of Mathematics of 1900 with Cantor’sa key question in set theory, and with the problem continuum problem [IV.22 §5](/part-04/set-theory), of whether every set can be well-ordered. His second problem amounted to establishing the consistency of the notion of the set R of real numbers. It was not by chance that he began with these problems:
rather, itwas a way of making a clear statement about how mathematics should be in the twentieth century. Those two problems, and the axiom of choice [III.1](/part-03/axiom-of-choice) employed by Hilbert’s young colleague Zermelo to show that R (the examples of the traits (i)–(iv) that were listed above. Itcontinuum) can be well-ordered, are quintessential is little wonder that less daring minds objected and revived Kronecker’s doubts, as can be seen in many publications of 1905–6. This brings us to the next stageof the debate.

145

2.1 Paradoxes and Consistency

In a remarkable turn of events, the champions of mod-ern mathematics stumbled upon arguments that cast new doubts on its cogency. In around 1896, Cantor discovered that the seemingly harmless concepts of theset of all ordinals and the set of all cardinals led to contradictions. In the former case the contradiction is usually called thethe Cantor paradox. The assumption that all transfi-Burali-Forti paradox; the latter is nite ordinals form a set leads, by Cantor’s previous results, to the result that there is an ordinal that is lessthan itself—and similarly for cardinals.
Upon learning of these paradoxes, Dedekind began to doubt whether human thought is completely rational. Even worse, in 1901–2 Zermelo and Russell discovered a very elemen-tary contradiction, now known as Russell’s paradox or sometimes as the Zermelo–Russell paradox, which will be discussed in a moment. The untenability of the previous understanding of set theory as logic became clear, and there began a new period of instability. But it should be said that only logicists were seriously up set by these arguments: they were presented with contradictions in their theories.
Let us explain the importance of the Zermelo–Russell paradox. From Riemann to Hilbert, many authors ac-cepted the principle that, given any well-defined logical or mathematical property, there exists a set of all objects satisfying that property. In symbols: given awell-defined propertyp, there exists another object, the set{x}: p(x). For example, corresponding to the property of “being a real number” (which is expressed formally by Hilbert’s axioms) there is the set of all real numbers; corresponding to the property of “being an ordinal” there is the set of all ordinals; and so on.
This is called thethe basis for the logicistic understanding of set theory, comprehension principle, and it constitutes often called naive set theory, although its naivete is only clear with hindsight. The principle was thoughtof as a basic logical law, so that all of set theory was merely a part of elementary logic. The Zermelo–Russell paradox shows that the comprehension principle is contradictory, and it does soby formulating a property that seems to be as basic and purely logical as possible.
Letertyx ∉ x (bearing in mind that negation and mem-p(x) be the prop- bership were assumed to be purely logical concepts).The comprehension principle yields the existence of the set$R = {x}$: x ∉ x, but this leads quickly to a contradiction: if$R \in R$, then R ∉ R(by the definition 146 of R), and similarly, if R ∉ R, then R \in R. Hilbert (like his older colleague logicism, and even wondered whether Kronecker might frege [VI.56](/part - 06/gottlob - frege - 18481925)) was led to abandon have been right all along.
Eventually he concluded thatset theory had shown the need to refine logical theory. It was also necessary to establish set theory axiomatically, as a basic ematical (not logical) axioms, and Zermelo undertook mathematical theory based on maththis task. Hilbert famously advocated that to claim that a set of mathematical objects exists is tantamount to proving that the corresponding axiom system is consistent— that is, free of contradictions. The documentary evi-dence suggests that Hilbert came to this celebrated principle in reaction to Cantor’s paradoxes.
His rea-soning may have been that, instead of jumping directly from well-defined concepts to their corresponding sets, one had first to prove that the concepts are logically consistent. For example, before one could accept the set of all real numbers, one should prove the consistency of Hilbert’s axiom system for them. Hilbert’s principle was a way of removing any metaphysical content fromthe notion of mathematical existence.
This view, that mathematical objects had a sort of “ideal existence” inthe realm of thought rather than an independent metaphysical existence, had been anticipated by Dedekind and Cantor. that go by the names of Burali - Forti, Cantor, and Rus - The “logical” paradoxes included not only the ones sell, but also many semantic paradoxes formulated by Russell, Richard, König, Grelling, etc. (Richard’s paradox will be discussed below.) Much confusion emerged from the abundance of different paradoxes, but one thing is clear:
they played an important role in promot-ing the development of modern logic and convincing mathematicians of the need for strictly formal presen-tation of their theories. Only when a theory has been stated within a precise formal language can one disre-gard the semantic paradoxes, and even formulate the distinction between these and the set-theoretic ones.
2.2 Predicativity When the books of Frege and Russell made the para-doxes of set theory widely known to the mathematical community in 1903, forward criticisms of both logicism and formalism.poincaré [VI.61](/part - 06/jules - henri - poincar - 18541912) used them to put His analysis of the paradoxes led him to coin an important new notion, impredicative definitions should be avoided in mathe - predicativity, and maintain that matics. Informally, a definition is impredicative when II.
The Origins of Modern Mathematics it introduces an element by reference to a totality that already contains that element. A typical example is the following: Dedekind defines the set N of natural numbers as the intersection of all sets that contain1 and are closed under an injective functionσ such$that 1 function$∉.) His idea was to characterizeσ (N). (The function σ is called the N as minimal, successor but in his procedure the set N is first introduced by appeal to a totality of sets that should already include N itself.
This kind of procedure appeared unacceptable to Poincaré (and also to Russell), especially when the relevant object can be specified only by reference to the more embracing totality. Poincaré found examplesof impredicative procedures in each of the paradoxes he studied. Take, for instance, Richard’s paradox, which is one of the linguistic or semantic paradoxes (where, as wesaid, the notions of truth and definability are prominent). One begins with the idea ofbers.
Because definitions must be expressed in a certain definable real num language by finite expressions, there are only count-ably many definable numbers. Indeed, we can explicitly count the definable real numbers by listing them in alphabetical order of their definitions. (This is known as theto this list a diagonal process, of the kind used by Can-lexicographic order.) Richard’s idea was to apply tor to prove that R is not countable [III.11](/part - 03/countable - and - uncountable - sets). Let the definable numbers beberr in a systematic way, making sure that thea1$, a2$, a3, . . ..
Define a new num-$nth$ decimal digit ofdigit of$an$. (For example, let theris different from thenth digit ofnth decimalr be 2 unless thenth digit ofnrth digit ofbe 4.) Thenan ris 2, in which case let thecannot belong to the set of definable numbers. But in the course of this con-struction, the number$r$has just been defined in finitely many words!
Poincaré would ban impredicative definitions and would therefore prevent the introduction ofthe number r, since it was defined with reference to the totality of all definable numbers.3 ematics, all mathematical objects (beyond the natural numbers) must be introduced by explicit definitions. In this kind of approach to the foundations of math If a definition refers to a presumed totality of whichthe object being defined is itself a member, we are involved in a circle: the object itself is then a con-stituent of its own definition.
In this view, “definitions” within a well-determined formal theory, whose language and expres-sions are fixed to begin with. Richard’s paradox takes advantage of an3. The modern solution is to establish mathematical definitions ambiguity as to what the available means of definition are.

II.7. The Crisis in the Foundations of Mathematics must be predicative: one refers only to totalities thathave already been established before the object one is defining. Important authors such as Russell and weyl [VI.80](/part-06/hermann-weyl-18851955) accepted this point of view and developed it. Zermelo was not convinced, arguing that impredicative definitions were often used unproblematical ly, notonly in set theory (as in Dedekind’s definition of N, for example), but also in classical analysis.
As a particular example, he cited cauchy’s [VI.29](/part-06/augustin-louis-cauchy-17891857) proof of the fun[V.13](/part-05/the-fundamental-theorem-of-algebra),4 but a simdamental theorem of algebrapler example of impredicative definition is the least upper bound in real analysis. The real numbers arenot introduced separately, by explicit predicative definitions of each one of them; rather, they are introduced as a completed whole, and the particular way in which the least upper bound of an infinite bounded set ofreals is singled out becomes impredicative.
But Zermelo insisted that these definitions are innocuous, because the object being defined is not “created” by the definition; it is merely singled out (see his paper of 1908 invan Heijenoort (1967, pp. 183–98)). tions became important for Russell, who incorporated it as the “vicious circle principle” in his influential Poincaré’s idea of abolishing impredicative de fin i theory of types logic, with quantification over properties or sets, over. Type theory is a system of higher-order relations, over sets of sets, and so on.
Roughly speaking, it is based on the idea that the elements of anyset should always be objects of a certain homogeneous type. For instance, we can have sets of “individuals,”such as\\{a}, b\\}, or sets of sets of individuals, such as{{a}}$, \\\\{a, b\\\\}$, but never a “mixed” set like{a}$, \\\{a, b\\\}$. Russell’s version of type theory became rather complicated because of the so-called ramification he adoptedin order to avoid impredicativity.
This system, together with axioms of infinity, choice, and “reducibility” (a surprisingly ad hoc means to “collapse” the ramification), sufficed for the development of set theory and the number systems. Thus it became the logical basis forthe renowned Principia Mathematica by Whitehead and Russell (1910–13), in which they carefully developed afoundation for mathematics. about 1930, but under the form of Type theory remained the main logical system until simple type theory tential” as we have been saying.
In order to show that the polynomial must have one root, Cauchy studied the absolute value of the polyno - 4. Cauchy’s reasoning was clearly nonconstructive, or “purely exismial, which has a global minimum i ca tive ly defined. Cauchy assumed that it was positive, and from thisσ . This global minimum is impred- he derived a contradiction. 147 (that is, without ramification), which, as Chwistek, Ram - sey, and others realized, suffices for a foundation in the style ofwere aimed at eliminating worries about i mp red ic at iv - Principia.
Ramsey proposed arguments that ity, and he tried to justify the other existence axioms ofchoice—as logical principles. But his arguments were Principia—the axiom of infinity and the axiom of inconclusive. Russell’s attempt to rescue logicism fromthe paradoxes remained unconvincing, except to some philosophers (especially members of the Vienna Circle).Poincaré’s suggestions also became a key principle for the interesting foundational approach proposed by Weyl in his book Das Kontinuum (1918).
The main idea was to accept the theory of the natural numbers as theywere conventionally developed using classical logic, but to work predicatively from there on. Thus, unlike Brouwer, Weyl accepted the principle of the excluded middle. (This, and Brouwer’s views, will be discussed inthe next section.) However, the full system of the real numbers was not available to him:
in his system the set R was not complete and the Bolzano–Weierstrass theorem failed, which meant that he had to devise sophisti-cated replacements for the usual derivations of results in analysis. The idea of predicative foundations for mathematics, in the style of Weyl, has been carefully developed inrecent decades with noteworthy results (see Feferman 1998). Predicative systems lie between those that coun-tenance all of the modern methodology and the more stringent constructivist ic systems.
This is one of sev-eral foundational approaches that do not fit into the conventional but by now outdated triad of logicism, formalism, and intuitionism. 2.3 Choices As important as the paradoxes were, their impact onthe foundational debate has often been over stated. One frequently finds accounts that take the paradoxes asthe real starting point of the debate, in strong contrast with our discussion in section 1. But even if werestrict our attention to the first decade of the twentieth century, there was another controversy of equal, if not greater, importance:
the arguments that surrounded the axiom of choice and Zermelo’s proof ofthe well-ordering theorem. sets and their defining properties was at the time Recall from section 2.1 that the association between deeply ingrained in the minds of mathematicians and logicians (via the contradictory principle of comprehension). The axiom of choice (AC) is the principle that, 148 given any infinite family of disjoint nonempty sets, there is a set, known as a choice set, that contains exactly one element from each set in the family.
The problem with this, said the critics, is that it merely stipulates the existence of the choice set and does notgive a defining property for it. Indeed, when it is possible to characterize the choice set explicitly, then theuse of AC is avoidable! But in the case of Zermelo’s well-ordering theorem it is essential to employ AC.
The required well-ordering of R “exists” in the ideal sense of Cantor, Dedekind, and Hilbert, but it seemed clear thatit was completely out of reach from any constructivist perspective. Thus, the axiom of choice exacerbated obscurities in previous conceptions of set theory, forcing mathemati-cians to introduce much - needed clarifications. On the one hand, AC was nothing but an explicit statementof previous views about arbitrary subsets, and yet, on the other, it obviously clashed with strongly held views about the need to explicitly define infinite sets by properties.
The stage was set for deep debate. The discus-sions about this particular topic contributed more than anything else to a clarification of the existential impli-cations of modern mathematical methods. It is instructive to know that[VI.72](/part - 06/henri - lebesgue - 18751941), who became critics, had all relied on AC in lessborel [VI.70](/part - 06/emile - borel - 18711956), Baire, and lebesgue obvious ways in order to prove theorems of analysis. Not by chance, the axiom was suggested to Zermeloby an analyst, Erhard Schmidt, who was a student of Hilbert.5 debate developed through out Europe.
Zermelo was spurred on to work out the foundations of set theory After the publication of Zermelo’s proof, an intense in an attempt to show that his proof could be devel-oped within an unexceptionable axiom system. The outcome was his famous axiom system [IV.22 §3](/part - 04/set - theory), a masterpiece that emerged from careful analysis of settheory as it was historically given in the contributions of Cantor and Dedekind and in Zermelo’s own theo - rem.
With some additions due to Fraenkel and von neumannity) and the major innovation proposed by Weyl and[VI.91](/part - 06/john - von - neumann - 19031957) (the axioms of replacement and regular skolem logic [IV.23 §1](/part - 04/logic - and - model - theory), i.e., quantifying over individuals, the[VI.81](/part - 06/thoralf - skolem - 18871963) (to formulate it within first-order sets, but not over their properties), the axiom system became in the 1920 s the one that we now know. by the French analysts in 1905 (see Moore 1982;
Ewald 1996) and Zer - melo’s clever arguments in his second 1908 proof of well - ordering5. One may still gain much insight by reading the letters exchanged (van Heijenoort 1967). II. The Origins of Modern Mathematics with choice”) codifies the key traits of modern math-ematical methodology, offering a satisfactory frame-The ZFC system (this stands for “Zermelo–Fraenkel work for the development of mathematical theories and the conduct of proofs.
In particular, it includes strong existence principles, allows impredicative def-initions and arbitrary functions, warrants purely existential proofs, and makes it possible to define the main mathematical structures. It thus exhibits all the ten - dencies (i)–(iv) mentioned in section 1. Zermelo’s own work was completely in line with Hilbert’s informal axiomatizations of about 1900, and he did not forget to promise a proof of consistency.
Axiomatic set theory, whether in the Zermelo–Fraenkel presentation or the von Neumann–Bernays–Gödel version, is the system that most mathematicians regard as the working foundation for their discipline. As of 1910, the contrast between Russell’s type theory and Zermelo’s set theory was strong. The for-mer system was developed within formal logic, and its point of departure (albeit later compromised for prag-matic reasons) was in line with predicativism;
in order to derive mathematics, the system needed the existential assumptions of infinity and choice, but these were rhetorically treated as tentative hypotheses rather than outright axioms. The latter system was presented infor - mally, adopted the impredicative standpoint wholeheartedly, and asserted as axioms strong existential assumptions that were sufficient to derive all of classi-cal mathematics and Cantor’s theory of the higher infinite. In the 1920 s the separation diminished greatly, especially with respect to the first two traits just indicated.
Zermelo’s system was perfected and formulated within the language of modern formal logic. And the Russellians adopted simple type theory, thus accepting the impredicative and “existential” methodology ofmodern mathematics. This is often given the (potentially confusing) term “Platonism”:
the objects that the theory refers to are treatedof what the mathematician can actually and explicitly as if they were independent define. Meanwhile, back in the first decade of the twentieth century, a young mathematician in the Netherlands was beginning to find his way toward a philosophically col-ored version of constructivism. Brouwer presented his strikingly peculiar metaphysical and ethical views in1905, and started to elaborate a corresponding foundation for mathematics in his thesis of 1907.
His philosophy of “intuitionism” derived from the old metaphys-ical view that individual consciousness is the one and II.7. The Crisis in the Foundations of Mathematics only source of knowledge. This philosophy is perhapsof little interest in itself, so we shall concentrate here on Brouwer’s constructivist ic principles. In the years around 1910, Brouwer became a renowned mathematician, with crucial contributions to topology such as hisfixed point theorem [V.11](/part - 05/fixed - point - theorems).
By the end of World War I, he started to publish detailed elaborations of his foun-dational ideas, helping to create the famous “crisis,” to which we now turn. He was also successful in establishing the customary (but misleading) distinction between formalism and intuitionism. 3 The Crisis in a Strict Sense In 1921, thepaper by Weyl in which the famous mathematician, who Mathematische Zeitschrift published a was a disciple of Hilbert, openly espoused intuitionism and diagnosed a “crisis in the foundations” of mathematics.
The crisis pointed toward a “dissolution” ofthe old state of analysis, by means of Brouwer’s “revolution.” Weyl’s paper was meant as a propaganda pam-phlet to rouse the sleepers, and it certainly did. Hilbert answered in the same year, accusing Brouwer and Weylof attempting a “putsch” aimed at establishing “dictatorship à la Kronecker” (see the relevant papers in Mancosu (1998) and van Heijenoort (1967)).
The foun-dational debate shifted dramatically toward the battle between Hilbert’s attempts to justify “classical” math-ematics and Brouwer’s developing reconstruction of a much - reformed intuitionistic mathematics. Why was Brouwer “revolutionary”? Up to 1920 the key foundational issues had been the acceptability ofthe real numbers and, more fundamentally, of the impredicativity and strong existential assumptions of set theory, which supported the higher infinite andthe unrestricted use of existential proofs.
Set theory and, by implication, classical analysis had been crit-icized for their reliance on impredicative definitions and for their strong existential assumptions (in par - ticular, the axiom of choice, of which extensive use was made by sierpi ́nski [VI.77](/part - 06/wacaw - sierpinski - 18821969) in 1918). Thus, the debate in the first two decades of the twentieth cen-tury was mainly about which principles to accept when it came to defining and establishing the exis-tence of sets and subsets. A key question was, can one make rigorous the vague idea behind talk of “arbi-trary subsets”?
The most coherent reactions had been Zermelo’s axiomatization of set theory and Weyl’s predicative system in Mathematica of Whitehead and Russell was an unsuc-Das Kontinuum. (The Principia 149 cessful compromise between predicativism and classi-cal mathematics.) questions to the fore. No one had questioned the tra-ditional ways of reasoning about the natural numbers: Brouwer, however, brought new and even more basic classical logic, in particular the use of quantifiers andthe principle of the excluded middle, had been used in this context without hesitation.
But Brouwer put for-ward principled critiques of these assumptions and started developing an alternative theory of analysis that was much more radical than Weyl’s. In doing so, he came upon a new theory of the continuum, which finally enticed Weyl and made him announce the coming of a new age. 3.1 Intuitionism Brouwer began systematically developing his viewswith two papers on “intuitionistic set theory,” written in German and published in 1918 and 1919 bythe Verhandelingen of the Dutch Academy of Sciences. These contributions were part of what he regarded asthe “Second Act” of intuitionism.
The “First Act” (from 1907) had been his emphasis on the intuitive founda-tions of mathematics. Already Klein and Poincaré had insisted that intuition has an inescapable role to play in mathematical knowledge: as important as logic is inproofs and in the development of mathematical theory, mathematics cannot be reduced to pure logic; theories and proofs are of course organized logically, but their basic principles (axioms) are grounded in intuition. But Brouwer went beyond them and insisted on the absolute independence of mathematics from language andlogic.
excluded middle (PEM), which he regarded as equiva-lent to Hilbert’s conviction that all mathematical prob-From 1907, Brouwer rejected the principle of the lems are solvable. PEM is the logical principle that the statementp ∨ ¬p (that is, either p or not p) must always be true, whatever the proposition(For example, it follows from PEM that either the deci-p may be.
mal expansion ofit contains only finitely many sevens, even though weπcontains infinitely many sevens or do not have a proof of which.) Brouwer held that our customary logical principles were abstracted from the way we dealt with subsets of a finite set, and that itwas wrong to apply them to infinite sets as well. After World War I he started the systematic reconstruction of mathematics. or The intuitionist position is that one can only state “$q$” when one can give either a constructive proof of$p$

150

pc on sequence that proofs by contradiction (or a constructive proof of q. This standpoint has the reductio ad absurdumof his basis theorem (section 1), achieved by) are not valid. Consider Hilbert’s first proof reductio: he showed that one can derive a contradiction from the assumption that the basis is infinite, and from this he concluded that the basis is finite. The logic behind this procedure is that we start from a concrete instance of PEM, p ∨ ¬p, show that ¬p is untenable, and conclude thatfor explicitp must be true.
But constructive mathematics asks procedures for constructing each object that is assumed to exist, and explicit constructions behindany mathematical statement. Similarly, we have mentioned before (section 2.1) Cauchy’s proof of the fun-damental theorem of algebra, as well as many proofs in real analysis that invoke the least upper bound. All ofthese proofs are invalid for a constructivist, and several mathematicians have tried to save the theoremsby finding constructivist proofs for them.
For instance, both Weyl and Kneser worked on constructivist proofs for the fundamental theorem of algebra. It is easy to give instances of the use of PEM that a constructivist will not accept: one just has to apply itto any unsolved mathematical problem. For example, Catalan’s constant is the number. nfty - n K = n = 0 (2(n + 1)1)2. It is not known whether the statement “Catalan’s constant is transcendental,”K is transcendental, so if p is then a constructivist will not accept thatp is either true or false.
one realizes that constructivists have a different viewabout what truth This may seem odd, or even obviously wrong, untilis. For a constructivist, to say that a proposition is true simply means that we can prove it in accordance with the stringent methods that we are discussing; to say that it is false means that we can actually exhibit a counterexample to it. Since there isno reason to suppose that every existence statement has either a strict constructivist proof or an explicit counterexample, there is no reason to believe PEM (with this notion of truth).
Thus, in order to establish the existence of a natural number with a certain prop - erty, a proof by reductio ad absurdum is not enough. Existence must be shown by explicit determination or construction if you want to persuade a constructivist. Notice also how this viewpoint implies that mathematics is not timeless or ahistorical. It was only in1882 that Lindemann proved thatπ is a transcenden - II. The Origins of Modern Mathematics tal numbersible to assign a truth value to statements that were[III.41](/part - 03/irrational - and-\text{transcendental} - numbers).
Since that date, it has been pos neither true nor false before, according to intuition-ists. This may seem paradoxical, but it was just right for Brouwer, since in his view mathematical objects are mental constructions and he rejected as “metaphysics” the assumption that they have an independent existence.
Zermelo by constructive counterparts, which he would In 1918, Brouwer replaced the sets of Cantor and later call “spreads” and “species.” Aa set that has been defined by a characteristic prop-species is basically erty, but with the proviso that previously and independently defined by an explicit every element has been construction. In particular, the definition of any given species will be strictly predicative. tic of intuitionism, and it forms the basis for Brouwer’s The concept of a spread is particularly character is definition of the continuum.
It is an attempt to avoid idealization and do justice to the temporal nature of mathematical constructions. Suppose, for example, that we wish to define a sequence of rational numbers that gives better and better approximations to the square root of 2. In classical analysis, one con-ceives of such sequences as existing in their entirety, but Brouwer defined a notion that he called asequence, which pays more attention to how they might choice be produced.
One way to produce them is to give a rule, such as the recurrence relation$x = (x2 + 2)/2x$ (and the initial condition make less rigidly determined choices that obey certain$x^{1} = 2)$. But another is to^n^+^1^n^n constraints: for instance, one might insist that denominator$n \text{and that} x^{2}$differs from 2 by at most$x^{n} has$ 100 ensure that the sequence produces better and better/n, which does not determinen xn uniquely but does approximations to$\sqrt{2}$.
A choice sequence is therefore not required to be completely specified from the outset, and it can involve choices that are freely made by the mathematician at different moments in time. Both these features make choice sequences very different from the sequences of classical analysis: it has been said that intuitionist mathematics is “mathematics in the making.” By con-trast, classical mathematics is marked by a kind of timeless objectivity, since its objects are assumed tobe fully determined in themselves and independent of the thinking processes of mathematicians.
A spread has choice sequences as its elements—it is something like a law that regulates how the sequences

II.7. The Crisis in the Foundations of Mathematics are constructed.6 For instance, one could take a spread that consisted of all choice sequences that began insome particular way, and such a spread would represent a segment—in general, spreads do not represent isolated elements, but continuous domains. By using spreads whose elements satisfy the Cauchy condition, Brouwer offered a new mathematical conception of the continuum:
rather than being made up of points (or real numbers) with some previous Platonic existence, it wasmore genuinely “continuous.” Interestingly, this view is reminiscent of Aristotle, who, twenty-three centuries earlier, had emphasized the priority of the continuum and rejected the idea that an extended continuum canbe made up of unextended points. sis was to analyze the idea of a function. brouwer defined a function to be an assignment of values to the The next stage in Brouwer’s redevelopment of an a ly elements of a spread.
However, because of the nature ofspreads, this assignment had to be wholly dependent on an initial segment of the choice sequence in orderto be constructively admissible. This threw up a big surprise: all functions that are every where defined are continuous (and even uniformly continuous). What, you might wonder, about the function whenx < 0 and f (x) = 1 when xf⩾where0? For Brouwer, f (x) = 0 this is not a well-defined function, and the underlying reason for this is that one can determine spreads for which we do not know (and may never know) whether they are positive, zero, or negative.
For instance, one could let2 n are sums of two primes, andxn be 1 if all the even numbers between 4 and - 1 otherwise. tic negation differs in meaning from classical negation. Thus, intuitionistic arithmetic is also different from The rejection of PEM has the effect that intuition is classical arithmetic. Nevertheless, in 1933 Gödel and Gentzen were able to show that the dedekind–peano axioms formalized intuitionistic arithmetic.
(That is, they were[III.67](/part - 03/the - peano - axioms) of arithmetic are consistent relative to able to establish a correspondence between the sen-tences of both formal systems, such that a contradiction in classical arithmetic yields a contradiction in its intuitionistic counterpart; thus, if the latter is consistent, the former must be as well.) This was a small triumph for the Hilbertians, though corresponding proofs Heyting (1956), or more recently van Atten (2003), for further detailson this and other points. One can picture a spread as a subtree of the6.
More precisely, a spread is defined by means of two laws; see universal tree of natural numbers (consisting of all finite sequences ofnatural numbers), together with an assignment of previously available mathematical objects to the nodes. One law of the spread determines nodes in the tree, the other maps them to objects. 151 for systems of analysis or set theory have never beenfound. ment of intuitionism would end in a simple and ele-Initially there had been hopes that the developgant presentation of pure mathematics.
However, as Brouwer’s reconstruction developed in the 1920 s, it became more and more clear that intuitionistic analysis was extremely complicated and foreign. Brouwer was not worried, for, as he would say in 1933, “the spheresof truth are less transparent than those of illusion.” But Weyl, although convinced that Brouwer had delineated the domain of mathematical intuition in a completely satisfactory way, remarked in 1925:
“the mathematician watches with pain the largest part of his tower-ing theories dissolve into mist before his eyes.” Weyl seems to have abandoned intuitionism shortly there - after. Fortunately, there was an alternative approach that suggested another way of rehabilitating classical mathematics. 3.2 Hilbert’s Program This alternative approach was, of course, Hilbert’s pro - gram, which promised, in the memorable phrasing of 1928, “to eliminate from the world once and for all the skeptical doubts” as to the acceptability of the classical theories of mathematics.
The new perspective, whichhe started to develop in 1904, relied heavily on formal logic and a combinatorial study of the formulas that are provable from given formulas (the axioms). With modern logic, proofs are turned into formal computations that can be checked mechanically, so that the process is purely constructivist ic. it is interesting that the new project was to employ Kronecker i an means for a justification of modern, anti-In the light of our previous discussion (section 1), Kronecker i an methodology.
Hilbert’s aim was to showthat it is impossible to prove a contradictory formula from the axioms. Once this had been shown combina-torially or constructively (or, as Hilbert also said, finitarily), the argument can be regarded as a justification of the axiom system—even if we read the axioms astalking about non-Kronecker i an objects like the real numbers or transfinite sets. Still, Hilbert’s ideas at the time were marred by a deficient understanding of logical theory.7 It was only in 1917–18 that Hilbert returned to this topic, now with of 1879 or Peano’s of the 1890 s.
We do not enter into the development of logical theory in this period (see, for example, Moore 1998).7. The logic he presented in 1905 lagged far behind Frege’s system 152 a refined understanding of logical theory and a greater awareness of the considerable technical difficulties of his project. Other mathematicians played very signif-icant parts in promoting this better understanding.
By 1921, helped by his assistant Bernays, Hilbert had arrived at a very refined conception of the formalization of mathematics, and had perceived the need for adeeper and more careful probing into the logical structure of mathematical proofs and theories. His program was first clearly formulated in a talk at Leipzig late in 1922.Here we will describe the mature form of Hilbert’s program, as it was presented for instance in the 1925 paper “On the infinite” (see van Heijenoort 1967).
The main goal was to establish, by means of syntactic con-sistency proofs, the logical acceptability of the principles and modes of inference of modern mathematics. Axiomatics, logic, and formalization made it possible to study mathematical theories from a purely mathe-matical standpoint (hence the name metamathematics), and Hilbert hoped to establish the consistency of the theories by employing very weak means.
In particular, Hilbert hoped to answer all of the criticisms of Weyland Brouwer, and thereby justify set theory, the classical theory of real numbers, classical analysis, and ofcourse classical logic with its PEM (the basis for indirect proofs by The whole point of Hilbert’s approach was to make reductio ad absurdum). mathematical theories fully precise, so that it would become possible to obtain precise results about their properties. The following steps are indispensable forthe completion of such a program.
(i) Finding suitable axioms and primitive concepts fora mathematical theory T , such as that of the real (ii) Finding axioms and inference rules for classical numbers. logic, which makes the passage from given propo-sitions to new propositions a purely syntactic, (iii) formalizing formal procedure.culus, so that propositions of T by means of the formal logical cal - T are just strings of symbols, and proofs are sequences of such strings that obey the formal rules of inference.
(iv) Ashows that it is impossible for a string of symbols finitary study of the formalized proofs of T that that expresses a contradiction to be the last line of a proof. In fact, steps (ii) and (iii) can be solved with rather sim-ple systems formalized in first-order logic, like those II. The Origins of Modern Mathematics studied in any introduction to mathematical logic, suchas Dedekind–Peano arithmetic or Zermelo–Fraenkel set theory.
It turns out that first-order logic is enough for codifying mathematical proofs, but, interestingly, this realization came rather late—after[V.15](/part - 05/gdels - theorem). gödel’s theorems formalized, any proof becomes a Hilbert’s main insight was that, when theories arefinite combinatorial object: it is just an array of strings of symbols com-plying with the formal rules of the system. As Bernays said, this was like “projecting” the deductive structureof a theory T into the number-theoretic domain, and it became possible to express in this domain the consis-tency of T.
These realizations raised hopes that a finitary study of formalized proofs would suffice to estab-lish the consistency of the theory, that is, to prove the sentence expressing the consistency ofnot warranted by the previous insights, turned out to T . But this hope, be wrong.8 that not only the logical calculus but also each of the axiomatic systems would be Also, a crucial presupposition of the program was complete.
Roughly speaking, this means that they would be sufficiently power-ful to allow the derivation of all the relevant results.9 This assumption turned out to be wrong for systems that contain (primitive recursive) arithmetic, as Gödel showed. It remains to say a bit more about what Hilbert meant bythe points in which his program of the 1920 s adopted finitism (for details, see Tait 1981). This is one of to some extent the principles of intuitionists such as Poincaré and Brouwer and deviated strongly from the ideas Hilbert himself had considered in 1900.
The keyidea is that, contrary to the views of logicists like Frege and Dedekind, logic and pure thought require something that is given “intuitively” in our immediate experience: the signs and formulas. In 1905, Poincaré had put forth the view that a formal consistency proof for arithmetic would be circu-lar, as such a demonstration would have to proceed by induction on the length of formulas and proofs, andthus would rely on the same axiom of induction that it was supposed to establish.
Hilbert replied in the 1920 sthat the form of induction required at the meta mathematical level is much weaker than full arithmetical induction, and that this weak form is grounded on the

8. For further details, see, for example, Sieg (1999).9. The notion of “relevant result” should of course be made precise: doing so leads to the notion either of syntactic completeness or ofsemantic completeness.

II.7. The Crisis in the Foundations of Mathematics finitary consider at i on of signs that he took to be intu-itively given. Finitary mathematics was not in need of any further justification or reduction. Hilbert’s program proceeded gradually by studying weak theories at first and proceeding to progressively stronger ones. The metatheory of a formal system studies properties such as consistency, completeness, andsome others (“completeness” in the logical sense means that all true orin the calculus are formally deducible in it).
Proposi-valid formulas that can be represented tional logic was quickly proved to be consistent and complete. First-order logic, also known as predicate logicof 1929. For all of the 1920 s, the attention of Hilbert, was proved complete by Gödel in his dissertation and coworkers was set on elementary arithmetic and its subsystems; once this had been settled, the project was to move on to the much more difficult, but crucial, casesof the theory of real numbers and set theory.
Ackermann and von Neumann were able to establish consis-tency results for certain subsystems of arithmetic, but between 1928 and 1930 Hilbert was convinced that the consistency of arithmetic had already been established. Then came the severe blow of Gödel’s incompleteness results (see section 4). gram, came from the fact that Hilbert’ssisted in formalizing each mathematical theory, and The name “formalism,” as a description of this pro-method conformally studying its proof structure.
However, thisname is rather one-sided and even confusing, especially because it is usually contrasted with intuition-ism, a full-blown philosophy of mathematics. Like most mathematicians, Hilbert never viewed mathematics asa mere game played with formulas. Indeed, he often emphasized the meaningfulness of (informal) mathe-matical statements and the depth of conceptual content expressed in them.10

3.3 Personal Disputes

The crisis was unfolding not just at an intellectual levelbut also at a personal level. One should perhaps tell this story as a tragedy, in which the personalities ofthe main figures and the successive events made the final result quite inescapable. Hilbert and Brouwer were very different personalities, though they were both extremely willful and clevermen. Brouwer’s worldview was idealistic and tended to solipsism. He had an artistic temperament and an edited by Rowe (1992), and also in the 1930 paper that bears exactly the same title (see10.
This is very explicit, for example, in the lectures of 1919–20 Gesammelte Abhandlungen, volume 3).

153

eccentric private life. He despised the modern world, looking to the inner life of the self as the only way out (at least in principle, though not always in practice). He preferred to work in isolation, although he hadgood friends in the mathematical community, especially in the international group of topologists that gathered around him. Hilbert was typically modernist in his views and attitudes; full of optimism and ratio-nalism, he was ready to lead his university, his country, and the international community into a new world.
He was very much in favor of collaboration, and felt happyto join Klein’s schemes for institutional development and power. As a consequence of World War I, Germans in the early 1920 s were not allowed to attend the Interna-tional Congresses of Mathematicians. When the opportunity finally arose in 1928, Hilbert was eager to seize on it, but Brouwer was furious because of restrictions that were still imposed on the German delegation and sent a circular letter in order to convince other math-ematicians. Their viewpoints were widely known and led to a clash between the two men.
On another level, Hilbert had made important concessions to his opponents in the 1920 s, hoping that he would succeed in his project of finding a consistency proof. brouwer emphasized these concessions, accusing him of failing to recognize authorship, and demanded new con-cessions.11 Hilbert must have felt insulted and perhaps even threatened by a man whom he regardedas perhaps the greatest mathematician of the younger generation. had since 1915 been a member of the editorial boardof The last straw came with an episode in 1928.
Brouwer Mathematische Annalen, the most prestigious mathematics journal at the time, of which Hilbert had beenthe main editor since 1902. Ill with “pernicious anemia,” and apparently thinking that he was close to theend, Hilbert feared for the future of his journal and decided it was imperative to remove Brouwer from the editorial board. When he wrote to other members of the board explaining his scheme, which he was already car-rying out, Einstein replied saying that his proposal was unwise and that he wanted to have nothing to do withit.
Other members, however, did not wish to upset the old and admired Hilbert. Finally, a dubious procedure was adopted, where the whole board was dissolved and created anew. Brouwer was greatly disturbed by this Mancosu 1998).11. See his “Intuitionistic reflections on formalism” of 1928 (in

154

action, and as a result of it the journal lost Einstein and Carathéodory, who had previously been main editors (see van Dalen 2005).After that, Brouwer ceased to publish for some years, leaving some book plans unfinished. With his disap-pearance from the scene, and with the gradual disappearance of previous political turbulences, the feelingsof “crisis” began to fade away (see Hesseling 2003). Hilbert did not intervene much in the subsequent debates and foundational developments.
4 Gödel and the Aftermath It was not only the mathematical community as a whole continued to work Annalen war that Hilbert won: the in the style of modern mathematics. And yet his program suffered a profound blow with the publication of Gödel’s famous 1931 article in the Monatshefte für Mathematik und Physik op ment of meta mathematical methods—the arithme-. An extremely ingenious develtization of metamathematics—allowed Gödel to provethat systems like axiomatic set theory or Dedekind Peano arithmetic are incomplete (see[V.15](/part-05/gdels-theorem)).
That is, there exist propositionsgödel’s theorem P formulated strictly in the language of the system such that neither P nor ¬P is formally provable in the system. Hilbert’s endeavor, as it shows that formal proof cannot This theorem already presented a deep problem for even capture arithmetical truth.
But there was more. A close look at Gödel’s arguments made it clear that this first meta mathematical proof could itself be for-malized, which led to “Gödel’s second theorem”—that it is impossible to establish the consistency of the systems mentioned above by any proof that can be codified within them. Gödel’s arithmetization of metamathematics makes it possible to build a sentence, inthe language of formal arithmetic, that expresses the consistency of this same formal system.
And this sen-tence turns out to be among those that are unprovable.12 To express it con tr a positively, a finitary formal proof (codifiable in the system of formal arithmetic)of the impossibility of proving 1= 0 could be trans-formed into a contradiction of the system! Thus, ifthe system is indeed consistent (as most mathematicians are convinced it is), then there is no such fini-tary proof. jenoort (1967), and good introductions to mathematical logic. both theorems were carefully proved in Hilbert and Bernays (1934/39). Bad12.
For further details, see, for example, Smullyan (2001), van He i expositions and faulty interpretations of Gödel’s results abound. II. The Origins of Modern Mathematics von Neumann conjecture” (namely, that if there is afinitary proof of consistency, then it can be formalized According to what Gödel called at the time “the and codified within elementary arithmetic), the second theorem implies the failure of Hilbert’s program (see Mancosu (1999, p. 38) and, for more on the reception, Dawson (1997, pp. 68 ff)).
One should emphasize that Gödel’s negative results are purely constructivist ic andeven finitistic, valid for all parties in the foundational debate. They were difficult to digest, but in the end they led to a reestablishment of the basic terms for foundational studies. tinued to develop brilliantly with Gentzen-style proof theory, with the rise of Mathematical logic and foundational studies con-model theory [IV.23](/part - 04/logic - and - model - theory), etc.— all of which had their roots in the foundational stud-ies of the first third of the twentieth century.
Although the Zermelo–Fraenkel axioms suffice for giving a rig-orous foundation to most of today’s mathematics, and have a rather convincing intuitive justification interms of the “iterative” conception of sets,13 there is a general feeling that foundational studies, insteadof achieving their ambitious goal, “found themselves attracted into the whirl of mathematical activity, and are now enjoying full voting rights in the mathematical senate.”14 Proof theory has developed, leading to noteworthy reductions of classical theories to systems that can be However, this impression is somewhat
superficial. regarded as constructive. A striking example is that analysis can be formalized in conservative extensions of arithmetic: that is, in systems that extend the lan-guage of arithmetic while including all theorems of arithmetic, but which are “conservative” in the sensethat they have no new consequences in the language of arithmetic. Some parts of analysis can even be devel-oped in conservative extensions of primitive recursive arithmetic (see Feferman 1998).
This raises questions about the philosophical bases on which the admissibil-ity of the relevant constructive theories can be founded. But for these systems the question is far less simple than it was for Hilbert’s finitary mathematics; it seems of iterating the following operation: one starts with a basic domain V013. The basic idea is to view the set-theoretic universe as a product(possibly finite or even equal to∅) and forms all possible sets of elements in the domain; this gives a new domain forming sets of$V^{0} ∪V^{1}$, and so on (to infinity and beyond!).
This pro-V1, and one iterates duces an open-ended set-theoretic universe, masterfully described by Zermelo (1930). On the iterative conception, see, for example, the last papers in Bernacerraf and Putnam (1983).14. To use the words of Gian-Carlo Rota in an essay of 1973.

II.7. The Crisis in the Foundations of Mathematics fair to say that no general consensus has yet been reached. Whatever its roots and justification may be, mathematics is a human activity. This truism is clear from the subsequent development of our story. The mathematical community refused to abandon “classical” ideas and methods; the constructivist “revolution” was aborted. In spite of its failure, formalism established itself in practice as the avowed ideology of twentieth-century mathematicians.
Some have remarked that formalism was less a real faith than a Sunday refuge for those whospent their weekdays working on mathematical objects as something very real. The Platonism of working days was only abandoned, as asaid, when a ready-made reply was needed to unwel-bourbaki [VI.96](/part-06/nicolas-bourbaki-1935) member come philosophical questions concerning mathemati-cal knowledge. One should note that formalism suited very well the needs of a self-conscious, autonomous community ofresearch mathematicians.
It granted them full freedom to choose their topics and to employ modern meth-ods to explore them. However, to reflective mathematical minds it has long been clear that it is not the answer. Epistemological questions about mathematical knowledge have not been “eliminated from the world”; philosophers, historians, cognitive scientists, and oth-ers keep looking for more adequate ways of understanding its content and development.
Needless to say, this does not threaten the autonomy of mathematical researchers—if autonomy is to be a concern, perhaps we should worry instead about the pressures exertedon us by the market and other powers. Both (semi-)constructivism and modern mathematics have continued to develop:
the contrast between them has simply been consolidated, though in a very unbalanced way, since some 99% of practicing mathe-maticians are “modern.” (But do statistics matter when it comes to the correct methods for mathematics?) In 1905, commenting on the French debate,[VI.65](/part-06/jacques-hadamard-18651963) wrote that “there are two conceptions of math-hadamard ematics, two mentalities, in evidence.” It has now cometo be recognized that there is value in both approaches: they complement each other and can coexist peacefully.
In particular, interest in effective methods, algorithms, and computational mathematics has grown markedly in recent decades—and all of these are closer to the constructivist tradition. The foundational debate left a rich legacy of ideas and results, key insights and developments, including the formulation of axiomatic set theories and the rise

155

of intuitionism. One of the most important of these developments was the emergence of modern mathematical logic as a refinement of axiomatics, which led tothe theories of recursion and computability in around 1936 (see understanding of the characteristics, possibilities, and algorithms [II.4 §3.2](/part-02/algorithms)). In the process, our limitations of formal systems was hugely clarified. One of the hottest issues through out the whole debate, and probably its main source, was the question of how to understand the continuum.
The reader mayrecall the contrast between the set-theoretic understanding of the real numbers and Brouwer’s approach, which rejected the idea that the continuum is “built of” points. That this is a labyrinthine question was further established by results on Cantor’s continuum hypothesis (CH), which postulates that the cardinality of the set of real numbers isnite cardinal, or equivalently that every infinite subset$\aleph^{1}$, the second transfiof R must biject with either N or with R itself.
Gödel proved in 1939 that CH is consistent with axiomatic set theory, but Paul Cohen proved in 1963 that it is independent of its axioms (i.e., Cohen proved thatthe negation of CH is consistent with axiomatic set theory [IV.22 §5](/part-04/set-theory)). The problem is still alive, with a few mathematicians proposing alternative approaches to the continuum and others trying to find new and con-vincing set-theoretic principles that will settle Cantor’s question (see Woodin 2001).
a definitive way to clarifying the peculiar style and methodology of modern mathematics, especially the The foundational debate has also contributed in so-called Platonism or existential character of modern mathematics (see the classic 1935 paper of Bernays in Benacerraf and Putnam (1983)), by which is meant(here at least) a methodological trait rather than any supposed implications of metaphysical existence. Mod-ern mathematics investigates structures by considering their elements as given independently of human (or mechanical) capabilities of effective definition and construction.
This may seem surprising, but perhaps this trait can be explained by broader characteristics of scientific thought and the role played by mathematical structures in the modeling of scientific phenomena. and its modern methods are still surrounded by impor-tant philosophical problems. When a sizable amount of In the end, the debate made it clear that mathematics mathematical knowledge can be taken for granted, the-orems can be established and problems can be solved with the certainty and clarity for which mathematics is celebrated.
But when it comes to laying out the bare 156 beginnings, philosophical issues cannot be avoided. The reader of these pages may have felt this at several places, especially in the discussion of intuitionism, but also in the basic ideas behind Hilbert’s program, andof course in the problem of the relationship between formal mathematics and its informal counterpart, aproblem that is brought into sharp focus by Gödel’s theorems. Acknowledgments. Paolo Mancosu, José F.
Ruiz, Wilfried Sieg, and the editors I thank Mark van Atten, Jeremy Gray, for their helpful comments on a previous version of thispaper. Further Reading It is impossible to list here all the relevant articlesby Bernays, Brouwer, Cantor, Dedekind, Gödel, Hilbert, Kronecker, von Neumann, Poincaré, Russell, Weyl, Zer - melo, etc. The reader can easily find them in the source books by van Heijenoort (1967), Benacerraf and Putnam(1983), Heinzmann (1986), Ewald (1996), and Mancosu (1998). Benacerraf, P., and H. Putnam, eds. 1983.Mathematics: Selected Readings. Cambridge:
Cambridge Philosophy of Dawson Jr., J. W. 1997.University Press.of Kurt Gödel. Wellesley, MA: A. K. Peters. Logical Dilemmas: The Life and Work Ewald, W., ed. 1996.the Foundations of Mathematics From Kant to Hilbert: A Source Book in, 2 vols. Oxford: Oxford Feferman, S. 1998.University Press. University Press. In the Light of Logic. Oxford: Oxford Ferreirós, J. 1999.Theory and Its Role in Modern Mathematics Labyrinth of Thought: A History of Set. Basel: Birk Heinzmann, G., ed. 1986.häuser. Peano. Paris: Vrin. Poincaré, Russell, Zermelo et II. The Origins of Modern Mathematics Hesseling, D. E.
2003.Brouwer’s Intuitionism in the 1920 s Gnomes in the Fog: The Reception of. Basel: Birkhäuser. Heyting, A. 1956.North - Holland. Third revised edition, 1971.Intuitionism: An Introduction. Amsterdam: Hilbert, D., and P. Bernays. 1934/39.ematik, 2 vols. Berlin: Springer. Grundlagen der Math Mancosu, P., ed. 1998.on the Foundations of Mathematics in the 1920 s From Hilbert to Brouwer: The Debate. Oxford: Oxford University Press.. 1999. Between Vienna and Berlin: the immediate reception of Gödel’s incompleteness theorems.and Philosophy of Logic 20:33–45. History Mehrtens, H. 1990.furt:
Suhrkamp. Moderne—Sprache—Mathematik. Frank Moore, G. H. 1982.Springer. Zermelo’s Axiom of Choice. New York: Encyclopedia of Philosophy Routledge.. 1998. Logic, early twentieth century. In, edited by E. Craig. London: Routledge Rowe, D. 1992.Birkhäuser. Natur und mathematisches Erkennen. Basel: Sieg, W. 1999. Hilbert’s programs: 1917–1922.of Symbolic Logic 5:1–44. The Bulletin Smullyan, R. 2001.ford: Oxford University Press. Gödel’s Incompleteness Theorems. Ox Tait, W. W. 1981. Finitism.van Atten, M. 2003. On Brouwer Journal of Philosophy. Belmont, CA: Wadsworth.78:524–46. van Dalen, D.
1999/2005.The Life of L. E. J. Brouwer Mystic, Geometer, and Intuitionist:. Volume I: The Dawning Revolution University Press.. Volume II: Hope and Disillusion. Oxford: Oxford van Heijenoort, J., ed. 1967.Book in Mathematical Logic From Frege to Gödel: A Source. Cambridge, MA: Harvard Weyl, H. 1918.Whitehead, N. R., and B. Russell. 1910/13.University Press. (Reprinted, 2002.)Das Kontinuum. Leipzig: Veit. Principia mathematica edition 1925/27. (Reprinted, 1978.). Cambridge: Cambridge University Press. Second Woodin, W. H. 2001.
The continuum hypothesis, I, II.of the American Mathematical Society 48:567–76, 681–90.Notices Mathematical Concepts III.1 The Axiom of Choice Consider the following problem: it is easy to find two irrational numbersa and b such that a + b is rational, or such thata = . qrt{2} andabb = −is rational (in both cases one could take. qrt{2}), but is it possible for a^b to be rational? Here is an elegant proof that the answer is yes. Let$x = \sqrt{2} \sqrt{}^{2}$.
If x is rational then we have our example.$But$ x. qrt2 = . qrt{2}2 = 2 is rational, so if x is irrational then again we have an example. Now this argument certainly establishes that it is possible fora and b to be irrational and for ab to be rational. However, the proof has a very interesting feature: it is nonconstructive, in the sense that it does not actually name two irrationals Instead, it tells us that either we can takea and bathat work.= b = . qrt{2} or we can takenot tell us which of these alternatives will work, it gives$a = \sqrt{2} \sqrt{}^{2} and b = \sqrt{2}$.
Not only does it us absolutely no clue about how to find out. Arguments of this kind have troubled some philosophers and philosophically inclined mathematicians, butas far as mainstream mathematics goes they are a fully accepted and important style of reasoning. Formally, we have appealed to the “law of the excluded middle.” We have shown that the negation of the statement cannot be true, and deduced that the statement itself must be true.
A typical reaction to the proof above isnot that it is in any sense invalid, but merely that its nonconstructive nature is rather surprising. Nevertheless, faced with a nonconstructive proof, it is very natural to ask whether there is a constructive proof. After all, an actual construction may give usmore insight into the statement, which is an important point since we prove things not only to be surethey are true but also to gain an idea of why they are true.
Of course, to ask whether there is a constructive proof is not to suggest that the nonconstructive proof is invalid, but just that it may be more informative tohave a constructive proof.

Part III

use for building sets out of other sets. Typical exam-ples of such rules are the statement that for any set The axiom of choice is one of several rules that we A we can form the set of all its subsets, and the statement that for any set A and any property p we can form the set of all elements of A that satisfy p (these are usually called thehension, respectively). Roughly speaking, the axiom ofpower-set axiom and the axiom of com pre choice says that we are allowed to make an arbitrary number of unspecified choices when we wish to form a set.
so natural that one may not even notice that one isusing it, and indeed it was applied by many math-Like the other axioms, the axiom of choice can seem ematicians before it was first formalized. To get anidea of what it means, let us look at the well-known proof that the union of a countable family of countable setsily is countable allows us to write out the sets in a[III.11](/part - 03/countable - and - uncountable - sets) is countable. The fact that the famlistual set A1, AA2, Ais countable allows us to write its elements3, . . .
, and then the fact that each individ- in a list finding some systematic way of counting through the(an)n 1, (an)2, (an)3, . . .. We then finish the proof by elements Now in that proof we actually made an infinite num-anm. ber of unspecified choices. We were told that each A was countable and then for each$An$we “chose” a list-$n$ ing of the elements ofwe had made. Moreover, since we are told absolutely An without specifying the choice nothing about the setssay how we choose to list them.
This remark does not$An$, it is clearly impossible to invalidate the proof, but it does show that it is nonconstructive. (Note, however, that if we are actually toldwhat the sets An are, then we may well be able to spec- ify listings of their elements and thereby give a con-structive proof that the union of those particular sets is countable.)Here is another example. A graph [III.34] is bipartite Y in such a way that no two vertices in the same classif its vertices can be split into two classes X and

158

are connected by an edge. For example, any even cycle(an even number of points arranged in a circle, with consecutive points joined) is bipartite, while no odd cycle is. Now, is an infinite disjoint union of even cycles bipartite? Of course it is: we just split each of the individual cycleslet X be the union of the sets C into two classes X Xand C and Y be the union YC and then of the sets YC. But how do we choose for each cycle CCwe cannot actually specify how we do this, so we arewhich set to call XC and which to call YC?
Again, using the axiom of choice (even if we do not explicitly say so). In general, the axiom of choice states that if we are given a family of nonempty setsan elementxi from each one. More precisely, it states Xi, then we may select that if the X are nonempty sets, where i ranges overi

some index setsuch thatf (i) \in I, then there is a function X for all i. Such a function fdef in ed onf is called Ii

a choice function For one set we do not need any separate rule to dofor the family. this: indeed, the statement that a set exactly the statement that there exists X1 xis nonempty is\in  X . (More formally, we might say that the function f1 that takes 11 toof the single set$x1$is a choice function for the “family” that consists$X1$.) For two sets, and indeed for any finite collection of sets, one can prove the existence ofa choice function by induction on the number of sets.
But for infinitely many sets it turns out that one cannot deduce the existence of a choice function from theother rules for building sets. choice? The main reason is that if it is used in a proof, then that part of the proof is automatically noncon-Why do people make a fuss about the axiom of structive. This is reflected in the very statement of theaxiom.
For the other rules that we use, such as “one may take the union of two sets,” the set whose exis-tence is being asserted is uniquely defined by its properties (u is an element of X ∪ Y if and only if it is an element ofwith the axiom of choice: the object whose existence is X or of Y or of both). But this is not the case asserted (a choice function) is not uniquely specified byits properties, and there will typically be many choice functions.
ematics is that, although there is nothing wrong withusing the axiom of choice, it is a good idea to signal For this reason, the general view in mainstream maththat one has used it, to draw attention to the fact thatone’s proof is not constructive. the axiom of choice is An example of a statement whose proof involves the banach–tarski paradox

III. Mathematical Concepts

[V.3](/part-05/the-banachtarski-paradox). This says that there is a way of dividing upa solid unit sphere into a finite number of subsets and then reassembling these subsets (using rotations, reflections, and translations) to form two solid unit spheres. The proof does not provide an explicit way of defining the subsets. It is sometimes claimed that the axiom of choice has “undesirable” or “highly counter intuitive” consequences, but in almost all cases a little thought reveals that the consequence under consider at i on is actually not counter intuitive at all.
For example, consider the Banach–Tarski paradox above. Why does it seem strange and paradoxical? It is because we feel that volume has not been preserved. And indeed, this feeling can be converted into a rigorous argument that the subsets used in the decomposition cannot all be sets towhich one can meaningfully assign a volume. But that is not a paradox at all:
we can say what we mean by the volume of a nice set such as a polyhedron, but there isno reason to suppose that we can give a sensible definition of volume forject called measure theory can be used to give a volumeall subsets of the sphere. (The subto a very wide class of sets, called the measurable sets [III.55](/part-03/measures), but there is no reason at all to believe that allsets should be measurable, and indeed it can be shown, again by a use of the axiom of choice, that there are setsthat are not measurable.) There are two forms of the axiom of choice that are more often used in daily
mathematical life thanthe basic form we have been discussing. One is the well-ordering principlebe well-ordered [III.66](/part-03/ordinals). The other is, which states that every set can Zorn’s lemma, which states that under certain circumstances “maximal” elements exist. For example, a basis for a vector space is precisely a maximal linearly independent set, and it turns out that Zorn’s lemma applies to the col-lection of linearly independent sets in a vector space, which shows that every vector space has a basis.
of choice because they are equivalent to it, in the sensethat each one both implies the axiom of choice and may These two statements are called forms of the axiom be deduced from it, in the presence of the other rulesfor building sets. A good way of seeing why these two other forms of the axiom have a nonconstructive feelto them is to spend a few minutes trying to find a wellordering of the reals, or a basis for the vector space ofall sequences of real numbers.
For more about the axiom of choice, and especially about its relationship to the other axioms of formal settheory, see set theory [IV.22](/part-04/set-theory).

III.3. Bayesian Analysis

III.2 The Axiom of Determinacy

Consider the following “infinite game.” Two players, A and B, take turns to name natural numbers, with Agoing first, say. By doing this, they generate an infinite sequence. A wins the game if this sequence is “eventu-ally periodic,” and B wins if it is not. (An eventually periodic sequence is one like 1,56, 4, 5, 8, 3, 5, 8, 3, 5, 8,3,5, 8 to a recurring pattern.) It is not hard to see that B, 3, . . .: that is, one that settles down after a while has a winning strategy for this game, since eventu-ally periodic sequences are rather special.
However, at any stage of the game it is always possible that Awill win (if B plays sufficiently badly), since every finite sequence is the beginning of many eventually periodic sequences. More generally, any collection Sof infinite sequences of natural numbers gives rise to an infinite game: A’sobject is now to ensure that the sequence produced is one of the sequences inthe reverse. The resulting game is called$S$, and B’s object is to ensure determined if one of the two players has a winning strategy.
As wehave seen, the game is certainly determined when S is the set of eventually periodic sequences, and indeed for just about any setsee that the corresponding game is determined. Never-S that one writes down it is easy to theless, it turns out that there are games that are not determined.
(It is an instructive exercise to see where the plausible-seeming argument, “If A does not have awinning strategy, then A cannot force a win, so B must have a winning strategy,” breaks down.) but the constructions use It is not too hard to construct nondetermined games, the axiom of choice [III.1](/part-03/axiom-of-choice):
roughly speaking, one can well-order all possible strate-gies so that each one has fewer predecessors than there are infinite sequences, and select sequences to belongto S or its complement in a way that stops each strat- egy in turn from being a winning strategy for either player. determined. It contradicts the axiom of choice, but itis a rather interesting axiom when it is added to The axiom of determinacy states that all games arethe zermelo–fraenkel axioms turns out, for example, to imply that many sets of[III.99](/part-03/the-zermelofraenkel-axioms) without choice.
It reals have surprisingly good properties, such as being Lebesgue measurable. Variants of the axiom of determinacy are closely connected with the theory of large cardinals. For more details, see set theory [IV.22](/part-04/set-theory).

159

Banach Spaces

See normed spaces and banach spaces

[III.62](/part-03/normed-spaces-and-banach-spaces)

III.3 Bayesian Analysis

Suppose you throw a pair of standard dice. The proba-bility that the total is 10 is 1 because there are thirtysix ways the dice can come up, of which three (4 and6, 5 and 5, and 6 and 4) give 10. If, however, you look12 at the first die and see that it came up as a 6, then the conditional probability that the total is 10, given this information, isother die comes up as a 4).16 (since that is the probability that the In general, the probability of A given Bis defined to be the probability ofof B. In symbols, one writes A and B divided by the probability P[A|B] = P[AP[B]∧ B] .
From this it follows that P[A ∧ B] is the same as PP[B[A∧∧A]B]. Therefore,= P[A|B] P[B]. Now P[A|B] P[B] = P[B|A] P[A], since the left-hand side isside is P[B ∧ A]. Dividing through by P[A ∧ B] and the right-hand P[B] we obtain Bayes’s theorem: P[A|B] = P[B|PA][B]P[A], which expresses the conditional probability of B in terms of the conditional probability of B given A given A. dom data given by an unknown tion A fundamental problem in statistics is to analyze ran-[III.71](/part - 03/probability - distributions). Here, Bayes’s theorem can make a signif-probability distri bui cant contribution.
 For example, suppose you are toldthat some unbiased coins have been tossed and that three of them have come up heads. Suppose that youare told that the number of coins tossed is between 1 and 10, and that you wish to guess this number. Letstand for the event that three coins came up heads and$H3$ letand 10 it is not hard to calculate the conditional prob-C be the number of coins. Then for each n between 1 ability reverse, namely P[H3|C =P[Cn]=, but we would like to know then|H ]. Bayes’s theorem tells us that it is P$[H^{3}|C = n] P[CP[H = {}^{3}n]]$.
This would tell us the ratios between the various con-ditional probabilities P[C = n|H ] if we knew what the$160 probabilities P$[C = n] were. Typically, one does not know this, but one makes some kind of guess, called aprior distribution. For example, one might guess, before knowing that three coins had come up heads, that for eachcoins had been chosen wasn between 1 and 10 the probability that1. After this information, n one would use the calculation above to revise one’sassessment and obtain a posterior distribution10 , in which the probability that1 P[H |C = n].
C = n would be proportional to 10 There is more to Bayesian analysis than simply apply-3 ing Bayes’s theorem to replace prior distributions byposterior distributions. In particular, as in the example just given, there is not always an obvious prior distribution to take, and it is a subtle and interesting mathematical problem to devise methods for choosing prior distributions that are “optimal” in different ways.
For further discussion, seecal statistics [VII.11](/part-07/mathematics-and-medical-statistics) and mathematical statistics mathematics and medi[VII.10](/part-07/mathematical-statistics). III.4 Braid Groups F. E. A. Johnson Take two parallel planes, each punctured at Label the holes 1 ton in each plane, and run a stringn points. from each hole in the first plane to one in the second, in such a way that no two strings go to the same hole. The result is ann-braid.
Two different 3-braids, shown in two-dimensional projection in a similar manner toknot diagrams [III.44](/part-03/knot-polynomials), are given in figure 1. go from left to right without “doubling back”; so, for example, a knotted string is not allowed. As the diagrams suggest, we insist that the strings braid: provided that the string ends remain fixed andthe strings do not break or pass through each other, A certain freedom is allowed when we describe a one can stretch, contract, bend, and otherwise movethe strings about in three dimensions and end up with the “same” braid.
This notion of “sameness” is an equivalence relation [I.2 §2.3](/part - 01/language - and - grammar) called braid isotopy. braids end to end to abut in a common (middle) plane, join up the strings, and remove the middle plane. For Braids may be composed as follows: arrange a pair of the braids X and Yin figure 1, the composition XY is given in figure 2.With this notion of composition, n-braids form a where groupthe strings tight” shows that Bn.
In our example, YXY= is isotopic to the X^-1, since “pulling all trivial thereader may perceive a similarity between the braid (figure 3), which acts as the identity. adjacent transpositions that generate the group

III. Mathematical Concepts

}

1 1

2 2

3 3

X

}

1 1

2 2

3 3

Y

Figure 1 Two 3-braids.

1 1

2 } } 2

3 3

X Y

Figure 2 Braid composition.

1 1

2 2

3 3

Figure 3 The trivial braid.

As a group,σ is formed from the trivial braid by crossing Bn is generated by elements (σi()1()⩽){i}⩽ n -1, iith string over the (i + 1)st as in figure 4. The

σi and the Sn of III.5. Buildings i− 1 i − 1 i i i+ 1 i + 1$i$+ 2 i + 2σ

i

Figure 4 The generatorσi.

permutations [III.68](/part-03/permutation-groups) of$\\{1}$, . . . , n\\\\\\\\\\\\\\\\\\\\}. Indeed, any braid determines a permutation by the rule i \to  right-hand label of ith string. Ignoring everything except the behavior at the endsgives a surjective homomorphism B \to S, which mapsσ to the transposition (i, i + 1). This isn notn an iso-i

morphism, however, asnite order, whereas the transposition Bnis infinite. In fact,(i, i + σ1)i has infi-squares to the identity. In his celebrated 1925 paper “The orie der Zöpfe,” artin [VI.86](/part-06/emil-artin-18981962) showed that multiplication in Bn is completely described by the relationsσiσj = σjσi (|i - j| ⩾ 2)$,σiσi + 1σi = σi + 1σiσi + 1$.

These relations have subsequently acquired impor-tance in statistical physics, where they are known as the Yang–Baxter equations. In groups defined by generators and relations it is usually difficult (there being no method that works uniformly in all cases) to decide whether an arbitrary word in the generators represents the identity element(see geometric and combinatorial group theory [IV.10](/part-04/geometric-and-combinatorial-group-theory)).
Forcally, by “combing the braid.” An alternative algebraic$Bn$, Artin solved this problem geometri- method, due to Garside (1967), also decides when two elements in B are conjugate. in many other respects, braid groups display close In relation to the decidability of such questions, and$n$ affinities with elements behave as if they were invertible linear groups: that is, groups in which all$N \times N matri-$ ces.
Although such similarities suggested that it shouldbe possible to prove that braid groups genuinely are linear, the problem of doing so remained unsolved for many years, until in 2001 a proof was eventually foundby Bigelow and independently by Krammer.

161

braid groups of the plane, the plane being the object punctured. Other braid groups also occur, often in sur-The groups described here are, strictly speaking, prising contexts. The connection with statistical phys-ics has already been mentioned. They also arise in algebraic geometry, when algebraic curves become punc-tured by discarding exceptional points. Thus, though originating in topology, braids may intervene signifi-cantly in areas such as “constructive Galois theory” that seem at first sight to be purely algebraic. III.5 Buildings

Mark Ronan

The invertible linear transformations on a vector spaceform a group, called the general linear group. Ifn is the dimension of the vector space and Kis the field of scalars, then it is denoted by GLa basis for the vector space, then each group elementn(K), and if we pick can be written as ann . imes n matrix whose determinant [III.15](/part - 03/determinants) is nonzero. This group and its subgroups are ofgreat interest in mathematics, and can be studied “geometrically” in the following way.
Instead of looking at the vector space unique role and is fixed by the group, we use the V, where of course the origin plays apro- jective spaceof projective space are the one-dimensional subspaces[I.3 §6.7](/part - 01/fundamental - definitions) associated with V: the points ofplanes are the three-dimensional subspaces, and so on. V , the lines are the two-dimensional subspaces, the tained by imposing constraints on the linear maps (ormatrices). For example, SLSeveral important subgroups of GLn(K) consists of all linearn(K) can be ob- transformations of determinant 1.
The group Osists of all linear transformationsα of an n(n)-dimen-con- sional real inner-product space such thatαv, αw =all real matrices ally, one can define many similar subgroups of GLv, w for any two vectors A such thatv and AAw T (or in matrix terms = I); more gener - n(K) by taking all linear maps that preserve certain forms, such as bilinear or sesquilinear forms. These subgroups are called classical groups. The classical groups are either simple or close to simple (for example, we canoften make them simple by quotienting out by the subgroup of scalar matrices).
When complex numbers, the classical groups are Kis the field of real or Lie groups. lie theory classical groups, which fall into one of four families, Lie groups and their classification are discussed in[III.48](/part - 03/lie - theory): the simple Lie groups comprise the known asnumber), along with other types known as$A^{n}$, Bn, Cn, and Dn (where n is a natural E6$, E7$, E8, 162 Fsions of the groups. For example, the groups of type4, and G2. The subscripts are related to the dimen-Ainnnare the groups of invertible linear transformations+ 1 dimensions.
field, where they are often referred to as Lie type These simple Lie groups have analogues over any. For example, Kcan be a finite field, in which groups of case the groups are finite. It turns out that almost all finite simple groups are of Lie type: seefication of finite simple groups [V.7](/part-05/the-classication-of-finite-simple-groups). A geometric the class i theory underlying the classical groups had been devel-oped by the first half of the twentieth century.
It used projective space and various subgeometries of projective space, which made it possible to provide analogues for the classical groups, but it did not provide analogues for the groups of typesthis reason, Jacques Tits looked for a geometric theory$E^{6}$, E7$, E8$, F4$, and G2$. For that would embrace all families, and ended up creating the theory of The full abstract definition of a building is somewhat buildings. complicated, so instead we shall try to give some idea ofthe concept by looking at the building associated with the groups GLn(K) and SLn(K), which are of type (An)-1.
This building is ancan be thought of as a higher-dimensional analogue of aabstract simplicial complex, which graph vertices[III.34]. It consists of a collection of points called; as in a graph, some pairs of vertices form edges; however, it is then possible for triples of vertices to form two-dimensional vertices to form(k - 1)-dimensional “simplexes.” (Thefaces, and for sets of$k$ geometrical meaning of the word “simplex” is a con-vex hull of a finite set of points in general position:
for instance, a three-dimensional simplex is a tetrahedron.) All faces of simplexes must also be included, so for example three vertices cannot form a two-dimensional face unless each pair is joined by an edge. To form the building of type$A^{-}$, we start by taking all the 1-spaces, 2-spaces, 3-spaces, and so on (corre-$n^{1}$ sponding to points, lines, planes, and so on, in projec-tive space), and treat them as “vertices.” The simplexes are formed by all nested sequences of proper sub - spaces:
for example, a 2-space inside a 4-space inside a 5-space will form a “triangle” whose vertices are these three subspaces. The simplexes of maximal dimen-sion haven - 1 vertices: a 1-space inside a 2-space inside a 3 - space, and so on. These simplexes are called chambers. There are many subspaces, so a building is a huge object. However, buildings have important subgeome-tries called apartments, which in the(An)-1 case are III. Mathematical Concepts obtained by taking a basis for the vector space, andthen taking all subspaces generated by subsets of this basis.
For example, in the A3 case our vector space is four dimensional, so a basis has four elements; its subsets span four 1 - spaces, six 2 - spaces, and four 3 - spaces. To visualize this apartment it helps to viewthe four 1-spaces as the vertices of a tetrahedron, the six 2-spaces as the midpoints of its edges, and the four 3-spaces as the midpoints of its faces. The apartment has twenty-four chambers, six for each face of the original tetrahedron, and they form a triangular tiling ofthe surface of the tetrahedron.
This surface is topologically equivalent to a sphere, as are all apartments of this building: such buildings are called buildings for the groups of Lie type are all spherical, spherical. The and, just asments are related to the regular and semiregular poly - A3 is related to the tetrahedron, their apart- hedra inn dimensions, where n is the subscript in the Lie notation given earlier. Buildings have the following two noteworthy features. First, any two chambers lie in a common apart - ment: this is not obvious in the example above but it can be proved using linear algebra.
Second, in any building all apartments are isomorphic and any two apartments intersect nicely: more precisely, if A and A^ are apart- ments, thenphism from AAto∩AAthat fixesis convex and there is an isomor- A∩A. These two features were originally used by Tits in defining buildings. a pleasing geometric basis for the groups of Lie type: itcan also be used to construct the ones of types The theory of spherical buildings does not just give E , E , Es op his ti cated machinery such as Lie algebras.
Once the8$, and F4$, for an arbitrary field K, without the need fo(r6)7 building has been constructed (and a construction canbe given in a surprisingly simple manner), a theorem of Tits on the existence of automorphisms shows that thegroups themselves must exist. In a spherical building the apartments are tilings of a sphere, but other types of buildings also play signifi-cant roles. Of particular importance are affine buildings, in which the apartments are tilings of Euclidean space;
such buildings arise in a natural way from groups, such as GLn(K), where K is a p-adic field [III.51](/part-03/local-and-global-in-number-theory). For such fields there are two buildings, one spherical and oneaffine, but the affine one carries more information and yields the spherical building as a structure “at infin-ity.” Going beyond affine buildings, there are hyperbolic buildings, whose apartments are tilings of hyperbolic space; they arise naturally in the study of hyperbolic Kac–Moody groups.

III.6. Calabi–Yau Manifolds

III.6 Calabi–Yau Manifolds

Eric Zaslow

1 Basic Definition

Calabi–Yau manifolds, named after Eugenio Calabi and Shing-Tung Yau, arise in Riemannian geometry and algebraic geometry, and play a prominent role in string theory and mirror symmetry. to recall the notion of orientability on a realfold In order to explain what they are, we need first[I.3 §6.9](/part-01/fundamental-definitions). Such a manifold is orientable if youmanican choose coordinate systems at each point in sucha way that any two systemsx = (x1, . . . , xm) andygive rise to a positive Jacobian: det= (y1, . . . , ym)that are defined on overlapping sets(. artial yi/. artial xj) > 0.
The notion of a Calabi–Yau manifold is the natural complex analogue of this. Now the manifold is complex, and for each local coordinate system z = (z1, . . . , zn) one has avital that holomorphic functionf should be nonvanishing[I.3 §5.6](/part - 01/fundamental - definitions): that is, it neverf (z). It is takes the value 0. There is also a compatibility condi-tion: i. ar{f}z(z) is another coordinate system, then the cor- responding function  ̃$f = f$ ̃$\det (\partial z$ ̃$a/\partial z^{b})$.
Note that if we replace all complexf is related to f by the equation terms by real terms in this definition, then we have thenotion of a real orientation. So a Calabi–Yau manifold can be thought of informally as a complex manifold with complex orientation. 2 Complex Manifolds and Hermitian Structure Before we go any further, a few words about complex and Kähler geometry are in order. A complex manifoldis a structure that looks locally like Cn, in the sense that one can find complex coordinates$z = (z^{1}$, . . . , zn) near every point.
Moreover, where two coordinate sys-tems$z$and  ̃zoverlap, the coordinates  ̃$z^{a} \text{are holomor}-$ phic when they are regarded as functions of the$z^{b}$. Thus, the notion of a holomorphic function on a com-plex manifold makes sense and does not depend on the coordinates used to express the function.
In this way, the local geometry of a complex manifold does indeed look like an open set inpoint looks like Cn itself. Cn, and the tangent space at a Hermitian On complex vector spaces it is natural to consider inner products [III.37](/part-03/bayesian-analysis) represented by hermitian matrices$ea$. On complex manifolds, a Hermitian inner product[III.50 §3](/part-03/linear-operators-and-their-properties)(ga)b^ ̄ with respect to a basis on the tangent spaces is called a “Hermitian metric,”

163

and is represented in a coordinate basis by a hermitian matrixg , which depends on position.1 ab^ ̄

3 Holonomy, and Calabi–Yau Manifolds

in Riemannian Geometry

On avector along a path so as to keep it of constant length riemannian manifold [I.3 §6.10](/part-01/fundamental-definitions) one can move a and “always pointing in the same direction.”expresses the fact that the vector you wind up with at Curvature the end of the path depends on the path itself. Whenyour path is a closed loop, the vector at the starting point comes back to a new vector at the same point.(A good example to think about is a path on a sphere that goes from the North Pole to the equator, then aquarter of the way around the equator, then back to the North Pole again.
When the journey is completed, the “constant” vector that began by pointing south will have been rotated by 90◦.) With each loop we asso- ciate a matrix operator called thewhich sends the starting vector to the ending vector; holonomy matrix, the group generated by all of these matrices is calledthe holonomy group of the manifold. Since the length of the vector does not change during the process ofkeeping it constant along the loop, the holonomy matrices all lie in the orthogonal group of length-preserving matrices, O(m).
If the manifold is oriented, then the holonomy group must lie in SO(m), as one can see by transporting an oriented basis of vectors aroundthe loop. is also a real manifold of (real) dimension which one can think of as coordinatized by the real Every complex manifold of (complex) dimension$m = 2nn$, and imaginary parts of the complex coordinates$z^{j}$. Real manifolds that arise in this way have additional structure.
For example, the fact that we can multiply complex coordinate directions by ithat there must be an operator on the real tangent$= \sqrt{-1} implies$ space that squares to±i, which can be thought of as “holomorphic” and-1. This operator has eigenvalues “anti-holomorphic” directions. The Hermitian property states that these directions are orthogonal, and we say that the manifold istransport around loops. This means that the holon-Kähler if they remain so after omy group is a subgroup of Usubgroup of SO(m): complex manifolds always have(n) (which itself is a realof the Kähler property:
if orientations). There is a nice local character izationg^ ̄ are the components ofab Hermitian inner product.1. The notationga^ ̄b indicates the conjugate-linear property of a 164 the Hermitian metric in some coordinate patch, thenthere exists a functionφ on that patch such that g = ab^ ̄. artial2φ/. artial za. artia. ar{l} zb.

definition of a Calabi–Yau manifold given above—a Given a complex orientation—that is, the nonmetric compatible Kähler structure lies in SU(n) ⊂ U(n), the natural analogue of the caseleads to a holonomy that of real orientation. This is the metric definition of a Calabi–Yau manifold. 4 The Calabi Conjecture Calabi conjectured that, for any Kähler manifold of complex dimension there exists a functionn and any complex orientation, uand a new Kähler metric  ̃g, given in coordinates by g̃ a^ ̄b = ga^ ̄b + . artial z. artia(la)2. artial u. ar{z}b , that is compatible with the orientation.
In equations, the compatibility condition states that . et ga^ ̄b + . artial z. artia(la)2. artial u. ar{z}$b = |f |2$, wherecussed above. Thus, the metric notion of a Calabi–Yauf is the holomorphic orientation function dis- manifold amounts to a formidable nonlinear partial dif-ferential equation foru. Calabi proved the uniqueness and Yau proved the existence of a solution to this equation. So in fact the metric definition of a Calabi–Yau manifold is uniquely determined by its Kähler structure and its complex orientation.
Yau’s theorem establishes that the space of metrics with holonomy group SUplex orientation is in correspondence with the space(n) on a manifold with com- of in equivalent Kähler structures. The latter space can easily be probed with the techniques of algebraic geometry. 5 Calabi–Yau Manifolds in Physics Einstein’s theory of gravity, general relativity, con-structs equations that the metric of a Riemannian space-time manifold must obey (see general relativity equations involve three symmetric tensors:
the metric, and the einstein equations [IV.13](/part - 04/general - relativity - and - the - einstein - equations)). The the ricci curvature [III.78](/part - 03/ricci - flow) tensor, and the energymomentum tensor of matter. A Riemannian manifold whose Ricci tensor vanishes is a solution to these equations when there is no matter, and is a special caseof an Einstein manifold. A Calabi–Yau manifold with III.
Mathematical Concepts its unique SUtensor, and is therefore of interest in general relativity.(n)-holonomy metric has vanishing Ricci A fundamental problem in theoretical physics is the in corporation of Einstein’s theory into the quantum theory of particles. This enterprise is known as quantum gravity nent ly in the leading theory of quantum gravity,, and Calabi–Yau manifolds figure promi-string theory [IV.17 §2](/part - 04/vertex - operator - algebras).
dimensional “strings.” The motion of the strings inspace-time is described by two-dimensional trajecto-In string theory, the fundamental objects are oneries, known assheet is labeled by the point in space-time where it sits.worldsheets, so every point on the world In this way, string theory is constructed from a quan-tum field theory of maps from two-dimensional riemann surfaces The two-dimensional surface should be given a Rie-[III.79](/part - 03/riemann - surfaces) to a space-time manifold M . mannian metric, and there is an infinite-dimensional space of such metrics to consider.
This means thatwe must solve quantum gravity in two dimensions— a problem that, like its four-dimensional cousin, is toohard. If, however, it happens that the two-dimensional worldsheet theory is conformal (invariant under local changes of scale), then just a finite-dimensional spaceof conformally in equivalent metrics remains, and the theory is well - defined. The Calabi–Yau condition arises from these considerations.
The requirement that the two-dimensional theory should be conformal, so that the string theory makes good sense, is in essence the requirement that the Ricci tensor of space-time should vanish. Thus, atwo-dimensional condition leads to a space-time equation, which turns out to be exactly Einstein’s equation without matter. We add to this condition the “phe-no meno logical” criterion that the theory be endowed with “supersymmetry,” which requires the space-time manifold M to be complex.
The two conditions together mean that M is a complex manifold with holonomy group SUtheorem, the choices of such(n): that is, a Calabi–Yau manifold. By Yau’s M can easily be described by algebraic geometric methods. We remark that there is a kind of distillation of string theory called “topological strings,” which can be given a rigorous mathematical framework. Calabi–Yau mani-folds are both symplectic and complex, and this leads to two versions of topological strings, called A and B, that one can associate with a Calabi–Yau manifold.
Mirror symmetry is the remarkable phenomenon that the A version of one Calabi–Yau manifold is related to the B version of an entirely different “mirror partner.” The III.8. Categories mathematical consequences of such an equivalence are extremely rich. (See mirror symmetry [IV.16](/part - 04/mirror - symmetry) for more details.
For other notions related to those discussed in this article, see symplectic manifolds [III.88](/part - 03/symplectic - manifolds).) The Calculus of Variations See Variational Methods [III.94](/part - 03/variational - methods) III.7 Cardinals The cardinality of a set is a measure of how large thatset is. More precisely, two sets are said to have the same cardinality if there is a bijection between them. So whatdo cardinalities look like? nalities of finite sets:
a set has “cardinality There are finite cardinalities, meaning the cardi - n” if it has precisely[III.11](/part - 03/countable - and - uncountable - sets) infinite sets: these all have the same cardinal - n elements. Then there are countable ity (this follows from the definition of “countable”), usually writtenא . For example, the natural numbers, the integers, and the rationals all have cardinality However, the reals are uncountable, and so do not0א0.have cardinality by 2א . א0.
In fact, their cardinality is denoted It turns out that cardinals can be added and multiplied and even raised to powers of other cardinals (so“2א0” is not an isolated piece of notation). For details, and more explanation, see set theory [IV.22 §2](/part-04/set-theory). III.8 Categories

Eugenia Cheng

When we study[I.3 §2.3](/part-01/fundamental-definitions), we pay particular attention to certain classes groups [I.3 §2.1](/part-01/fundamental-definitions) or vector spaces of maps between them: the important maps between groups are the group homomorphisms [I.3 §4.1](/part-01/fundamental-definitions), and the important maps between vector spaces are theear maps [I.3 §4.2](/part-01/fundamental-definitions). What makes these maps important linis that they are the functions that “preserve structure”:
for example, ifφ is a homomorphism from a group G to a group sense that Hφ(g, then it “preserves multiplication,” in theg ) = φ(g )φ(g ) for any pair of ele - mentsg1 and (g1()2)2 of G. Similarly, linear maps preserv(e1)2 addition and scalar multiplication. The notion of a structure-preserving map applies far more generally than just to these two examples, andone of the purposes of category theory is to understand the general properties of such maps.
For instance, if B, and C are mathematical structures of some given A, 165 type, and A to B and fromf and Bgtoare structure-preserving maps from C, respectively, then their compos- ite g◦f is a structure-preserving map from A to C. That is, structure-preserving maps can beif the range of one equals the domain of the other). Wecomposed (at least also use structure-preserving maps to decide when to regard two structures as “essentially the same”:
we call A and B isomorphic if there is a structure-preserving map from structure. A to B with an inverse that also preserves one to discuss properties such as these in the abstract. A category is a mathematical structure that allows It consists of a collection ofphisms between those objects. That is, ifobjects, together witha and bmor-are two objects in the category, then there is a collection of morphisms between composition of morphisms: ifa and b.
There is also a notion off is a morphism from a to com posi teb and gofis a morphism fromf and g, which is a morphism fromb to c, then there is aa to c. This composition must be associative. In addition, foreach object$a$ there is an “identity morphism,” which has the property that if you compose it with another morphismf then you get f . a category is the category of groups. The objects of As the earlier discussion suggests, an example of this category are groups, the morphisms are group homomorphisms, and composition and the identity are defined in the way we are used to.
However, it is by no means the case that all categories are like this, as the following examples show. (i) We can form a category by taking the natural num-bers as its objects, and letting the morphisms from n to m be all the n . imes  m matrices with real entries. Composition of morphisms is the usual matrix multiplication. We would not normally think of ann . imes  m matrix as a map from the number n to the number nevertheless satisfied.m, but the axioms for a category are (ii) Any set can be turned into a category:
the objects are the elements of the set, and a morphism from x to yis the assertion “ x = y.” We can also make an ordered set into a category by letting a mor-phism fromx to ybe the assertion “x ⩽ y.” (The “composite” of “x ⩽ y” and “y ⩽ z” is “x ⩽ z.”) (iii) Any grouplows: you have just one object, and the morphisms G can be made into a category as fol- from that object to itself are the elements of the group, with the group multiplication defining the composition of two morphisms.

166

(iv) There is an obvious category where the objects are topological spaces [III.90](/part-03/topological-spaces) and the morphisms are continuous functions. A less obvious category with the same objects takes as its morphisms not continuous functions but homotopy classes [IV.6 §2](/part-04/algebraic-topology) of continuous functions. Morphisms are also called maps. However, as the above examples illustrate, the maps in a category donot have to be remotely map-like.
They are also called arrows, partly to emphasize the more abstract nature of a general category, and partly because arrows areoften used to represent morphisms pictorially. morphisms” enable us to seek and study structural fea-The general framework and language of “objects and tures that depend only on the “shape” of the category, that is, on its morphisms and the equations they satisfy.
The idea is both to make general arguments that are then applicable to all categories possessing partic-ular structural features, and also to be able to make arguments in specific environments without having to go into the details of the structures in question. The useof the former to achieve the latter is sometimes referred to, endearingly or otherwise, as “abstract nonsense.” As we mentioned above, the morphisms in a category are generally depicted as arrows, so a morphism

ffis depicted by concatenating the arrows from a to b is depicted as a −→- b and composition a −→-f b −→-g c. This notation greatly eases complex calculations and gives rise to the so-calledare often associated with category theory; an equality commutative diagrams that between composites of morphisms such as$g \circf = t \circs$ is expressed by asserting that the following diagram commutes, that is, that either of the two different paths froma to cyields the same composite:

$a^{f} // bs^{g}$

//

d ct

Proving that one long string of compositions equals another then becomes a matter of “filling in” the space inbetween with smaller diagrams that are already known to commute. Further more, many important mathematical concepts can be described in terms of commutative diagrams: some examples are free groups, free rings, free algebras, quotients, products, disjoint unions, function spaces, direct and inverse limits, completion, compact if ic at i on, and geometric realization.

III. Mathematical Concepts

unions. We say that aset Let us see how it is done in the case of disjoint U equipped with morphisms disjoint union Aof sets−→-p U and A and B B−→qis a U such that, given any setand B −→-g X, there is a unique morphism X and morphisms U -−→h AX−→-fthat X makes the following diagram commute: ;; XOO ccf??$U^{h}$__???$g$

~

~$p$~~~~ ???$q$?

$A$~$B$

Herejoint union. The “such that” part of the definition abovep and q tell us how A and B inject into the dis- is aing a function from the disjoint union to another set universal property. It expresses the fact that givis precisely the same as giving a function from eachof the individual sets; this completely characterizes a disjoint union (which we regard as defined up to isomorphism).
Another viewpoint is that the universal property expresses the fact that a disjoint unionis the “most free” way of having two sets map into another set, neither adding any information nor col-lapsing any information. Universal properties are central to the way category theory describes structures that are somehow “canonical.” (See also the discus-sion of free groups in geometric and combinatorial group theory Another key concept in a category is that of an[IV.10](/part-04/geometric-and-combinatorial-group-theory).) isomorphism morphism with a two-sided inverse. Isomorphic objects.
As one might expect, this is defined to be a in a given category are thought of as “the same, as far asthis particular category is concerned.” Thus, categories provide a framework in which the most natural way of classifying objects is “up to isomorphism.” kind, and as such they themselves form a category Categories are mathematical structures of a certain (subject to size restrictions so as to avoid a Russell-type paradox). The morphisms, which are the structure preserving maps for categories, are called other words, a functor F from a category Xfunctorsto a cate-.
In gory Y takes the objects of X to the objects of Y and the morphisms ofa way that the identity of X to the morphisms ofa is taken to the identity Y in such ofcomposite of Fa and the composite of Ff and Fg. An important example of af and g is taken to the functor is the one that takes a topological spacea “marked point”s to its fundamental group π1 S(S, s)with:

III.9. Compactness and Compact if ic at i on

it is one of the basic theorems of algebraic topology that a continuous map between two topological spaces (that takes marked point to marked point) gives rise to a homomorphism between their fundamental groups. Further more, there is a notion of morphism between functors called aogous to the notion of homotopy between maps ofnatural transformation, which is anal topological spaces. Given continuous maps F, G: X \to YX, a homotopy from, a path in Y from Fx F toto GGxgives us, for every point; analogously, given func-x in tors F, G:
X −→ Y , a natural transformation from F to GFxgives us, for every pointto Gx. There is also a commuting condition that isx in X, a morphism in Y from analogous to the fact that, in the case of homotopy, apath in X must have its image under F continuously transformed to its image underany “holes” in the space Y. This avoidance of holes is G without passing over expressed in the category case by the commutativity of certain squares in the target categoryas the “naturality condition.”Y , which is known the fact that every vector space isphic to its double dual;
there is a functor from the One example of a natural transformation encodes canonically is om or category of vector spaces to itself that takes each vec-tor space to its double dual, and there is an invertible natural transformation from this functor to the iden-tity functor via the canonical isomorphisms. By contrast, every finite-dimensional vector space is isomorphic to its dual, but not canonically so because the isomorphism involves an arbitrary choice of basis; if we attempt to construct a natural transformation inthis case, we find that the naturality condition fails.
In the presence of natural transformations, categories actually form a 2 generalization of a category, with objects, morphisms,-category, which is a two-dimensional and morphisms between morphisms. These last are thought of as two-dimensional morphisms; more generally ann-category has morphisms for each dimension up to Categories and the language of categories are usedn. in a wide variety of other branches of mathematics. Historically, the subject is closely associated with algebraic topology; the notions were first introduced in 1945 by Eilenberg and Mac Lane.
Applications followedin algebraic geometry, theoretical computer science, theoretical physics, and logic. Category theory, with its abstract nature and lack of dependency on other fields of mathematics, can be thought of as “foundational.” In fact, it has been proposed as an alternative candidate for the foundations of mathematics, with the notion of

167

morphism as the basic one from which everything elseis built up, instead of the relation of set membership that is used in set-theoretic foundations [IV.22 §4](/part-04/set-theory). Class Field Theory See from quadratic reciprocity to class field theory [V.28](/part - 05/from - quadratic - reciprocity - to - vi38 - augustus - de - morgan - 18061871) Cohomology See homology and cohomology [III.38](/part - 03/homology - and - cohomology) III.9 Compactness and Compact if ic at i on Terence Tao In mathematics, it is well-known that the behavior offinite sets and the behavior of infinite sets can
be rather different. For instance, each of the following statements is easily seen to be true whenever Xis a finite set but false whenever Xis an infinite set. All functions are bounded. If f:$X \to R \text{is a real}-$ valued function onthere exists a finite number X, then f Mmust be bounded (i.e., such that |f (x)| ⩽ M All functions attain a maximum.for all$x \in X)$. If f: X \to R is a real- valued function onone pointx \in  X Xsuch that, then there must exist at leastf (x ) ⩾ f (x) for all 0 0

$x \in X$.

All sequences have constant subsequences.x ,· · · ∈ X is a sequence of points in X, then there If x1$, x2$, must exist a subsequence constant. In other words,3$x (xn)1=$, x(xn)2, x= · · · =n 3, . . . that isc for some infinite pigeonhole princi plec \in  X. (This fact is sometimes known as the.()n()1()n)2 are bounded—can be viewed as a very simple exam-ple of a The first statement—that all functions on a finite setlocal-to-global principle. The hypothesis is an assertion of “local” boundedness:
it asserts that|f (x)| is bounded for each pointx \in X separately, but with a bound that may depend onof “global” boundedness: thatx|. The conclusion is thatf (x)| is bounded by a single bound$M \text{for all} x \in X$. However, in many areas of mathematics we like toendow our objects with additional structures, such as a So far we have viewed the object X only as a set. topology ture [I.3 §2.1](/part-01/fundamental-definitions). When we do this, it turns out that some[III.90](/part-03/topological-spaces), a metric [III.56](/part-03/metric-spaces), or a group struc-

168

objects exhibit properties similar to those of finite sets (in particular, they enjoy local-to-global principles), even though as sets they are infinite. In the categories of topological spaces and metric spaces, these “almostfinite” objects are known asegories have “almost - finite” objects as well. For exam-compact spaces. (Other catple, in the category of groups there is a notion of apro-finite group;
for linear operators [III.50](/part - 03/linear - operators - and - their - properties) between normed spaces [III.62](/part - 03/normed - spaces - and - banach - spaces) the analogous notion is that of aand so forth.)compact operator, which is “almost of finite rank”; interval A good example of a compact set is the closed unit X = [0,1]. This is an infinite set, so the previous three assertions are all false as stated forwe modify them by inserting topological concepts such X. But if as continuity and convergence, then we can restore these assertions for[0,1] as follows.
All continuous functions are bounded. If$f$:$X \to R is$ a real-valued continuous function on X, then f must be bounded. (This is again a type of local-to-global principle: if a function does not vary too much locally, then it does not vary too much globally.) All continuous functions attain a maximum. X \to  R is a real-valued continuous function on If f X:, then there must exist at least one pointthatf (x ) ⩾ f (x) for all x \in  X.
x0 \in  X such All sequences have convergent subsequences.$x$, x , x0, · · · ∈ X is a sequence of points in X, then If there must exist a subsequence converges to some limit1 2 3 c \in  Xx. (This statement i(sn)1 , (xn)2, (xn)3, . . . that known as the Bolzano–Weierstrass theorem.) To these assertions we can add a fourth (which, like the others, has a rather trivial analogue for finite sets). All open covers have finite subcovers.
If V is a col- lection of open sets and the union of all these opensets contains X (in which case V is called an open cover le ct i on of V X, V), then there must exist a finite subcol-, . . . , V of sets in V that still covers(n1()n()2()n)k X .

All four of these topological statements are false for sets such as the open unit interval line R, as one can easily check by constructing simple(0, 1) or the real counterexamples. Thewhen X is a subset of a Euclidean space Heine–Borel theorem Rnasserts that, the above statements are all true when X is topologically closed and bounded, and all false otherwise.

III. Mathematical Concepts

other. For instance, if you know that all sequencesin The above four assertions are closely related to each X contain convergent subsequences, then you can quickly deduce that all continuous functions have amaximum. This is done by first constructing a maximizing sequencef (x ) approaches the maximal value of—a sequence of pointsxnfin(or, more pre-X such that cisely, its supremum)—and then investigating a conver-$n$ gent subsequence of that sequence.
In fact, given some fairly mild assumptions on the space X (e.g., that X is a metric space), one can deduce any of these four statements from any of the others. spacefour assertions holds for To oversimplify a little, we say that a topological X is compact if one (and hence all) of the above X. Because the four assertions are not quite equivalent in general, the formal defini-tion of compactness uses only the fourth version: that every open cover has a finite subcover.
There are other notions of compactness, such asness, for example, which is based on the third version, sequential compact but the distinctions between these notions are technical and we shall gloss over them here. is used in many ways in many different areas of math-ematics. One is via appeal to local-to-global principles: Compactness is a powerful property of spaces, and it one establishes local control on a function, or on someother quantity, and then uses compactness to boost the local control to global control.
Another is to locate maxima or minima of a function, which is particularly useful in the calculus of variations [III.94](/part-03/variational-methods). A third is to partially recover the notion of a limit when deal-ing with nonconvergent sequences, by accepting the need to pass to a subsequence of the original sequence. (However, different subsequences may converge to dif-ferent limits; compactness guarantees the existence of a limit point, but not its uniqueness.) Compactness ofone object also tends to beget compactness of other objects;
for instance, the image of a compact set under a continuous map is still compact, and the productof finitely many or even infinitely many compact sets continues to be compact. This last result is known as Tychonoff’s theorem. An obvious example is the real linepact, because it contains sequences such as 1 Of course, many spaces of interest are not compact. R, which is not com-,2,3, . . . that are “trying to escape” the real line and that do notleave behind any convergent subsequences. However, one can often recover compactness by adding a fewmore points to the space:
this process is known as compact if ic at i on. For instance, one can compactify the real

III.10. Computational Complexity Classes

line by adding one point at each end: we call the added points+$\infty\text{and} −$. nfty. The resulting object, known as the extended real line[−$\infty$, +$\infty$], can be given a topology in a natural way, which basically defines what it meansto converge to$+$. nfty or to −$\infty$. The extended real line is compact: any sequence will have a subsequence that either converges toxn of extended real numbers+$\infty$, or converges to−. nfty, or converges to a finite number.
Thus, by using this compact if ic at i on of the real line, we can generalize the notion of a limit to one that no longerhas to be a real number. While there are some drawbacks to dealing with extended reals instead of ordi-nary reals (for instance, one can always add two real numbers together, but the sum of$+$. nfty and −$\infty$ is unde- fined), the ability to take limits of what would otherwise be divergent sequences can be very useful, par-ticularly in the theory of infinite series and improper integrals. many different compactificatio ns.
For instance, by the It turns out that a single noncompact space can have device ofcally identify the real line with a circle that has a sin-stereographic projection, one can topologigle point removed. (For example, if one maps the real number$x \text{to the point} (x/(1 + x^{2})$, x^2/(1 + x^2)), then R maps to the circle of radius 12 and center(0,1 2), with the north pole missing point, we obtain the(0,1) removed.) If we then insert theone-point compact if ic at i on R∪ {}. nfty of the real line.
More generally, any reason- able topological space (e.g., a locally compact Hausdorff space) has a number of compactificatio ns, rang-ing from the one-point compact if ic at i on X ∪{}. nfty, which is the “minimal” compact if ic at i on as it adds only onepoint, to the Stone– ˇCech compactificationβX, which is the “maximal” compact if ic at i on and adds an enormous number of points. The Stone–ˇCech compactificationβN of the natural numbers N is the space of ultrafilters, which are very useful tools in the more infinitary parts of mathematics. tween different types of divergence in a space.
For instance, the extended real line One can use compactificatio ns to distinguish be-[−. nfty,+. nfty] distinguishes between divergence to+. nftyand divergence to −. nfty. In a similar spirit, by using compactificatio ns of the plane R2 such as the [I.3 §6.7](/part - 01/fundamental - definitions), one can distinguish a sequence that diverges along (or near) thex-axis from a sequence that diverges along (or near) the projective planeytions in which sequences that diverge in different ways - axis. Such compactificatio ns arise naturally in sit ua exhibit markedly different behavior.
169 view one type of mathematical object rigorously as alimit of others. For instance, one can view a straight Another use of compactificatio ns is to allow one to line in the plane as the limit of increasingly large circles by describing a suitable compact if ic at i on of the spaceof circles that includes lines. This perspective allows us to deduce certain theorems about lines from analo-gous theorems about circles, and conversely to deduce certain theorems about very large circles from theo-rems about lines.
In a rather different area of mathematics, the Dirac delta function is not, strictly speaking, a function, but it exists in certain (local) compactificatio ns of spaces of functions, such as spaces ofsures [III.55](/part - 03/measures) or distributions [III.18](/part - 03/distributions). Thus, one canmeaview the Dirac delta function as a limit of classical func-tions, and this can be very useful for manipulating it. One can also use compactificatio ns to view the continu-ous as the limit of the discrete: for instance, it is possible to compactify the sequence Z/2 Z, Z/3 Z, Z/4 Z, . . .
of cyclic groups in such a way that their limit is the circle group T= R/Z. These simple examples can be general- ized to much more sophisticated examples of compact-ifications, which have many applications in geometry, analysis, and algebra. III.10 Computational Complexity

Classes

One of the basic challenges of theoretical computer sci-ence is to determine what computational resources are necessary in order to perform a given computational task. The most basic resource is time, or equivalently (given the hardware) the number of steps needed toimplement the most efficient algorithm that will carry out the task. Especially important is how this time scales up with the size of the input for the task: for instance, how much longer does it take to factorize an integer with 2 Another resource connected with the feasibility of an digits than an integer with ndigits?
computation isage space a computer will need in order to implement memory: one can ask how much storan algorithm, and how this can be minimized. Aplexity class is a set of computational problems that cancombe performed with certain restrictions on the resources allowed. For instance, the complexity class P consists of all problems that can be performed in “polynomialtime”: that is, there is some positive integerk such that if the size of the problem issize was the number of digits of the integer to be fac-n (in the example above, the torized), then the computation can be carried out in at

170

mostnk steps. A problem belongs to P if and only if the time taken to solve it scales up by at most a constant factor when the size of the input scales up by a con-stant factor. A good example of such a problem is multiplication of two n-digit numbers: if you use ordinary long multiplication, then replacing the time taken by a factor of 4. n by 2 n increases ger Suppose that you are presented with a positive inte-x and told that it is a product of two primes p andqknows, but one thing is easy to see: if you are told. How difficult is it to determinep and q?
Nobody$p$ andq, then it is not hard (for a computer, at any rate) to check thathave just seen, long multiplication takes polynomial pq really does equal x. Indeed, as we time, and comparing the answer withier. The complexity class NP consists of those compu-x is even eas- tational tasks for which a correct answer can beified in polynomial time, even if it cannot necessar-verily be found in polynomial time. Remarkably, although this is a fundamental distinction, nobody knows howto prove that$P = NP$: this problem is widely considered to be the most important in theoretical computer science.
classes.solved using an amount of memory that grows at most We briefly mention two other important complexity PSPACE consists of all problems that can be polynomially with the size of the input. It turns out tobe the natural class associated with reasonable computational strategies for games such as chess. The com-plexity class NC is the set of all Boolean functions that can be computed by a “circuit of polynomial size anddepth at most a polynomial in log$n$.” This last class is a model for the class of problems that can be solved very rapidly using parallel processing.
In general, complexity classes are often surprisingly good at character-izing large families of problems with interesting and intuitively recognizable features in common. another remarkable fact is that almost all complexity classes have “hardest problems” within them: that is, problems for which a solution can be converted into a solution forany other problem in the class. These problems are said to be complete for the class in question. These issues, as well as several other complexity classes, are discussed in[IV.20](/part-04/computational-complexity).
A vast number of further classes can be found computational complexity at http://qwiki.stanford.edu/wiki/Complexity_Zoo along with a brief definition of each.

III. Mathematical Concepts

Continued Fractions

See the euclidean algorithm and

continued fractions [III.22]

III.11 Countable and Uncountable Sets

Infinite sets arise all the time in mathematics: the natu-ral numbers, the squares, the primes, the integers, the rationals, the reals, and so on. It is often natural to try to compare the sizes of these sets: intuitively, one feelsthat the set of natural numbers is “smaller” than the set of integers (as it contains just the positive ones), and much larger than the set of squares (since a typical large integer is unlikely to be a square). But can wemake comparisons of size in a precise way? ition about finite sets.
Ifare two ways we might go about comparing their sizes. An obvious method of attack is to build on our intu-A and Bare finite sets, there One is to count their elements: we obtain two nonnega-tive integersm and n and just look at whether m < n, m = n, or m > n. But there is another important method, which does not require us to know the sizes ofeither A or B. This is to pair off elements from A with elements ofof elements: the first one to run out is the smaller set, B until one or other of the sets runs out and if there is a dead heat, then the sets have the samesize.
for infinite sets as well: we can declare two sets tobe of equal size if there is a one-to-one correspon-A suitable modification of this second method works dence between them. This turns out to be an important and useful definition, though it does have some consequences that seem a little odd at first. For example, there is an obvious one-to-one correspondence between natural numbers and perfect squares: for each n correspond to n2. Thus, according to this definitionn we let there are “as many” squares as there are natural num - bers.
Similarly, we could show that there are as many primes as natural numbers by associating nth prime number.1 n with the large” asspondence between them. We just list the integers in What about N, but again we can find a one - to-one corre - Z? It seems that it should be “twice as the order 0,1,-1, 2, -2, 3, -3, . . . and then match the sity” that can be useful too. According to this definition, the even num-bers have density1. For sufficiently nice sets of integers there is a definition of “den - 1 , while the squares and the primes have density 0, as one might expect.
However, this is not the notion of size under discussion here. III.11. Countable and Uncountable Sets natural numbers with them in the obvious way: 1 with0, then 2 with 1, then 3 with - 1, then 4 with 2, then 5 with$-2$, and so on. size as the natural numbers. As the above example shows, this is exactly the same as saying that we can An infinite set is called countable if it has the same lista set asthe elements of the set. Indeed, if we have listeda , a , a , . . . , then our correspondence is just to send course many attempted listings that fail: for example, n1 to2(an)3.
It is worth noting that there are of for Z we might have tried-3, -2, -1,0,1,2,3,4, . . . . So it is important to recognize that when we say that aset is countable we are not saying that every attempt to list it works, or even that the obvious attempt does: we are merely saying that there is some way of listing the elements. This is in complete contrast to finite sets, where if we attempt to match up two sets and find some elements of one set left over, then we know that the two sets cannot be in one - to - one correspondence.
It isthis difference that is mainly responsible for the “odd consequences” mentioned above. Now that we have established that some sets that seem smaller or larger than N, such as the squares or the integers, are actually countable, let us turn toa set that seems “much larger,” namely Q. How could we hope to list all the rationals? After all, between anytwo of them you can find infinitely many others, so it seems hard not to leave some of them out when you try to list them. However, remarkable as it may seem, it is possible to list the rationals.
The key idea is that listing the rationals whose numerator and denominator are both smaller (in modulus) than some fixed number kis easy, as there are only finitely many of them. So we go through in order: first when both numerator and denominator are at most 1, then when they are at most 2, and so on (being careful not to relist any number, sothat for example 1 should not also appear as 2 or 3).
This leads to an ordering such as 03, -3,1, -1,2 ,-2 2,3 ,-3,4$,-4, . . . .,1,-1,2,-2^{4}$,1 2,-6 1 2, larger, such as, for example, thereal numbers, such as We could use the same idea to list sets that look even3 3 3 3 2 2$\sqrt{2}$, that satisfy a polynomial algebraic numbers (all equation with integer coefficients). Indeed, we note that each polynomial has only finitely many roots (which are therefore listable), so all we need to do is list the polynomials (as then we can go through them, in order, listing their roots). And we can do that by applying the same technique again:
for eachd we list those polynomials of degree at most coefficients that are at mostd that we have not already listed, withd in modulus.

171

that Based on the above examples, one might well guess every infinite set is countable. But a beautiful argument ofment, shows that the real numbers are not countable.cantor [VI.54](/part-06/georg-cantor-18451918), called his “diagonal” argu We imagine that we have a list of all real numbers, sayr , r , r , . . . . Our aim is to show that this list cannot possibly contain all the reals, so we wish to construct areal that is not on this list. How do we accomplish this?1 2 3 We have eachnow we define a new number ri written as an infinite decimal, say, andsas follows.
For the first digit ofis not the first digit ofs (after the decimal point), we choose a digit thatr . Note that this already guaran- tees that recurring 9 s and the like, it is best to choose this firsts cannot equal1 r1. (To avoid coincidences with digit ofdigit ofss, we choose a digit that is not the second digitnot to be 0 or 9 either.) Then, for the second oftinuing in this way, we end up with a real number r2; this guarantees thats cannot be equal to r2. Con-s that is not on our list: whatevern is, the number s cannot ber^n, as s and r^ndiffer in thenth decimal place!
“an infinite number of independent choices” to make One can use similar arguments any time that we have in specifying an object (like the various digits ofexample, let us use the same ideas to show that thes). For set of all subsets of N is uncountable. Suppose we have listed all the subsets as$A^{1}$, A2$, A3$, . . .. We will define a new set include the point 1 in B that is not equal to any of the B if and only if 1 does not belong An. So wetowe include 2 in A1 (this guarantees that B if and only if 2 does not belong to B is not equal to A1), and A , and so on.
It is amusing to note that one can write thisset$B \text{down as} {n \in N}$:$n \in A$, which shows a striking2 resemblance to the set in Russell’s paradox.$n$ Countable sets are the “smallest” infinite sets. However, the set of real numbers is by no means the“largest” infinite set. Indeed, the above argument shows that no setdence with the set of all its subsets. So the set of all X can be put into one-to-one correspon- subsets of the real numbers is “strictly larger” than theset of real numbers, and so on. The notion of countability is often a very fruitful one to bear in mind.
For example, suppose we want toknow whether or not all real numbers are algebraic. It is a genuinely hard exercise to write down a particu-lar real that is transcendental [III.41](/part-03/irrational-and-transcendental-numbers) (meaning not algebraic; seerem [V.22](/part-05/liouvilles-theorem-and-roths-theorem) for an idea of how it can be done), but the liouville’s theorem and roth’s theoabove notions make it utterly trivial that transcenden-tal numbers exist. Indeed, the set of all real numbers is

172

uncountable but the set of algebraic numbers is count-able! Further more, this shows that “most” real numbers are transcendental: the algebraic numbers form only atiny proportion of the reals. III.12 C* - Algebras A[I.3 §2.3](/part - 01/fundamental - definitions) and abanach space metric space[III.62](/part - 03/normed - spaces - and - banach - spaces) is both a[III.56](/part - 03/metric - spaces), and the study ofvector space Banach spaces is therefore a mixture of linear algebra and analysis.
However, one can arrive at more sophisticated mixtures of algebra and analysis if one looks at Banach spaces that have more algebraic structure. In particular, while one can add two elements of a Banach space together, one cannot in general multiply them. However, sometimes one can: a vector space with a mul-tiplicative structure is called an algebra, and if the vector space is also a Banach space, and if the multipli-cation has the property thatxy ⩽ x . um y for any two elements bra.
(This name does not really reflect historical real-x and y , then it is called a Banach alge- ity, since the basic theory of Banach algebras was notworked out by Banach. A more appropriate name might have been Gelfand algebras.)AC*-algebra is a Banach algebra with an involution, which means a function that associates with each ele-mentx another element x* in such a way that x∗∗ = x, x* = x , (x + y)* = x* + y*, and (xy)* = y*x* for any elements satisfy the$C^{*} - \text{identityx and yxx}$; this involution is required to${}^{*} = x^{2}$.
A basic example of a C*-algebra is the algebra B(H) of all continuous linear maps The norm of$TT$defined on ais defined to be the smallest constant hilbert space [III.37](/part-03/bayesian-analysis)H.Minvolution takessuch that T x T to its⩽ M adjointx for every. This is a mapx \in  H, and the T* that has the property that x, T y = T*x, y for every x andmap with this property.) Ify in H . (It can be shown that there is exactly one His finite dimensional, then TT*can be thought of as anis then the complex conjugate of the transpose ofn . imes n matrix for some n, and T.
states that every subalgebra of A fundamental theorem of Gelfand and Naimark B(H)C*for some Hilbert space-algebra can be represented as a H. For more information, see operator algebras [IV.15 §3](/part-04/operator-algebras). III.13 Curvature If you cut an orange in half, scoop out the inside, and try to flatten one of the resulting hemispheres of peel, then you will tear it. If you try to flatten a horse’s saddle, or a soggy potato chip, then you will have the opposite

III. Mathematical Concepts

problem: this time, there is “too much” of the surfaceto flatten and you will have to fold it over itself. If, however, you have a roll of wallpaper and wish to flatten it, then there is no difficulty: you just unroll it. Surfaces such as spheres are said to be positively curved, ones with a saddle-like shape arelike a piece of wallpaper are negatively curved flat. , and ones it does not lie in a plane.
This is because curvature isdefined in terms of the Notice that a surface can be flat in this sense even ifintrinsic geometry of a surface, where distance is measured in terms of paths that lieinside the surface. There are various ways of making the above notion of curvature precise, and also quantitative, so that witheach point of a surface one can associate a number that tells you “how curved” it is at that point. In order todo this, the surface must have a riemannian metric [I.3 §6.10](/part-01/fundamental-definitions) on it, which is used to determine the lengthsof paths.
The notion of curvature can also be generalized to higher dimensions, so that one can talk aboutthe curvature of a point in ad-dimensional Rieman- nian manifold. However, when the dimension is higher than 2, the way that the manifold can curve at a point is more complicated, and is expressed not by a single number but by the so-called Ricci tensor. See ricci flow [III.78](/part-03/ricci-flow) for more details. Curvature is one of the fundamental concepts of modern geometry:
not only the notion just described but also various alternative definitions that measure in other ways how far a geometric object deviates from being flat. It is also an integral part of the theoryof general relativity (which is discussed in general relativity and the einstein equations [IV.13](/part-04/general-relativity-and-the-einstein-equations)). III.14 Designs Peter J. Cameron Block designs were first used in the design of experiments in statistics, as a method for coping with sys-tematic differences in the experimental material.
Suppose, for example, that we want to test seven differ-ent varieties of seed in an agricultural experiment, and that we have twenty-one plots of land available for the experiment. If the plots can be regarded as identical, then the best strategy is clearly to plant three plotswith each variety. Suppose, however, that the available plots are on seven farms in different regions, with three plots on each farm. If we simply plant one variety on each farm, we lose information, because we cannot dis-tinguish systematic differences between regions from

III.14. Designs

3 5

2 6 4

Figure 1 A block design.

differences in the seed varieties. It is better to followa scheme like this: plant varieties 1, 2, 3 on the first farm; 1, 4, 5 on the second; and then 1, 6, 7; 2, 4, 6; 2, 5, 7; 3, 4, 7; and 3, 5, 6. This design is represented infigure 1. block design sets of seed varieties used on the seven farms. The This arrangement is called a, or BIBD for short. The blocks are the balanced incomplete blocks are “incomplete” because not every variety canbe planted on every farm;
the design is “balanced” because each pair of varieties occurs in the same block the same number of times (just once in this case).This is a(7, 3, 1)design: there are seven varieties; each block contains three of them; and two varieties occur together in a block once. It is also an example of a finite geometry, varieties are usually called “points.”projective plane. Because of the connection with of BIBDs and related classes of designs. Indeed, the Mathematicians have developed an extensive theory study of such designs predates their use in statistics. In 1847, T. P.
Kirkman showed that a(v$, 3, 1) design$ exists if and only ifdesigns are now calledv is congruent to 1 or 3 mod 6. (Such Steiner triple systems, although Steiner did not pose the problem of their existence until1853.) own words, Kirkman also posed a more difficult problem. In his Fifteen young ladies in a school walk out three abreast for seven days in succession: it is required to arrange them daily so that no two shall walk twice abreast.
The solution requires awith the extra property that the thirty-five blocks can(15, 3, 1) Steiner triple system 173 be partitioned into seven sets called “replicates,” each replicate consisting of five blocks that partition the set of points. Kirkman himself gave a solution, but it wasnot until the late 1960 s that Ray-Chaudhuri and Wilson showed that(v, 3,1) designs with this property exist wheneverv is congruent to 3 mod 6. ments show that, given For whichv , k, . ambda do designs exist? Counting argu - k and λ, the values of v for whichtain congruence classes.
(We noted above that(v, k, λ) designs exist are restricted to cer-(v, 3, 1) designs exist only ifv is congruent to 1 or 3 mod 6.) An asymptotic existence theory developed by Richard Wilson shows that this necessary condition is sufficient for the existence of a design, apart from finitely many exceptions, for each value ofk and λ. The concept of design has been further generalized: aare contained in exactlyt–(v, k, λ) design has the property that any. ambda blocks. Luc Teirlinck showedt points that nontrivialt-designs exist for all t, but examples fort > 3 are comparatively rare.
introductory example, if only six farms were available, The statisticians’ concerns are a bit different. In our we could not use a BIBD for the experiment, but wouldhave to choose the most “efficient” possible design (allowing the most information to be obtained from the experimental results). A BIBD is most efficient if itexists; but not much is known in other cases. There are other types of design; these can be important to statistics and also lead to new mathematics. Here, for example, is an orthogonal array:
if you take any two rows of this matrix you obtain a 2$\times 9 matrix$ in which each ordered pair of symbols from$\\{0}$,1,2\\\\\\\\\\\\\\\\\\\\\\} occurs exactly once as a column. 0 0 0 1 1 1 2 2 2 0 1 2 0 1 2 0 1 2 0 1 2 1 2 0 2 0 1 0 2 1 1 0 2 2 1 0 It could be used if we had four different treatments, each of which could be applied at three different levels, and if we had nine plots available for testing. Design theory is closely related to other combinatorial topics such as error-correcting codes; indeed, Fisher “discovered” the Hamming codes as designs five years before R. W.
Hamming found them in the context of error correction. Other related subjects include pack-ing and covering problems, and especially finite geometry, where many finite versions of classical geometries can be regarded as designs.

174

III.15 Determinants

The determinant of a 2$\times 2 \text{matrixac bd}$

is defined to bead - bc. The determinant of a 3 . imes  3 matrix⎛a b c⎞⎜⎜⎝d e f ⎟⎟⎠g h i

is defined to beaei+bf g+cdh-af h-bdi-ceg. What do these expressions have in common, how do they generalize, and why is the generalization significant? simple observations. Both expressions are sums and differences of products of entries from the matrix. Each To begin with the first question, let us make a few one of these products contains exactly one element from each row of the matrix and also exactly one element from each column.
In both cases, a minus signseems to attach itself to the products for which the entries selected from the matrix “slope upward” rather than “downward.” definition totake sums and differences of all possible products of Up to a point it is easy to see how to extend thisn . imes  n matrices with n ⩾ 4. We simply none from each column. The difficulty comes in decid-entries, where one entry from each row is used and ing which of these products to add and which to sub-tract. To do this we take one of the products and use it to define a permutation follows.
For eachi ⩽ n, the product contains exactlyσ of the set \\{1,2, . . . , n\\} as one entry in thethenσ (i) = j. The product is added if this permutation ith row. If it belongs to the jth column is even and subtracted if it is odd (seegroups [III.68](/part-03/permutation-groups)). So, for example, the permutation cor-permutation responding to the entryaf h in the 3 . imes  3 determinant above sends 1 to 1, 2 to 3, and 3 to 2. This is an odd permutation, which is whyaf h receives a minus sign. products and minus signs that we have just definedis important.
The reason is that it tells us something We still need to explain why the particular choice of about the effect of a matrix when it is considered as alinear map. Let A be an n . imes  n matrix. Then, as explained in [I.3 §3.2](/part-01/fundamental-definitions), Aspecifies a linear mapα from Rn to Rn. The determinant ofdoes to volumes. More precisely, if A tells us what this linear map X is a subset of Rn with transformingn-dimensional volume X using the linear map V , then αXα, will have vol-, the result of

III. Mathematical Concepts

ume symbolically as follows: V times the determinant of A. We could write this vol$(αX) = \det A · vol(X)$.For example, consider the 2. imes  2 matrix A = . os . in  θθ -. os . in θθ .

The corresponding linear map is a rotation of R2 through an angle ofaffect its volume, we should expect the determinant ofθ. Since rotating a shape does not A to be 1, and sure enough it is cos^2 θ + . in^2 θ, which is 1 by Pythagoras’s theorem. tion in one respect: determinants can be negative, but clearly volumes cannot. If the determinant of a matrix The above explanation is a slight over sim pl if i ca is-2, to give an example, it means that the linear map multiplies volumes by 2 but also “turns shapes insideout” by reflecting them.
become obvious once one knows the above interpre-tation in terms of volumes. (However, it is much less Determinants have many useful properties, which obvious that this interpretation is correct: in setting up the theory of determinants one must do some work somewhere.) Let us give three of these properties. (i) Let V be a vector space[I.3 §2.3](/part-01/fundamental-definitions) and letα:$V \to V$ be a linear map. Let A be the matrix of α vwith respect to this basis. Now let1, . . . , vn be a basis of V and letwof1α, . . . , with respect to this different basis.
Thenwn be another basis of V and let B be the matrix A and B are different matrices, but since they both represent the linear map volumes. It follows that detα, they must have the same effect on$(A) = \det (B)$. To put this another way: the determinant is better thought of as aproperty of linear maps rather than of matrices. Two matrices that represent the same linear map in the above sense are calledand B are similar if and only if there is an invertible similar. It turns out that A matrix P such that P-1 AP = B.
(An n . imes  n matrix P is invertible then . imes  n if there is a matrix identity matrix, I , which turns out to imply Q such that P Q equals that called the QP equals inverse Inofas well. If this is true, then P and is denotedn P-1.) What we Q is have just shown is that similar matrices have the same determinant. represent linear maps(ii) If A and B are any twoα andn . imes βnofmatrices, then they Rn. The product ABmap that results from doing represents the linear mapβ followed byαβ: that is, the linearα. Since β multiplies volumes by det B and α multiplies them by

III.16. Differential Forms and Integration

. et . et (AB)A, αβ=multiplies them by det. et  A . et  B. (The determinant of a product A. et  B. It follows that equals the product of the determinants.) other matrix, thenby the multiplicative property just discussed. It follows(iii) If A is a matrix with determinant 0 and AB will have determinant 0 as well, B is any that Therefore a matrix with determinant 0 is not invert-$\text{AB cannot equal} I^{n}$, since In has determinant 1. ible. The converse of this turns out to be true as well: a matrix with nonzero determinant is invertible.
Thus, the determinant gives us a way of finding out whethera matrix can be inverted. III.16 Differential Forms and

Integration

Terence Tao

It goes without saying that integration is one of the fundamental concepts of single-variable calculus. How-ever, there are in fact three concepts of integration that appear in the subject: theknown as the antiderivative indefinite integral), the unsigned definite inte-f (also gral[a, b] f (x) dx(which one would use to find the area under a curve, or the mass of a one-dimensional object of varying density), and the signed definite integral compute the work required to move a particle fromab f (x) dx (which one would use, for instance, toa tob functions).
For simplicity we shall restrict our attention here tof: R\to  R that are continuous on the entire real line (and similarly, when we come to differential forms, we shall discuss only forms that are continuous on the entire domain). We shall also informally use terminology such as “infinitesimal” in order to avoid having to discuss the (routine) “epsilon–delta” analytical issues that one must resolve in order to make these integration concepts fully rigorous. closely related to each other in single-variable calcu - lus;
indeed, These three concepts of integration are of coursethe fundamental theorem of calculus [I.3 §5.5](/part - 01/fundamental - definitions) relates the signed definite integralto any one of the indefinite integrals F = a bff (x)by thedx formula$bf (x) dx = F(b) - F(a)$, (1)

while the signed and unsigned integrals are related bythe simple identity ab f (x) dx = −a f (x) dx = f (x) dx, (2) which is valid wheneverab a ⩽ b.[a, b] 175 several-variable calculus, though, these three concepts begin to diverge significantly from each other. The When one moves from single-variable calculus to indefinite integral generalizes to the notion of ato a differential equation, or to an integral of a connec-solution tion, unsigned definite integral generalizes to thevector field [IV.6 §5](/part - 04/algebraic - topology), or bundle [IV.6 §5](/part - 04/algebraic - topology).
The lebesgue integral measure space[III.55](/part - 03/measures), or more generally to. Finally, the signed definite integral gen-integration on a eralizes to thefocus here. While these three concepts are still related integration of forms, which will be our to each other, they are not as interchangeable as they are in the single-variable setting.
The integration - of-forms concept is of fundamental importance in differential topology, geometry, and physics, and also yieldsone of the most important examples of cohomology [IV.6 §4](/part - 04/algebraic - topology), namely speaking) measures the extent to which the fundamen-de Rham cohomology, which (roughly tal theorem of calculus fails in higher dimensions andon general manifolds.
informally revisit one of the basic applications of thesigned definite integral from physics, namely com-To provide some motivation for the concept, let us puting the amount of work required to move a one dimensional particle from point presence of an external field.
(For example, one mighta to point b in the be moving a charged particle in an electric field.) Atthe infinitesimal level, the amount of work required to move a particle from a pointx \in  R to a nearby point ix place men(ti)+1 \in  R is (up to a small error) proportional to the dis-Δx = x - x , with the constant of pro- portion al it yf ((xi)i) depending on the initial locatio(ni()+1)i xi of the particle. Thus, the total work required for this is approximate lyf (x )Δx .
Note that we do not requirexthe infinitesimal worki+1 to be to the right ofi f (xixi, so the displacement)Δx ) may well be negative.Δxi (or To return to the non infinitesimal problem of comput-$ii$ ing the work required to move fromtrarily select a discrete pathx = a, xa, xto, . . . , xb, we arbi-= b froma to b, and approximate the work a(s0)1 2 nb f (x) dx . pprox n-1 f (xi)Δxi. (3)ai = 0

Again, we do not require(xi)+1 to be to the right of xi; it is quite possible for the path to “backtrack” repeat-edly: for instance, one might havex < x+ > x+ for some backtracking eventually cancels itself out; regard less$i$. However, it turns out that the effect of such(ii()1()i)2 of what path we choose, the expression (3) above con-verges as the maximum step size tends to zero, and the

176

limit is the signed definite integral

bf (x) dx, (4)

provided only that the total length path (which controls the amount of backtracking in-(an)i=-0 1 |Δxi| of the volved) stays bounded. In particular, in the case whena = b, so that all paths are closed (i.e., x = x ), we see 0 n that the signed definite integral is zero: af (x) dx = 0. (5)

integral it is obvious that we have the concatenation formula From this informal definition of the signed definite ac f (x) dx = b f (x) dx + c f (x) dx (6)regard less of the relative position of the real numbersa, b, andac. In particular (settinga a =b c and using (5)) we conclude that ba Thus, if we reverse a path froma path fromab f (x)to ad, then the sign of the integralx = −b f (x)adx.to b to form changes. This contrasts with thegralf (x) dx, since the set unsigned definite inte-[a, b] of numbers between bers between[a, b]a andbbandis exactly the same as the set of num-a.
Thus we see that paths are not quite the same as sets: they carry ancan be reversed, whereas sets do not.orientation which to higher-dimensional integration: that is, from single-variable calculus to several-variable calculus. It turns Now let us move from one-dimensional integration out that there are increase: the “ambient space,”two objects whose dimensions may1 which will now be R ninstead of R, and the path, which will now become an oriented gr at i on will take place.
For example, ifk-dimensional manifold S, over which the inte-n = 3 and k = 2, then one is integrating over a surface that lives in R3. Let us begin with the case n ⩾ 1 and k = 1. Here, we will be integrating over a continuously differentiable path (or oriented rectifiable curve)$γ in R^{n} \text{starting and}$ ending at pointsmay or may not be distinct, depending on whether thea and b, respectively.
(These points path is open or closed.) From a physical point of view, we are still computing the work required to move froma to b, but now we are moving in several dimensions plicity, although the true power of the integration-of-forms concept ismuch more apparent when we integrate on more general spaces, such1. We will start with integration on Euclidean spaces Rn for sim- as abstractn-dimensional manifolds.

III. Mathematical Concepts

instead of one. In the one-dimensional case, we did notneed to specify exactly which path we used to get from a However, in higher dimensions, the exact choice of theto b, because all backtracking canceled itself out. pathγ becomes important. parametrizedγ Formally, a path fromfrom the unit interval) as a continuously differentiable function[a0,1 to] bto can be described (or Rn such that γ(0) =a and γ(1) = b. For instance, the line segment froma to b can be parametrized as γ(t) = (1 - t)a + tb. This segment also has many other par a me tr iz at i ons, such as  ̃γ(t) = (1 - t2)a + t2 b;
however, as in the one dimensional case, the exact choice of parametrization does not ultimately influence the integral. On the other hand, the reverse line segment$(-γ)(t) = ta + (1 - t)b$ fromalongb-γtowill turn out to be the negative of the integralais a genuinely different path; the integral alongγ. approximate the continuous path As in the one-dimensional case, we will need to$γ \text{by a discrete pathx}^{0} = γ(t^{0})$, x1 = γ(t1)$, x2 = γ(t2)$, $. . . , xn = γ(tn)$, whereγ(t0) = a and γ(tn) = b. Again, we allow some backtracking:
displacementtΔi +x1 is not necessarily larger than= x - x \in  Rn from x to xti. Theis now aon the generalization to manifolds, one should think vector rather than a scalar. (Indeed, with an eye(ii()+1()i()i()i)+1 ofΔxas an infinitesimal tangent vector to the ambii ent space Rn at the point x .) In the one-dimensional i

case, we converted the scalar displacementΔx intoi

a new number$f (x^{i})\Delta x^{i}$, which was linearly related to the original displacement by a proportionality con-stantf (x ) that depended on the position x . In higher dimensions, we again have a linear dependence, but$i^{i}$ this time, since the displacement is a vector, we must replace the simple constant of proportionality by a linear transformation represents the infinitesimal “work” required to move(ωx)i from Rn to R. Thus, ωx i(Δxi) fromxi to (xi)+1. In technical terms, ωx is a linear func-i

tional on the space of tangent vectors atx , and is thusi

a cotangent vector at$x$. By analogy with (3), the neti

workγ is approximated byγ ω required to move from a to b along the pathγ ω . pprox n i=-0 1 ωx i(Δxi). (7) As in the one-dimensional case, one can show thatthe right-hand side of (7) converges if the maximum step size supzero and the total length0⩽i⩽n - 1 |. elta xi|nof the path converges to - 1 |. elta xi| of the path staysi = 0 III.16. Differential Forms and Integration bounded. The limit is written asare restricting our attention to continuous functions.γ ω.
(Recall that we The existence of this limit uses the continuity of The objectω, which continuously assigns2 a cotan-ω.) gent vector to each point in Rn, is called a 1 - form, and (7) leads to a recipe for integrating any 1-formon a pathγ. That is, to shift the emphasis slightly, itω allows us to integrate the pathω. Indeed, it is useful to think of this integration asγ“against” the 1-form aproduct) that takes the curve binary operation (similar in some ways to the dotγ and the form ω as inputs, and returns a scalarin fact a “duality” between curves and forms; compare,γ ω as output.
There is for instance, the identity which expresses (part of) the fundamental fact that integration of forms is a linear operation, with theγ(ω1 + ω2) =γ ω1 +γ ω2, identity which generalizes (6) whenever the initial point ofthe final point ofγ1γ+ γ, where2 ω =γγ1 ω+ +γ is theγ2 ω, concatenationγ2 is 1 1 2 of Recall that ifγ1 and γ2.3 fis a differentiable function from Rn tofrom R, then its derivative at a point Rn to R(see [I.3 §5.3](/part - 01/fundamental - definitions)).
If fis continuously differ-x is a linear map entiable, then this linear map depends continuously onx, and can therefore be thought of as a 1-form, which we denote by d This 1-form can be characterized as the unique 1-formf , writing dfx for the derivative at x. such that one has the approximation

$f (x + v) \approx f (v) + df^{x} (v)$

for all infinitesimal is that|f (x + v) - f (v)v . (More rigorously, the condition- df (v)|/|v| → 0 as v \to  0.) alizes to The fundamental theorem of calculus (1) now gener-$x$ d$f = f (b) - f (a) (8)$ whenever pointb. In particular, ifγ is any oriented curve from a pointγ γ is closed, then df = 0. Notea to a that in order to interpret the left-hand side of the above equation, we are regarding it as a particular example ofγ bundle2. More precisely, one can think of3.
This duality is best understood using the abstract, and much.ω as a section of the cotangent more general, formalism of homology and cohomology. In particular, one can remove the requirement thatγ2 begins where γ1 leaves off by generalizing the notion of an integral to cover not just integration on paths, but also integration on formal sums or differences of paths. This makes the duality between curves and forms more symmetric.

177

an integral of the formbe the form df . Note also that, with this interpretation,γ ω: in this case,ω happens to dit does not appear under an integral sign.f has an independent meaning (it is a 1-form) even if small1-form that can be written as d A 1-form whose integral against every sufficiently4 closed curve vanishes is calledf for some continuously closed, while a differentiable function is called mental theorem implies that every exact form is closed.exact. Thus, the funda This turns out to be a general fact, valid for all mani-folds. Is the converse true:
that is, is every closed form exact? If the domain is a Euclidean space, or indeedany other simply connected manifold, then the answer is yes (this is a special case of theit is not true for general domains. In modern terminol-Poincaré lemma), but ogy, this demonstrates that the de Rham cohomology of such domains can be nontrivial. an object which we denote by As we have just seen, a 1-form can be thought of asω that associates with each pathω. Of course, ω is not justγ a scalar, any old function from paths to scalars:
it must sat-isfy the concatenation and reversing rules discussedγ earlier, and this, together with our continuity assump - tions, more or less forces it to be associated with some kind of continuously varying linear function that can beused, in combination withγ, to define an integral. Now let us see if we can generalize this basic idea from paths tostick to the two-dimensional case, that is, to int eg ratio nk-dimensional sets with k > 1.
For simplicity we shall of forms on (oriented) surfaces in Rn, since this already illustrates many features of the general case. Physically, such integrals arise when one is computing aacross a surface. We parametrized one-dimensional ori-flux of some field (e.g., a magnetic field) ented curves as continuously differentiable functionsγ from the interval [0, 1] to Rn. It is thus natural to parametrize two-dimensional oriented surfaces as con - tinuously differentiable functionsφdefined on the unit square[0, 1]2.
This does not in fact cover all possible surfaces one wishes to integrate over, but it turns outthat one can cut up more general surfaces into pieces that can be parametrized using “nice” domains suchas[0,1]2. intervalt In the one-dimensional case, we cut up the orientedto t [0=, 1]tinto infinitesimal oriented intervals from+ . elta t, which led to infinitesimal curves fromi xi + i 1= γ((ti)i) to xi + 1 = γ(ti + 1) = xi + . elta xi. Note that tract i ble point.4.
The precise condition needed is that the curve should be, which means that it can be continuously shrunk down to acon - 178 . eltaγx^ (ti and). elta t . In the two-dimensional case, we will cut up. elta t are related by the approximation . elta xi . pprox the unit square obvious way.(ii)5 A typical one of these will have cor-[0,1]2 into infinitesimal squares in an ners of the form(t + . elta t, t + . elta t).
The surface described by(t1$, t2)$, (t1 + Δt$, t2)$, (t1$, t2 +φ \delta\text{cant})$, then be partitioned into regions, with corners$φ(t^{1} +\Delta t$, t2 ), φ(t $, t +\Delta t)$, φ(t +Δt$, t +\Delta t)φ(t, \text{each of}1$, t2), which carries an orientation.
Sinceit is approximately linear at small distance scales, so1 2 1 2 1φis differentiable,2 this region is approximately an oriented parallelogram in Rn with corners x, x + . elta x, x + . elta x, x + . elta x +. elta2 x, where x = φ(t1, t2) and1 . elta1 x and2 . elta2 x are the1 infinitesimal vectors$\partialφ \partialφ\Delta1 x = \partial t1 (t1$, t2). elta t, . elta2 x = . artial t2 (t1, t2). elta t. Let us refer to this object as the infinitesimal parallel-ogram with dimensions. elta x ∧ . elta x and base point x.
For now, we will think of the symbol “notational convenience and not try to interpret it. In1 2∧” as a mere order to integrate in a manner analogous with integration on curves, we now need some sort of func-tionalωx at this base point that depends continuously onmal parallelogram and return an infinitesimal number x. This functional should take the above infinitesiωof “flux” passing through this parallelogram.$x (\Delta^{1}x ∧ \Delta^{2}x)$, which one can think of as the amount certain properties.
For instance, if you double double one of the sides of the infinitesimal parallel-As in the one-dimensional case, we expectω. elt(ax)1 to havex, you ogram, so (by the continuity ofthrough the parallelogram should double. More gener-ω) the “flux” passing ally,. elta x ωandx (. elta \1 elta1 xx∧: in other words, it isΔ2 x) should depend linearly on each ofbilinear. (This gen- eralizes the linear dependence in the one-dimensional case.)1 2 Another important property is that $ω^{x} (\Delta^{2}x ∧ \Delta^{1}x) = −ω^{x}(\Delta^{1}x ∧ \Delta^{2}x)$.
(9) That is, the bilinear formthis has an intuitive explanation: the parallelogram rep-ωx is antisymmetric. Again, resented bybyΔ x ∧ ΔΔx2 xexcept that it has had its orientation∧Δ1 x is the same as that represented reversed, so the “flux” now counts negatively where itused to count positively, and vice versa. Another way1 2 of seeing this is to note that if al le lo gram is degenerate and there should be no flux.$\Delta^{1}x = \Delta^{2}x$, then the par- ograms, triangles, etc.; this leads to an equivalent concept of the integral.5.
One could also use infinitesimal oriented rectangles, parallel-

III. Mathematical Concepts

Antisymmetry follows from this and the bilinearity. A2-formω is a continuous assignment of a functionalωx If with these properties to each pointω is a 2-form and φ:[0, 1]2 \to Rn is a continuous lyx. differentiable function, we can now define the integralω of ω“against”φ (or, more precisely, the inte- gral against the image under[φ0, 1]2) by the approximation φ of the oriented squareω . pprox  ωx i(. elta(x1), i ∧ . elta(x2), i ), (10)φi

where the image ofinto parallelograms of dimensionsφ is (approximately) partitioned. elta x ∧ . elta x based at pointsx . We do not need to decide what orde(r1)$, (i2)$, ii these parallelograms should be arranged in, because addition is both commutative and associative. One can show that the right-hand side of (10) converges to a unique limit as one makes the partition of parallelo - grams “increasingly fine,” though we will not make this precise here. We have thus shown how to integrate 2-forms against oriented two-dimensional surfaces.
More generally, onecan define the concept of ak-form on an n-dimensional manifold (such as Rn) for any 0 ⩽ k ⩽ n and inte- grate this against an orientedin that manifold. For instance, a 0-form on a manifoldk-dimensional surface X is the same thing as a scalar function f: X \to R, whose integral on a positively oriented pointis zero dimensional) isf (x), and on a negatively ori - x (which ented pointx is - f (x).
A k-form tells us how to assign a value to an infinitesimal with dimensionsΔx ∧· · ·∧k-dimensional parallelepipedΔx , and hence to a portion ofwe have seen when$k$-dimensional “surface,” in much the same way as1 k = 2. By convention, ifk k . neq k^ , the integral of ak - dimensional form on a k^ -dimensional surface is understood to be zero. We refer to 0-forms, 1-forms, 2-forms, etc. (and formal sums and differences there of), collectively as differential forms. perform on scalar functions:
addition pointwise product There are three fundamental operations that one can(f $, g) \to f g$, and differentiation(f , g) \to  f + g, f \to  df , although the last of these is not especially use- ful unless at i ons have various relationships with each other. Forfis continuously differentiable. These op er instance, the product is distributive over addition,

$f (g + h) = f g + f h$,

and differentiation is aproduct: derivation with respect to the d$(f g) = (df )g + f (dg)$.

III.16. Differential Forms and Integration

these operations to differential forms. Adding a pair It turns out that one can generalize all three of of forms is easy: if[0,1]k \to Rnis a continuously differentiable function,ω and η are two k-forms and φ: thenφ(ω + η)is defined to beφ ω +φ η. One multi- plies forms using the so-calledk-form and η is an l-form, thenwedge productω ∧η is a (k +.
Ifl)-form.ω is a Roughly speaking, given a$(k + l)$-dimensional infinitesimal parallelepiped with base pointΔx ∧ · · · ∧ Δx , one evaluates ωxandand dimensionsη at the par- all el ep ip eds with base point· · · ∧1 Δx and Δk +xl ∧ · · · ∧xΔand dimensionsx , respectively, andΔx1 ∧ multiplies the results together.(kk()+1()k)+l tiablethat measures something like the “rate of change” of As for differentiation, ifk-form, then its derivative dωis a continuously differen-ω is a (k + 1)-formω.
To see what this might mean, and in particular to seewhy dω is a (k + 1)-form, let us think how we might answer a question of the following kind. We are givena spherical surface in R3 and a flow, and we would like to know the net flux out of the surface: that is, the dif-ference between the amount of flux coming out and the amount going in. One way to do this would be to approximate the surface of the sphere by a union of tiny parallelograms, to measure the flux through each one, and to take the sum of all these fluxes.
another would be to approximate the solid sphere by a union of tiny parallelepipeds, to measure the net flux out of each of these, and to add up the results. If a parallelepiped issmall enough, then we can closely approximate the net flux out of it by looking at the difference, for each pair of opposite faces, between the amount coming out ofthe parallelepiped through one and the amount going into it through the other, and this will depend on the rate of change of the 2-form.
parallelepipeds is more rigorously described as inte-The process of summing up the net fluxes out of the grating a 3-form over the solid sphere. In this way, onecan see that it is natural to expect that information about how a 2-form varies should be encapsulated in a 3-form. a little bit of algebra and is omitted here. However, The exact construction of these operations requires we remark that they obey similar laws to their scalar counterparts, except that there are some sign changes that are ultimately due to the antisymmetry (9).
For instance, if commutative law for multiplication becomesω is a k-form and η is an l - form, theω ∧ η = (-1)klη ∧ ω, 179 basically because dimensions withlkl dimensions; and the derivation ruleswaps are needed to interchange k for differentiation becomes d(ω ∧ η) = (dω) ∧ η + (-1)kω ∧ (dη). Another rule is that the differentiation operator d isnilpotent: d(dω) = 0. (11) This may seem rather unintuitive, but it is fundamen-tally important. To see why it might be expected, let us think about differentiating a 1-form twice. The orig-inal 1-form associates a scalar with each small line segment.
Its derivative is a 2-form that associates a scalar with each small parallelogram. This scalar essentially measures the sum of the scalars given by the 1-formas you go around the four edges of the parallelogram, though to get a sensible answer when you pass to the limit you have to divide by the area of the parallelo-gram. If we now repeat the process, we are looking at a sum of the six scalars associated with the six facesof a parallelepiped.
But each of these scalars in turn comes from a sum of the scalars associated with thefour directed edges around the corresponding face, and each edge is therefore counted twice (as it belongs totwo faces), once in each direction. Therefore, the contributions from each edge cancel and the sum of all contributions is zero.
tween integrating a 2-form over the surface of a sphere The description given earlier of the relationship beand integrating its derivative over the solid sphere canbe thought of as a generalization of the fundamental theorem of calculus, and can itself be generalized considerably: Stokes’s theorem is the assertion that for any oriented manifold oriented boundary of SSd(which we will not define here).ωS=and form. artial S ω ω, where . artial S is the(12) Indeed one can view this theorem as a definition of the derivative operationω \to dω;
thus, differentiation is the identity (11) is dual to the geometric observation that adjoint of the boundary operation. (For instance, the the boundary boundary:. artial(. artial S). artial S = ∅of an oriented manifold itself has no.) As a particular case of Stokes’s theorem, we see that dω = 0 whenever S is a closed S manifold, i.e., one with no boundary. This observation lets one extend the notions of closed and exact forms to general differential forms, which (together with (11)) allows one to fully set up We have already seen that 0-forms can be identified de Rham cohomology.
with scalar functions. Also, in Euclidean spaces one can 180 use the inner product to identify linear functionals with vectors, and therefore 1-forms can be identified with vector fields. In the special (but very physical) case ofthree-dimensional Euclidean space R3, 2-forms can also be identified with vector fields via the famous hand rule,6 and 3-forms can be identified with scalar right functions by a variant of this rule.
(This is an exam-ple of a concept known as Hodge duality.) In this case, the differentiation operationω \to dω can be identi- fied with the0 - form, with the gradient curl operation operation Xf→ ∇ . imes→ ∇f Xwhenwhenωωis ais a 1 - form, and with the divergence operation X → ∇ · X when implies thatω is a 2 - form.
Thus, for instance, the rule (11)∇ . imes ∇f = 0 and ∇ · (∇ . imes X) for any suit- ably smooth scalar function various cases of Stokes’s theorem (12), with this inter-fand vector field X, while pretation, become the various theorems about integralsof curves and surfaces in three dimensions that you may have seen referred to as “the divergence theorem,”“Green’s theorem,” and “Stokes’s theorem” in a course on several-variable calculus. Just as the signed definite integral is connected to the unsigned definite integral in one dimension via(2), there is a connection between integration of
differential forms and the Lebesgue (or Riemann) inte-gral. On the Euclidean space Rn one has the n stan- dard coordinate functions Their derivatives dx , . . . , dxx1 are then 1-forms on, x2, . . . , xn: R$n \to RRn$.. Taking their wedge product, one obtains andx ∧ · · · ∧ dx . We can multiply this by any (contin-1 n n-formuous) scalar functionform1 f (x) dx ∧ · · · ∧n fd:$xR^{n}$.
If\to ΩRis any open boundedto obtain another n- domain in Rn, we then have the identit(y1)n where on the left-hand side we have an integral of a dif-ferential form (withΩ f (x) dx1 ∧ · · · ∧Ω viewed as a positively oriented dxn =Ω f (x) dx, nhave the Riemann or Lebesgue integral of-dimensional manifold) and on the right-hand side wef on Ω. If we givethe sign of the left-hand side. This correspondenceΩ the negative orientation, we have to reverse$generalizes (2)$.There is one last operation on forms that is worth pointing out. Suppose we have a continuously differen-tiable mapΦ:
X \to  Y from one manifold to another (we allow X and Yto have different dimensions). Then have used the left-hand rule to provide this identification, and apartfrom some harmless sign changes here and there, one gets essentially6. This is an entirely arbitrary convention; one could just as easily the same theory as a consequence.

III. Mathematical Concepts

of course every pointΦ(x) in Y. Similarly, if we letx in X pushes forwardv \in  T Xbe an infinites-to a point imal tangent vector togent vector also pushes forward X based atto a tangent vectorxx, then this tan-Φcan be defined by requiring the infinitesimal approxi-*v \in TΦ(x)Y based at Φ(x); informally speaking,$Φ^{*}v$ mation DΦ(x)(v)Φ(x$, where D + v) = Φ(x)Φ$: T+XΦ*\to v . One can write T Y is the deriva-Φ*v = tivek-dimensional oriented manifoldof the several-variable mapx ΦΦ(x)S atin x X.
Finally, anyalso pushes forward to a X, although in some cases (e.g., if the image ofk-dimensional oriented manifold Φ(S)Φ hasin dimension less thanmay be degenerate.k) this pushed-forward manifold between manifolds and forms. Since manifolds push forward under We have seen that integration is a duality pairingΦ from X to Y , we expect forms to pull backcan define thefrom Y topullback X. Indeed, given anyΦ*ω as the uniquek-form ωk-form onon Y, we X such that we have the change-of-variables formula In the case of 0-forms (i.e., scalar functions), the pull - backΦ*f:
X \to R of a scalar functionΦ(S) ω =S Φ*(ω).f:$Y \to R \text{is given}$ explicitly by$Φ^{*}f (x) = f (Φ(x))$, while the pullback of$a 1 - form$ω is given explicitly by the formula(Φ^*ω)x (v) = ω^Φ(x)(Φ^*v).

Similar definitions can be given for other differen-tial forms. The pullback operation enjoys several nice properties: for instance, it respects the wedge product,

$Φ^{*}(ω ∧ η) = (Φ^{*}ω) ∧ (Φ^{*}η)$,

and the derivative,

d$(Φ^{*}ω) = Φ^{*}(dω)$.

By using these properties, one can recover rather painlessly the change-of-variables formulas in severalvariable calculus. Moreover, the whole theory carries over effortlessly from Euclidean spaces to other manifolds. It is because of this that the theory of differ-ential forms and integration is an indispensable tool in the modern study of manifolds, and especially in differential topology [IV.7](/part-04/dierential-topology). III.17 Dimension What is the difference between a two-dimensional set and a three-dimensional set?
A rough answer that onemight give is that a two-dimensional set lives inside a plane, while a three-dimensional set fills up a portion of

III.17. Dimension

space. Is this a good answer? For many sets it does seemto be: triangles, squares, and circles can be drawn in a plane, while tetrahedra, cubes, and spheres cannot. But how about the surface of a sphere? This we would nor-mally think of as two dimensional, contrasting it with the solid sphere, which is three dimensional. But the surface of a sphere does not live inside a plane. Does this mean that our rough definition was incorrect? Not exactly. From the perspective of linear alge-bra, the set\\{(x}, y, z):
x2 + y2 + z2 = 1, which is the surface of a sphere of radius 1 in R3 centered at the origin, contained in a plane. (One can express this in algebraicis three dimensional, precisely because it is not language by saying that the affine subspace generatedby the sphere is the whole of R3.) However, this sense of “three dimensional” does not do justice to the roughidea that the surface of a sphere has no thickness.
Surely there ought to be another sense of dimension in which the surface of a sphere is two dimensional?As this example illustrates, dimension, though very important through out mathematics, is not a single con - cept. There turn out to be many natural ways of generalizing our ideas about the dimensions of simple sets such as squares and cubes, and they are often incom-patible with one another, in the sense that the dimension of a set may vary according to which definition you use. The remainder of this article will set out a few different definitions.
set is that it is “the number of coordinates you need tospecify a point.” We can use this to justify our instinct One very basic idea we have about the dimension of a that the surface of a sphere is two dimensional: youcan specify any point by giving its longitude and latitude. It is a little tricky to turn this idea into a rigorous mathematical definition because you can in fact specify a point of the sphere by means of justber if you do not mind doing it in a highly artificial one numway.
This is because you can take any two numbers and interleave the digits to form a single number fromwhich the original two numbers can be recovered. For instance, from the two numbers and e = 2.718281828 . . . you can form the numberπ = 3.141592653 . . .$32$.174\,118\,529\,821\,685\,238 . . ., and by taking alternate digits you get backto find a continuousπfunctionand e again. It is even possiblef from the closed inter - valand 1, inclusive) to the surface of a sphere that takes[0,1] (that is, the set of all real numbers between 0 every value. ural” coordinate system.
One way of making this deci-We therefore have to decide what we mean by a “nat - 181 sion leads to the definition of atant concept that is discussed in [I.3 §6.9](/part - 01/fundamental - definitions) and also inmanifold, a very impor differential topology idea that every point in the sphere is contained in a[IV.7](/part - 04/dierential - topology). This is based on the neighborhood in the sense that there is a “nice” one - to-one correspon - Nthat “looks like” a piece of the plane, dence R2. Here, “nice” can have different meanings:
typicalφ between N and a subset of the Euclidean plane ones are thatuous, or differentiable, or infinitely differentiable.φ and its inverse should both be contin- is one where you needcan be developed into a rigorous definition that tells Thus, the intuitive notion that ad numbers to specify a pointd-dimensional set us, as we had hoped, that the surface of a sphere is two dimensional. Now let us take another intuitive notion and see what we can get from it. Suppose I want to cut a piece of paper into two pieces.
The boundary that separates the pieces will be a curve, which we would normally like to think of as one dimen - sional. Why is it one dimensional? Well, we could use the same reasoning: if you cut a curve into two pieces then the part where the two pieces meet each other is a single point (or pair of points if the curve is a loop), which is zero dimensional. That is, there appears to bea sense in which a(d - 1)-dimensional set is needed if you want to cut a Let us try to be slightly more precise about this idea.d-dimensional set into two. Suppose that X is a set and x and y are points in X .
Let us call a setis no continuous path from Y a barrier xbetweento y that avoidsx and y if there Y . For example, ifcenter of X, and X is a solid sphere of radius 2, y is a point on the boundary ofx Xis the, then one possible barrier betweenx and y is the surface of a sphere of radius 1. With this terminology in place, wecan make the following inductive definition. A finite set is zero dimensional, and in general we say thatmostd dimensional if between any two points in XXthereis at is a barrier that is at most$(d - 1) dimensional$.
We also say thatbut not at most X is d dimensional(d - 1) dimensional.if it is at most d dimensional difficulties: one can construct a pathological set The above definition makes sense, but it runs into X that acts as a barrier between any two points in the plane, but contains no segment of any curve. This makes$X$ zero dimensional and therefore makes the plane one dimensional, which is not satisfactory.
A small modification to the above definition eliminates such patholo-gies and gives a definition that was put forward by brouweris said to have dimension at most[VI.75](/part-06/luitzen-egbertus-jan-brouwer-18811966). A complete metric spaced if, given any pair[III.56](/part - 03/metric - spaces) X 182 Figure 1 so that no four overlap. How to cover with squares of disjoint closed setsopen sets U and V with A Aand⊂ BU, you can find disjoint and B ⊂ V such that the complement Y of U ∪ V (that is, everything in X that does not belong to eitherat most$d - 1$.
The set Yis the barrier—the main differ - U or V ) has dimension ence is that we have now asked for it to be closed. the induction starts with the empty set, which has dimension - 1. Brouwer’s definition is known as the inductive dimension of a set. inition of dimension, proposed by Suppose you want to cover an open interval of real Here is another basic idea that leads to a useful def - lebesgue [VI.72](/part - 06/henri - lebesgue - 18751941). numbers (that is, an interval that does not contain its endpoints) with shorter open intervals.
Then you will beforced to make the shorter ones overlap, but you can do it in such a way that no point is contained in morethan two of your intervals: just start each new interval close to the end of the previous one. (that is, one that does not contain its boundary) with smaller open squares. Again you will be forced to make Now suppose that you want to cover an open square the smaller squares overlap, but this time the situationis slightly worse: some points will have to be contained in three squares.
However, if you take squares arranged like bricks, as in figure 1, and expand them slightly, then you can do the covering in such a way that nofour squares overlap. In general, it seems that to cover a typical need to have overlaps ofd-dimensional set with small open sets, youd + 1 sets but you do not need to have overlaps greater than this. The precise definition that this leads to is surprisingly general: it makes sense not just for subsets of R$n$ but even for an arbitrary topological space [III.90](/part-03/topological-spaces).
We say that a setever you cover X Xwith a finite collection of open setsis at mostd dimensional if, how-

III. Mathematical Concepts

$UV^{1}$, . . . , V, . . . , Un, you can find a finite collection of open setswith the following properties: 1$m$ (i) the sets V also cover the whole of X;

$i$

(iii) no point is contained in more than(ii) every Vi is a subset of at least one Udi+; 1 of the V .i

Ifsmall diameter, thereby forcing the X is a metric space, then we can choose our Vi to be small. So Ui to have this definition is basically saying that it is possible tocover X with open sets with no d + 2 of them overlap- ping, and that these open sets can be as small as youlike. be the smallest sion al.
And again it can be shown that this definition We then define thed such that topological dimension X is at most dofdimen-X to assigns the “correct” dimension to the familiar shapes of elementary geometry. A fourth intuitive idea leads to concepts known as homological with any suitable topological spaceand cohomological dimension. Associated X, such as a man- ifold, are sequences of groups known asand cohomology groups [IV.6 §4](/part-04/algebraic-topology). Here we will dis-homology cuss homology groups, but a very similar discussion is possible for cohomology.
Roughly speaking, the$nth$ homology group tells you how many interestingly dif-ferent continuous maps there are from closedn-dimen- sional manifolds less thann, then it can be shown that the M to X. If X is a manifold of dimension nth homology group is trivial: in a sense, there is not enough room in Xto define any map that is interestingly different from a constant map.
On the other hand, thegroup of then-sphere itself is Z, which says that onenth homology can classify the maps from themeans of an integer parameter.n-sphere to itself by It is therefore tempting to say that a space is at least ning maps from dimensional if there is room inside it for interest-n-dimensional manifolds. This thought leads to a whole class of definitions. The homological dimension of a structure Xis defined to be the largest nnth homology group.
(It is necessary to consider sub-for which some substructure of X has a nontrivial structures, because homology groups can also be trivial when there is too much room: it then becomes easy to deform a continuous map and show that it is equiva-lent to a constant map.) However, homology is a very general concept and there are many different homology theories, so there are many different notions of homo-logical dimension. Some of these are geometric, but there are also homology theories for algebraic struc-tures: for example, using suitable theories, one can

III.17. Dimension

define the homological dimension of algebraic struc-tures such as rings [III.81 §1](/part-03/rings-ideals-and-modules) or groups [I.3 §2.1](/part-01/fundamental-definitions). This is a very good example of geometrical ideas having an algebraic payoff. Now let us turn to a fifth and final (for this article at least) intuitive idea about dimension, namely the way itaffects how we measure size. If you want to convey how big a shape X is, then a good way of doing so is to give the length oftwo dimensional, and the volume if it is three dimen-X if X is one dimensional, the area if it is sional.
Of course, this presupposes that you already know what the dimension is, but, as we shall see, there is a way of deciding which measure is the most appropriate Then the tables are turned: we can actually without determining the dimension in advance.define the dimension to be the number that corresponds to thebest measure. To do this, we use the fact that length, area, and volume scale in different ways when you expand a shape. If you take a curve and expand it by a factor of 2 (in all directions), then its length doubles.
More generally, ifyou expand by a factor of C, then the length multiplies byexpand it by C. However, if you take a two-dimensional shape and C, then its area multiplies by C2. (Roughly speaking, this is because each little portion of the shape expands by C“in two directions” so you have to multiply the area by dimensional shape multiplies by C twice.) And the volume of a three - C3: for instance, the volume of a sphere of radius 3 is twenty-seven timesthe volume of a sphere of radius 1.
advance whether we will talk about length, area, or vol-It may look as though we still have to decide in ume before we can even begin to think about how the measurement scales when we expand the shape. But this is not the case. For instance, if we expand a squareby a factor of 2, then we obtain a new square that can be divided up into four congruent copies of the original square. So, without having decided in advance that we are talking about area, we can say that the size of thenew square is four times that of the old square.
there are sets to which it is natural to assign a dimen-This observation has a remarkable consequence: sion that is not an integer! Perhaps the simplest exam-ple is a famous set first defined by cantor [VI.54](/part - 06/georg - cantor - 18451918) and now known as the follows. You start with the closed interval Cantor set. This set is produced as[0, 1], and call itdle third of$X0$. Then you form a set X: that is, you remove all points between X1 by removing the mid- union of the closed intervals13 and 23, but leave0 13 and 23$[0themselves$. So,1 3] and [2 3, 1]. Next, you X1 is the

183

remove the middle thirds of these two closed intervalsto produce a set X , so X is the union of the intervals[0,1 9 ], [2 9,1 3 ], [2 3,7 9 2], and2[8 9,1]. is what you get by removing the middle thirds of each In general, Xn is a union of closed intervals, and (Xn)+1 of these intervals—sointervals as X , but they are a third of the size. Once you(Xn)+1 consists of twice as many have produced the sequence$n X^{0}$, X1$, X2$, . . ., you define the Cantor set to be the intersection of all the$X$: that

$i$

is, all the real numbers that remain, no matter how far you go with the process of removing middle thirdsof intervals. It is not hard to show that these are precisely the numbers whose ternary expansions consist just of 0 s and 2 s. (There are some numbers that have two different ternary expansions. For instance, be written either as 0.1 or as 0.02222 . . .. In such case(s1)3 can we take the recurring expansion rather than the ter-minating one.
So 1 belongs to the Cantor set.) Indeed, when you remove middle thirds for the3 nth time, you are removing all numbers that have a 1 in theafter the “decimal” (in fact, ternary) point.nth place The Cantor set has many interesting properties. For example, it issure [III.55](/part-03/measures) zero. Briefly, the first of these assertions uncountable [III.11](/part-03/countable-and-uncountable-sets), but it also has meafollows from the fact that there is a different element of the Cantor set for every subset bers (just take the ternary number 0 A of the natural num-.a a a . .
., whereaare uncountably many subsets of the natural numbers.i = 2 whenever i \in  A and ai = 0 otherwise), and ther(e1()2){3}To justify the second, note that the total length of the intervals making up X is (2)n (since one removes a third ofcontained in every(Xn)-1 to produce Xn, its measure must be smaller (Xn)3). Since the Cantor set is thanzero. Thus, the Cantor set is very large in one respect( {}23)n, whatever nnis, which means that it must be and very small in another.
A further property of the Cantor set is that it is selfsimilar look at just one of these intervals as the middle thirds. The set X1 consists of two intervals, and if you are repeatedly removed, then what you see is just like the construction of the whole Cantor set, but scaled down by a factor of 3. That is, the Cantor set consists of two copies of itself, each scaled down by a factorof 3. From this we deduce the following statement:
if you expand the Cantor set by a factor of 3, then you candivide the expanded set up into two congruent copies of the original, so it is “twice as big.” What consequence should this have for the dimension of the Cantor set? Well, if the dimension isd, then

184

the expanded set ought to be 3 fore, 3 d should equal 2. This means that^d times as big. There-d should be$log 2$/ log 3, which is roughly 0.63. is lessened. As we shall see in a moment, a theory of fractional dimension can be developed with the use-Once one knows this, the mystery of the Cantor set ful property that a countable union of sets of dimen-sion at mostd has dimension at most d. Therefore, the fact that the Cantor set has dimension greater than 0 implies that it cannot be countable (since single points have dimension 0).
On the other hand, because the dimension of the Cantor set is less than 1, it is much smaller than a one-dimensional set, so it is no surprise that its measure is zero. (This is a bit like saying thata surface has no volume, but now the two dimensions are 0.63 and 1 instead of 2 and 3.)The most useful theory of fractional dimension is one developed by hausdorff [VI.68](/part-06/felix-hausdor-18681942).
One begins with a concept known as Hausdorff measure, which is a nat-ural way of assessing the “$d$-dimensional volume” of a set, even ifin R3 and you want to work out its length by consider-d is not an integer. Suppose you have a curve ing how easy it is to cover it with spheres. A first idea might be to say that the length was the smallest youcould make the sum of the diameters of the spheres. But this does not work: you might be lucky and find thata long curve was tightly wrapped up, in which case you could cover it with a single sphere of small diameter. spheres were required to be small.
Suppose, therefore, that we require all the diameters of the spheres to be However, this would no longer be possible if your at mostsum of the diameters to be. The smallerδ. Let L(δ) be the smallest we can then get theδ is, the less flexibility we have, so the larger L(δ)tends to a (possibly infinite) limit L(δ) will be. Therefore, L as δ tends to 0, and we call Now suppose that we have a smooth surface in L the length of the curve. R3 and want to deduce its area from information about covering it with spheres.
This time, the area that you can cover with a very small sphere (so small that itmeets only one portion of the surface and that portion is almost flat) will be roughly proportional to thesquare of the diameter of the sphere. But that is the only detail we need to change: letcan make the sum of the squares of the diameters of a A(δ) be the smallest we set of spheres that cover the surface, if all those spheres have diameter at mostδ. Then declare the area of the surface to be the limit of A(δ) as δ tends to 0.
(Strictly speaking, we ought to multiply this limit bythen we get a definition that does not generalize easily.)$π/4$, but

III. Mathematical Concepts

for shapes inwas that for length we considered the sum of the diam-We have just given a way of defining length and area, R3. The only difference between the two eters of small spheres, while for area we considered the sum of the In general, we define the squares of the diameters of small spheres.$d$-dimensional Hausdorff measuredth powers of the diameters.in a similar way, but considering the sum of the a rigorous definition of fractional dimension. It is not We can use the concept of Hausdorff measure to give hard to show that for any shapeone appropriate$d$, in the following sense:
if X there will be exactlyc is less than Xis infinite, while ifd, then the c-dimensional Hausdorff measure ofc is greater than d, then it is 0. (For instance, thea smooth surface is 0 if$c$-dimensional Hausdorff measure of$c <$2 and infinite if$c > 2$.) Thisddorff dimension is very useful for analyzing fractal sets, is called the Hausdorff dimension of the set X. Haus- which are discussed further in It is important to realize that the Hausdorff dimen-dynamics [IV.14](/part-04/dynamics).
sion of a set need not equal its topological dimension. For example, the Cantor set has topological dimension zero and Hausdorff dimension log 2/ log 3. A larger example is a very wiggly curve known as the snowflake. Because it is a curve (and a single point is Koch enough to cut it into two) it has topological dimen-sion 1. However, because it is very wiggly, it has infinite length, and its Hausdorff dimension is in factlog 4/ log 3. III.18 Distributions

Terence Tao

A function is normally defined to be an object f:$X \to Y$ which assigns to each pointx in a set X, known as the domain range (see, a pointthe language and grammar of mathe-f (x) in another set Y , known as the maticsset-theoretic and the fundamental operation that one[I.2 §2.2](/part-01/language-and-grammar)). Thus, the definition of functions is can perform on a function ismentx of X, one evaluates f a te va lu at io nx to obtain the element: given an elef (x)However, there are some fields of mathematics whereof Y .
this may not be the best way of describing functions. In geometry, for instance, the fundamental property of a function is not necessarily how it acts on points, butrather how it pushes forward or pulls back objects that are more complicated than points (e.g., other functions, bundles sheaves, etc.). Similarly, in analysis, a function need not[IV.6 §5](/part-04/algebraic-topology) and sections, schemes [IV.5 §3](/part-04/arithmetic-geometry) and

III.18. Distributions

necessarily be defined by what it does to points, butmay instead be defined by what it does to objects of different kinds, such as sets or other functions; the for-mer leads to the notion of a measure; the latter to that of a distribution. like objects are related. In analysis, it is helpful to think Of course, all these notions of function and functionof the various notions of a function as forming a spec-trum, with very “smooth” classes of functions at one end and very “rough” ones at the other. The smooth classes of functions are very restrictive in their membership:
this means that they have good properties, andthere are many operations that one can perform on them (such as, for example, differentiation), but it also means that one cannot necessarily ensure that the func-tions one is working with belong to this category. Conversely, the rough classes of functions are very general and inclusive: it is easy to ensure that one is working with them, but the price one pays is that the number of operations one can perform on these functions is often sharply reduced (see function spaces [III.29](/part-03/function-spaces)).
often be treated in a unified manner, because it is Nevertheless, the various classes of functions can often possible to approximate rough functions arbitrar-ily well (in an appropriate topology [III.90](/part-03/topological-spaces)) by smooth ones. Then, given an operation that is naturally defined for smooth functions, there is a good chance that therewill be exactly one natural way to extend it to an operation on rough functions: one takes a sequence of better and better smooth approximations to the rough func-tions, performs the operation on them, and passes to the limit.
rough end of the spectrum, but before we say what Distributions, or generalized functions, belong at the they are, it will be helpful to begin by considering some smoother classes of functions, partly for comparison and partly because one obtains rough classes of func-tions from smooth ones by a process known as duality: ais simply a linear maplinear functional defined on a spaceφ from E to the scalars E of functions R or C. Typically, topology, and the E is a normed space, or at least comes with adual space is the space of continuous linear functionals.
The class Cω[-1, 1] of analytic functions. These are in many ways the “nicest” functions of all, and include many familiar functions such as exp(x), sin(x), poly - nomials, and so on. However, we shall not discuss them further, because for many purposes they form too rigida class to be useful. (For example, if an analytic func - 185 tion is zero every where on an interval, then it is forcedto be zero every where.) The class C. nfty [-1, 1] of test functions.
These are the c smooth (that is, infinitely differentiable) functions defined on the interval[-1, 1], that vanish on neighbor - f , hoods of 1 andf$(x) = 0 whenever - 1$. (That is, one can findx > 1 - δ or x < -1δ >+ δ0 such that.) They are more numerous than analytic functions and therefore more tractable for analysis. For instance, it is often use-ful to construct smooth “cutoff functions,” which are functions that vanish outside some small set but do notvanish inside it.
Also, all the operations from calculus (differentiation, integration, composition, convolution, evaluation, etc.) are available for these functions. The class$C0[-1$, 1] of continuous functions. These functions are regular enough for the notion of evalua-tion,$x \to f (x)$, to make sense for every x \in  [-1, 1], and one can integrate such functions and perform algebraic operations such as multiplication and compo-sition, but they are not regular enough that operations such as differentiation can be performed on them. Still, they are usually considered among the smoother examples of functions
in analysis. The class L2[-1, 1] of square - integrable functions. These are measurable functions which the Lebesgue integral 1 f|f (x):[-|12, d1 x]is finite.$\to R for$ Usually one regards two such functions equal if the set ofx such that - 1 f (x) =f g(x)and ghasas measure zero. (Thus, from the set-theoretic point ofview, the object in question is really an equivalence class [I.2 §2.3](/part - 01/language - and - grammar) of functions.) Since a singletonx has measure zero, we can change the value ofout changing the function.
Thus, the notion of evalua - f (x) with- tion does not make sense for a square-integrable func - tionf (x)at any specific pointx. However, two func- tions that differ on a set of measure zero have thesame lebesgue integral [III.55](/part - 03/measures), so integration does make sense. in the following sense. Any two functions in thisclass can be paired together by the A key point about this class is that it isinner product self-dual gtional onf, g \in L =2[-1 L-1,2 11[f (x)g(x)]-, the map1, 1], which turns out to be continuous.dfx→ .
Therefore, given a functionf , gdefines a linear func Moreover, given any continuous linear functional L2[-1,1], there is a unique function g \in  L2[-1,1]φsuchon thatφ(f ) = f , g for every f . This is a special case of one of the Riesz representation theorems.

186

The class$C0[-1$, 1]*of finite Borel measures. Any finite Borel linear functional onmeasure C[III.55](/part-03/measures)0[-1,μ1]gives rise to a continuous defined byf → μ, f  = rems says that every continuous linear functional on C-1 0 1[f (x)-1, 1 d]\mu arises in this way, so one could in principle. Another of the Riesz representation theo- define a finite Borel measure to be a continuous linear functional on$C0[-1$, 1].The class C. nf ty [-1, 1]* of distributions.
Just as mea- c sures can be viewed as continuous linear functionals on C0[-1, 1], a distribution \mu is a continuous linear functional on C. nfty [-1,1] (with an appropriate topol- c ogy). Thus, a distribution can be viewed as a “virtual function”: it cannot itself be directly evaluated, or even integrated over an open set, but it can still be paired with any test functiong \in C . nfty [-1, 1], producing a num - c berδ, defined as the functional which, when paired with\mu, g . A famous example is the Dirac distribution any test function zero:0δ$, g = g(g0, \text{returns the evaluation})$.
Similarly, we have the derivativeg(0) of g at of the Dirac distribution, any test function0 g, returns the derivative-δ0, which, when paired withg^ (0) of g at zero: will be given later.) Since test functions have so many-δ0$, g = g (0)$. (The reason for the minus sign operations available to them, there are many ways todefine continuous linear functionals, so the class of distributions is quite large. Despite this, and despite theindirect, virtual nature of distributions, one can still define many operations on them; we shall discuss thislater. The class Cω[-1, 1]* of hyperfunctions.
There are classes of functions more general still than distribu-tions. For instance, there are hyperfunctions, which roughly speaking one can think of as linear function-als that can be tested only against analytic functions g C . nfty \in [-C1ω, [1-]. However, as the class of analytic functions1,1] rather than against test functions g \in is so sparse, hyperfunctions tend not to be as useful inanalysis as distributions.
ited utility, since all a distribution is to be tested against test functions At first glance, the concept of a distribution has lim-\mu is empowered to dog to produce inner products can often take operations that are initially defined only\mu, g . However, using this inner product, one on test functions, and duality. A typical example is differentiation. suppose extend them to distributions by one wants to know how to define the derivativea distribution, or in other words how to define\mu\mu^, gof

III. Mathematical Concepts

for any test functiona test function\mu = fg, then we can evaluate this usingand distribution \mu. If \mu is itself integration by parts (recalling that test functions vanishat-1 and 1). We havef^ , g =-1 1 f^ (x)g(x) dx= −-1 1 f (x)g^ (x) dx = −f , g^ . Note that ifg is a test function, then so is g^ . We can therefore generalize this formula to arbitrary distribu-tions by defining\mu^, g = −\mu, g^. This is the justification for the differentiation of the Dirac distribution:δ^, g = −δ , g^ = −g^ (0).
More formally, what we have done here is to com - 0 0 pute the adjoint of the differentiation operation (asdefined on the dense space of test functions). Then we have taken adjoints again to define the differentiation operation for general distributions. This proce-dure is well-defined and also works for many other concepts; for instance, one can add two distributions, multiply a distribution by a smooth function, convolve two distributions, and compose distributions on both the left and the right with suitably smooth functions.
One can even take Fourier transforms of distributions. For instance, the Fourier transform of the Dirac deltaδ is the constant function 1, and vice versa (this is essen - 0 tially the Fourier inversion formula), while the distribu - tionδ (x - n) is its own Fourier transform (this is essentially the Poisson summation formula). Thus, n \in Z)0 the space of distributions is quite a good space to workin, in that it contains a large class of functions (e.g., all measures and integrable functions), and is also closed under a large number of common operations in analy-sis.
Because the test functions are dense in the space of distributions, the operations as defined on distributions are usually compatible with those on test func-tions. For instance, iff and g are test functions andf^  = g in the sense of distributions, then f^  = g will also be true in the classical sense. This often allowsone to manipulate distributions as if they were test functions without fear of confusion or inaccuracy.
The main operations one has to be careful about are evalua-tion and pointwise multiplication of distributions, both of which are usually not well-defined (e.g., the square of the Dirac delta distribution is not well-defined as a distribution). Another way to view distributions is as the weak limit of test functions. A sequence of functions converge weakly to a distribution\mu if f , gfn → is said to\mu, gn III.19. Duality for all test functions tion with total integralg.
For instance, if1 φ = 1, then the test func-φ is a test func- tions weakly to the Dirac delta distribution fn(x) = nφ(nx)-1 can be shown to convergeδ , while the functions derivativefδn^ (x)of the Dirac delta. On the other hand,= n2φ^ (nx) converge weakly to the0 the functionsto zero (this is a variant of the0$gn(x) = \cos (nx)φ(x)$ Riemann–lebesgue converge weakly lemma). Thus weak convergence has some unusual features not present in stronger notions of convergence, in that severe oscillations can sometimes “disappear” in the limit.
One advantage of working with distribu-tions instead of smoother functions is that one often has some compactness in the space of distributions under weak limits (e.g., by the Banach–Alaoglu theorem). Thus, distributions can be thought of as asymp-totic extremes of behavior of smoother functions, just as real numbers can be thought of as limits of rational numbers.
while still being closely connected to smoother func - tions, they have been extremely useful in the study of Because distributions can be easily differentiated, partial differential equations (PDEs), particularly whenthe equations are linear. For instance, the general solution to a linear PDE can often be described in termsof its fundamental solution, which solves the PDE in the sense of distributions.
More generally, distribution theory (together with related concepts, such as that of anot the only) means to define weak derivative) gives an important (though certainly generalized solutions of both linear and nonlinear PDEs. As the name suggests, these generalize the concept of smooth (orsolutions by allowing the formation of singularities, classical) shocks, and other nonsmooth behavior. In some casesthe easiest way to construct a smooth solution to a PDE is first to construct a generalized solution and then touse additional arguments to show that the generalized solution is in fact smooth.
 III.19 Duality Duality is an important general theme that has manifes-tations in almost every area of mathematics. Over and over again, it turns out that one can associate with agiven mathematical object a related, “dual” object that helps one to understand the properties of the objectone started with. Despite the importance of duality in mathematics, there is no single definition that covers all instances of the phenomenon. So let us look at a 187 few examples and at some of the characteristic features that they exhibit.
1 Platonic Solids Suppose you take a cube, draw points at the centers ofeach of its six faces, and let those points be the vertices of a new polyhedron. The polyhedron you get willbe a regular octahedron. What happens if you repeat the process? If you draw a point at the center of eachof the eight faces of the octahedron, you will find that these points are the eight vertices of a cube. We say thatthe cube and the octahedron are dual to one another. The same can be done for the other Platonic solids:
the dodecahedron and the icosahedron are dual to one another, while the dual of a tetrahedron is again a tetrahedron. The duality just described does more than just split up the five Platonic solids into three groups: it allows usto associate statements about a solid with statements about its dual. For instance, two faces of a dodecahe-dron are adjacent if they share an edge, and this is so if and only if the corresponding vertices of the dual icosahedron are linked by an edge. And for this reason there is also a correspondence between edges of the dodecahedron and edges of the icosahedron.
2 Points and Lines in the Projective Plane There are several equivalent definitions of the projective planethat it is the set of all lines in[I.3 §6.7](/part - 01/fundamental - definitions). One, which we shall use here, is R3 that go through the origin. These lines we call the “points” of the projec-tive plane. In order to visualize this set as a geometrical object and to make its “points” more point - like, itis helpful to associate each line through the origin with the pair of points in R3 at which it intersects the unit sphere:
indeed, one can define the projective plane asthe unit sphere with opposite points identified. all “points” (that is, lines through the origin) that lie insome plane through the origin. This is associated with A typical “line” in the projective plane is the set of the great circle in which that plane intersects the unit sphere, once again with opposite points identified. points in the projective plane:
each point P is associated with the line L that consists of all points orthogonal to There is a natural association between lines and P, and each line L is associated with the single point P that is orthogonal to all points in L. For example, if P isthez - axis, then the associated projective line L is the set of all lines through the origin that lie in thexy - plane, 188 and vice versa. This association has the following basic property:
if a point P belongs to a line L, then the line associated with P contains the point associated with L.This allows us to translate statements about points and lines into logically equivalent statements about lines and points. For example, three points are collinear (that is, they all lie in a line) if and only if the corre-sponding lines are concurrent (that is, there is some point that is contained in all of them). In general, onceyou have proved a theorem in projective geometry, you get another, dual, theorem for free (unless the dual theorem turns out to be the same as the original one).
3 Sets and Their Complements Let ple ment X be a set. Ifof A, written A is any subset of Ac, is the set of all elements of X, then the com-X that do not belong toplement of A is clearly A. The complement of the com-A, so there is a kind of dual- ity between sets and their complements.laws are the statements that$(A ∩ B)c =$ De Morgan’s Ac ∪ Bc and(A ∪ B)c = Ac ∩ Bc: they tell us that complement at i on “turns intersections into unions,” and vice versa. Notice that if we apply the first law to Ac and Bc, then we find that(Ac ∩ Bc)c = A ∪ B.
Taking complements of both sides of this equality gives us the second law. ing unions and intersections remains true when you interchange them. For example, one useful identity is Because of de Morgan’s laws, any identity involv$A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C)$. Applying this to the complements of the sets and using de Morgan’s laws, itis straightforward to deduce the equally useful identity

$A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C)$. 4 Dual Vector Spaces Letspace V be a V^*is defined to be the set of allvector space [I.3 §2.3](/part-01/fundamental-definitions), over linear functionals R, say. The dual on$V$: that is, linear maps from V to R. It is not hard to define appropriate notions of addition and scalar mul-tiplication and show that these make$V^{*} \text{into a vector}$ space as well. Suppose that T is a linear map[I.3 §4.2](/part-01/fundamental-definitions) from a vector spacementw* of the dual space V to a vector space W W*, then we can use.
If we are given an ele-T andwthat takes* to create an element ofv to the real number V*as follows: it is the map$w^{*}(T v)$. This map, which is denoted byear. The function T*T*is itself a linear map, called thew*, is easily checked to be lin- adjointof$V^{*}$. of T, and it takes elements of W* to elements

III. Mathematical Concepts

object This is a typical feature of duality: a function A to object B very often gives rise to a functionf fromg from the dual of Suppose that T*Bis a surjection. Then ifto the dual of A. v = v^ , we can find$v^{*} \text{such that} v^{*}(v) = v^{*}(v)$, and thenw T^*^*w\in^*(v W^*^ ), and therefore such that T*w*w=*v(T v)*, so that = w*T(T v*w*)(v). This= implies thattion. We can also prove that if T v = T v^ , which proves that T* is an injection, then T is an injec-T is a surjection.
Indeed, if T is not a surjection, then T Va nonzero linear functional is a proper subspace of Ww*, which allows us to findsuch that w*(T v) = 0 for every contradicts the injectivity ofv \in V , and hence such that T*. If VTand*w*W=are finite0, which dimensional, thenthat T is an injection if and only if(T*)* = T, so in this case we find T* is a surjection, and vice versa. Therefore, we can use duality to convert an existence problem into a uniqueness problem. This conversion of one kind of problem into a different kind is another characteristic and very useful featureof duality.
tion of the dual space may well change. For instance, if XIf a vector space has additional structure, the defini-is a real [III.62](/part - 03/normed - spaces - and - banach - spaces), then X*is defined to be the space of allfrom X to Rbanach space, rather than the space of continuous linear functionals all linear func- tionals. This space is also a Banach space: the norm of a continuous linear functional$\sup {|f (x)|}$:$x \in X$, x ⩽ 1.
If X is an explicit exam-fis defined to be ple of a Banach space (such as one of the spaces dis-cussed in function spaces [III.29](/part-03/function-spaces)), it can be extremely useful to have an explicit description of the dual space. That is, one would like to find an explicitly described Banach space Y and a way of associating with each nonzero element functionalφdefined ony of Y a nonzero continuous linear X, in such a way that every continuous linear functional is equal to$y \in Y$.y φy for some and From this perspective, it is more natural to regard Yas having the same status.
We can reflect this in$X$ our notation by writingdo this, then we are drawing attention to the fact that$x$, y instead of φy(x). If we the mapnumber·x, y, ·, which takes the pair, is a continuous bilinear map from(x, y) to the real X . imes Y to R. More generally, whenever we have two mathematical objectsa function A andβ: AB, a set . imes B \to SSof “scalars” of some kind, andthat is a structure-preserving map in each variable separately, we can think of the III.19. Duality elements ofversa. Functions like A as elements of the dual ofβ are called pairings.
B, and vice 5 Polar Bodies Let X be a subset of[III.37](/part - 03/bayesian - analysis) on Rn and let Rn. Then the· , · be the standard polar of X, inner product denoted X◦, is the set of all points y \in  Rn such that Xconvex, thenx, y◦ is closed and convex, and that if⩽ 1 for every(X◦)◦ =x X\in . Further more, if X.
It is not hard to check that X is closed andn = 3 and X is a Platonic solid centered at the origin, then X◦ is (a multiple of) the dual Platonic solid, and ifball” of a normed space (that is, the set of all points of$X$is the “unit norm at most 1), then$X^{\circ}$is (easily identified with) the unit ball of the dual space. 6 Duals of Abelian Groups if homomorphism from G is an Abelian group, then a G to the group character T of all complexon G is a numbers of modulus 1.
Two characters can be multi-plied together in an obvious way, and this multiplication makes the set of all characters on Abelian group, called the dual group, ˆG, of the group G into another G. Again, ifimposes an additional continuity condition. G has a topological structure, then one usually An important example is when the group is itself T. It is not hard to show that the continuous homomor-phisms from T to T all have the form eiθ \to (ei)nθ for some integer the dual of Tnis (isomorphic to)(which may be negative or zero). Thus, Z.
tryagin duality ing between This form of duality between groups is called$G$. Note that there is an easily defined pair-and ˆ$G$: given an element$g \in G \text{and a Pon}-$ character$ψ \in G$ˆ, we defineg, ψ to be ψ(g). functions$G$ˆ Under suitable conditions, this pairing extends toare finite, and defined onf G: and ˆG \to G. For instance, if C and F: ˆ$G G \to and C$, then we can define|G|-1 f (g)F(ψ)f , F to be the complex number.
In general, one obtains a pairing between a complex functions on$g \in^{G} G^{ψ} \in$and a Hilbert space of functions on ˆGˆ hilbert space [III.37](/part-03/bayesian-analysis) of G. duality. Given a function in the Hilbert spaceits This extended pairing leads to another important Fourier transform is the function ˆf \in (ZL)2 that(T), is defined by the formula f (n)ˆ= 21π0 2 π f ((ei)θ)(e-i)nθ dθ. The Fourier transform, which can be defined similarly for functions on other Abelian groups, is immensely

189

useful in many areas of mathematics. (See, for exam-ple, fourier transforms [III.27](/part-03/the-fourier-transform) and representation theory examples, it is[IV.9](/part-04/representation-theory).) By contrast with some of the previous not always easy to translate a statement about a function about its Fourier transform ˆf into an equivalent statementf , but this is what gives the Fourier transform its power: if you wish to under-stand a function fdef in ed on T, then you can explore its properties by looking at both$f$and ˆf .
Some proper- ties will follow from facts that are naturally expressedin terms off and others from facts that are naturally expressed in terms of ˆ“doubles one’s mathematical power.”f . Thus, the Fourier transform 7 Homology and Cohomology Let If MX andbe a compact M^  are ann-dimensional i-dimensional submanifold and manifold[I.3 §6.9](/part-01/fundamental-definitions). an(n - i)-dimensional submanifold of X, respectively, and if they are well-behaved and in sufficiently general position, then they will intersect in a finite set ofpoints.
If one assigns either 1 or-1 to each of these points in a natural way that takes account of howand M^  intersect, then the sum of the numbers at the M points is an invariant called the M and M^ . This number turns out to depend only on intersection number of theit defines a map from homology classes H (X)[IV.6 §4](/part-04/algebraic-topology) of. imes  H^- (X)M andto Z, where we M^ . Thus, writeis a group homomorphism in each variable separately, Hr (X) for the r th homology group o(fi()n)i X.
This map and the resulting pairing leads to a notion of duality called Poincaré duality, and ultimately to the modern theory ofwith some of our other examples, many concepts asso-cohomology, which is dual to homology. As ciated with homology have dual concepts: for exam-ple, in homology one has a boundary map, whereas in cohomology there is adirection).
Another example is that a continuous map coboundary map (in the opposite from X to Y gives rise to a homomorphism from the homology groupand also to a homomorphism from the cohomology Hi(X) to the homology group Hi(Y ), group Hi(Y ) to the cohomology group Hi(X). 8 Further Examples Discussed in This Book The examples above are not even close to a complete list: even in this book there are several more.
For instance, the article oncusses a pairing, and hence a duality, between differential forms [III.16](/part-03/dierential-forms-and-integration) dis-k-forms and integrating the form over the surface.) The article onk-dimensional surfaces. (The pairing is given by

190

distributions rigorous definitions of function-like objects such as the[III.18](/part-03/distributions) shows how to use duality to give Dirac delta function. The article on[IV.16](/part-04/mirror-symmetry) discusses an astonishing (and still largely con-mirror symmetry jectural) duality between and so-called “mirror manifolds.” Often the mirror calabi–yau manifolds [III.6](/part-03/calabiyau-manifolds) manifold is much easier to understand than the origi-nal manifold, so this duality, like the Fourier transform, makes certain calculations possible that would otherwise be unthinkable.
And the article ontion theory [IV.9](/part-04/representation-theory) discusses the “Langlands dual” of represent a certain (non-Abelian) groups: a proper understanding of this duality would solve many major open problems. III.20 Dynamical Systems and Chaos From a scientific point of view, a dynamical system is aphysical system, such as a collection of planets or the water in a canal, that changes over time.
Typically, the positions and velocities of the parts of such a system at a timeties of those parts just before that time, which meanst depend only on the positions and veloci- that the behavior of the system is governed by a systemof partial differential equations [I.3 §5.3](/part-01/fundamental-definitions). Often, a very simple collection of partial differential equations can lead to very complicated behavior of the physical system.
tem is any mathematical object that evolves in time From a mathematical point of view, a dynamical sys according to a precise rule that determines the behaviorof the system at timet from its behavior just before- hand. Sometimes, as above, “just beforehand” refers toa time infinitesimally earlier, which is why calculus is involved. But there is also a vigorous theory of discrete dynamical systems, where the “time”values, and the “time just before$t$” istt-takes integer1.
If f is the function that tells us how the system at timeon the system at timet - 1, then the system as a wholet depends can be thought of as the process ofapplyingf over and over again. iterating f: that is, function iterate it enough times. In particular, some of the most As with continuous dynamical systems, a very simplef can lead to very complicated behavior if you interesting dynamical systems, both discrete ones and continuous ones, exhibit an extreme sensitivity to initial conditions, which is known asfor example, of the equations that govern weather. Onechaos.
This is true, cannot hope to specify exactly the wind speed at every point on the Earth’s surface (not to mention high above

III. Mathematical Concepts

it), which means that one has to make do with approx-imations. Because the relevant equations are chaotic, the resulting inaccuracies, which may be small to start with, rapidly propagate and overwhelm the system: youcould start with a different, equally good approximation and find that after a fairly short time the systemhad evolved in a completely different way. This is why accurate forecasting is impossible more than a few days in advance. For more about dynamical systems and chaos, see dynamics [IV.14](/part-04/dynamics). III.21 Elliptic Curves Jordan S.
Ellenberg An elliptic curve over a field algebraic curve of genus 1 over KK, endowed with a pointcan be defined as an defined over tastes, then an equivalent definition is the following: an K. If this definition is too abstract for your elliptic curve is a curve in the plane determined by anequation of the form y2 + a1 xy + a3 y = x3 + a2 x2 + a4 x + a6. (1) When the characteristic ofform this equation into the simpler form K is not 2, we can trans - y2 = f (x), for some cubic polynomial tic curve is a rather concrete object. However, this def-f .
In this sense, an ellip- inition has given rise to a subject of seemingly inexhaustible mathematical interest, which has provided atremendous fund of ideas, examples, and problems in number theory and algebraic geometry. This is in part because there are many values of “$X$” for which it is the case that “the simplest interesting example of X is an elliptic curve.”For instance, the points of an elliptic curve E with coordinates inwhich we call E(K)K naturally form an Abelian group,.
The connected projective vari- eties [III.95](/part-03/varieties) that admit a group law of this kind are calledthe Abelian varieties that are one dimensional. The Abelian varieties; and elliptic curves are just Mordell–Weil theorem tells us that, whenfield and A is an Abelian variety, A(K)Kis actually ais a number finitely generated group; these Abelian groups are much studied but Abelian group, called a Mordell–Weil have retained much of their mystery (see rational points on curves and the mordell conjecture[V.29](/part-05/rational-points-on-curves-and-vi40-ernst-eduard-kummer-18101893)).
Even when A is an elliptic curve, in which case we would call itdo not know, though E instead, there is a great deal that wethe birch–swinnerton-dyer conjecture [V.4](/part-05/the-birchswinnerton-dyer-conjecture) offers a conjectural formula for the

III.22. The Euclidean Algorithm and Continued Fractions rank of the groupof rational points on elliptic curves, see E(K). For much more on the topic arithmetic geometry [IV.5](/part-04/arithmetic-geometry). pthat Sinceone can look at the subgroup of elementsp P E(K)= 0. This subgroup is called forms an Abelian group, given any prime E(K)[p]. In par-P such ticular, we can take the algebraic closur. ar{e}look at E(K)[p] ̄ .
It turns out that, when KK is aof K and ber field ac ter i st ic not equal to[III.63](/part-03/number-fields) (or, for that matter, any field of char-p), this group is isomorphic tonum-(Z/p Z)2, no matter what choice of E we started with. If the group is the same for all elliptic curves, why is it interesting? Because it turns out that the galois group [V.21](/part - 05/the - insolubility - of - the - quintic) Galaction of Gal$(K/K)$(K/K) ̄ permutes the seton the group$(E(Z/p K)[p] Z$)2 gives rise to.
In fact, the aa foundational example in the theory of representation [III.77](/part - 03/\text{representations}) of the Galois group. This is Galois representations, which has become central to contemporary number theory. Indeed, the proof oftheorem [V.10](/part - 05/fermats - last - theorem) by Andrew Wiles is in the end a the - fermat’s last orem about the Galois representations that arise from elliptic curves.
And what Wiles proved about these special Galois representations is itself a small special case of the family of conjectures known as the program, which proposes a thoroughgoing correspon-Langlands dence between Galois representations andforms, which are generalized versions of the classical automorphic analytic functions called modular forms [III.59](/part - 03/modular - forms). Cates, which we denote, then the set of points of In another direction, if E(CE), is a Eis an elliptic curve overwith complex coordin-complex manifold [III.88 §3](/part - 03/symplectic - manifolds).
It turns out that this manifold can always beexpressed as the quotient of the complex plane by a certain group transformations are just translations: each map sendsΛ of transformations. What is more, thesezsion ofto z + E(c Cfor some complex number) as a quotient is carried out with the helpc. (This expres- of elliptic functions [V.31](/part - 05/the - riemannroch - theorem).) Each elliptic curve gives rise in this way to a subset—indeed, a subgroup—ofthe complex numbers; the elements of this subgroup are called tion can be regarded as the very beginning ofperiods of the elliptic curve.
This construc-Hodge theory, a powerful branch of algebraic geometry with a reputation for extreme difficulty. (Theture, a central question in the theory, is one of the Clay Hodge conjec Institute’s million-dollar-prize problems.)Yet another point of view is presented by the moduli space itself a curve, but not an elliptic one. (In fact, if I am[IV.8](/part-04/moduli-spaces) of elliptic curves, denoted M1\\\{}},\\\\\\\\\\\\\\\\\\\}1. This is completely honest, I should say that$M1\\{}$,\\\\\\\\\\\\\\\\\\}1 is not quite a}}

191

curve at all—it is an object called, depending on whomyou ask, an orbifold [IV.4 §7](/part-04/algebra) or an algebraic stack— you can think of it as a curve from which someone has removed a few points, folded the points in half or into thirds, and then glued the folded-up points back in. You might find it reassuring to know that even pro-fessionals in the subject find this process rather difficult to visualize.) The curveple” in two ways: it is the simplest M1\\\{}},\\\\\\\\\\\\\\\\\\\\}1}}is a “simplest exam-modular curve, and simultaneously the simplest moduli space of curves.
III.22 The Euclidean Algorithm and

Continued Fractions

Keith Ball

1 The Euclidean Algorithm

the fundamental theorem of arithmetic [V.14](/part-05/the-fundamental-theorem-of-arithmetic),

which states that every integer can be factored into primes in a unique way, has been known since antiquity. The usual proof depends upon what is known as the Euclidean algorithm, which constructs the highest common factor (h, say) of two numbers m and n. In doing so, it shows thatam+ bn for some pair of integersh can be written in the forma, b (not necessarily positive). For example, the highest common factor of 17 and 7 is 1, and sure enough we can express 1 as the combination 1= 5 . imes 17 - 12 . imes 7. The algorithm works as follows.
Assume thatm is larger than quotientq nand a nonnegative remainder and start by dividing m byr nthat is lessto yield a than$n$. Then we hav(e1)1 m = q1 n + r1. (1)

Now since second quotient and remainder: r1 < n we may divide n by r1 to obtain an = q2 r1 + r2. (2)

Continue in this way, dividingon. The remainders get smaller each time but cannot$r^{1} by r^{2}$, r2 by r3, and so go below zero. So the process must stop at some pointwith a remainder of 0: that is, with a division that comes out exactly. For instance, if$m = 165 and n = 70$, the algorithm generates the sequence of divisions 165$= 2 \times 70 + 25$, (3) 70$= 2 \times 25 + 20$, (4) 25$= 1 \times 20 + 5$, (5)$20$= 4 . imes 5 + 0. (6)

192

The process guarantees that the last nonzero remain-der, 5 in this case, is the highest common factor of$m$ andn. On the one hand, the last line shows that 5 is a factor of the previous remainder 20. Now the last-but-one line shows that 5 is also a factor of the remainder 25 that occurred one step earlier, because 25 isexpressed as a combination of 20 and 5. Working back up the algorithm we conclude that 5 is a factor of bothm = 165 and n = 70. So 5 is certainly a common factor of On the other hand, the last-but-one line shows thatm and n.
5 can be written as a combination of 25 and 20 with integer coefficients. Since the previous line shows that 20 can be written as a combination of 70 and 25 we canwrite 5 in terms of 70 and 25: 5$= 25 - 20 = 25 - (70 - 2 \times 25) = 3 \times 25 - 70$. Continuing back up the algorithm we can express 25 in terms of 165 and 70 and conclude that 5$= 3 \times (165 - 2 \times 70) - 70 = 3 \times 165 - 7 \times 70$. of 165 and 70 because any factor of 165 and 70 would automatically be a factor of 3 This shows that 5 is the. imes highest165 - 7 common factor. imes70: that is, a factor of 5.
Along the way we have shown that the high-est common factor can be expressed as a combination of the two original numbersm and n. 2 Continued Fractions for Numbers During the 1500 years following Euclid, it was realizedby mathematicians of the Indian and Arabic schools that the application of the Euclidean algorithm to a pairof integersm and n could be encoded in a formula for the ratiom/n. The equation (1) can be writtenmn = q1 + rn1 = q1 + F1 ,

where$F = n/r^{1}$. Now equation (2) expressesr2 F as F = q2 + r1.

The next step of the algorithm will produce an expres-sion forr /r and so on. If the algorithm stops afterk steps, then we can put these expressions together t(o1)2 get what is called the continued fraction for$m/n$:

$m = q1 + 11$.n q2 +q 3^+ . .

.$+q 1 k$

For example,

16570$= 2 + 2 + 11$.$1$+1

III. Mathematical Concepts

from the ratio 165 ence to the integers 165 and 70. We start by subtract-The continued fraction can be constructed directly/70 = 2.35714 . . . without refer-ing from 2.35714 . . .the largest whole number we can: namely 2. Now we take the reciprocal of what is left:1$/0$.35714 . . . = 2.$8$. Again we subtract off the largest integer we can, 2, which tells us thatrocal of 0$.8 is 1$.25, so q =1 and then, finally, 1$q2 = 2$.
The recip-/0.25 =$4$, so The mathematician John Wallis, who worked in theq4 = 4 and the continued fraction stops.3 seventeenth century, seems to have been the first to give a systematic account of continued fractions andto recognize that continued-fraction expansions exist for all numbers (not only rational numbers), provided that we allow the continued fraction to have infinitely many levels. If we start with any positive number, wecan build its continued fraction in the same way as for the ratio 2 isπ = 3.14159265.35714. . .. . ., we start by subtracting 3, then.
For example, if the number take the reciprocal of what is left: 1$/0$.14159 . . . =7 is 7. Continuing the process we build the continued.06251 . . . . So for π we get that the second quotient fractionπ = 3 + 7 +15+ (11)1. (7)

1+ {}29(2+1()1()+1)^{}.}..

The numbers 3, 7, 15, and so on, that appear in the fraction are called the The continued fraction for a real number can be used partial quotients ofπ. to approximate it by rational numbers. If we truncate the continued fraction after several steps, we are left with a finite continued fraction which is a rational num-ber: for example, by truncating the fraction (7), one level down we get the familiar approximation3$+ 1/7 = 22/$7; at the second level we get the approx-$π \approx$ imation 3$+ 1/(7 + 1/15) = 333/106$.
The truncations at different levels thus generate a sequence of rational approximations: the sequence forπ begins$3$, 22/7, 333/106, 355/113, . . . . Whatever positive real number sequence of continued-fraction approximations willx we start with, the approach Indeed, the formal interpretation of the equation (7) isx as we move further down the fraction. precisely that the successive truncations of the fraction approachπ. Naturally, in order to get better approximations to a number fractions—fractions with larger numerator and denom-$x$we need to take more “complicated” inator.
The continued-fraction approximations tox are